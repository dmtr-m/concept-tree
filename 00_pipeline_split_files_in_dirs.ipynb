{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения анафоры разобъем файлы на директории, содержащие файлы по k предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_sentences(text):\n",
    "    \"\"\"\n",
    "    Разбивает текст на предложения.\n",
    "    :param text: Исходный текст.\n",
    "    :return: Список предложений.\n",
    "    \"\"\"\n",
    "    return sent_tokenize(text)\n",
    "\n",
    "def group_sentences(sentences, group_size=10):\n",
    "    \"\"\"\n",
    "    Группирует предложения по заданному размеру.\n",
    "    :param sentences: Список предложений.\n",
    "    :param group_size: Размер группы (по умолчанию 10).\n",
    "    :return: Список групп предложений.\n",
    "    \"\"\"\n",
    "    return [sentences[i:i + group_size] for i in range(0, len(sentences), group_size)]\n",
    "\n",
    "def process_file(file, input_directory, output_directory, group_size):\n",
    "    \"\"\"\n",
    "    Обрабатывает один файл: разбивает его на части и сохраняет в выходную директорию.\n",
    "    :param file: Путь к входному файлу.\n",
    "    :param input_directory: Директория с входными файлами.\n",
    "    :param output_directory: Директория для выходных файлов.\n",
    "    :param group_size: Количество предложений в каждой части.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Читаем текст из входного файла\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        # Разбиваем текст на предложения\n",
    "        sentences = split_text_into_sentences(text)\n",
    "\n",
    "        # Группируем предложения по group_size\n",
    "        groups = group_sentences(sentences, group_size)\n",
    "\n",
    "        # Вычисляем относительный путь файла относительно input_directory\n",
    "        relative_path = file.relative_to(input_directory)\n",
    "\n",
    "        # Создаем путь к выходной директории, сохраняя структуру поддиректорий\n",
    "        output_subdir = output_directory / relative_path.parent / file.stem\n",
    "        os.makedirs(output_subdir, exist_ok=True)\n",
    "\n",
    "        # Сохраняем каждую группу в отдельный файл\n",
    "        for i, group in enumerate(groups):\n",
    "            output_path = output_subdir / f\"part_{i + 1}.txt\"\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(\" \".join(group))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "def split_files(input_directory, output_directory, group_size=10, max_workers=8):\n",
    "    \"\"\"\n",
    "    Разбивает файлы на части по group_size предложений и сохраняет в директории.\n",
    "    Использует многопоточность для ускорения.\n",
    "    :param input_directory: Директория с входными файлами.\n",
    "    :param output_directory: Директория для выходных файлов.\n",
    "    :param group_size: Количество предложений в каждой части.\n",
    "    :param max_workers: Максимальное количество потоков.\n",
    "    \"\"\"\n",
    "    # Получаем список всех txt файлов рекурсивно (включая поддиректории)\n",
    "    input_files = list(input_directory.rglob(\"*.txt\"))\n",
    "\n",
    "    # Используем ThreadPoolExecutor для многопоточной обработки\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for file in input_files:\n",
    "            futures.append(executor.submit(\n",
    "                process_file, file, input_directory, output_directory, group_size\n",
    "            ))\n",
    "\n",
    "        # Отслеживаем прогресс выполнения задач\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing files\"):\n",
    "            try:\n",
    "                future.result()  # Проверяем результат выполнения задачи\n",
    "            except Exception as e:\n",
    "                print(f\"Error during processing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_directory = Path(\"/home/simon/Desktop/concept-tree/concept-tree/nn_graph_makers/test_files\")\n",
    "# output_directory = Path(\"/home/simon/Desktop/concept-tree/concept-tree/nn_graph_makers/test_files_output\")\n",
    "\n",
    "input_directory = Path(\"/home/kdemyokhin_1/concept-tree-course-work/articles_parsed/arxiv-txt-cs\")\n",
    "output_directory = Path(\"/home/kdemyokhin_1/concept-tree-course-work/articles_parsed_splitted/arxiv-txt-cs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 100/100 [00:00<00:00, 1923.79it/s]\n"
     ]
    }
   ],
   "source": [
    "split_files(input_directory, output_directory, group_size=8, max_workers=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-concept-graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
