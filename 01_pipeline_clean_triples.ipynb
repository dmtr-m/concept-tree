{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Очищаем триплеты от мусора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация лемматизатора\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Настройка логирования\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "# Регулярное выражение для проверки допустимых символов (английские буквы, цифры, дефис, +-=_%)\n",
    "allowed_pattern = re.compile(r\"^[a-zA-Z0-9\\-\\+\\=\\%\\_]+$\")\n",
    "\n",
    "# Функция для проверки строки на наличие недопустимых символов\n",
    "def contains_invalid_chars(text):\n",
    "    return not bool(allowed_pattern.match(text))\n",
    "\n",
    "# Функция для лемматизации текста\n",
    "def lemmatize_text(text):\n",
    "    # Удаляем стоп-слова и лемматизируем каждое слово\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(lemmatized_words)\n",
    "\n",
    "# Функция для обработки одной строки датафрейма\n",
    "def process_row(row, invalid_count):\n",
    "    processed_row = []\n",
    "    for item in row:\n",
    "        if contains_invalid_chars(item):\n",
    "            invalid_count += 1\n",
    "            processed_row.append(\"\")  # Заменяем недопустимую строку на пустую\n",
    "        else:\n",
    "            processed_row.append(lemmatize_text(item))\n",
    "    return processed_row, invalid_count\n",
    "\n",
    "# Функция для обработки одного файла\n",
    "def process_file(input_file_path, output_file_path):\n",
    "    invalid_count = 0\n",
    "    try:\n",
    "        # Чтение файла как CSV с разделителем \";\"\n",
    "        df = pd.read_csv(input_file_path, sep=\";\", header=None)\n",
    "        \n",
    "        # Обработка каждой строки\n",
    "        processed_data = []\n",
    "        for _, row in df.iterrows():\n",
    "            processed_row, invalid_count = process_row(row, invalid_count)\n",
    "            processed_data.append(processed_row)\n",
    "        \n",
    "        # Создание нового датафрейма из обработанных данных\n",
    "        processed_df = pd.DataFrame(processed_data)\n",
    "        \n",
    "        # Сохранение обработанного файла\n",
    "        processed_df.to_csv(output_file_path, sep=\";\", index=False, header=False)\n",
    "        \n",
    "        return len(df), invalid_count, None  # Возвращаем None, если ошибок нет\n",
    "    except Exception as e:\n",
    "        error_message = f\"Ошибка при обработке файла {input_file_path}: {e}\"\n",
    "        logging.error(error_message)\n",
    "        return 0, invalid_count, input_file_path  # Возвращаем путь к файлу с ошибкой\n",
    "\n",
    "# Основная функция для обработки всех файлов в директории\n",
    "def process_directory(input_directory_path, output_directory_path):\n",
    "    input_directory = Path(input_directory_path)\n",
    "    output_directory = Path(output_directory_path)\n",
    "    \n",
    "    # Создаем выходную директорию, если она не существует\n",
    "    output_directory.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    total_files = sum(1 for _ in input_directory.rglob(\"*.txt\"))  # Подсчет всех txt файлов\n",
    "    total_rows_processed = 0\n",
    "    total_invalid_rows = 0\n",
    "    error_files = []  # Список для хранения путей файлов с ошибками\n",
    "    \n",
    "    # Итерация по всем файлам в директории с прогресс-баром\n",
    "    with tqdm(total=total_files, desc=\"Обработка файлов\") as pbar:\n",
    "        for input_file_path in input_directory.rglob(\"*.txt\"):\n",
    "            # Генерация пути для выходного файла\n",
    "            relative_path = input_file_path.relative_to(input_directory)\n",
    "            output_file_path = output_directory / relative_path\n",
    "            output_file_path.parent.mkdir(parents=True, exist_ok=True)  # Создаем поддиректории\n",
    "            \n",
    "            rows_processed, invalid_rows, error_file = process_file(input_file_path, output_file_path)\n",
    "            total_rows_processed += rows_processed\n",
    "            total_invalid_rows += invalid_rows\n",
    "            if error_file:\n",
    "                error_files.append(error_file)  # Добавляем путь файла с ошибкой\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix({\n",
    "                \"Обработано строк\": total_rows_processed,\n",
    "                \"Удалено строк\": total_invalid_rows\n",
    "            })\n",
    "    \n",
    "    # Логирование файлов с ошибками\n",
    "    if error_files:\n",
    "        logging.warning(f\"Обработка завершена, но возникли ошибки в следующих файлах:\")\n",
    "        for error_file in error_files:\n",
    "            logging.warning(error_file)\n",
    "    else:\n",
    "        logging.info(\"Обработка завершена без ошибок.\")\n",
    "    \n",
    "    print(f\"Обработка завершена. Всего обработано строк: {total_rows_processed}, удалено строк: {total_invalid_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вызов основной функции\n",
    "input_directory = Path(\"/home/kdemyokhin_1/concept-tree-course-work/articles_triples/arxiv-txt-cs\")\n",
    "output_directory = Path(\"/home/kdemyokhin_1/concept-tree-course-work/articles_triples_cleaned/arxiv-txt-cs\")\n",
    "process_directory(input_directory, output_directory)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
