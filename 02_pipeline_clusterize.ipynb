{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# input_directory = Path(\"/home/kdemyokhin_1/concept-tree-course-work/articles_triples_cleaned/arxiv-txt-cs\")\n",
    "input_directory = Path(\"/home/simon/Desktop/concept-tree/concept-tree/process_graph/articles_triples_cleaned/arxiv-txt-cs\")\n",
    "\n",
    "# Получаем список всех txt файлов рекурсивно (включая поддиректории)\n",
    "input_files = list(input_directory.rglob(\"*.txt\"))\n",
    "\n",
    "# PICKLED_GRAPHS = \"/home/kdemyokhin_1/concept-tree-course-work/pickled_graphs/\"\n",
    "PICKLED_GRAPHS = \"/home/simon/Desktop/concept-tree/concept-tree/process_graph/pickled_graphs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from directed_graph.graph import Graph\n",
    "\n",
    "graph = Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение графа из триплетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "added_edges = set()\n",
    "\n",
    "for path in random.sample(input_files, 2):\n",
    "    with open(path, newline='') as csvfile:\n",
    "        triplets_reader = csv.reader(csvfile, delimiter=\";\")\n",
    "        for triplet in triplets_reader:\n",
    "            agent_1, action, agent_2 = triplet\n",
    "            edge = (\n",
    "                agent_1,\n",
    "                agent_2,\n",
    "                action,\n",
    "            )\n",
    "            if len(agent_1) == 0 or len(agent_2) == 0 or len(action) == 0:\n",
    "                continue\n",
    "\n",
    "            if edge not in added_edges:\n",
    "                added_edges.add(edge)\n",
    "                if edge[0] not in graph.vertices:\n",
    "                    graph.add_vertex(edge[0])\n",
    "                if edge[1] not in graph.vertices:\n",
    "                    graph.add_vertex(edge[1])\n",
    "                graph.add_edge(*edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохранение дампа графа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from directed_graph.graph import save_graph\n",
    "\n",
    "save_graph(graph, PICKLED_GRAPHS+\"raw_graph.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подгружаем построенный сырой граф:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from directed_graph.graph import load_graph\n",
    "\n",
    "graph = load_graph(PICKLED_GRAPHS+\"raw_graph.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Edge(sophisticated algorithm <--[make]--> rapid trading decision),\n",
       " Edge(sophisticated algorithm <--[make on]--> large volume),\n",
       " Edge(these decision <--[hinge on]--> predictive model),\n",
       " Edge(scarcity <--[skews of]--> these event),\n",
       " Edge(scarcity <--[skews]--> distribution),\n",
       " Edge(scarcity <--[skews of]--> label),\n",
       " Edge(this imbalance <--[complicates]--> model training),\n",
       " Edge(standard machine learning algorithm <--[become towards]--> more frequent label),\n",
       " Edge(scarce occurrence <--[make of]--> rare event),\n",
       " Edge(imbalanced data <--[refers to]--> dataset),\n",
       " Edge(one or more class <--[have]--> significantly greater number),\n",
       " Edge(one or more class <--[have of]--> example),\n",
       " Edge(classification <--[pose of]--> imbalanced data),\n",
       " Edge(classification <--[pose]--> significant challenge),\n",
       " Edge(classification <--[pose to]--> traditional classification model),\n",
       " Edge(set <--[produce]--> suboptimal classification model),\n",
       " Edge(set <--[produce to]--> good coverage),\n",
       " Edge(set <--[produce to]--> frequent misclassification),\n",
       " Edge(algorithm <--[deliver]--> best performance),\n",
       " Edge(algorithm <--[deliver for]--> imbalanced datasets),\n",
       " Edge(use <--[bias of]--> global performance measure),\n",
       " Edge(use <--[bias]--> result),\n",
       " Edge(use <--[bias towards]--> majority class),\n",
       " Edge(this <--[lead to]--> exclusion),\n",
       " Edge(machine learning community <--[shown]--> significant interest),\n",
       " Edge(these approach <--[rely on]--> preprocessing technique),\n",
       " Edge(these approach <--[rely on]--> cost sensitive learning),\n",
       " Edge(we <--[delve into]--> detail),\n",
       " Edge(these <--[mitigate]--> adverse effect),\n",
       " Edge(these <--[mitigate of]--> skewed distribution),\n",
       " Edge(two widely used method <--[duplicating]--> minority sample),\n",
       " Edge(these <--[address]--> issue),\n",
       " Edge(these <--[address]--> decay),\n",
       " Edge(these <--[address from]--> skewed distribution),\n",
       " Edge(these technique <--[combine]--> over sampling and under sampling method),\n",
       " Edge(two widely used method <--[duplicating]--> under sampling method),\n",
       " Edge(these technique <--[combine in]--> study),\n",
       " Edge(under sampling method <--[outperformed]--> over sampling method),\n",
       " Edge(under sampling method <--[outperformed in]--> term),\n",
       " Edge(smote <--[exhibit]--> slightly higher efficacy),\n",
       " Edge(under sampling <--[exhibit]--> slightly higher efficacy),\n",
       " Edge(this subset <--[enable]--> classifier),\n",
       " Edge(which <--[corresponds to]--> dimensionality reduction),\n",
       " Edge(feature selection <--[return]--> subset),\n",
       " Edge(extraction <--[return]--> subset),\n",
       " Edge(feature selection <--[return of]--> original feature),\n",
       " Edge(extraction <--[return of]--> original feature),\n",
       " Edge(feature extraction <--[generates]--> new feature),\n",
       " Edge(feature extraction <--[generates from]--> original one),\n",
       " Edge(cost sensitive learning <--[considers]--> varying cost),\n",
       " Edge(ensemble method <--[considers]--> varying cost),\n",
       " Edge(domain expert <--[determine]--> cost matrix),\n",
       " Edge(domain expert <--[determine in]--> fixed cost matrix),\n",
       " Edge(these matrix <--[vary at]--> each optimisation loop step),\n",
       " Edge(our primary interest <--[lie in]--> minority class),\n",
       " Edge(we <--[defined]--> which),\n",
       " Edge(we <--[defined a]--> positive class),\n",
       " Edge(cost sensitive learning <--[concern]--> incorporation),\n",
       " Edge(ensemble method <--[concern]--> incorporation),\n",
       " Edge(cost sensitive learning <--[concern of]--> preprocessing mechanism),\n",
       " Edge(cost sensitive learning <--[concern of]--> postprocessing),\n",
       " Edge(ensemble method <--[concern of]--> preprocessing mechanism),\n",
       " Edge(ensemble method <--[concern of]--> postprocessing),\n",
       " Edge(thresholding <--[operates on]--> principle),\n",
       " Edge(sampling <--[operates on]--> principle),\n",
       " Edge(typical decision tree <--[assigns]--> class label),\n",
       " Edge(typical decision tree <--[assigns of]--> leaf node),\n",
       " Edge(cost sensitive algorithm <--[designates]--> class label),\n",
       " Edge(cost sensitive algorithm <--[designates to]--> node),\n",
       " Edge(method <--[concluded in]--> comparison),\n",
       " Edge(which <--[requires]--> modification),\n",
       " Edge(which <--[requires of]--> learning algorithm),\n",
       " Edge(ensemble <--[emerged of]--> classifier),\n",
       " Edge(ensemble based method <--[involve]--> blend),\n",
       " Edge(ensemble based method <--[involve of]--> ensemble learning algorithm),\n",
       " Edge(new hybrid method <--[preprocesses]--> data),\n",
       " Edge(new hybrid method <--[preprocesses]--> resource),\n",
       " Edge(cost sensitive ensemble <--[guide]--> cost minimisation procedure),\n",
       " Edge(cost sensitive ensemble <--[guide through]--> ensemble learning algorithm),\n",
       " Edge(author <--[categorise]--> four distinct family),\n",
       " Edge(author <--[categorise among]--> ensemble approach),\n",
       " Edge(family <--[identify]--> cost sensitive boosting approach),\n",
       " Edge(cost minimisation procedure <--[guided by]--> boosting algorithm),\n",
       " Edge(family <--[distinguish]--> three more family),\n",
       " Edge(all <--[embed]--> data preprocessing technique),\n",
       " Edge(all <--[embed in]--> ensemble learning algorithm),\n",
       " Edge(algorithm <--[surpass]--> performance),\n",
       " Edge(feature vector <--[include]--> various indicator),\n",
       " Edge(feature vector <--[include a]--> price change),\n",
       " Edge(each instance <--[ha]--> corresponding label),\n",
       " Edge(price <--[go in]--> next time interval),\n",
       " Edge(volume <--[go in]--> next time interval),\n",
       " Edge(we <--[consider]--> three class classification problem),\n",
       " Edge(we <--[consider in]--> horizon),\n",
       " Edge(which <--[result in]--> case),\n",
       " Edge(our method <--[consists of]--> three main phase),\n",
       " Edge(we <--[represent]--> data feature),\n",
       " Edge(we <--[represent a]--> 13 dimensional vector),\n",
       " Edge(we <--[identified]--> significant label imbalance issue),\n",
       " Edge(we <--[identified in]--> dataset),\n",
       " Edge(approximately 80 % <--[belonging of]--> sample),\n",
       " Edge(we <--[implemented]--> strategy),\n",
       " Edge(we <--[split]--> dataset),\n",
       " Edge(we <--[split through]--> random sampling),\n",
       " Edge(we <--[offer]--> optional normalization operation),\n",
       " Edge(we <--[offer for]--> each sample),\n",
       " Edge(we <--[offer]--> [[[formula]]]),\n",
       " Edge(we <--[observe]--> significant variance),\n",
       " Edge(we <--[observe in]--> our experiment),\n",
       " Edge(variance impact <--[appears across]--> neural network),\n",
       " Edge(variance impact <--[appears across]--> other machine learning model),\n",
       " Edge(variance impact <--[appears across]--> method),\n",
       " Edge(we <--[categorize]--> variance effect),\n",
       " Edge(we <--[categorize in]--> our task),\n",
       " Edge(we <--[utilize]--> training set),\n",
       " Edge(we <--[elaborate on]--> our network architecture),\n",
       " Edge(we <--[elaborate on]--> approach),\n",
       " Edge(we <--[employ]--> standard early stopping mechanism),\n",
       " Edge(we <--[monitor]--> model s accuracy),\n",
       " Edge(we <--[monitor at]--> end),\n",
       " Edge(accuracy <--[improve over]--> several consecutive epoch),\n",
       " Edge(figure reference <--[show]--> mlp),\n",
       " Edge(network <--[create]--> fairly intricate transformation),\n",
       " Edge(network <--[create of]--> formula),\n",
       " Edge(we <--[proceed to]--> output layer),\n",
       " Edge(we <--[set]--> formula),\n",
       " Edge(we <--[set for]--> categorical response),\n",
       " Edge(we <--[apply]--> activation function),\n",
       " Edge(we <--[apply a]--> sigmoid function),\n",
       " Edge(both activation function <--[utilise in]--> hidden layer),\n",
       " Edge(both activation function <--[utilise in]--> output layer),\n",
       " Edge(output layer <--[utilise in]--> hidden layer),\n",
       " Edge(output layer <--[utilise in]--> output layer),\n",
       " Edge(both activation function <--[utilise]--> leakyrelu function),\n",
       " Edge(output layer <--[utilise]--> leakyrelu function),\n",
       " Edge(each vector <--[contains in]--> input sequence),\n",
       " Edge(each vector <--[contains]--> component),\n",
       " Edge(conventional rnns <--[have]--> difficulty),\n",
       " Edge(lstms <--[provide]--> novel architecture),\n",
       " Edge(we <--[see]--> layout),\n",
       " Edge(we <--[see of]--> memory cell),\n",
       " Edge(three main component <--[oversee]--> functioning),\n",
       " Edge(three main component <--[oversee of]--> memory cell),\n",
       " Edge(we <--[denote]--> collection),\n",
       " Edge(we <--[denote of]--> weight),\n",
       " Edge(we <--[denote]--> formula),\n",
       " Edge(we <--[denote a]--> formula),\n",
       " Edge(we <--[express]--> three component),\n",
       " Edge(which <--[capture]--> relationship),\n",
       " Edge(which <--[capture]--> three gate),\n",
       " Edge(which <--[capture between]--> any two position),\n",
       " Edge(mamba <--[gained on]--> structured state space sequence model),\n",
       " Edge(mamba <--[gained]--> widespread attention),\n",
       " Edge(mamba <--[gained a]--> potential replacement),\n",
       " Edge(mamba <--[enhances]--> this process),\n",
       " Edge(mamba <--[enhances through]--> selection mechanism),\n",
       " Edge(formula <--[depend on]--> input),\n",
       " Edge(formula <--[depend on]--> output layer),\n",
       " Edge(mamba <--[employ]--> distinct processing pattern),\n",
       " Edge(mamba <--[employ for]--> hidden state),\n",
       " Edge(which <--[incorporates]--> historical information),\n",
       " Edge(which <--[incorporates to]--> transformer),\n",
       " Edge(mamba <--[offer]--> faster inference speed),\n",
       " Edge(poor performance <--[arises of]--> model),\n",
       " Edge(model <--[focus on]--> class),\n",
       " Edge(our initial approach <--[involves]--> implementation),\n",
       " Edge(our initial approach <--[involves of]--> under sampling technique),\n",
       " Edge(we <--[drop]--> formula),\n",
       " Edge(we <--[drop of]--> sample),\n",
       " Edge(cost sensitive learning <--[aim at]--> algorithmic level),\n",
       " Edge(ensemble method <--[aim at]--> algorithmic level),\n",
       " Edge(we <--[employed]--> straightforward method),\n",
       " Edge(we <--[designated]--> weight),\n",
       " Edge(we <--[designated for]--> class),\n",
       " Edge(this method <--[serf]--> similar process),\n",
       " Edge(this method <--[serf to]--> resampling),\n",
       " Edge(we <--[adjusted]--> weight),\n",
       " Edge(we <--[adjusted on]--> specific size),\n",
       " Edge(we <--[incorporated]--> cost),\n",
       " Edge(we <--[incorporated into]--> mean square error),\n",
       " Edge(method <--[incorporates]--> dynamic cost matrix),\n",
       " Edge(method <--[incorporates for]--> each sample),\n",
       " Edge(focal loss <--[assigns]--> greater weight),\n",
       " Edge(focal loss <--[assigns to]--> sample),\n",
       " Edge(model <--[ha]--> formula),\n",
       " Edge(model <--[ha in]--> correct class),\n",
       " Edge(model <--[exhibit]--> lower confidence),\n",
       " Edge(model <--[exhibit for]--> class),\n",
       " Edge(dynamic nature <--[ensures of]--> cost),\n",
       " Edge(cost <--[remain throughout]--> process),\n",
       " Edge(our data <--[span from]--> may 4th),\n",
       " Edge(dataset <--[includes]--> six variety),\n",
       " Edge(each variety <--[ha]--> different trading hour),\n",
       " Edge(each variety <--[ha in]--> varying sample size),\n",
       " Edge(silver <--[have]--> larger sample size),\n",
       " Edge(fuel oil <--[have]--> larger sample size),\n",
       " Edge(gold <--[have]--> larger sample size),\n",
       " Edge(rebar <--[have]--> smaller one),\n",
       " Edge(silver <--[have]--> smaller one),\n",
       " Edge(fuel oil <--[have]--> smaller one),\n",
       " Edge(raw data <--[contains]--> key information),\n",
       " Edge(raw data <--[contains a]--> trading time),\n",
       " Edge(raw data <--[contains a]--> daily price),\n",
       " Edge(which <--[represents]--> 5 position),\n",
       " Edge(which <--[represents on]--> this data),\n",
       " Edge(we <--[constructed]--> 13 variable),\n",
       " Edge(these variable <--[include]--> formula),\n",
       " Edge(we <--[compute]--> rate),\n",
       " Edge(we <--[compute of]--> change),\n",
       " Edge(we <--[filled]--> forward missing value),\n",
       " Edge(we <--[constructed]--> several factor),\n",
       " Edge(significant and unstable difference <--[indicate in]--> effect),\n",
       " Edge(significant and unstable difference <--[indicate]--> need),\n",
       " Edge(we <--[utilized]--> intelr xeonr silver 4210r cpu),\n",
       " Edge(we <--[utilized]--> two nvidia rtx 4090 gpus),\n",
       " Edge(training set <--[consists of]--> only one item),\n",
       " Edge(which <--[contains]--> significant amount),\n",
       " Edge(which <--[contains of]--> noise),\n",
       " Edge(we <--[utilized]--> all six item),\n",
       " Edge(lstm cite and mamaba cite model <--[outperform]--> mlp),\n",
       " Edge(lstm cite and mamaba cite model <--[outperform in]--> most scenario),\n",
       " Edge(time <--[compute in]--> parallel),\n",
       " Edge(further reduction <--[prof of]--> comparison scale),\n",
       " Edge(both resampling <--[performed than]--> benchmark),\n",
       " Edge(focal loss <--[performed than]--> benchmark),\n",
       " Edge(method <--[performed than]--> benchmark),\n",
       " Edge(which <--[employed]--> no specific approach),\n",
       " Edge(which <--[employed for]--> label imbalance problem),\n",
       " Edge(reason <--[require for]--> this),\n",
       " Edge(reason <--[require]--> further investigation),\n",
       " Edge(reason <--[require in]--> this project),\n",
       " Edge(we <--[illustrate]--> efficiency),\n",
       " Edge(financial data <--[contains]--> significant noise),\n",
       " Edge(which <--[complicates]--> training process),\n",
       " Edge(we <--[consider]--> two approach),\n",
       " Edge(which <--[proven in]--> high noise or dynamic data scenario),\n",
       " Edge(we <--[identified]--> some effective feature),\n",
       " Edge(we <--[identified in]--> figure reference),\n",
       " Edge(we <--[used]--> mean),\n",
       " Edge(we <--[used]--> standard deviation),\n",
       " Edge(this oversight <--[led to]--> noticeable improvement),\n",
       " Edge(testing data <--[exhibit]--> significant domain gap),\n",
       " Edge(testing data <--[exhibit from]--> training data),\n",
       " Edge(data domain <--[change over]--> time),\n",
       " Edge(this work <--[ha]--> several limitation),\n",
       " Edge(we <--[developed]--> bert model),\n",
       " Edge(we <--[developed for]--> financial data),\n",
       " Edge(we <--[tested]--> repository performance),\n",
       " Edge(we <--[trained]--> model),\n",
       " Edge(we <--[trained on]--> single item),\n",
       " Edge(we <--[used]--> multiple item),\n",
       " Edge(large volume <--[of]--> financial data),\n",
       " Edge(issue <--[of]--> label imbalance),\n",
       " Edge(decay <--[of]--> label imbalance),\n",
       " Edge(rare event <--[like]--> sudden market crash),\n",
       " Edge(scarcity <--[of]--> these event),\n",
       " Edge(scarcity <--[in]--> historical data),\n",
       " Edge(distribution <--[of]--> label),\n",
       " Edge(higher risk <--[of]--> substantial financial loss),\n",
       " Edge(robustness <--[of]--> predictive model),\n",
       " Edge(reliability <--[of]--> predictive model),\n",
       " Edge(robustness <--[in]--> high frequency trading),\n",
       " Edge(reliability <--[in]--> high frequency trading),\n",
       " Edge(field <--[of]--> data mining),\n",
       " Edge(return <--[in]--> high frequency trading),\n",
       " Edge(scarce occurrence <--[of]--> rare event),\n",
       " Edge(significantly greater number <--[of]--> example),\n",
       " Edge(example <--[than]--> others),\n",
       " Edge(concept <--[of]--> interest),\n",
       " Edge(classification <--[of]--> imbalanced data),\n",
       " Edge(significant challenge <--[to]--> traditional classification model),\n",
       " Edge(most standard classification algorithm <--[a]--> logistic regression),\n",
       " Edge(good coverage <--[of]--> majority example),\n",
       " Edge(frequent misclassification <--[of]--> majority example),\n",
       " Edge(frequent misclassification <--[of]--> minority one),\n",
       " Edge(several reason <--[for]--> this behaviour),\n",
       " Edge(use <--[of]--> global performance measure),\n",
       " Edge(global performance measure <--[like]--> standard accuracy rate),\n",
       " Edge(exclusion <--[of]--> class),\n",
       " Edge(exclusion <--[in]--> favour),\n",
       " Edge(favour <--[of]--> more general rule),\n",
       " Edge(very small cluster <--[of]--> minority class example),\n",
       " Edge(rare pattern <--[in]--> sample space),\n",
       " Edge(detail <--[of]--> these three method),\n",
       " Edge(quality <--[of]--> input data),\n",
       " Edge(impact <--[of]--> skewed class distribution),\n",
       " Edge(adverse effect <--[of]--> skewed distribution),\n",
       " Edge(sample <--[from]--> majority class),\n",
       " Edge(effectiveness <--[of]--> various re sampling method),\n",
       " Edge(important insight <--[regarding]--> selection),\n",
       " Edge(selection <--[of]--> re sampling method),\n",
       " Edge(hundred <--[of]--> minority observation),\n",
       " Edge(term <--[of]--> computational time),\n",
       " Edge(aim <--[of]--> feature selection),\n",
       " Edge(subset <--[of]--> k feature),\n",
       " Edge(subset <--[of]--> original feature),\n",
       " Edge(various technique <--[for]--> feature extraction),\n",
       " Edge(various technique <--[a]--> principal component analysis),\n",
       " Edge(unstructured data <--[like]--> image),\n",
       " Edge(variety <--[of]--> metric),\n",
       " Edge(common choice <--[for]--> wrapper method),\n",
       " Edge(frequent use <--[of]--> feature selection),\n",
       " Edge(real world problem <--[a]--> disease diagnosis),\n",
       " Edge(class <--[a]--> class),\n",
       " Edge(fixed cost matrix <--[with]--> binary class),\n",
       " Edge(reason <--[for]--> higher cost),\n",
       " Edge(sample <--[from]--> minority class),\n",
       " Edge(both data level <--[a]--> sampling),\n",
       " Edge(algorithmic level <--[a]--> sampling),\n",
       " Edge(incorporation <--[of]--> preprocessing mechanism),\n",
       " Edge(preprocessing mechanism <--[for]--> training data),\n",
       " Edge(postprocessing <--[for]--> training data),\n",
       " Edge(postprocessing <--[of]--> output),\n",
       " Edge(postprocessing <--[in]--> manner),\n",
       " Edge(principle <--[of]--> basic decision theory),\n",
       " Edge(class <--[with]--> lowest expected cost),\n",
       " Edge(class label <--[of]--> leaf node),\n",
       " Edge(majority class <--[of]--> training sample),\n",
       " Edge(original class distribution <--[of]--> training dataset),\n",
       " Edge(comprehensive overview <--[of]--> cost sensitive learning method),\n",
       " Edge(comparison <--[to]--> resampling method),\n",
       " Edge(modification <--[of]--> learning algorithm),\n",
       " Edge(performance <--[of]--> single classifier),\n",
       " Edge(ensemble <--[of]--> classifier),\n",
       " Edge(blend <--[of]--> ensemble learning algorithm),\n",
       " Edge(comprehensive taxonomy <--[for]--> ensemble method),\n",
       " Edge(ensemble approach <--[for]--> imbalanced learning),\n",
       " Edge(state <--[of]--> market),\n",
       " Edge(state <--[at]--> time),\n",
       " Edge(various indicator <--[a]--> price change),\n",
       " Edge(number <--[of]--> possible outcome),\n",
       " Edge(three class classification problem <--[in]--> horizon),\n",
       " Edge(forward 1 minute return <--[for]--> instance),\n",
       " Edge(model <--[a]--> logistic regression),\n",
       " Edge(short horizon <--[a]--> 1 min),\n",
       " Edge(value <--[of]--> 0),\n",
       " Edge(three main phase <--[during]--> training),\n",
       " Edge(detail <--[regarding]--> data structure),\n",
       " Edge(data structure <--[of]--> our dataset),\n",
       " Edge(data processing method <--[of]--> our dataset),\n",
       " Edge(13 dimensional vector <--[for]--> each second),\n",
       " Edge(preceding 60 second <--[of]--> data),\n",
       " Edge(significant label imbalance issue <--[in]--> dataset),\n",
       " Edge(approximately 80 % <--[of]--> sample),\n",
       " Edge(optional normalization operation <--[for]--> each sample),\n",
       " Edge([[[formula dimension]]] <--[of]--> [[[formula position]]]),\n",
       " Edge([[[formula position]]] <--[in]--> sample),\n",
       " Edge(end <--[of]--> each epoch),\n",
       " Edge(type <--[of]--> neural network),\n",
       " Edge(multiple layer <--[including]--> input layer),\n",
       " Edge(node <--[in]--> hidden layer),\n",
       " Edge(two hidden layer <--[along]--> input),\n",
       " Edge(activation <--[in]--> layer),\n",
       " Edge(input vector <--[of]--> variable),\n",
       " Edge(function <--[of]--> activation),\n",
       " Edge(activation <--[from]--> previous layer),\n",
       " Edge(function <--[of]--> input vector),\n",
       " Edge(fairly intricate transformation <--[of]--> formula),\n",
       " Edge(activation function <--[a]--> sigmoid function),\n",
       " Edge(both activation function <--[in]--> hidden layer),\n",
       " Edge(output layer <--[in]--> hidden layer),\n",
       " Edge(sequential input data <--[a]--> financial time series data),\n",
       " Edge(each vector <--[in]--> input sequence),\n",
       " Edge(weight <--[for]--> input layer),\n",
       " Edge(weight <--[for]--> hidden to hidden layer),\n",
       " Edge(additional sigmoid function <--[for]--> binary outcome),\n",
       " Edge(each element <--[of]--> sequence),\n",
       " Edge(issue <--[with]--> vanishing gradient),\n",
       " Edge(decay <--[with]--> vanishing gradient),\n",
       " Edge(decay <--[of]--> error flow),\n",
       " Edge(layout <--[of]--> memory cell),\n",
       " Edge(functioning <--[of]--> memory cell),\n",
       " Edge(state <--[of]--> memory cell),\n",
       " Edge(rest <--[of]--> network),\n",
       " Edge(collection <--[of]--> weight),\n",
       " Edge(input vector <--[at]--> sequence),\n",
       " Edge(hidden state <--[at]--> sequence),\n",
       " Edge(relationship <--[between]--> cell s state),\n",
       " Edge(three gate <--[between]--> cell s state),\n",
       " Edge(prominent topic <--[in]--> deep learning),\n",
       " Edge(development <--[of]--> rnn),\n",
       " Edge(significant attention <--[for]--> time series task),\n",
       " Edge(relationship <--[between]--> any two position),\n",
       " Edge(three gate <--[between]--> any two position),\n",
       " Edge(any two position <--[in]--> sequence),\n",
       " Edge(considerable debate <--[regarding]--> debate effectiveness),\n",
       " Edge(potential replacement <--[for]--> transformer),\n",
       " Edge(attention mechanism <--[in]--> transformer),\n",
       " Edge(distinct processing pattern <--[for]--> hidden state),\n",
       " Edge(various sequence level task <--[a]--> audio processing),\n",
       " Edge(poor performance <--[of]--> model),\n",
       " Edge(class <--[with]--> larger number),\n",
       " Edge(larger number <--[of]--> sample),\n",
       " Edge(implementation <--[of]--> under sampling technique),\n",
       " Edge(equilibrium <--[among]--> label),\n",
       " Edge(proportion <--[of]--> class),\n",
       " Edge(sample <--[from]--> class),\n",
       " Edge(cost sensitive learning <--[at]--> algorithmic level),\n",
       " Edge(ensemble method <--[at]--> algorithmic level),\n",
       " Edge(class <--[with]--> fewer sample),\n",
       " Edge(intuition <--[behind]--> resampling method),\n",
       " Edge(loss <--[for]--> sample),\n",
       " Edge(number <--[of]--> class),\n",
       " Edge(loss function <--[for]--> sample),\n",
       " Edge(weight <--[for]--> class),\n",
       " Edge(similar process <--[to]--> resampling),\n",
       " Edge(specific size <--[of]--> each class),\n",
       " Edge(mean square error <--[for]--> each class),\n",
       " Edge(castro and braga s research <--[on]--> imbalanced binary label),\n",
       " Edge(loss function <--[for]--> each sample),\n",
       " Edge(number <--[of]--> sample),\n",
       " Edge(true distribution <--[of]--> label),\n",
       " Edge(dynamic cost matrix <--[for]--> each sample),\n",
       " Edge(vector output <--[of]--> probability),\n",
       " Edge(probability <--[for]--> each class),\n",
       " Edge(confidence <--[for]--> which),\n",
       " Edge(confidence <--[in]--> correct class),\n",
       " Edge(scenario <--[with]--> imbalanced label),\n",
       " Edge(dynamic nature <--[of]--> cost),\n",
       " Edge(dynamic nature <--[during]--> training),\n",
       " Edge(average accuracy <--[of]--> class),\n",
       " Edge(total <--[of]--> 20 trading day),\n",
       " Edge(20 trading day <--[of]--> high frequency future data),\n",
       " Edge(frequency <--[of]--> 05 second),\n",
       " Edge(key information <--[a]--> trading time),\n",
       " Edge(price <--[of]--> buy and sell order),\n",
       " Edge(volume <--[of]--> buy and sell order),\n",
       " Edge(price <--[at]--> first to fifth trading position),\n",
       " Edge(volume <--[at]--> first to fifth trading position),\n",
       " Edge(average <--[of]--> best buy buy one and sell sell one price),\n",
       " Edge(average <--[at]--> each data point),\n",
       " Edge(price difference <--[between]--> each level),\n",
       " Edge(price difference <--[between]--> latest transaction price),\n",
       " Edge(logarithm <--[of]--> transaction volume),\n",
       " Edge(calculation <--[of]--> return),\n",
       " Edge(rate <--[of]--> change),\n",
       " Edge(rate <--[of]--> average),\n",
       " Edge(average <--[at]--> time),\n",
       " Edge(interval <--[of]--> 59 data point),\n",
       " Edge(interval <--[with]--> 05 second),\n",
       " Edge(05 second <--[between]--> each data point),\n",
       " Edge(top 59 return <--[for]--> each transaction segment),\n",
       " Edge(130 pm <--[on]--> current day),\n",
       " Edge(missing value <--[for]--> each trading day),\n",
       " Edge(quality <--[of]--> our data),\n",
       " Edge(accumulated sum <--[of]--> factor),\n",
       " Edge(factor <--[of]--> return),\n",
       " Edge(accumulated sum <--[for]--> 8 different factor),\n",
       " Edge(significant and unstable difference <--[in]--> effect),\n",
       " Edge(effect <--[of]--> factor),\n",
       " Edge(implementation detail <--[of]--> our proposed method),\n",
       " Edge(detail <--[of]--> each neural network),\n",
       " Edge(limited amount <--[of]--> data),\n",
       " Edge(significant amount <--[of]--> noise),\n",
       " Edge(training time <--[for]--> mamaba),\n",
       " Edge(comparison higher number <--[of]--> parameter),\n",
       " Edge(further reduction <--[of]--> comparison scale),\n",
       " Edge(better performance <--[than]--> others),\n",
       " Edge(reason <--[for]--> this),\n",
       " Edge(high frequency trading <--[with]--> label imbalance),\n",
       " Edge(addition <--[to]--> finding),\n",
       " Edge(mean <--[of]--> entire dataset),\n",
       " Edge(standard deviation <--[of]--> entire dataset),\n",
       " Edge(noticeable improvement <--[in]--> model performance),\n",
       " Edge(significant domain gap <--[from]--> training data),\n",
       " Edge(bert model <--[for]--> financial data),\n",
       " Edge(other method <--[a]--> data augmentation),\n",
       " Edge(large foundation model <--[for]--> financial data),\n",
       " Edge(field <--[of]--> finance),\n",
       " Edge(prediction <--[for]--> forward 1 min return),\n",
       " Edge(forward 1 min return <--[in]--> chinese future market),\n",
       " Edge(substantial challenge <--[in]--> high frequency trading nature),\n",
       " Edge(model <--[with]--> stable predictive power),\n",
       " Edge(uq <--[support]--> decision making and risk assessment process),\n",
       " Edge(uq <--[support in]--> engineering system design),\n",
       " Edge(application <--[span of]--> uq),\n",
       " Edge(input uncertainty <--[arise from]--> various source),\n",
       " Edge(this paper <--[focus on]--> uq problem),\n",
       " Edge(non intrusive approach <--[gained]--> popularity),\n",
       " Edge(non intrusive approach <--[gained due]--> approach ease),\n",
       " Edge(most common non intrusive method <--[include]--> method),\n",
       " Edge(most common non intrusive method <--[include]--> polynomial chaos),\n",
       " Edge(most common non intrusive method <--[include of]--> moment),\n",
       " Edge(these method <--[have]--> method strength),\n",
       " Edge(these method <--[have]--> weakness),\n",
       " Edge(choice <--[depends of]--> method),\n",
       " Edge(choice <--[depends of]--> polynomial chaos),\n",
       " Edge(method <--[employ of]--> moment),\n",
       " Edge(polynomial chaos <--[employ of]--> moment),\n",
       " Edge(method <--[employ]--> taylor series approximation),\n",
       " Edge(polynomial chaos <--[employ]--> taylor series approximation),\n",
       " Edge(this method <--[struggle with]--> more complex risk measure),\n",
       " Edge(monte carlo method <--[necessitate]--> significantly larger number),\n",
       " Edge(monte carlo method <--[necessitate of]--> model evaluation),\n",
       " Edge(kriging <--[creates a]--> gaussian process regression),\n",
       " Edge(monte carlo <--[creates a]--> gaussian process regression),\n",
       " Edge(polynomial chaos <--[creates a]--> gaussian process regression),\n",
       " Edge(kriging <--[creates]--> response surface function),\n",
       " Edge(monte carlo <--[creates]--> response surface function),\n",
       " Edge(polynomial chaos <--[creates]--> response surface function),\n",
       " Edge(this trained kriging model <--[serf a]--> surrogate),\n",
       " Edge(polynomial chaos method <--[represents]--> qoi),\n",
       " Edge(polynomial chaos method <--[represents a]--> orthogonal polynomial),\n",
       " Edge(this method <--[exploit]--> smoothness),\n",
       " Edge(this method <--[exploit in]--> random space),\n",
       " Edge(common polynomial chaos based method <--[include]--> non intrusive polynomial chaos),\n",
       " Edge(common polynomial chaos based method <--[include]--> stochastic collocation),\n",
       " Edge(problem <--[encounter]--> challenge),\n",
       " Edge(problem <--[encounter with]--> high dimensional uq),\n",
       " Edge(wang <--[introduced]--> graph accelerated nipc method),\n",
       " Edge(al <--[introduced]--> graph accelerated nipc method),\n",
       " Edge(this approach <--[combine]--> novel computational graph transformation technique),\n",
       " Edge(this approach <--[combine a]--> accelerated model evaluation),\n",
       " Edge(amtc method <--[accelerates]--> tensor grid evaluation),\n",
       " Edge(this approach <--[demonstrated]--> superiority),\n",
       " Edge(this approach <--[demonstrated over]--> existing uq method),\n",
       " Edge(approach <--[suffers from]--> curse),\n",
       " Edge(notable method <--[include]--> sensitivity analysis),\n",
       " Edge(notable method <--[include]--> principal component analysis),\n",
       " Edge(notable method <--[include]--> partial least square),\n",
       " Edge(local sensitivity analysis <--[measure]--> perturbation),\n",
       " Edge(local sensitivity analysis <--[measure of]--> each input),\n",
       " Edge(this method <--[lack]--> accuracy),\n",
       " Edge(this method <--[lack]--> computational cost),\n",
       " Edge(this method <--[lack in]--> many case),\n",
       " Edge(global sensitivity analysis <--[computes]--> sobol index),\n",
       " Edge(which <--[measure]--> output variation),\n",
       " Edge(which <--[measure over]--> full range),\n",
       " Edge(pca <--[conduct]--> eigenvalue decomposition),\n",
       " Edge(pca <--[conduct on]--> covariance matrix),\n",
       " Edge(pls <--[utilizes]--> regression),\n",
       " Edge(pls <--[suffer from]--> overfitting),\n",
       " Edge(a <--[us]--> gradient information),\n",
       " Edge(a <--[strike]--> balance),\n",
       " Edge(a <--[strike between]--> accuracy),\n",
       " Edge(a <--[strike between]--> computational cost),\n",
       " Edge(glaws <--[connected]--> a method),\n",
       " Edge(constantine <--[connected]--> a method),\n",
       " Edge(glaws <--[connected to]--> gaussian quadrature rule),\n",
       " Edge(constantine <--[connected to]--> gaussian quadrature rule),\n",
       " Edge(he <--[linked]--> a method),\n",
       " Edge(al <--[linked]--> a method),\n",
       " Edge(he <--[linked to]--> regression based nipc method),\n",
       " Edge(al <--[linked to]--> regression based nipc method),\n",
       " Edge(which <--[relies on]--> integration based approach),\n",
       " Edge(this paper <--[proposes]--> general framework),\n",
       " Edge(which <--[generates]--> pce basis function),\n",
       " Edge(which <--[generates]--> efficient quadrature rule),\n",
       " Edge(which <--[generates]--> quadrature rule),\n",
       " Edge(which <--[generates]--> corresponding quadrature rule),\n",
       " Edge(which <--[generates for]--> active subspace s uncertain input),\n",
       " Edge(which <--[include]--> 7 dimensional analytical piston model),\n",
       " Edge(which <--[include]--> 81 dimensional air taxi trajectory simulation model),\n",
       " Edge(a amtc <--[improve]--> amtc efficiency),\n",
       " Edge(a amtc <--[improve on]--> second problem),\n",
       " Edge(which <--[involves]--> multidisciplinary system),\n",
       " Edge(sequence reference <--[give]--> some background),\n",
       " Edge(sequence reference <--[give for]--> graph accelerated nipc and a method),\n",
       " Edge(formula <--[denotes]--> deterministic model evaluation function),\n",
       " Edge([[[formula]]] <--[represents]--> input vector),\n",
       " Edge(these two approach <--[show]--> similar performance),\n",
       " Edge(these two approach <--[show on]--> low dimensional uq problem),\n",
       " Edge(integration approach <--[make]--> use),\n",
       " Edge(integration approach <--[make of]--> orthogonality property),\n",
       " Edge(which <--[result into]--> integration problem),\n",
       " Edge(number <--[affect of]--> pce basis function),\n",
       " Edge(number <--[affect of]--> efficient quadrature rule),\n",
       " Edge(number <--[affect of]--> quadrature rule),\n",
       " Edge(number <--[affect of]--> corresponding quadrature rule),\n",
       " Edge(number <--[affect]--> model evaluation cost),\n",
       " Edge(we <--[use]--> same quadrature rule),\n",
       " Edge(node <--[integrate]--> polynomial),\n",
       " Edge(weight <--[integrate]--> polynomial),\n",
       " Edge(node <--[integrate up]--> formula),\n",
       " Edge(weight <--[integrate up]--> formula),\n",
       " Edge(number <--[increase of]--> quadrature point),\n",
       " Edge(number <--[increase of]--> weight),\n",
       " Edge(more efficient quadrature rule <--[include for]--> high dimensional problem),\n",
       " Edge(more efficient quadrature rule <--[include]--> smolyak sparse grid quadrature rule),\n",
       " Edge(more efficient quadrature rule <--[include]--> designed quadrature rule),\n",
       " Edge(which <--[drop]--> higher order term),\n",
       " Edge(which <--[drop in]--> gauss quadrature rule),\n",
       " Edge(which <--[generate]--> quadrature rule),\n",
       " Edge(regression approach <--[computes]--> pce coefficient),\n",
       " Edge(regression approach <--[computes]--> desired quantity),\n",
       " Edge([[[formula]]] <--[denotes]--> set),\n",
       " Edge([[[formula]]] <--[denotes of]--> formula),\n",
       " Edge(number <--[affect]--> required number),\n",
       " Edge(number <--[affect]--> accuracy),\n",
       " Edge(number <--[affect of]--> model evaluation),\n",
       " Edge(wang et al <--[introduced]--> accelerated model evaluation),\n",
       " Edge(wang et al <--[introduced on]--> tensor grid),\n",
       " Edge(wang et al <--[introduced]--> method),\n",
       " Edge(amtc method <--[take]--> advantage),\n",
       " Edge(amtc method <--[take of]--> fact),\n",
       " Edge(we <--[view]--> computational model),\n",
       " Edge(we <--[view]--> numerical solution method),\n",
       " Edge(we <--[view a]--> computational graph),\n",
       " Edge(each operation s output <--[requires]--> distinct evaluation),\n",
       " Edge(each operation s output <--[requires on]--> distinct node),\n",
       " Edge(many operation <--[depend on]--> all),\n",
       " Edge(traditional framework <--[creates]--> many repeated evaluation),\n",
       " Edge(traditional framework <--[creates on]--> operation level),\n",
       " Edge(amtc method <--[partition]--> computational graph),\n",
       " Edge(amtc method <--[partition into]--> sub graph),\n",
       " Edge(operation <--[share within]--> each sub graph),\n",
       " Edge(operation <--[share]--> same input space),\n",
       " Edge(operation <--[share on]--> distinct node),\n",
       " Edge(which <--[us]--> full grid quadrature rule),\n",
       " Edge(which <--[demonstrated]--> effectiveness),\n",
       " Edge(wang <--[proposed]--> framework),\n",
       " Edge(al <--[proposed]--> framework),\n",
       " Edge(we <--[project]--> high dimensional input space),\n",
       " Edge(we <--[project onto]--> lower dimensional subspace),\n",
       " Edge(eigenvectors <--[define]--> rotation),\n",
       " Edge(eigenvectors <--[define of]--> original uncertain input space),\n",
       " Edge(magnitude <--[represents of]--> eigenvalue),\n",
       " Edge(magnitude <--[represents of]--> eigenvectors),\n",
       " Edge(magnitude <--[represents]--> function s average variation),\n",
       " Edge(magnitude <--[represents in]--> each direction),\n",
       " Edge(a method <--[identifies]--> active subspace),\n",
       " Edge(a method <--[identifies]--> formula),\n",
       " Edge(this <--[result in]--> two set),\n",
       " Edge(which <--[reduces]--> computational cost),\n",
       " Edge(which <--[reduces of]--> analysis),\n",
       " Edge(which <--[reduces of]--> optimization),\n",
       " Edge(we <--[propose]--> novel framework),\n",
       " Edge(we <--[propose]--> extension),\n",
       " Edge(we <--[propose of]--> this framework),\n",
       " Edge(this <--[separate]--> rotated coordinate),\n",
       " Edge(this <--[separate into]--> two set),\n",
       " Edge(function <--[varies with]--> respect),\n",
       " Edge(we <--[call]--> formula),\n",
       " Edge(we <--[call]--> active variable),\n",
       " Edge(we <--[call]--> non sparse uncertain input),\n",
       " Edge(we <--[call]--> inactive variable),\n",
       " Edge(we <--[approximate]--> model output),\n",
       " Edge(efficient quadrature rule <--[need in]--> original input space),\n",
       " Edge(we <--[solve]--> first challenge),\n",
       " Edge(we <--[follow]--> method),\n",
       " Edge(we <--[follow]--> polynomial chaos),\n",
       " Edge(we <--[want for]--> [[[formula matrix]]]),\n",
       " Edge(we <--[define]--> monomial matrix),\n",
       " Edge([[[formula matrix]]] <--[satisfies]--> formula),\n",
       " Edge([[[formula matrix]]] <--[satisfies through]--> cholesky factorization),\n",
       " Edge(we <--[utilize]--> linear relationship),\n",
       " Edge(we <--[approximate]--> pce coefficient),\n",
       " Edge(we <--[approximate]--> desired quantity),\n",
       " Edge(this <--[result in]--> integration problem),\n",
       " Edge(computational model <--[accepts]--> input),\n",
       " Edge(computational model <--[accepts]--> output),\n",
       " Edge(numerical solution method <--[accepts]--> input),\n",
       " Edge(numerical solution method <--[accepts]--> output),\n",
       " Edge(computational model <--[accepts in]--> term),\n",
       " Edge(numerical solution method <--[accepts in]--> term),\n",
       " Edge(we <--[denote]--> quadrature point),\n",
       " Edge(we <--[denote]--> weight),\n",
       " Edge(quadrature rule <--[approximates]--> integral),\n",
       " Edge(we <--[solve]--> quadrature rule),\n",
       " Edge(designed quadrature method <--[generates]--> quadrature rule),\n",
       " Edge(point weight <--[integrate]--> polynomial function),\n",
       " Edge(point weight <--[integrate to]--> specific order),\n",
       " Edge(node <--[satisfy]--> multi variate moment matching equation),\n",
       " Edge(weight <--[satisfy]--> multi variate moment matching equation),\n",
       " Edge(quadrature rule <--[integrate]--> any polynomial),\n",
       " Edge(quadrature rule <--[integrate of]--> formula),\n",
       " Edge(quadrature rule <--[integrate]--> polynomial),\n",
       " Edge(we <--[write]--> moment matching equation),\n",
       " Edge(we <--[write a]--> formula),\n",
       " Edge(we <--[generated]--> that),\n",
       " Edge(we <--[generated in]--> previous step),\n",
       " Edge(we <--[represent]--> moment matching equation),\n",
       " Edge(we <--[represent a]--> residual equation),\n",
       " Edge(which <--[minimizes]--> norm),\n",
       " Edge(which <--[minimizes of]--> residual equation),\n",
       " Edge(number <--[depends of]--> node),\n",
       " Edge(number <--[depends of]--> weight),\n",
       " Edge(we <--[generate]--> pce basis function),\n",
       " Edge(we <--[generate]--> efficient quadrature rule),\n",
       " Edge(we <--[generate]--> quadrature rule),\n",
       " Edge(we <--[generate]--> corresponding quadrature rule),\n",
       " Edge(rotated coordinate <--[satisfy]--> linear relationship),\n",
       " Edge(rotated coordinate <--[satisfy with]--> original coordinate),\n",
       " Edge(rotated coordinate <--[satisfy]--> formula),\n",
       " Edge(this approach result <--[require]--> fewest quadrature point),\n",
       " Edge(we <--[refer to]--> this a based nipc method),\n",
       " Edge(we <--[presented in]--> previous sequence reference),\n",
       " Edge(quadrature point <--[possess]--> tensor structure),\n",
       " Edge(weight <--[possess]--> tensor structure),\n",
       " Edge(we <--[follow]--> partially tensor structured quadrature rule),\n",
       " Edge(evaluation cost <--[take of]--> operation),\n",
       " Edge(evaluation cost <--[take]--> small percentage),\n",
       " Edge(evaluation cost <--[take of]--> total model evaluation cost),\n",
       " Edge(we <--[refer to]--> these uncertain input),\n",
       " Edge(we <--[refer]--> other uncertain input),\n",
       " Edge(we <--[refer a]--> non sparse uncertain input),\n",
       " Edge(we <--[choose]--> sparse uncertain input),\n",
       " Edge(we <--[partition]--> uncertain input),\n",
       " Edge(we <--[partition a]--> formula),\n",
       " Edge(sparse uncertain input <--[affect]--> small amount),\n",
       " Edge(sparse uncertain input <--[affect of]--> model evaluation cost),\n",
       " Edge(this <--[result in]--> total),\n",
       " Edge(most operation <--[depend in]--> computational graph),\n",
       " Edge(we <--[address]--> this problem),\n",
       " Edge(we <--[generate of]--> active variable),\n",
       " Edge(we <--[generate of]--> non sparse uncertain input),\n",
       " Edge(we <--[denote]--> node),\n",
       " Edge(we <--[approximate]--> stochastic output),\n",
       " Edge(we <--[approximate a]--> pce basis function),\n",
       " Edge(we <--[approximate a]--> efficient quadrature rule),\n",
       " Edge(we <--[approximate a]--> quadrature rule),\n",
       " Edge(we <--[approximate a]--> corresponding quadrature rule),\n",
       " Edge(quadrature rule <--[follows]--> same tensor structure),\n",
       " Edge(this <--[result in]--> efficient quadrature rule),\n",
       " Edge(this <--[come to]--> model evaluation),\n",
       " Edge(first test problem <--[involves]--> analytical nonlinear model),\n",
       " Edge(we <--[notice]--> rapid decline),\n",
       " Edge(we <--[notice in]--> eigenvalue),\n",
       " Edge(we <--[notice in]--> eigenvectors),\n",
       " Edge(we <--[notice]--> formula),\n",
       " Edge(both a based approach <--[outperform]--> monte carlo method),\n",
       " Edge(both a based approach <--[outperform to]--> 10 or fewer model evaluation),\n",
       " Edge(a nipc <--[achieves]--> this level),\n",
       " Edge(a kriging <--[achieves]--> this level),\n",
       " Edge(a amtc <--[achieves]--> this level),\n",
       " Edge(a nipc <--[achieves of]--> accuracy),\n",
       " Edge(a nipc <--[achieves of]--> computational cost),\n",
       " Edge(a kriging <--[achieves of]--> accuracy),\n",
       " Edge(a kriging <--[achieves of]--> computational cost),\n",
       " Edge(a amtc <--[achieves of]--> accuracy),\n",
       " Edge(a amtc <--[achieves of]--> computational cost),\n",
       " Edge(a nipc <--[result with]--> only 5 model evaluation),\n",
       " Edge(a kriging <--[result with]--> only 5 model evaluation),\n",
       " Edge(a amtc <--[result with]--> only 5 model evaluation),\n",
       " Edge(this computational model <--[calculates]--> average ground level sound pressure level),\n",
       " Edge(this computational model <--[calculates during]--> aircraft s flight),\n",
       " Edge(trajectory model <--[integrates]--> three discipline),\n",
       " Edge(acoustic model <--[integrates]--> three discipline),\n",
       " Edge(it <--[computes]--> aircraft s flight path),\n",
       " Edge(it <--[computes on]--> control input history),\n",
       " Edge(it <--[computes]--> formula),\n",
       " Edge(it <--[computes on]--> other hand),\n",
       " Edge(acoustic model <--[computes]--> ground level sound pressure level),\n",
       " Edge(acoustic model <--[computes]--> formula),\n",
       " Edge(we <--[have]--> control input),\n",
       " Edge(we <--[have]--> acoustic parameter),\n",
       " Edge(we <--[have with]--> time step),\n",
       " Edge(we <--[assume]--> linear relationship),\n",
       " Edge(we <--[assume between]--> consecutive step),\n",
       " Edge(white noise <--[added at]--> each step),\n",
       " Edge(figure reference <--[illustrates]--> control input history),\n",
       " Edge(figure reference <--[illustrates alongside]--> input average),\n",
       " Edge(figure reference <--[illustrates alongside]--> 95 % confidence interval),\n",
       " Edge(we <--[have]--> gaussian uncertain input),\n",
       " Edge(we <--[have with]--> three parameter),\n",
       " Edge(we <--[present]--> first seven eigenvalue),\n",
       " Edge(we <--[present of]--> [[[formula matrix]]]),\n",
       " Edge(we <--[observe]--> rapid decay),\n",
       " Edge(we <--[observe after]--> sixth eigenvalue),\n",
       " Edge(we <--[compute]--> sparsity ratio),\n",
       " Edge(we <--[compute of]--> each uncertain input),\n",
       " Edge(these parameter uncertainty <--[affect]--> operation),\n",
       " Edge(these parameter uncertainty <--[affect within]--> acoustic sub model),\n",
       " Edge(which <--[constitutes]--> very small portion),\n",
       " Edge(which <--[constitutes of]--> overall computational cost),\n",
       " Edge(which <--[comprises]--> formula),\n",
       " Edge(which <--[comprises in]--> tab),\n",
       " Edge(we <--[present alongside]--> those),\n",
       " Edge(eigenvalue <--[decay in]--> a amtc method),\n",
       " Edge(eigenvectors <--[decay in]--> a amtc method),\n",
       " Edge(monte carlo method <--[exhibit]--> superior performance),\n",
       " Edge(this superiority <--[stem from]--> inherent trade off),\n",
       " Edge(both <--[demonstrate of]--> our proposed method),\n",
       " Edge(both <--[demonstrate]--> superior performance),\n",
       " Edge(both <--[demonstrate for]--> instance),\n",
       " Edge(a nipc <--[achieves]--> relative error),\n",
       " Edge(a kriging <--[achieves]--> relative error),\n",
       " Edge(a amtc <--[achieves]--> relative error),\n",
       " Edge(a nipc <--[achieves than]--> a kriging),\n",
       " Edge(a nipc <--[achieves than]--> a nipc),\n",
       " Edge(a kriging <--[achieves than]--> a kriging),\n",
       " Edge(a kriging <--[achieves than]--> a nipc),\n",
       " Edge(a amtc <--[achieves than]--> a kriging),\n",
       " Edge(a amtc <--[achieves than]--> a nipc),\n",
       " Edge(these input <--[affect]--> about 2 %),\n",
       " Edge(these input <--[affect of]--> model evaluation cost),\n",
       " Edge(we <--[observe]--> more rapid decay rate),\n",
       " Edge(we <--[observe of]--> eigenvalue),\n",
       " Edge(we <--[observe of]--> eigenvectors),\n",
       " Edge(we <--[observe]--> matrix),\n",
       " Edge(we <--[observe in]--> tab),\n",
       " Edge(this <--[enables]--> u),\n",
       " Edge(we <--[present]--> two uq method),\n",
       " Edge(a nipc method <--[integrates]--> integration based non intrusive polynomial chaos method),\n",
       " Edge(a nipc method <--[integrates with]--> active subspace method),\n",
       " Edge(a amtc method <--[incorporates]--> computational graph transformation method),\n",
       " Edge(a nipc <--[demonstrates]--> superior efficiency),\n",
       " Edge(a kriging <--[demonstrates]--> superior efficiency),\n",
       " Edge(a amtc <--[demonstrates]--> superior efficiency),\n",
       " Edge(a nipc <--[demonstrates to]--> existing method),\n",
       " Edge(a kriging <--[demonstrates to]--> existing method),\n",
       " Edge(a amtc <--[demonstrates to]--> existing method),\n",
       " Edge(both a nipc <--[outperform]--> existing method),\n",
       " Edge(a amtc <--[outperform]--> existing method),\n",
       " Edge(a nipc <--[achieves]--> 30 % reduction),\n",
       " Edge(a kriging <--[achieves]--> 30 % reduction),\n",
       " Edge(a amtc <--[achieves]--> 30 % reduction),\n",
       " Edge(a nipc <--[achieves in]--> relative error),\n",
       " Edge(a kriging <--[achieves in]--> relative error),\n",
       " Edge(a amtc <--[achieves in]--> relative error),\n",
       " Edge(a amtc <--[achieves]--> 80 % reduction),\n",
       " Edge(future research <--[explore]--> dimension reduction technique),\n",
       " Edge(author <--[have]--> no known competing financial interest),\n",
       " Edge(author <--[have]--> personal relationship),\n",
       " Edge(impact <--[of]--> uncertain input),\n",
       " Edge(impact <--[on]--> system s output),\n",
       " Edge(quantity <--[of]--> interest),\n",
       " Edge(reliable estimate <--[of]--> uncertainty),\n",
       " Edge(application <--[of]--> uq),\n",
       " Edge(various engineering discipline <--[including]--> structure analysis),\n",
       " Edge(variation <--[in]--> operating condition),\n",
       " Edge(variation <--[among]--> others),\n",
       " Edge(lack <--[of]--> knowledge),\n",
       " Edge(uq problem <--[within]--> probabilistic formalism),\n",
       " Edge(key statistical parameter <--[like]--> mean),\n",
       " Edge(mean <--[of]--> qoi),\n",
       " Edge(variance <--[of]--> qoi),\n",
       " Edge(more intricate risk measure <--[of]--> qoi),\n",
       " Edge(more intricate risk measure <--[a]--> probability),\n",
       " Edge(probability <--[of]--> failure),\n",
       " Edge(conditional value <--[of]--> failure),\n",
       " Edge(conditional value <--[at]--> risk),\n",
       " Edge(approach ease <--[of]--> implementation),\n",
       " Edge(method <--[of]--> moment),\n",
       " Edge(polynomial chaos <--[of]--> moment),\n",
       " Edge(choice <--[of]--> method),\n",
       " Edge(problem <--[at]--> hand),\n",
       " Edge(statistical moment <--[of]--> qoi),\n",
       " Edge(risk measure <--[of]--> qoi),\n",
       " Edge(rule <--[of]--> large number),\n",
       " Edge(convergence <--[of]--> monte carlo),\n",
       " Edge(number <--[of]--> uncertain input),\n",
       " Edge(significantly larger number <--[of]--> model evaluation),\n",
       " Edge(comparable accuracy <--[to]--> other uq method),\n",
       " Edge(surrogate <--[for]--> original function),\n",
       " Edge(optimization <--[under]--> uncertainty),\n",
       " Edge(distribution <--[of]--> uncertain input),\n",
       " Edge(smoothness <--[in]--> random space),\n",
       " Edge(challenge <--[with]--> high dimensional uq),\n",
       " Edge(curse <--[of]--> dimensionality),\n",
       " Edge(accelerated model evaluation <--[on]--> tensor grid),\n",
       " Edge(computational graph <--[of]--> model),\n",
       " Edge(redundant evaluation <--[at]--> operation level),\n",
       " Edge(tensor structure <--[of]--> input),\n",
       " Edge(quadrature rule <--[with]--> desired tensor structure),\n",
       " Edge(sparsity <--[in]--> computational model),\n",
       " Edge(superiority <--[over]--> existing uq method),\n",
       " Edge(existing uq method <--[for]--> specific low dimensional uq problem),\n",
       " Edge(specific low dimensional uq problem <--[involving]--> multidisciplinary system),\n",
       " Edge(impact <--[of]--> input parameter),\n",
       " Edge(impact <--[on]--> output uncertainty),\n",
       " Edge(perturbation <--[of]--> each input),\n",
       " Edge(perturbation <--[at]--> nominal value),\n",
       " Edge(analysis effect <--[on]--> output),\n",
       " Edge(output variation <--[over]--> full range),\n",
       " Edge(full range <--[of]--> input),\n",
       " Edge(dimension <--[of]--> problem),\n",
       " Edge(highest degree <--[of]--> problem),\n",
       " Edge(eigenvalue decomposition <--[on]--> covariance matrix),\n",
       " Edge(covariance matrix <--[of]--> uncertain input),\n",
       " Edge(highest variance direction <--[in]--> input space),\n",
       " Edge(covariant direction <--[between]--> input),\n",
       " Edge(first order change <--[in]--> output),\n",
       " Edge(balance <--[between]--> accuracy),\n",
       " Edge(tool <--[for]--> high dimensional uq problem),\n",
       " Edge(capability <--[of]--> graph accelerated nipc method),\n",
       " Edge(low dimensional uq problem <--[with]--> sparsity),\n",
       " Edge(low dimensional uq problem <--[in]--> computational graph),\n",
       " Edge(pce basis function <--[for]--> active subspace s uncertain input),\n",
       " Edge(efficient quadrature rule <--[for]--> active subspace s uncertain input),\n",
       " Edge(quadrature rule <--[for]--> active subspace s uncertain input),\n",
       " Edge(corresponding quadrature rule <--[for]--> active subspace s uncertain input),\n",
       " Edge(efficient quadrature rule <--[in]--> original uncertain input space),\n",
       " Edge(extension <--[of]--> this framework),\n",
       " Edge(small amount <--[of]--> computational cost),\n",
       " Edge(amtc efficiency <--[on]--> second problem),\n",
       " Edge(some background <--[for]--> graph accelerated nipc and a method),\n",
       " Edge(detail <--[of]--> a nipc and a amtc method),\n",
       " Edge(numerical result <--[of]--> test problem),\n",
       " Edge(uq problem <--[with]--> continuous random input),\n",
       " Edge(key idea <--[of]--> gpc),\n",
       " Edge(stochastic output <--[of]--> model),\n",
       " Edge(linear combination <--[of]--> orthogonal polynomial basis function),\n",
       " Edge(statistical moment <--[of]--> stochastic output),\n",
       " Edge(risk measure <--[of]--> stochastic output),\n",
       " Edge(infinite series <--[of]--> orthogonal polynomial),\n",
       " Edge(orthogonal polynomial <--[of]--> uncertain input),\n",
       " Edge(total number <--[of]--> pce term),\n",
       " Edge(rapid convergence <--[of]--> any gpc based method),\n",
       " Edge(common type <--[of]--> continuous random variable),\n",
       " Edge(multi dimensional problem <--[with]--> mutually independent input),\n",
       " Edge(tensor product <--[of]--> univariate orthogonal polynomial),\n",
       " Edge(similar performance <--[on]--> low dimensional uq problem),\n",
       " Edge(use <--[of]--> orthogonality property),\n",
       " Edge(orthogonality property <--[of]--> pce basis function),\n",
       " Edge(integration problem <--[for]--> each coefficient),\n",
       " Edge(number <--[of]--> pce basis function),\n",
       " Edge(tensor product <--[of]--> 1d quadrature rule),\n",
       " Edge(number <--[of]--> quadrature point),\n",
       " Edge(dimension <--[a]--> formula),\n",
       " Edge(highest degree <--[a]--> formula),\n",
       " Edge(set <--[of]--> sample point),\n",
       " Edge(2 3 time number <--[of]--> coefficient),\n",
       " Edge(required number <--[of]--> model evaluation),\n",
       " Edge(accuracy <--[of]--> model evaluation),\n",
       " Edge(accuracy <--[of]--> nipc method),\n",
       " Edge(computational cost <--[of]--> nipc method),\n",
       " Edge(model evaluation cost <--[on]--> tensor structured input),\n",
       " Edge(advantage <--[of]--> fact),\n",
       " Edge(computational graph <--[with]--> elementary operation),\n",
       " Edge(distinct evaluation <--[on]--> distinct node),\n",
       " Edge(distinct node <--[in]--> space),\n",
       " Edge(space <--[of]--> output dependent input),\n",
       " Edge(many repeated evaluation <--[on]--> operation level),\n",
       " Edge(dependency information <--[of]--> operation),\n",
       " Edge(operation <--[within]--> each sub graph),\n",
       " Edge(distinct node <--[within]--> that space),\n",
       " Edge(correct data flow <--[between]--> sub graph),\n",
       " Edge(full grid input point <--[with]--> point),\n",
       " Edge(point <--[in]--> each dimension),\n",
       " Edge(sequence <--[of]--> elementary operation),\n",
       " Edge(elementary operation <--[in]--> function),\n",
       " Edge(computational graph <--[for]--> this function),\n",
       " Edge(operation <--[in]--> computational graph),\n",
       " Edge(middle end <--[of]--> compiler),\n",
       " Edge(repeated evaluation <--[on]--> operation level),\n",
       " Edge(demonstration <--[for]--> amtc implementation),\n",
       " Edge(amtc implementation <--[in]--> csdl),\n",
       " Edge(application <--[of]--> graph accelerated nipc method),\n",
       " Edge(lot <--[of]--> popularity),\n",
       " Edge(basic idea <--[behind]--> a),\n",
       " Edge(some direction <--[in]--> input parameter space),\n",
       " Edge(greater impact <--[on]--> output uncertainty),\n",
       " Edge(greater impact <--[than]--> others),\n",
       " Edge(mean squared gradient <--[of]--> objective function),\n",
       " Edge(mean squared gradient <--[with]--> respect),\n",
       " Edge(respect <--[to]--> uncertain input),\n",
       " Edge(rotation <--[of]--> original uncertain input space),\n",
       " Edge(magnitude <--[of]--> eigenvectors),\n",
       " Edge(magnitude <--[in]--> decreasing order),\n",
       " Edge(magnitude <--[of]--> eigenvalue),\n",
       " Edge(function s average variation <--[in]--> each direction),\n",
       " Edge(two set <--[of]--> rotated coordinate),\n",
       " Edge(space <--[of]--> formula),\n",
       " Edge(computational cost <--[of]--> analysis),\n",
       " Edge(orthogonal pce basis function <--[of]--> active subspace variable),\n",
       " Edge(sparsity <--[of]--> computational graph),\n",
       " Edge(desired rotation <--[of]--> input coordinate),\n",
       " Edge(respect <--[to]--> small number),\n",
       " Edge(small number <--[of]--> input),\n",
       " Edge(eigenvalue decomposition <--[a]--> formula),\n",
       " Edge(two set <--[a]--> formula),\n",
       " Edge(respect <--[to]--> formula),\n",
       " Edge(term <--[of]--> formula),\n",
       " Edge(probability density <--[of]--> distribution),\n",
       " Edge(distribution <--[in]--> active space),\n",
       " Edge(pce term <--[in]--> active subspace),\n",
       " Edge(efficient quadrature rule <--[in]--> original input space),\n",
       " Edge(pce term <--[of]--> active subspace uncertain input),\n",
       " Edge(coefficient <--[of]--> pce basis function),\n",
       " Edge(pce basis function <--[of]--> formula),\n",
       " Edge(efficient quadrature rule <--[of]--> formula),\n",
       " Edge(quadrature rule <--[of]--> formula),\n",
       " Edge(corresponding quadrature rule <--[of]--> formula),\n",
       " Edge(monomial basis vector <--[in]--> formula),\n",
       " Edge(coefficient <--[for]--> monomial basis polynomial),\n",
       " Edge(coefficient <--[in]--> univariate pce basis function),\n",
       " Edge(pce basis function <--[for]--> uniform uncertain input),\n",
       " Edge(efficient quadrature rule <--[for]--> uniform uncertain input),\n",
       " Edge(quadrature rule <--[for]--> uniform uncertain input),\n",
       " Edge(corresponding quadrature rule <--[for]--> uniform uncertain input),\n",
       " Edge(form <--[of]--> monomial basis vector),\n",
       " Edge(probability distribution <--[of]--> active variable),\n",
       " Edge(change <--[of]--> variable),\n",
       " Edge(integration problem <--[in]--> space),\n",
       " Edge(given point <--[in]--> space),\n",
       " Edge(infinite number <--[of]--> point),\n",
       " Edge(point <--[in]--> formula),\n",
       " Edge(probability density distribution <--[of]--> active variable),\n",
       " Edge(direct generation <--[of]--> quadrature point),\n",
       " Edge(efficient quadrature rule <--[with]--> node),\n",
       " Edge(node <--[in]--> original input space),\n",
       " Edge(weight <--[in]--> original input space),\n",
       " Edge(node <--[of]--> quadrature rule),\n",
       " Edge(weight <--[of]--> quadrature rule),\n",
       " Edge(multi variate moment matching equation <--[a]--> formula),\n",
       " Edge(any polynomial <--[of]--> formula),\n",
       " Edge(polynomial <--[of]--> formula),\n",
       " Edge(norm <--[of]--> residual equation),\n",
       " Edge(number <--[of]--> node),\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Перебор параметров для кластеризации ребер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получение верхней оценки на eps в переборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size 100: Median cosine distance = 0.6417, 90th percentile = 0.8282\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size 200: Median cosine distance = 0.5531, 90th percentile = 0.7131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{100: {'median_distance': np.float32(0.6417062),\n",
       "  'percentile_90': np.float32(0.8281681)},\n",
       " 200: {'median_distance': np.float32(0.5531133),\n",
       "  'percentile_90': np.float32(0.71305406)}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from process_graph.edges_clustering import analyze_distance_distributions\n",
    "\n",
    "analyze_distance_distributions(graph.edges, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size 100: Median euclidean distance = 2.1328, 90th percentile = 2.4958\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size 200: Median euclidean distance = 2.3043, 90th percentile = 2.8031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{100: {'median_distance': np.float32(2.1327868),\n",
       "  'percentile_90': np.float32(2.4958158)},\n",
       " 200: {'median_distance': np.float32(2.3042572),\n",
       "  'percentile_90': np.float32(2.8030775)}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_distance_distributions(graph.edges, metric=\"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер эмбеддинга: 100, Количество рёбер: 842\n",
      "Размер эмбеддинга: 200, Количество рёбер: 284\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Инициализация словаря для хранения количества рёбер по размеру эмбеддингов\n",
    "edges_count_by_size = defaultdict(int)\n",
    "\n",
    "# Подсчёт количества рёбер для каждого размера эмбеддингов\n",
    "for edge in graph.edges:\n",
    "    embedding_size = len(edge.embedding)\n",
    "    edges_count_by_size[embedding_size] += 1\n",
    "\n",
    "# Вывод результатов\n",
    "for size, count in edges_count_by_size.items():\n",
    "    print(f\"Размер эмбеддинга: {size}, Количество рёбер: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No edges found for embedding size 300. Skipping.\n",
      "Warning: No edges found for embedding size 300. Skipping.\n"
     ]
    }
   ],
   "source": [
    "from process_graph.edges_clustering import grid_search_cluster_params, compute_connectivity_matrix\n",
    "import numpy as np\n",
    "\n",
    "model_param_grid = {\n",
    "    \"DBSCAN\": {\n",
    "        \"eps\": np.linspace(1, 2.8, 20),\n",
    "        \"min_samples\": np.linspace(20, 200, 20, dtype=np.int64),\n",
    "        \"metric\": [\"euclidean\"]\n",
    "    },\n",
    "    \"AgglomerativeClustering\": {\n",
    "        \"n_clusters\": np.linspace(10, 100, 1, dtype=np.int64),\n",
    "        \"metric\": [\"euclidean\", \"cosine\", \"\"],\n",
    "        \"linkage\": [\"ward\", \"complete\", \"average\", \"single\"],\n",
    "        \"connectivity\": [None, compute_connectivity_matrix(graph.edges, [100, 200, 300], \"adjacency\"), compute_connectivity_matrix(graph.edges, [100, 200, 300], \"shortest_path\")]\n",
    "    }\n",
    "}\n",
    "embedding_sizes = [100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(29), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(38), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(48), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(57), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(67), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(29), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(38), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(48), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(57), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(67), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(29), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(38), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(48), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(57), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(67), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(20), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(29), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(38), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(48), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(57), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(67), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(20), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(29), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(38), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(48), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(57), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(67), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(20), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(29), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(38), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(48), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(57), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(67), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(20), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(29), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(38), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(48), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(57), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(67), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(20), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(29), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(38), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(48), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(57), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(67), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 100, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:325: UserWarning: the number of connected components of the connectivity matrix is 136 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:325: UserWarning: the number of connected components of the connectivity matrix is 136 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 136 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 136 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 136 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 136 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 136 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 136 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine was provided as metric. Ward can only work with euclidean distances.\n",
      "cosine was provided as metric. Ward can only work with euclidean distances.\n",
      "cosine was provided as metric. Ward can only work with euclidean distances.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 136 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 136 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 136 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 136 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 136 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 136 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "Embedding size 100: Best model = DBSCAN, Best params = {'eps': np.float64(1.9473684210526314), 'min_samples': np.int64(124), 'metric': 'euclidean'}\n",
      "Best Metrics:\n",
      "  Silhouette Score: 0.6500403881072998\n",
      "  Davies-Bouldin Index: 1.206540966559327\n",
      "  Calinski-Harabasz Index: 689.7146606445312\n",
      "  Dunn Index: 0.871819794178009\n",
      "  Connectivity Score: 0.004513064133016627\n",
      "  Intra-Cluster Variance: 0.3824126124382019\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0), 'min_samples': np.int64(67), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0947368421052632), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0947368421052632), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0947368421052632), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0947368421052632), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0947368421052632), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0947368421052632), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0947368421052632), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0947368421052632), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0947368421052632), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0947368421052632), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0947368421052632), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0947368421052632), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0947368421052632), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.0947368421052632), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.1894736842105262), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.1894736842105262), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.1894736842105262), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.1894736842105262), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.1894736842105262), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.1894736842105262), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.1894736842105262), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.1894736842105262), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.1894736842105262), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.1894736842105262), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.1894736842105262), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.1894736842105262), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.1894736842105262), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.1894736842105262), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.2842105263157895), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.2842105263157895), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.2842105263157895), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.2842105263157895), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.2842105263157895), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.2842105263157895), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.2842105263157895), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.2842105263157895), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.2842105263157895), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.2842105263157895), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.2842105263157895), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.2842105263157895), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.2842105263157895), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.2842105263157895), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.3789473684210525), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.3789473684210525), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.3789473684210525), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.3789473684210525), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.3789473684210525), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.3789473684210525), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.3789473684210525), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.3789473684210525), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.3789473684210525), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.3789473684210525), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.3789473684210525), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.3789473684210525), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.3789473684210525), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.3789473684210525), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.4736842105263157), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.4736842105263157), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.4736842105263157), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.4736842105263157), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.4736842105263157), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.4736842105263157), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.4736842105263157), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.4736842105263157), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.4736842105263157), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.4736842105263157), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.4736842105263157), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.4736842105263157), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.4736842105263157), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.4736842105263157), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.568421052631579), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.568421052631579), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.568421052631579), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.568421052631579), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.568421052631579), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.568421052631579), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.568421052631579), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.568421052631579), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.568421052631579), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.568421052631579), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.568421052631579), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.568421052631579), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.568421052631579), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.568421052631579), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.663157894736842), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.663157894736842), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.663157894736842), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.663157894736842), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.663157894736842), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.663157894736842), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.663157894736842), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.663157894736842), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.663157894736842), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.663157894736842), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.663157894736842), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.663157894736842), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.663157894736842), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.663157894736842), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.7578947368421052), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.7578947368421052), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.7578947368421052), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.7578947368421052), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.7578947368421052), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.7578947368421052), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.7578947368421052), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.7578947368421052), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.7578947368421052), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.7578947368421052), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.7578947368421052), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.7578947368421052), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.7578947368421052), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.7578947368421052), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.8526315789473684), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.8526315789473684), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.8526315789473684), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.8526315789473684), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.8526315789473684), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.8526315789473684), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.8526315789473684), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.8526315789473684), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.8526315789473684), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.8526315789473684), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.8526315789473684), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.8526315789473684), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.8526315789473684), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.9473684210526314), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.9473684210526314), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.9473684210526314), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.9473684210526314), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.9473684210526314), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.9473684210526314), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.9473684210526314), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.9473684210526314), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.9473684210526314), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.9473684210526314), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.9473684210526314), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.9473684210526314), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(1.9473684210526314), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.042105263157895), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.042105263157895), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.042105263157895), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.042105263157895), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.042105263157895), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.042105263157895), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.042105263157895), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.042105263157895), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.042105263157895), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.042105263157895), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.042105263157895), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.042105263157895), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.042105263157895), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(29), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(38), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(48), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(57), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(67), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.136842105263158), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(29), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(38), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(48), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(57), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(67), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.231578947368421), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(29), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(38), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(48), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(57), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(67), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.326315789473684), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(20), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(29), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(38), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(48), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(57), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(67), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.421052631578947), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(20), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(29), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(38), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(48), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(57), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(67), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.5157894736842104), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(20), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(29), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(38), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(48), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(57), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(67), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.610526315789474), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(20), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(29), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(38), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(48), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(57), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(67), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.705263157894737), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(20), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(29), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(38), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(48), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(57), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(67), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(76), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(86), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(95), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(105), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(114), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(124), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(133), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(143), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(152), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(162), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(171), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(181), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(190), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n",
      "Embedding size 200, model=DBSCAN, params={'eps': np.float64(2.8), 'min_samples': np.int64(200), 'metric': 'euclidean'}: Skipping due to infinite or undefined metric values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:325: UserWarning: the number of connected components of the connectivity matrix is 77 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:325: UserWarning: the number of connected components of the connectivity matrix is 78 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 77 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 78 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 77 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 78 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 77 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 78 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine was provided as metric. Ward can only work with euclidean distances.\n",
      "cosine was provided as metric. Ward can only work with euclidean distances.\n",
      "cosine was provided as metric. Ward can only work with euclidean distances.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 77 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 78 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 77 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 78 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 77 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n",
      "/home/simon/miniconda3/envs/venv_02_pipeline/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:596: UserWarning: the number of connected components of the connectivity matrix is 78 > 1. Completing it to avoid stopping the tree early.\n",
      "  connectivity, n_connected_components = _fix_connectivity(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "The 'metric' parameter of AgglomerativeClustering must be a str among {'precomputed', 'mahalanobis', 'russellrao', 'canberra', 'l1', 'sokalsneath', 'nan_euclidean', 'sokalmichener', 'cosine', 'dice', 'jaccard', 'chebyshev', 'yule', 'correlation', 'matching', 'haversine', 'hamming', 'manhattan', 'braycurtis', 'cityblock', 'rogerstanimoto', 'minkowski', 'euclidean', 'l2', 'seuclidean', 'sqeuclidean', 'wminkowski'} or a callable. Got '' instead.\n",
      "Embedding size 200: Best model = DBSCAN, Best params = {'eps': np.float64(1.8526315789473684), 'min_samples': np.int64(29), 'metric': 'euclidean'}\n",
      "Best Metrics:\n",
      "  Silhouette Score: 0.4017127752304077\n",
      "  Davies-Bouldin Index: 1.6121673536359715\n",
      "  Calinski-Harabasz Index: 107.83165740966797\n",
      "  Dunn Index: 0.8383738994598389\n",
      "  Connectivity Score: 0.03028169014084507\n",
      "  Intra-Cluster Variance: 0.8272082209587097\n"
     ]
    }
   ],
   "source": [
    "    # Поиск оптимальных параметров\n",
    "best_params, best_scores = grid_search_cluster_params(graph.edges, embedding_sizes, model_param_grid, standardize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{100: {'model': 'DBSCAN',\n",
       "  'params': {'eps': np.float64(1.9473684210526314),\n",
       "   'min_samples': np.int64(124),\n",
       "   'metric': 'euclidean'}},\n",
       " 200: {'model': 'DBSCAN',\n",
       "  'params': {'eps': np.float64(1.8526315789473684),\n",
       "   'min_samples': np.int64(29),\n",
       "   'metric': 'euclidean'}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{100: {'Silhouette Score': np.float32(0.6500404),\n",
       "  'Davies-Bouldin Index': np.float64(1.206540966559327),\n",
       "  'Calinski-Harabasz Index': np.float32(689.71466),\n",
       "  'Dunn Index': np.float32(0.8718198),\n",
       "  'Connectivity Score': 0.004513064133016627,\n",
       "  'Intra-Cluster Variance': np.float32(0.3824126)},\n",
       " 200: {'Silhouette Score': np.float32(0.40171278),\n",
       "  'Davies-Bouldin Index': np.float64(1.6121673536359715),\n",
       "  'Calinski-Harabasz Index': np.float32(107.83166),\n",
       "  'Dunn Index': np.float32(0.8383739),\n",
       "  'Connectivity Score': 0.03028169014084507,\n",
       "  'Intra-Cluster Variance': np.float32(0.8272082)}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_graph.edges_clustering import cluster_and_evaluate_all_sizes\n",
    "metrics, edge_label_map = cluster_and_evaluate_all_sizes(graph.edges, best_params, standardize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{100: {np.str_('make'): np.str_('within'),\n",
       "  np.str_('skews'): np.str_('within'),\n",
       "  np.str_('complicates'): np.str_('within'),\n",
       "  np.str_('have'): np.str_('within'),\n",
       "  np.str_('pose'): np.str_('within'),\n",
       "  np.str_('produce'): np.str_('within'),\n",
       "  np.str_('deliver'): np.str_('within'),\n",
       "  np.str_('bias'): np.str_('within'),\n",
       "  np.str_('shown'): np.str_('within'),\n",
       "  np.str_('mitigate'): np.str_('within'),\n",
       "  np.str_('duplicating'): np.str_('within'),\n",
       "  np.str_('address'): np.str_('within'),\n",
       "  np.str_('combine'): np.str_('within'),\n",
       "  np.str_('outperformed'): np.str_('within'),\n",
       "  np.str_('exhibit'): np.str_('within'),\n",
       "  np.str_('enable'): np.str_('within'),\n",
       "  np.str_('return'): np.str_('within'),\n",
       "  np.str_('generates'): np.str_('within'),\n",
       "  np.str_('considers'): np.str_('within'),\n",
       "  np.str_('determine'): np.str_('within'),\n",
       "  np.str_('defined'): np.str_('within'),\n",
       "  np.str_('concern'): np.str_('within'),\n",
       "  np.str_('assigns'): np.str_('within'),\n",
       "  np.str_('designates'): np.str_('within'),\n",
       "  np.str_('requires'): np.str_('within'),\n",
       "  np.str_('involve'): np.str_('within'),\n",
       "  np.str_('preprocesses'): np.str_('within'),\n",
       "  np.str_('guide'): np.str_('within'),\n",
       "  np.str_('categorise'): np.str_('within'),\n",
       "  np.str_('identify'): np.str_('within'),\n",
       "  np.str_('distinguish'): np.str_('within'),\n",
       "  np.str_('embed'): np.str_('within'),\n",
       "  np.str_('surpass'): np.str_('within'),\n",
       "  np.str_('include'): np.str_('within'),\n",
       "  np.str_('consider'): np.str_('within'),\n",
       "  np.str_('represent'): np.str_('within'),\n",
       "  np.str_('identified'): np.str_('within'),\n",
       "  np.str_('implemented'): np.str_('within'),\n",
       "  np.str_('split'): np.str_('within'),\n",
       "  np.str_('offer'): np.str_('within'),\n",
       "  np.str_('observe'): np.str_('within'),\n",
       "  np.str_('categorize'): np.str_('within'),\n",
       "  np.str_('utilize'): np.str_('within'),\n",
       "  np.str_('employ'): np.str_('within'),\n",
       "  np.str_('monitor'): np.str_('within'),\n",
       "  np.str_('show'): np.str_('within'),\n",
       "  np.str_('create'): np.str_('within'),\n",
       "  np.str_('set'): np.str_('within'),\n",
       "  np.str_('apply'): np.str_('within'),\n",
       "  np.str_('utilise'): np.str_('within'),\n",
       "  np.str_('contains'): np.str_('within'),\n",
       "  np.str_('provide'): np.str_('within'),\n",
       "  np.str_('see'): np.str_('within'),\n",
       "  np.str_('oversee'): np.str_('within'),\n",
       "  np.str_('denote'): np.str_('within'),\n",
       "  np.str_('express'): np.str_('within'),\n",
       "  np.str_('capture'): np.str_('within'),\n",
       "  np.str_('gained'): np.str_('within'),\n",
       "  np.str_('enhances'): np.str_('within'),\n",
       "  np.str_('incorporates'): np.str_('within'),\n",
       "  np.str_('involves'): np.str_('within'),\n",
       "  np.str_('drop'): np.str_('within'),\n",
       "  np.str_('employed'): np.str_('within'),\n",
       "  np.str_('designated'): np.str_('within'),\n",
       "  np.str_('serf'): np.str_('within'),\n",
       "  np.str_('adjusted'): np.str_('within'),\n",
       "  np.str_('incorporated'): np.str_('within'),\n",
       "  np.str_('includes'): np.str_('within'),\n",
       "  np.str_('represents'): np.str_('within'),\n",
       "  np.str_('constructed'): np.str_('within'),\n",
       "  np.str_('compute'): np.str_('within'),\n",
       "  np.str_('filled'): np.str_('within'),\n",
       "  np.str_('indicate'): np.str_('within'),\n",
       "  np.str_('utilized'): np.str_('within'),\n",
       "  np.str_('outperform'): np.str_('within'),\n",
       "  np.str_('require'): np.str_('within'),\n",
       "  np.str_('illustrate'): np.str_('within'),\n",
       "  np.str_('used'): np.str_('within'),\n",
       "  np.str_('developed'): np.str_('within'),\n",
       "  np.str_('tested'): np.str_('within'),\n",
       "  np.str_('trained'): np.str_('within'),\n",
       "  np.str_('like'): np.str_('within'),\n",
       "  np.str_('in'): np.str_('within'),\n",
       "  np.str_('than'): np.str_('within'),\n",
       "  np.str_('for'): np.str_('within'),\n",
       "  np.str_('from'): np.str_('within'),\n",
       "  np.str_('regarding'): np.str_('within'),\n",
       "  np.str_('with'): np.str_('within'),\n",
       "  np.str_('during'): np.str_('within'),\n",
       "  np.str_('including'): np.str_('within'),\n",
       "  np.str_('along'): np.str_('within'),\n",
       "  np.str_('between'): np.str_('within'),\n",
       "  np.str_('among'): np.str_('within'),\n",
       "  np.str_('behind'): np.str_('within'),\n",
       "  np.str_('support'): np.str_('within'),\n",
       "  np.str_('necessitate'): np.str_('within'),\n",
       "  np.str_('creates'): np.str_('within'),\n",
       "  np.str_('exploit'): np.str_('within'),\n",
       "  np.str_('encounter'): np.str_('within'),\n",
       "  np.str_('introduced'): np.str_('within'),\n",
       "  np.str_('accelerates'): np.str_('within'),\n",
       "  np.str_('demonstrated'): np.str_('within'),\n",
       "  np.str_('measure'): np.str_('within'),\n",
       "  np.str_('lack'): np.str_('within'),\n",
       "  np.str_('computes'): np.str_('within'),\n",
       "  np.str_('conduct'): np.str_('within'),\n",
       "  np.str_('utilizes'): np.str_('within'),\n",
       "  np.str_('strike'): np.str_('within'),\n",
       "  np.str_('connected'): np.str_('within'),\n",
       "  np.str_('linked'): np.str_('within'),\n",
       "  np.str_('proposes'): np.str_('within'),\n",
       "  np.str_('improve'): np.str_('within'),\n",
       "  np.str_('give'): np.str_('within'),\n",
       "  np.str_('denotes'): np.str_('within'),\n",
       "  np.str_('affect'): np.str_('within'),\n",
       "  np.str_('use'): np.str_('within'),\n",
       "  np.str_('integrate'): np.str_('within'),\n",
       "  np.str_('generate'): np.str_('within'),\n",
       "  np.str_('take'): np.str_('within'),\n",
       "  np.str_('view'): np.str_('within'),\n",
       "  np.str_('partition'): np.str_('within'),\n",
       "  np.str_('share'): np.str_('within'),\n",
       "  np.str_('proposed'): np.str_('within'),\n",
       "  np.str_('project'): np.str_('within'),\n",
       "  np.str_('define'): np.str_('within'),\n",
       "  np.str_('identifies'): np.str_('within'),\n",
       "  np.str_('reduces'): np.str_('within'),\n",
       "  np.str_('propose'): np.str_('within'),\n",
       "  np.str_('separate'): np.str_('within'),\n",
       "  np.str_('call'): np.str_('within'),\n",
       "  np.str_('approximate'): np.str_('within'),\n",
       "  np.str_('solve'): np.str_('within'),\n",
       "  np.str_('follow'): np.str_('within'),\n",
       "  np.str_('satisfies'): np.str_('within'),\n",
       "  np.str_('accepts'): np.str_('within'),\n",
       "  np.str_('approximates'): np.str_('within'),\n",
       "  np.str_('satisfy'): np.str_('within'),\n",
       "  np.str_('write'): np.str_('within'),\n",
       "  np.str_('generated'): np.str_('within'),\n",
       "  np.str_('minimizes'): np.str_('within'),\n",
       "  np.str_('possess'): np.str_('within'),\n",
       "  np.str_('refer'): np.str_('within'),\n",
       "  np.str_('choose'): np.str_('within'),\n",
       "  np.str_('follows'): np.str_('within'),\n",
       "  np.str_('notice'): np.str_('within'),\n",
       "  np.str_('achieves'): np.str_('within'),\n",
       "  np.str_('calculates'): np.str_('within'),\n",
       "  np.str_('integrates'): np.str_('within'),\n",
       "  np.str_('assume'): np.str_('within'),\n",
       "  np.str_('illustrates'): np.str_('within'),\n",
       "  np.str_('present'): np.str_('within'),\n",
       "  np.str_('constitutes'): np.str_('within'),\n",
       "  np.str_('comprises'): np.str_('within'),\n",
       "  np.str_('demonstrate'): np.str_('within'),\n",
       "  np.str_('enables'): np.str_('within'),\n",
       "  np.str_('demonstrates'): np.str_('within'),\n",
       "  np.str_('explore'): np.str_('within'),\n",
       "  np.str_('within'): np.str_('within'),\n",
       "  np.str_('under'): np.str_('within'),\n",
       "  np.str_('over'): np.str_('within'),\n",
       "  np.str_('involving'): np.str_('within'),\n",
       "  np.str_('after'): np.str_('within'),\n",
       "  np.str_('about'): np.str_('within'),\n",
       "  np.str_('of'): np.str_('of'),\n",
       "  np.str_('ha'): np.str_('ha'),\n",
       "  np.str_('to'): np.str_('to'),\n",
       "  np.str_('a'): np.str_('a'),\n",
       "  np.str_('at'): np.str_('at'),\n",
       "  np.str_('on'): np.str_('on'),\n",
       "  np.str_('us'): np.str_('us'),\n",
       "  np.str_('by'): np.str_('by')},\n",
       " 200: {np.str_('make on'): np.str_('generates from'),\n",
       "  np.str_('hinge on'): np.str_('generates from'),\n",
       "  np.str_('become towards'): np.str_('generates from'),\n",
       "  np.str_('deliver for'): np.str_('generates from'),\n",
       "  np.str_('bias towards'): np.str_('generates from'),\n",
       "  np.str_('rely on'): np.str_('generates from'),\n",
       "  np.str_('delve into'): np.str_('generates from'),\n",
       "  np.str_('address from'): np.str_('generates from'),\n",
       "  np.str_('combine in'): np.str_('generates from'),\n",
       "  np.str_('outperformed in'): np.str_('generates from'),\n",
       "  np.str_('generates from'): np.str_('generates from'),\n",
       "  np.str_('determine in'): np.str_('generates from'),\n",
       "  np.str_('lie in'): np.str_('generates from'),\n",
       "  np.str_('operates on'): np.str_('generates from'),\n",
       "  np.str_('concluded in'): np.str_('generates from'),\n",
       "  np.str_('guide through'): np.str_('generates from'),\n",
       "  np.str_('categorise among'): np.str_('generates from'),\n",
       "  np.str_('embed in'): np.str_('generates from'),\n",
       "  np.str_('consider in'): np.str_('generates from'),\n",
       "  np.str_('result in'): np.str_('generates from'),\n",
       "  np.str_('identified in'): np.str_('generates from'),\n",
       "  np.str_('split through'): np.str_('generates from'),\n",
       "  np.str_('offer for'): np.str_('generates from'),\n",
       "  np.str_('observe in'): np.str_('generates from'),\n",
       "  np.str_('appears across'): np.str_('generates from'),\n",
       "  np.str_('categorize in'): np.str_('generates from'),\n",
       "  np.str_('elaborate on'): np.str_('generates from'),\n",
       "  np.str_('improve over'): np.str_('generates from'),\n",
       "  np.str_('set for'): np.str_('generates from'),\n",
       "  np.str_('utilise in'): np.str_('generates from'),\n",
       "  np.str_('contains in'): np.str_('generates from'),\n",
       "  np.str_('capture between'): np.str_('generates from'),\n",
       "  np.str_('gained on'): np.str_('generates from'),\n",
       "  np.str_('enhances through'): np.str_('generates from'),\n",
       "  np.str_('depend on'): np.str_('generates from'),\n",
       "  np.str_('employ for'): np.str_('generates from'),\n",
       "  np.str_('focus on'): np.str_('generates from'),\n",
       "  np.str_('designated for'): np.str_('generates from'),\n",
       "  np.str_('adjusted on'): np.str_('generates from'),\n",
       "  np.str_('incorporated into'): np.str_('generates from'),\n",
       "  np.str_('incorporates for'): np.str_('generates from'),\n",
       "  np.str_('exhibit for'): np.str_('generates from'),\n",
       "  np.str_('remain throughout'): np.str_('generates from'),\n",
       "  np.str_('span from'): np.str_('generates from'),\n",
       "  np.str_('represents on'): np.str_('generates from'),\n",
       "  np.str_('indicate in'): np.str_('generates from'),\n",
       "  np.str_('outperform in'): np.str_('generates from'),\n",
       "  np.str_('compute in'): np.str_('generates from'),\n",
       "  np.str_('performed than'): np.str_('generates from'),\n",
       "  np.str_('employed for'): np.str_('generates from'),\n",
       "  np.str_('require for'): np.str_('generates from'),\n",
       "  np.str_('require in'): np.str_('generates from'),\n",
       "  np.str_('proven in'): np.str_('generates from'),\n",
       "  np.str_('exhibit from'): np.str_('generates from'),\n",
       "  np.str_('change over'): np.str_('generates from'),\n",
       "  np.str_('developed for'): np.str_('generates from'),\n",
       "  np.str_('trained on'): np.str_('generates from'),\n",
       "  np.str_('support in'): np.str_('generates from'),\n",
       "  np.str_('arise from'): np.str_('generates from'),\n",
       "  np.str_('gained due'): np.str_('generates from'),\n",
       "  np.str_('struggle with'): np.str_('generates from'),\n",
       "  np.str_('exploit in'): np.str_('generates from'),\n",
       "  np.str_('encounter with'): np.str_('generates from'),\n",
       "  np.str_('demonstrated over'): np.str_('generates from'),\n",
       "  np.str_('suffers from'): np.str_('generates from'),\n",
       "  np.str_('lack in'): np.str_('generates from'),\n",
       "  np.str_('measure over'): np.str_('generates from'),\n",
       "  np.str_('conduct on'): np.str_('generates from'),\n",
       "  np.str_('suffer from'): np.str_('generates from'),\n",
       "  np.str_('strike between'): np.str_('generates from'),\n",
       "  np.str_('relies on'): np.str_('generates from'),\n",
       "  np.str_('generates for'): np.str_('generates from'),\n",
       "  np.str_('improve on'): np.str_('generates from'),\n",
       "  np.str_('give for'): np.str_('generates from'),\n",
       "  np.str_('show on'): np.str_('generates from'),\n",
       "  np.str_('result into'): np.str_('generates from'),\n",
       "  np.str_('include for'): np.str_('generates from'),\n",
       "  np.str_('drop in'): np.str_('generates from'),\n",
       "  np.str_('introduced on'): np.str_('generates from'),\n",
       "  np.str_('requires on'): np.str_('generates from'),\n",
       "  np.str_('creates on'): np.str_('generates from'),\n",
       "  np.str_('partition into'): np.str_('generates from'),\n",
       "  np.str_('share within'): np.str_('generates from'),\n",
       "  np.str_('share on'): np.str_('generates from'),\n",
       "  np.str_('project onto'): np.str_('generates from'),\n",
       "  np.str_('represents in'): np.str_('generates from'),\n",
       "  np.str_('separate into'): np.str_('generates from'),\n",
       "  np.str_('varies with'): np.str_('generates from'),\n",
       "  np.str_('need in'): np.str_('generates from'),\n",
       "  np.str_('want for'): np.str_('generates from'),\n",
       "  np.str_('satisfies through'): np.str_('generates from'),\n",
       "  np.str_('accepts in'): np.str_('generates from'),\n",
       "  np.str_('generated in'): np.str_('generates from'),\n",
       "  np.str_('satisfy with'): np.str_('generates from'),\n",
       "  np.str_('presented in'): np.str_('generates from'),\n",
       "  np.str_('depend in'): np.str_('generates from'),\n",
       "  np.str_('notice in'): np.str_('generates from'),\n",
       "  np.str_('result with'): np.str_('generates from'),\n",
       "  np.str_('calculates during'): np.str_('generates from'),\n",
       "  np.str_('computes on'): np.str_('generates from'),\n",
       "  np.str_('have with'): np.str_('generates from'),\n",
       "  np.str_('assume between'): np.str_('generates from'),\n",
       "  np.str_('illustrates alongside'): np.str_('generates from'),\n",
       "  np.str_('observe after'): np.str_('generates from'),\n",
       "  np.str_('affect within'): np.str_('generates from'),\n",
       "  np.str_('comprises in'): np.str_('generates from'),\n",
       "  np.str_('present alongside'): np.str_('generates from'),\n",
       "  np.str_('decay in'): np.str_('generates from'),\n",
       "  np.str_('stem from'): np.str_('generates from'),\n",
       "  np.str_('demonstrate for'): np.str_('generates from'),\n",
       "  np.str_('achieves than'): np.str_('generates from'),\n",
       "  np.str_('integrates with'): np.str_('generates from'),\n",
       "  np.str_('achieves in'): np.str_('generates from'),\n",
       "  np.str_('skews of'): np.str_('demonstrate of'),\n",
       "  np.str_('make of'): np.str_('demonstrate of'),\n",
       "  np.str_('have of'): np.str_('demonstrate of'),\n",
       "  np.str_('pose of'): np.str_('demonstrate of'),\n",
       "  np.str_('bias of'): np.str_('demonstrate of'),\n",
       "  np.str_('mitigate of'): np.str_('demonstrate of'),\n",
       "  np.str_('return of'): np.str_('demonstrate of'),\n",
       "  np.str_('concern of'): np.str_('demonstrate of'),\n",
       "  np.str_('assigns of'): np.str_('demonstrate of'),\n",
       "  np.str_('requires of'): np.str_('demonstrate of'),\n",
       "  np.str_('emerged of'): np.str_('demonstrate of'),\n",
       "  np.str_('involve of'): np.str_('demonstrate of'),\n",
       "  np.str_('consists of'): np.str_('demonstrate of'),\n",
       "  np.str_('belonging of'): np.str_('demonstrate of'),\n",
       "  np.str_('create of'): np.str_('demonstrate of'),\n",
       "  np.str_('see of'): np.str_('demonstrate of'),\n",
       "  np.str_('oversee of'): np.str_('demonstrate of'),\n",
       "  np.str_('denote of'): np.str_('demonstrate of'),\n",
       "  np.str_('arises of'): np.str_('demonstrate of'),\n",
       "  np.str_('involves of'): np.str_('demonstrate of'),\n",
       "  np.str_('drop of'): np.str_('demonstrate of'),\n",
       "  np.str_('ensures of'): np.str_('demonstrate of'),\n",
       "  np.str_('compute of'): np.str_('demonstrate of'),\n",
       "  np.str_('contains of'): np.str_('demonstrate of'),\n",
       "  np.str_('prof of'): np.str_('demonstrate of'),\n",
       "  np.str_('span of'): np.str_('demonstrate of'),\n",
       "  np.str_('include of'): np.str_('demonstrate of'),\n",
       "  np.str_('depends of'): np.str_('demonstrate of'),\n",
       "  np.str_('employ of'): np.str_('demonstrate of'),\n",
       "  np.str_('necessitate of'): np.str_('demonstrate of'),\n",
       "  np.str_('measure of'): np.str_('demonstrate of'),\n",
       "  np.str_('affect of'): np.str_('demonstrate of'),\n",
       "  np.str_('increase of'): np.str_('demonstrate of'),\n",
       "  np.str_('denotes of'): np.str_('demonstrate of'),\n",
       "  np.str_('take of'): np.str_('demonstrate of'),\n",
       "  np.str_('define of'): np.str_('demonstrate of'),\n",
       "  np.str_('represents of'): np.str_('demonstrate of'),\n",
       "  np.str_('reduces of'): np.str_('demonstrate of'),\n",
       "  np.str_('propose of'): np.str_('demonstrate of'),\n",
       "  np.str_('integrate of'): np.str_('demonstrate of'),\n",
       "  np.str_('minimizes of'): np.str_('demonstrate of'),\n",
       "  np.str_('generate of'): np.str_('demonstrate of'),\n",
       "  np.str_('achieves of'): np.str_('demonstrate of'),\n",
       "  np.str_('present of'): np.str_('demonstrate of'),\n",
       "  np.str_('constitutes of'): np.str_('demonstrate of'),\n",
       "  np.str_('demonstrate of'): np.str_('demonstrate of'),\n",
       "  np.str_('observe of'): np.str_('demonstrate of'),\n",
       "  np.str_('refers to'): np.str_('refers to'),\n",
       "  np.str_('pose to'): np.str_('pose to'),\n",
       "  np.str_('produce to'): np.str_('produce to'),\n",
       "  np.str_('lead to'): np.str_('lead to'),\n",
       "  np.str_('corresponds to'): np.str_('corresponds to'),\n",
       "  np.str_('vary at'): np.str_('vary at'),\n",
       "  np.str_('defined a'): np.str_('defined a'),\n",
       "  np.str_('designates to'): np.str_('designates to'),\n",
       "  np.str_('guided by'): np.str_('guided by'),\n",
       "  np.str_('include a'): np.str_('include a'),\n",
       "  np.str_('go in'): np.str_('go in'),\n",
       "  np.str_('represent a'): np.str_('represent a'),\n",
       "  np.str_('monitor at'): np.str_('monitor at'),\n",
       "  np.str_('proceed to'): np.str_('proceed to'),\n",
       "  np.str_('apply a'): np.str_('apply a'),\n",
       "  np.str_('denote a'): np.str_('denote a'),\n",
       "  np.str_('gained a'): np.str_('gained a'),\n",
       "  np.str_('incorporates to'): np.str_('incorporates to'),\n",
       "  np.str_('aim at'): np.str_('aim at'),\n",
       "  np.str_('serf to'): np.str_('serf to'),\n",
       "  np.str_('assigns to'): np.str_('assigns to'),\n",
       "  np.str_('ha in'): np.str_('ha in'),\n",
       "  np.str_('contains a'): np.str_('contains a'),\n",
       "  np.str_('led to'): np.str_('led to'),\n",
       "  np.str_('creates a'): np.str_('creates a'),\n",
       "  np.str_('serf a'): np.str_('serf a'),\n",
       "  np.str_('represents a'): np.str_('represents a'),\n",
       "  np.str_('combine a'): np.str_('combine a'),\n",
       "  np.str_('connected to'): np.str_('connected to'),\n",
       "  np.str_('linked to'): np.str_('linked to'),\n",
       "  np.str_('integrate up'): np.str_('integrate up'),\n",
       "  np.str_('view a'): np.str_('view a'),\n",
       "  np.str_('integrate to'): np.str_('integrate to'),\n",
       "  np.str_('write a'): np.str_('write a'),\n",
       "  np.str_('refer to'): np.str_('refer to'),\n",
       "  np.str_('refer a'): np.str_('refer a'),\n",
       "  np.str_('partition a'): np.str_('partition a'),\n",
       "  np.str_('approximate a'): np.str_('approximate a'),\n",
       "  np.str_('come to'): np.str_('come to'),\n",
       "  np.str_('outperform to'): np.str_('outperform to'),\n",
       "  np.str_('added at'): np.str_('added at'),\n",
       "  np.str_('demonstrates to'): np.str_('demonstrates to')}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_words = {}\n",
    "for emb_size in edge_label_map:\n",
    "    cluster_to_words[emb_size] = {}\n",
    "    for label1, label2 in edge_label_map[emb_size].items():\n",
    "        if label2 not in cluster_to_words[emb_size]:\n",
    "            cluster_to_words[emb_size][label2] = []\n",
    "        cluster_to_words[emb_size][label2].append(label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{100: {np.str_('within'): [np.str_('make'),\n",
       "   np.str_('skews'),\n",
       "   np.str_('complicates'),\n",
       "   np.str_('have'),\n",
       "   np.str_('pose'),\n",
       "   np.str_('produce'),\n",
       "   np.str_('deliver'),\n",
       "   np.str_('bias'),\n",
       "   np.str_('shown'),\n",
       "   np.str_('mitigate'),\n",
       "   np.str_('duplicating'),\n",
       "   np.str_('address'),\n",
       "   np.str_('combine'),\n",
       "   np.str_('outperformed'),\n",
       "   np.str_('exhibit'),\n",
       "   np.str_('enable'),\n",
       "   np.str_('return'),\n",
       "   np.str_('generates'),\n",
       "   np.str_('considers'),\n",
       "   np.str_('determine'),\n",
       "   np.str_('defined'),\n",
       "   np.str_('concern'),\n",
       "   np.str_('assigns'),\n",
       "   np.str_('designates'),\n",
       "   np.str_('requires'),\n",
       "   np.str_('involve'),\n",
       "   np.str_('preprocesses'),\n",
       "   np.str_('guide'),\n",
       "   np.str_('categorise'),\n",
       "   np.str_('identify'),\n",
       "   np.str_('distinguish'),\n",
       "   np.str_('embed'),\n",
       "   np.str_('surpass'),\n",
       "   np.str_('include'),\n",
       "   np.str_('consider'),\n",
       "   np.str_('represent'),\n",
       "   np.str_('identified'),\n",
       "   np.str_('implemented'),\n",
       "   np.str_('split'),\n",
       "   np.str_('offer'),\n",
       "   np.str_('observe'),\n",
       "   np.str_('categorize'),\n",
       "   np.str_('utilize'),\n",
       "   np.str_('employ'),\n",
       "   np.str_('monitor'),\n",
       "   np.str_('show'),\n",
       "   np.str_('create'),\n",
       "   np.str_('set'),\n",
       "   np.str_('apply'),\n",
       "   np.str_('utilise'),\n",
       "   np.str_('contains'),\n",
       "   np.str_('provide'),\n",
       "   np.str_('see'),\n",
       "   np.str_('oversee'),\n",
       "   np.str_('denote'),\n",
       "   np.str_('express'),\n",
       "   np.str_('capture'),\n",
       "   np.str_('gained'),\n",
       "   np.str_('enhances'),\n",
       "   np.str_('incorporates'),\n",
       "   np.str_('involves'),\n",
       "   np.str_('drop'),\n",
       "   np.str_('employed'),\n",
       "   np.str_('designated'),\n",
       "   np.str_('serf'),\n",
       "   np.str_('adjusted'),\n",
       "   np.str_('incorporated'),\n",
       "   np.str_('includes'),\n",
       "   np.str_('represents'),\n",
       "   np.str_('constructed'),\n",
       "   np.str_('compute'),\n",
       "   np.str_('filled'),\n",
       "   np.str_('indicate'),\n",
       "   np.str_('utilized'),\n",
       "   np.str_('outperform'),\n",
       "   np.str_('require'),\n",
       "   np.str_('illustrate'),\n",
       "   np.str_('used'),\n",
       "   np.str_('developed'),\n",
       "   np.str_('tested'),\n",
       "   np.str_('trained'),\n",
       "   np.str_('like'),\n",
       "   np.str_('in'),\n",
       "   np.str_('than'),\n",
       "   np.str_('for'),\n",
       "   np.str_('from'),\n",
       "   np.str_('regarding'),\n",
       "   np.str_('with'),\n",
       "   np.str_('during'),\n",
       "   np.str_('including'),\n",
       "   np.str_('along'),\n",
       "   np.str_('between'),\n",
       "   np.str_('among'),\n",
       "   np.str_('behind'),\n",
       "   np.str_('support'),\n",
       "   np.str_('necessitate'),\n",
       "   np.str_('creates'),\n",
       "   np.str_('exploit'),\n",
       "   np.str_('encounter'),\n",
       "   np.str_('introduced'),\n",
       "   np.str_('accelerates'),\n",
       "   np.str_('demonstrated'),\n",
       "   np.str_('measure'),\n",
       "   np.str_('lack'),\n",
       "   np.str_('computes'),\n",
       "   np.str_('conduct'),\n",
       "   np.str_('utilizes'),\n",
       "   np.str_('strike'),\n",
       "   np.str_('connected'),\n",
       "   np.str_('linked'),\n",
       "   np.str_('proposes'),\n",
       "   np.str_('improve'),\n",
       "   np.str_('give'),\n",
       "   np.str_('denotes'),\n",
       "   np.str_('affect'),\n",
       "   np.str_('use'),\n",
       "   np.str_('integrate'),\n",
       "   np.str_('generate'),\n",
       "   np.str_('take'),\n",
       "   np.str_('view'),\n",
       "   np.str_('partition'),\n",
       "   np.str_('share'),\n",
       "   np.str_('proposed'),\n",
       "   np.str_('project'),\n",
       "   np.str_('define'),\n",
       "   np.str_('identifies'),\n",
       "   np.str_('reduces'),\n",
       "   np.str_('propose'),\n",
       "   np.str_('separate'),\n",
       "   np.str_('call'),\n",
       "   np.str_('approximate'),\n",
       "   np.str_('solve'),\n",
       "   np.str_('follow'),\n",
       "   np.str_('satisfies'),\n",
       "   np.str_('accepts'),\n",
       "   np.str_('approximates'),\n",
       "   np.str_('satisfy'),\n",
       "   np.str_('write'),\n",
       "   np.str_('generated'),\n",
       "   np.str_('minimizes'),\n",
       "   np.str_('possess'),\n",
       "   np.str_('refer'),\n",
       "   np.str_('choose'),\n",
       "   np.str_('follows'),\n",
       "   np.str_('notice'),\n",
       "   np.str_('achieves'),\n",
       "   np.str_('calculates'),\n",
       "   np.str_('integrates'),\n",
       "   np.str_('assume'),\n",
       "   np.str_('illustrates'),\n",
       "   np.str_('present'),\n",
       "   np.str_('constitutes'),\n",
       "   np.str_('comprises'),\n",
       "   np.str_('demonstrate'),\n",
       "   np.str_('enables'),\n",
       "   np.str_('demonstrates'),\n",
       "   np.str_('explore'),\n",
       "   np.str_('within'),\n",
       "   np.str_('under'),\n",
       "   np.str_('over'),\n",
       "   np.str_('involving'),\n",
       "   np.str_('after'),\n",
       "   np.str_('about')],\n",
       "  np.str_('of'): [np.str_('of')],\n",
       "  np.str_('ha'): [np.str_('ha')],\n",
       "  np.str_('to'): [np.str_('to')],\n",
       "  np.str_('a'): [np.str_('a')],\n",
       "  np.str_('at'): [np.str_('at')],\n",
       "  np.str_('on'): [np.str_('on')],\n",
       "  np.str_('us'): [np.str_('us')],\n",
       "  np.str_('by'): [np.str_('by')]},\n",
       " 200: {np.str_('generates from'): [np.str_('make on'),\n",
       "   np.str_('hinge on'),\n",
       "   np.str_('become towards'),\n",
       "   np.str_('deliver for'),\n",
       "   np.str_('bias towards'),\n",
       "   np.str_('rely on'),\n",
       "   np.str_('delve into'),\n",
       "   np.str_('address from'),\n",
       "   np.str_('combine in'),\n",
       "   np.str_('outperformed in'),\n",
       "   np.str_('generates from'),\n",
       "   np.str_('determine in'),\n",
       "   np.str_('lie in'),\n",
       "   np.str_('operates on'),\n",
       "   np.str_('concluded in'),\n",
       "   np.str_('guide through'),\n",
       "   np.str_('categorise among'),\n",
       "   np.str_('embed in'),\n",
       "   np.str_('consider in'),\n",
       "   np.str_('result in'),\n",
       "   np.str_('identified in'),\n",
       "   np.str_('split through'),\n",
       "   np.str_('offer for'),\n",
       "   np.str_('observe in'),\n",
       "   np.str_('appears across'),\n",
       "   np.str_('categorize in'),\n",
       "   np.str_('elaborate on'),\n",
       "   np.str_('improve over'),\n",
       "   np.str_('set for'),\n",
       "   np.str_('utilise in'),\n",
       "   np.str_('contains in'),\n",
       "   np.str_('capture between'),\n",
       "   np.str_('gained on'),\n",
       "   np.str_('enhances through'),\n",
       "   np.str_('depend on'),\n",
       "   np.str_('employ for'),\n",
       "   np.str_('focus on'),\n",
       "   np.str_('designated for'),\n",
       "   np.str_('adjusted on'),\n",
       "   np.str_('incorporated into'),\n",
       "   np.str_('incorporates for'),\n",
       "   np.str_('exhibit for'),\n",
       "   np.str_('remain throughout'),\n",
       "   np.str_('span from'),\n",
       "   np.str_('represents on'),\n",
       "   np.str_('indicate in'),\n",
       "   np.str_('outperform in'),\n",
       "   np.str_('compute in'),\n",
       "   np.str_('performed than'),\n",
       "   np.str_('employed for'),\n",
       "   np.str_('require for'),\n",
       "   np.str_('require in'),\n",
       "   np.str_('proven in'),\n",
       "   np.str_('exhibit from'),\n",
       "   np.str_('change over'),\n",
       "   np.str_('developed for'),\n",
       "   np.str_('trained on'),\n",
       "   np.str_('support in'),\n",
       "   np.str_('arise from'),\n",
       "   np.str_('gained due'),\n",
       "   np.str_('struggle with'),\n",
       "   np.str_('exploit in'),\n",
       "   np.str_('encounter with'),\n",
       "   np.str_('demonstrated over'),\n",
       "   np.str_('suffers from'),\n",
       "   np.str_('lack in'),\n",
       "   np.str_('measure over'),\n",
       "   np.str_('conduct on'),\n",
       "   np.str_('suffer from'),\n",
       "   np.str_('strike between'),\n",
       "   np.str_('relies on'),\n",
       "   np.str_('generates for'),\n",
       "   np.str_('improve on'),\n",
       "   np.str_('give for'),\n",
       "   np.str_('show on'),\n",
       "   np.str_('result into'),\n",
       "   np.str_('include for'),\n",
       "   np.str_('drop in'),\n",
       "   np.str_('introduced on'),\n",
       "   np.str_('requires on'),\n",
       "   np.str_('creates on'),\n",
       "   np.str_('partition into'),\n",
       "   np.str_('share within'),\n",
       "   np.str_('share on'),\n",
       "   np.str_('project onto'),\n",
       "   np.str_('represents in'),\n",
       "   np.str_('separate into'),\n",
       "   np.str_('varies with'),\n",
       "   np.str_('need in'),\n",
       "   np.str_('want for'),\n",
       "   np.str_('satisfies through'),\n",
       "   np.str_('accepts in'),\n",
       "   np.str_('generated in'),\n",
       "   np.str_('satisfy with'),\n",
       "   np.str_('presented in'),\n",
       "   np.str_('depend in'),\n",
       "   np.str_('notice in'),\n",
       "   np.str_('result with'),\n",
       "   np.str_('calculates during'),\n",
       "   np.str_('computes on'),\n",
       "   np.str_('have with'),\n",
       "   np.str_('assume between'),\n",
       "   np.str_('illustrates alongside'),\n",
       "   np.str_('observe after'),\n",
       "   np.str_('affect within'),\n",
       "   np.str_('comprises in'),\n",
       "   np.str_('present alongside'),\n",
       "   np.str_('decay in'),\n",
       "   np.str_('stem from'),\n",
       "   np.str_('demonstrate for'),\n",
       "   np.str_('achieves than'),\n",
       "   np.str_('integrates with'),\n",
       "   np.str_('achieves in')],\n",
       "  np.str_('demonstrate of'): [np.str_('skews of'),\n",
       "   np.str_('make of'),\n",
       "   np.str_('have of'),\n",
       "   np.str_('pose of'),\n",
       "   np.str_('bias of'),\n",
       "   np.str_('mitigate of'),\n",
       "   np.str_('return of'),\n",
       "   np.str_('concern of'),\n",
       "   np.str_('assigns of'),\n",
       "   np.str_('requires of'),\n",
       "   np.str_('emerged of'),\n",
       "   np.str_('involve of'),\n",
       "   np.str_('consists of'),\n",
       "   np.str_('belonging of'),\n",
       "   np.str_('create of'),\n",
       "   np.str_('see of'),\n",
       "   np.str_('oversee of'),\n",
       "   np.str_('denote of'),\n",
       "   np.str_('arises of'),\n",
       "   np.str_('involves of'),\n",
       "   np.str_('drop of'),\n",
       "   np.str_('ensures of'),\n",
       "   np.str_('compute of'),\n",
       "   np.str_('contains of'),\n",
       "   np.str_('prof of'),\n",
       "   np.str_('span of'),\n",
       "   np.str_('include of'),\n",
       "   np.str_('depends of'),\n",
       "   np.str_('employ of'),\n",
       "   np.str_('necessitate of'),\n",
       "   np.str_('measure of'),\n",
       "   np.str_('affect of'),\n",
       "   np.str_('increase of'),\n",
       "   np.str_('denotes of'),\n",
       "   np.str_('take of'),\n",
       "   np.str_('define of'),\n",
       "   np.str_('represents of'),\n",
       "   np.str_('reduces of'),\n",
       "   np.str_('propose of'),\n",
       "   np.str_('integrate of'),\n",
       "   np.str_('minimizes of'),\n",
       "   np.str_('generate of'),\n",
       "   np.str_('achieves of'),\n",
       "   np.str_('present of'),\n",
       "   np.str_('constitutes of'),\n",
       "   np.str_('demonstrate of'),\n",
       "   np.str_('observe of')],\n",
       "  np.str_('refers to'): [np.str_('refers to')],\n",
       "  np.str_('pose to'): [np.str_('pose to')],\n",
       "  np.str_('produce to'): [np.str_('produce to')],\n",
       "  np.str_('lead to'): [np.str_('lead to')],\n",
       "  np.str_('corresponds to'): [np.str_('corresponds to')],\n",
       "  np.str_('vary at'): [np.str_('vary at')],\n",
       "  np.str_('defined a'): [np.str_('defined a')],\n",
       "  np.str_('designates to'): [np.str_('designates to')],\n",
       "  np.str_('guided by'): [np.str_('guided by')],\n",
       "  np.str_('include a'): [np.str_('include a')],\n",
       "  np.str_('go in'): [np.str_('go in')],\n",
       "  np.str_('represent a'): [np.str_('represent a')],\n",
       "  np.str_('monitor at'): [np.str_('monitor at')],\n",
       "  np.str_('proceed to'): [np.str_('proceed to')],\n",
       "  np.str_('apply a'): [np.str_('apply a')],\n",
       "  np.str_('denote a'): [np.str_('denote a')],\n",
       "  np.str_('gained a'): [np.str_('gained a')],\n",
       "  np.str_('incorporates to'): [np.str_('incorporates to')],\n",
       "  np.str_('aim at'): [np.str_('aim at')],\n",
       "  np.str_('serf to'): [np.str_('serf to')],\n",
       "  np.str_('assigns to'): [np.str_('assigns to')],\n",
       "  np.str_('ha in'): [np.str_('ha in')],\n",
       "  np.str_('contains a'): [np.str_('contains a')],\n",
       "  np.str_('led to'): [np.str_('led to')],\n",
       "  np.str_('creates a'): [np.str_('creates a')],\n",
       "  np.str_('serf a'): [np.str_('serf a')],\n",
       "  np.str_('represents a'): [np.str_('represents a')],\n",
       "  np.str_('combine a'): [np.str_('combine a')],\n",
       "  np.str_('connected to'): [np.str_('connected to')],\n",
       "  np.str_('linked to'): [np.str_('linked to')],\n",
       "  np.str_('integrate up'): [np.str_('integrate up')],\n",
       "  np.str_('view a'): [np.str_('view a')],\n",
       "  np.str_('integrate to'): [np.str_('integrate to')],\n",
       "  np.str_('write a'): [np.str_('write a')],\n",
       "  np.str_('refer to'): [np.str_('refer to')],\n",
       "  np.str_('refer a'): [np.str_('refer a')],\n",
       "  np.str_('partition a'): [np.str_('partition a')],\n",
       "  np.str_('approximate a'): [np.str_('approximate a')],\n",
       "  np.str_('come to'): [np.str_('come to')],\n",
       "  np.str_('outperform to'): [np.str_('outperform to')],\n",
       "  np.str_('added at'): [np.str_('added at')],\n",
       "  np.str_('demonstrates to'): [np.str_('demonstrates to')]}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_to_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_amount = {}\n",
    "for emb_size in cluster_to_words:\n",
    "    clusters_amount[emb_size]=len(cluster_to_words[emb_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{100: 9, 200: 44}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set()\n",
    "for edge in graph.edges:\n",
    "    unique_labels.add(edge.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "rgb(87, 104, 117)"
         },
         "mode": "markers+text",
         "name": "Cluster (within), Size: 521",
         "text": [
          "make",
          "skews",
          "complicates",
          "have",
          "pose",
          "produce",
          "deliver",
          "bias",
          "shown",
          "mitigate",
          "duplicating",
          "address",
          "address",
          "combine",
          "duplicating",
          "outperformed",
          "exhibit",
          "exhibit",
          "enable",
          "return",
          "return",
          "generates",
          "considers",
          "considers",
          "determine",
          "defined",
          "concern",
          "concern",
          "assigns",
          "designates",
          "requires",
          "involve",
          "preprocesses",
          "preprocesses",
          "guide",
          "categorise",
          "identify",
          "distinguish",
          "embed",
          "surpass",
          "include",
          "consider",
          "represent",
          "identified",
          "implemented",
          "split",
          "offer",
          "offer",
          "observe",
          "categorize",
          "utilize",
          "employ",
          "monitor",
          "show",
          "create",
          "set",
          "apply",
          "utilise",
          "utilise",
          "contains",
          "have",
          "provide",
          "see",
          "oversee",
          "denote",
          "denote",
          "express",
          "capture",
          "capture",
          "gained",
          "enhances",
          "employ",
          "incorporates",
          "offer",
          "involves",
          "drop",
          "employed",
          "designated",
          "serf",
          "adjusted",
          "incorporated",
          "incorporates",
          "assigns",
          "exhibit",
          "includes",
          "have",
          "have",
          "have",
          "have",
          "have",
          "have",
          "contains",
          "represents",
          "constructed",
          "include",
          "compute",
          "filled",
          "constructed",
          "indicate",
          "utilized",
          "utilized",
          "contains",
          "utilized",
          "outperform",
          "employed",
          "require",
          "illustrate",
          "contains",
          "complicates",
          "consider",
          "identified",
          "used",
          "used",
          "exhibit",
          "developed",
          "tested",
          "trained",
          "used",
          "like",
          "in",
          "in",
          "in",
          "in",
          "than",
          "for",
          "like",
          "in",
          "in",
          "from",
          "regarding",
          "for",
          "like",
          "for",
          "with",
          "for",
          "from",
          "for",
          "for",
          "in",
          "with",
          "for",
          "for",
          "in",
          "for",
          "during",
          "regarding",
          "for",
          "in",
          "for",
          "in",
          "including",
          "in",
          "along",
          "in",
          "from",
          "in",
          "in",
          "in",
          "for",
          "for",
          "for",
          "with",
          "with",
          "between",
          "between",
          "in",
          "for",
          "between",
          "between",
          "in",
          "regarding",
          "for",
          "in",
          "for",
          "with",
          "among",
          "from",
          "with",
          "behind",
          "for",
          "for",
          "for",
          "for",
          "for",
          "for",
          "for",
          "for",
          "in",
          "with",
          "during",
          "between",
          "between",
          "with",
          "between",
          "for",
          "for",
          "for",
          "in",
          "for",
          "than",
          "for",
          "with",
          "in",
          "from",
          "for",
          "for",
          "for",
          "in",
          "in",
          "with",
          "support",
          "gained",
          "include",
          "include",
          "have",
          "have",
          "employ",
          "employ",
          "necessitate",
          "creates",
          "creates",
          "creates",
          "represents",
          "exploit",
          "include",
          "include",
          "encounter",
          "introduced",
          "introduced",
          "combine",
          "accelerates",
          "demonstrated",
          "include",
          "include",
          "include",
          "measure",
          "lack",
          "lack",
          "computes",
          "measure",
          "conduct",
          "utilizes",
          "strike",
          "connected",
          "connected",
          "linked",
          "linked",
          "proposes",
          "generates",
          "generates",
          "generates",
          "generates",
          "include",
          "include",
          "improve",
          "involves",
          "give",
          "denotes",
          "represents",
          "show",
          "make",
          "affect",
          "use",
          "integrate",
          "integrate",
          "include",
          "include",
          "drop",
          "generate",
          "computes",
          "computes",
          "denotes",
          "affect",
          "affect",
          "introduced",
          "introduced",
          "take",
          "view",
          "view",
          "requires",
          "creates",
          "partition",
          "share",
          "demonstrated",
          "proposed",
          "proposed",
          "project",
          "define",
          "represents",
          "identifies",
          "identifies",
          "reduces",
          "propose",
          "propose",
          "separate",
          "call",
          "call",
          "call",
          "call",
          "approximate",
          "solve",
          "follow",
          "follow",
          "define",
          "satisfies",
          "utilize",
          "approximate",
          "approximate",
          "accepts",
          "accepts",
          "accepts",
          "accepts",
          "denote",
          "denote",
          "approximates",
          "solve",
          "generates",
          "integrate",
          "satisfy",
          "satisfy",
          "integrate",
          "integrate",
          "write",
          "generated",
          "represent",
          "minimizes",
          "generate",
          "generate",
          "generate",
          "generate",
          "satisfy",
          "satisfy",
          "require",
          "possess",
          "possess",
          "follow",
          "take",
          "refer",
          "choose",
          "partition",
          "affect",
          "address",
          "denote",
          "approximate",
          "follows",
          "involves",
          "notice",
          "notice",
          "outperform",
          "achieves",
          "achieves",
          "achieves",
          "calculates",
          "integrates",
          "integrates",
          "computes",
          "computes",
          "computes",
          "computes",
          "have",
          "have",
          "assume",
          "illustrates",
          "have",
          "present",
          "observe",
          "compute",
          "affect",
          "constitutes",
          "comprises",
          "exhibit",
          "demonstrate",
          "achieves",
          "achieves",
          "achieves",
          "affect",
          "observe",
          "observe",
          "enables",
          "present",
          "integrates",
          "incorporates",
          "demonstrates",
          "demonstrates",
          "demonstrates",
          "outperform",
          "outperform",
          "achieves",
          "achieves",
          "achieves",
          "achieves",
          "explore",
          "have",
          "have",
          "including",
          "in",
          "among",
          "within",
          "like",
          "for",
          "under",
          "in",
          "with",
          "with",
          "in",
          "over",
          "for",
          "involving",
          "over",
          "in",
          "between",
          "in",
          "between",
          "for",
          "with",
          "in",
          "for",
          "for",
          "for",
          "for",
          "in",
          "for",
          "with",
          "with",
          "for",
          "with",
          "in",
          "within",
          "within",
          "between",
          "with",
          "in",
          "in",
          "for",
          "in",
          "for",
          "in",
          "behind",
          "in",
          "than",
          "with",
          "in",
          "in",
          "in",
          "in",
          "in",
          "in",
          "for",
          "in",
          "for",
          "for",
          "for",
          "for",
          "in",
          "in",
          "in",
          "with",
          "in",
          "in",
          "with",
          "in",
          "in",
          "in",
          "in",
          "between",
          "in",
          "in",
          "in",
          "in",
          "with",
          "with",
          "in",
          "in",
          "for",
          "for",
          "with",
          "in",
          "in",
          "with",
          "in",
          "in",
          "with",
          "in",
          "in",
          "in",
          "in",
          "with",
          "within",
          "in",
          "after",
          "for",
          "than",
          "during",
          "along",
          "in",
          "among",
          "including",
          "with",
          "about",
          "with",
          "with",
          "between",
          "in",
          "in",
          "after",
          "in",
          "within",
          "in",
          "in",
          "in",
          "about",
          "in",
          "for",
          "for",
          "for",
          "in",
          "in",
          "in",
          "with",
          "with",
          "in"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          -0.8075286149978638,
          -0.783499002456665,
          -0.9269558191299438,
          -0.9365538954734802,
          -1.0216823816299438,
          -0.9265215992927551,
          -0.96108478307724,
          -0.8377408385276794,
          -0.9961404800415039,
          -0.9399155378341675,
          -0.930324137210846,
          -0.977988064289093,
          -0.977988064289093,
          -0.9341570734977722,
          -0.930324137210846,
          -0.9991594552993774,
          -0.9346702694892883,
          -0.9346702694892883,
          -0.9360049962997437,
          -0.9321929812431335,
          -0.9321929812431335,
          -0.9392071962356567,
          -0.9326347708702087,
          -0.9326347708702087,
          -0.9331007599830627,
          -0.9767429828643799,
          -0.9978147149085999,
          -0.9978147149085999,
          -0.8574137091636658,
          -0.9174848794937134,
          -0.9110671281814575,
          -0.8920738697052002,
          -0.9578040242195129,
          -0.9578040242195129,
          -0.9931908249855042,
          -0.9549306631088257,
          -0.9647846817970276,
          -0.9645739197731018,
          -0.9406571984291077,
          -0.8783796429634094,
          -0.8738281726837158,
          -0.9259719848632812,
          -0.9493427276611328,
          -0.9970576763153076,
          -1.0407360792160034,
          -0.9249662160873413,
          -0.9337721467018127,
          -0.9337721467018127,
          -0.9364127516746521,
          -0.9589204788208008,
          -0.947776198387146,
          -0.9488114714622498,
          -0.9730490446090698,
          -0.9149404764175415,
          -0.9067652821540833,
          -0.8979487419128418,
          -0.9831912517547607,
          -0.9268267154693604,
          -0.9268267154693604,
          -0.8951629400253296,
          -0.9365538954734802,
          -0.9512694478034973,
          -0.8673482537269592,
          -0.9071614742279053,
          -0.8824906945228577,
          -0.8824906945228577,
          -0.9598715901374817,
          -0.9228110909461975,
          -0.9228110909461975,
          -0.9256038665771484,
          -0.8794186115264893,
          -0.9488114714622498,
          -0.935491144657135,
          -0.9337721467018127,
          -0.8564745187759399,
          -0.9308982491493225,
          -1.0013830661773682,
          -0.9712148904800415,
          -0.83335942029953,
          -1.006111979484558,
          -0.9794865846633911,
          -0.935491144657135,
          -0.8574137091636658,
          -0.9346702694892883,
          -0.8748239874839783,
          -0.9365538954734802,
          -0.9365538954734802,
          -0.9365538954734802,
          -0.9365538954734802,
          -0.9365538954734802,
          -0.9365538954734802,
          -0.8951629400253296,
          -0.9216364026069641,
          -0.9667761921882629,
          -0.8738281726837158,
          -0.9057883024215698,
          -0.9332024455070496,
          -0.9667761921882629,
          -0.9514416456222534,
          -0.9955784678459167,
          -0.9955784678459167,
          -0.8951629400253296,
          -0.9955784678459167,
          -1.0168700218200684,
          -1.0013830661773682,
          -0.9328811764717102,
          -0.9693799614906311,
          -0.8951629400253296,
          -0.9269558191299438,
          -0.9259719848632812,
          -0.9970576763153076,
          -0.9977878928184509,
          -0.9977878928184509,
          -0.9346702694892883,
          -1.0071306228637695,
          -1.023180365562439,
          -1.0149149894714355,
          -0.9977878928184509,
          -0.8877211213111877,
          0.3160170316696167,
          0.3160170316696167,
          0.3160170316696167,
          0.3160170316696167,
          -0.8480261564254761,
          -0.6968483924865723,
          -0.8877211213111877,
          0.3160170316696167,
          0.3160170316696167,
          -0.6862431764602661,
          -0.9219372272491455,
          -0.6968483924865723,
          -0.8877211213111877,
          -0.6968483924865723,
          -0.8094186782836914,
          -0.6968483924865723,
          -0.6862431764602661,
          -0.6968483924865723,
          -0.6968483924865723,
          0.3160170316696167,
          -0.8094186782836914,
          -0.6968483924865723,
          -0.6968483924865723,
          0.3160170316696167,
          -0.6968483924865723,
          -0.8274312615394592,
          -0.9219372272491455,
          -0.6968483924865723,
          0.3160170316696167,
          -0.6968483924865723,
          0.3160170316696167,
          -0.8856127262115479,
          0.3160170316696167,
          -0.9224544763565063,
          0.3160170316696167,
          -0.6862431764602661,
          0.3160170316696167,
          0.3160170316696167,
          0.3160170316696167,
          -0.6968483924865723,
          -0.6968483924865723,
          -0.6968483924865723,
          -0.8094186782836914,
          -0.8094186782836914,
          -0.8197082281112671,
          -0.8197082281112671,
          0.3160170316696167,
          -0.6968483924865723,
          -0.8197082281112671,
          -0.8197082281112671,
          0.3160170316696167,
          -0.9219372272491455,
          -0.6968483924865723,
          0.3160170316696167,
          -0.6968483924865723,
          -0.8094186782836914,
          -0.8381604552268982,
          -0.6862431764602661,
          -0.8094186782836914,
          -0.9056673645973206,
          -0.6968483924865723,
          -0.6968483924865723,
          -0.6968483924865723,
          -0.6968483924865723,
          -0.6968483924865723,
          -0.6968483924865723,
          -0.6968483924865723,
          -0.6968483924865723,
          0.3160170316696167,
          -0.8094186782836914,
          -0.8274312615394592,
          -0.8197082281112671,
          -0.8197082281112671,
          -0.8094186782836914,
          -0.8197082281112671,
          -0.6968483924865723,
          -0.6968483924865723,
          -0.6968483924865723,
          0.3160170316696167,
          -0.6968483924865723,
          -0.8480261564254761,
          -0.6968483924865723,
          -0.8094186782836914,
          0.3160170316696167,
          -0.6862431764602661,
          -0.6968483924865723,
          -0.6968483924865723,
          -0.6968483924865723,
          0.3160170316696167,
          0.3160170316696167,
          -0.8094186782836914,
          -0.9879557490348816,
          -0.9256038665771484,
          -0.8738281726837158,
          -0.8738281726837158,
          -0.9365538954734802,
          -0.9365538954734802,
          -0.9488114714622498,
          -0.9488114714622498,
          -0.9193821549415588,
          -0.9139801263809204,
          -0.9139801263809204,
          -0.9139801263809204,
          -0.9216364026069641,
          -0.9572762846946716,
          -0.8738281726837158,
          -0.8738281726837158,
          -0.9701434969902039,
          -1.017072319984436,
          -1.017072319984436,
          -0.9341570734977722,
          -0.9340956807136536,
          -0.9889018535614014,
          -0.8738281726837158,
          -0.8738281726837158,
          -0.8738281726837158,
          -0.9562920928001404,
          -0.657047688961029,
          -0.657047688961029,
          -0.9103108644485474,
          -0.9562920928001404,
          -0.9754393696784973,
          -0.9176464676856995,
          -0.980135977268219,
          -0.9785552620887756,
          -0.9785552620887756,
          -0.9691063165664673,
          -0.9691063165664673,
          -0.9472578763961792,
          -0.9392071962356567,
          -0.9392071962356567,
          -0.9392071962356567,
          -0.9392071962356567,
          -0.8738281726837158,
          -0.8738281726837158,
          -0.9793233871459961,
          -0.8564745187759399,
          -0.9318578243255615,
          -0.8835648894309998,
          -0.9216364026069641,
          -0.9149404764175415,
          -0.8075299859046936,
          -0.9342318773269653,
          -0.8173179030418396,
          -0.9589552879333496,
          -0.9589552879333496,
          -0.8738281726837158,
          -0.8738281726837158,
          -0.9308982491493225,
          -0.9389991164207458,
          -0.9103108644485474,
          -0.9103108644485474,
          -0.8835648894309998,
          -0.9342318773269653,
          -0.9342318773269653,
          -1.017072319984436,
          -1.017072319984436,
          -0.8693327903747559,
          -0.8171790242195129,
          -0.8171790242195129,
          -0.9110671281814575,
          -0.9139801263809204,
          -0.9266711473464966,
          -0.9357640147209167,
          -0.9889018535614014,
          -0.9730271100997925,
          -0.9730271100997925,
          -0.9769713282585144,
          -0.9250435829162598,
          -0.9216364026069641,
          -0.9549364447593689,
          -0.9549364447593689,
          -0.8581308722496033,
          -0.9654391407966614,
          -0.9654391407966614,
          -0.9390540719032288,
          -0.9741849303245544,
          -0.9741849303245544,
          -0.9741849303245544,
          -0.9741849303245544,
          -0.9353705048561096,
          -0.9728720188140869,
          -1.0233367681503296,
          -1.0233367681503296,
          -0.9250435829162598,
          -0.9382658004760742,
          -0.947776198387146,
          -0.9353705048561096,
          -0.9353705048561096,
          -0.9367404580116272,
          -0.9367404580116272,
          -0.9367404580116272,
          -0.9367404580116272,
          -0.8824906945228577,
          -0.8824906945228577,
          -0.92292720079422,
          -0.9728720188140869,
          -0.9392071962356567,
          -0.9589552879333496,
          -0.9325805902481079,
          -0.9325805902481079,
          -0.9589552879333496,
          -0.9589552879333496,
          -1.0050394535064697,
          -0.9754154086112976,
          -0.9493427276611328,
          -0.9096889495849609,
          -0.9389991164207458,
          -0.9389991164207458,
          -0.9389991164207458,
          -0.9389991164207458,
          -0.9325805902481079,
          -0.9325805902481079,
          -0.9328811764717102,
          -0.8822461366653442,
          -0.8822461366653442,
          -1.0233367681503296,
          -0.8693327903747559,
          -0.939423143863678,
          -0.955720841884613,
          -0.9266711473464966,
          -0.9342318773269653,
          -0.977988064289093,
          -0.8824906945228577,
          -0.9353705048561096,
          -0.981490433216095,
          -0.8564745187759399,
          -0.9454237222671509,
          -0.9454237222671509,
          -1.0168700218200684,
          -0.9196404814720154,
          -0.9196404814720154,
          -0.9196404814720154,
          -0.9393737316131592,
          -0.9408080577850342,
          -0.9408080577850342,
          -0.9103108644485474,
          -0.9103108644485474,
          -0.9103108644485474,
          -0.9103108644485474,
          -0.9365538954734802,
          -0.9365538954734802,
          -0.9577840566635132,
          -0.9536901116371155,
          -0.9365538954734802,
          -0.9450639486312866,
          -0.9364127516746521,
          -0.9057883024215698,
          -0.9342318773269653,
          -0.8743138313293457,
          -0.8288002014160156,
          -0.9346702694892883,
          -0.9605397582054138,
          -0.9196404814720154,
          -0.9196404814720154,
          -0.9196404814720154,
          -0.9342318773269653,
          -0.9364127516746521,
          -0.9364127516746521,
          -0.8893353939056396,
          -0.9450639486312866,
          -0.9408080577850342,
          -0.935491144657135,
          -0.9600182771682739,
          -0.9600182771682739,
          -0.9600182771682739,
          -1.0168700218200684,
          -1.0168700218200684,
          -0.9196404814720154,
          -0.9196404814720154,
          -0.9196404814720154,
          -0.9196404814720154,
          -0.8831858038902283,
          -0.9365538954734802,
          -0.9365538954734802,
          -0.8856127262115479,
          0.3160170316696167,
          -0.8381604552268982,
          -0.8287113904953003,
          -0.8877211213111877,
          -0.6968483924865723,
          -0.8459729552268982,
          0.3160170316696167,
          -0.8094186782836914,
          -0.8094186782836914,
          0.3160170316696167,
          -0.8061575889587402,
          -0.6968483924865723,
          -0.8940405249595642,
          -0.8061575889587402,
          0.3160170316696167,
          -0.8197082281112671,
          0.3160170316696167,
          -0.8197082281112671,
          -0.6968483924865723,
          -0.8094186782836914,
          0.3160170316696167,
          -0.6968483924865723,
          -0.6968483924865723,
          -0.6968483924865723,
          -0.6968483924865723,
          0.3160170316696167,
          -0.6968483924865723,
          -0.8094186782836914,
          -0.8094186782836914,
          -0.6968483924865723,
          -0.8094186782836914,
          0.3160170316696167,
          -0.8287113904953003,
          -0.8287113904953003,
          -0.8197082281112671,
          -0.8094186782836914,
          0.3160170316696167,
          0.3160170316696167,
          -0.6968483924865723,
          0.3160170316696167,
          -0.6968483924865723,
          0.3160170316696167,
          -0.9056673645973206,
          0.3160170316696167,
          -0.8480261564254761,
          -0.8094186782836914,
          0.3160170316696167,
          0.3160170316696167,
          0.3160170316696167,
          0.3160170316696167,
          0.3160170316696167,
          0.3160170316696167,
          -0.6968483924865723,
          0.3160170316696167,
          -0.6968483924865723,
          -0.6968483924865723,
          -0.6968483924865723,
          -0.6968483924865723,
          0.3160170316696167,
          0.3160170316696167,
          0.3160170316696167,
          -0.8094186782836914,
          0.3160170316696167,
          0.3160170316696167,
          -0.8094186782836914,
          0.3160170316696167,
          0.3160170316696167,
          0.3160170316696167,
          0.3160170316696167,
          -0.8197082281112671,
          0.3160170316696167,
          0.3160170316696167,
          0.3160170316696167,
          0.3160170316696167,
          -0.8094186782836914,
          -0.8094186782836914,
          0.3160170316696167,
          0.3160170316696167,
          -0.6968483924865723,
          -0.6968483924865723,
          -0.8094186782836914,
          0.3160170316696167,
          0.3160170316696167,
          -0.8094186782836914,
          0.3160170316696167,
          0.3160170316696167,
          -0.8094186782836914,
          0.3160170316696167,
          0.3160170316696167,
          0.3160170316696167,
          0.3160170316696167,
          -0.8094186782836914,
          -0.8287113904953003,
          0.3160170316696167,
          -0.8177841901779175,
          -0.6968483924865723,
          -0.8480261564254761,
          -0.8274312615394592,
          -0.9224544763565063,
          0.3160170316696167,
          -0.8381604552268982,
          -0.8856127262115479,
          -0.8094186782836914,
          -0.8698123693466187,
          -0.8094186782836914,
          -0.8094186782836914,
          -0.8197082281112671,
          0.3160170316696167,
          0.3160170316696167,
          -0.8177841901779175,
          0.3160170316696167,
          -0.8287113904953003,
          0.3160170316696167,
          0.3160170316696167,
          0.3160170316696167,
          -0.8698123693466187,
          0.3160170316696167,
          -0.6968483924865723,
          -0.6968483924865723,
          -0.6968483924865723,
          0.3160170316696167,
          0.3160170316696167,
          0.3160170316696167,
          -0.8094186782836914,
          -0.8094186782836914,
          0.3160170316696167
         ],
         "y": [
          -0.19524377584457397,
          -0.187664195895195,
          -0.3140936493873596,
          -0.2162151336669922,
          -0.11710994690656662,
          -0.27111539244651794,
          -0.23242489993572235,
          -0.324038565158844,
          -0.2456997036933899,
          -0.2780178189277649,
          -0.32562097907066345,
          -0.22678624093532562,
          -0.22678624093532562,
          -0.26869678497314453,
          -0.32562097907066345,
          -0.28454744815826416,
          -0.2712119519710541,
          -0.2712119519710541,
          -0.23772107064723969,
          -0.24377267062664032,
          -0.24377267062664032,
          -0.30211594700813293,
          -0.30561137199401855,
          -0.30561137199401855,
          -0.2628295123577118,
          -0.28662165999412537,
          -0.3282534182071686,
          -0.3282534182071686,
          -0.29881614446640015,
          -0.2995082437992096,
          -0.3100741505622864,
          -0.30089670419692993,
          -0.31632545590400696,
          -0.31632545590400696,
          -0.2429598718881607,
          -0.28125327825546265,
          -0.27748337388038635,
          -0.3178119659423828,
          -0.2050004005432129,
          -0.26579946279525757,
          -0.2866121232509613,
          -0.26813772320747375,
          -0.28277093172073364,
          -0.32426562905311584,
          -0.29468151926994324,
          -0.20091982185840607,
          -0.2454848289489746,
          -0.2454848289489746,
          -0.2259337455034256,
          -0.298433780670166,
          -0.2673437297344208,
          -0.26140937209129333,
          -0.25324779748916626,
          -0.1217840239405632,
          -0.2290235459804535,
          -0.08015713840723038,
          -0.22051803767681122,
          -0.25922632217407227,
          -0.25922632217407227,
          -0.30731630325317383,
          -0.2162151336669922,
          -0.23646461963653564,
          -0.018236182630062103,
          -0.2552778124809265,
          -0.250306636095047,
          -0.250306636095047,
          -0.2513968050479889,
          -0.2823563516139984,
          -0.2823563516139984,
          -0.23518776893615723,
          -0.3226819634437561,
          -0.26140937209129333,
          -0.3181803226470947,
          -0.2454848289489746,
          -0.30432572960853577,
          -0.08263074606657028,
          -0.3101750314235687,
          -0.2773912847042084,
          -0.2043108493089676,
          -0.2511889636516571,
          -0.2997961640357971,
          -0.3181803226470947,
          -0.29881614446640015,
          -0.2712119519710541,
          -0.30477097630500793,
          -0.2162151336669922,
          -0.2162151336669922,
          -0.2162151336669922,
          -0.2162151336669922,
          -0.2162151336669922,
          -0.2162151336669922,
          -0.30731630325317383,
          -0.2990272045135498,
          -0.2832617163658142,
          -0.2866121232509613,
          -0.2312442660331726,
          -0.24225860834121704,
          -0.2832617163658142,
          -0.29366350173950195,
          -0.2886362075805664,
          -0.2886362075805664,
          -0.30731630325317383,
          -0.2886362075805664,
          -0.25231701135635376,
          -0.3101750314235687,
          -0.28946271538734436,
          -0.29105299711227417,
          -0.30731630325317383,
          -0.3140936493873596,
          -0.26813772320747375,
          -0.32426562905311584,
          -0.21345101296901703,
          -0.21345101296901703,
          -0.2712119519710541,
          -0.29475879669189453,
          -0.2687376141548157,
          -0.28366929292678833,
          -0.21345101296901703,
          -0.14361906051635742,
          1.3090496063232422,
          1.3090496063232422,
          1.3090496063232422,
          1.3090496063232422,
          -0.20255805552005768,
          -0.07105232030153275,
          -0.14361906051635742,
          1.3090496063232422,
          1.3090496063232422,
          -0.06679660081863403,
          -0.320099800825119,
          -0.07105232030153275,
          -0.14361906051635742,
          -0.07105232030153275,
          -0.09424912184476852,
          -0.07105232030153275,
          -0.06679660081863403,
          -0.07105232030153275,
          -0.07105232030153275,
          1.3090496063232422,
          -0.09424912184476852,
          -0.07105232030153275,
          -0.07105232030153275,
          1.3090496063232422,
          -0.07105232030153275,
          -0.18052904307842255,
          -0.320099800825119,
          -0.07105232030153275,
          1.3090496063232422,
          -0.07105232030153275,
          1.3090496063232422,
          -0.28499066829681396,
          1.3090496063232422,
          -0.0730254203081131,
          1.3090496063232422,
          -0.06679660081863403,
          1.3090496063232422,
          1.3090496063232422,
          1.3090496063232422,
          -0.07105232030153275,
          -0.07105232030153275,
          -0.07105232030153275,
          -0.09424912184476852,
          -0.09424912184476852,
          -0.22122707962989807,
          -0.22122707962989807,
          1.3090496063232422,
          -0.07105232030153275,
          -0.22122707962989807,
          -0.22122707962989807,
          1.3090496063232422,
          -0.320099800825119,
          -0.07105232030153275,
          1.3090496063232422,
          -0.07105232030153275,
          -0.09424912184476852,
          -0.29588815569877625,
          -0.06679660081863403,
          -0.09424912184476852,
          -0.26733630895614624,
          -0.07105232030153275,
          -0.07105232030153275,
          -0.07105232030153275,
          -0.07105232030153275,
          -0.07105232030153275,
          -0.07105232030153275,
          -0.07105232030153275,
          -0.07105232030153275,
          1.3090496063232422,
          -0.09424912184476852,
          -0.18052904307842255,
          -0.22122707962989807,
          -0.22122707962989807,
          -0.09424912184476852,
          -0.22122707962989807,
          -0.07105232030153275,
          -0.07105232030153275,
          -0.07105232030153275,
          1.3090496063232422,
          -0.07105232030153275,
          -0.20255805552005768,
          -0.07105232030153275,
          -0.09424912184476852,
          1.3090496063232422,
          -0.06679660081863403,
          -0.07105232030153275,
          -0.07105232030153275,
          -0.07105232030153275,
          1.3090496063232422,
          1.3090496063232422,
          -0.09424912184476852,
          -0.3191646337509155,
          -0.23518776893615723,
          -0.2866121232509613,
          -0.2866121232509613,
          -0.2162151336669922,
          -0.2162151336669922,
          -0.26140937209129333,
          -0.26140937209129333,
          -0.30267465114593506,
          -0.29070502519607544,
          -0.29070502519607544,
          -0.29070502519607544,
          -0.2990272045135498,
          -0.2846527695655823,
          -0.2866121232509613,
          -0.2866121232509613,
          -0.27770987153053284,
          -0.3049130141735077,
          -0.3049130141735077,
          -0.26869678497314453,
          -0.2710585296154022,
          -0.31427550315856934,
          -0.2866121232509613,
          -0.2866121232509613,
          -0.2866121232509613,
          -0.27448728680610657,
          -0.4163418114185333,
          -0.4163418114185333,
          -0.24644967913627625,
          -0.27448728680610657,
          -0.2822311818599701,
          -0.29790249466896057,
          -0.20480583608150482,
          -0.28076493740081787,
          -0.28076493740081787,
          -0.3008008301258087,
          -0.3008008301258087,
          -0.28105130791664124,
          -0.30211594700813293,
          -0.30211594700813293,
          -0.30211594700813293,
          -0.30211594700813293,
          -0.2866121232509613,
          -0.2866121232509613,
          -0.22989562153816223,
          -0.30432572960853577,
          -0.18730734288692474,
          -0.32375454902648926,
          -0.2990272045135498,
          -0.1217840239405632,
          -0.19526073336601257,
          -0.23020529747009277,
          -0.20058166980743408,
          -0.27385181188583374,
          -0.27385181188583374,
          -0.2866121232509613,
          -0.2866121232509613,
          -0.08263074606657028,
          -0.2655784785747528,
          -0.24644967913627625,
          -0.24644967913627625,
          -0.32375454902648926,
          -0.23020529747009277,
          -0.23020529747009277,
          -0.3049130141735077,
          -0.3049130141735077,
          -0.05726340040564537,
          -0.21468408405780792,
          -0.21468408405780792,
          -0.3100741505622864,
          -0.29070502519607544,
          -0.27460193634033203,
          -0.15281237661838531,
          -0.31427550315856934,
          -0.3137950897216797,
          -0.3137950897216797,
          -0.2703147232532501,
          -0.23618166148662567,
          -0.2990272045135498,
          -0.3288384974002838,
          -0.3288384974002838,
          -0.318552166223526,
          -0.25473228096961975,
          -0.25473228096961975,
          -0.265354722738266,
          -0.20830319821834564,
          -0.20830319821834564,
          -0.20830319821834564,
          -0.20830319821834564,
          -0.276885986328125,
          -0.2173997014760971,
          -0.2035432755947113,
          -0.2035432755947113,
          -0.23618166148662567,
          -0.2849983274936676,
          -0.2673437297344208,
          -0.276885986328125,
          -0.276885986328125,
          -0.3119947016239166,
          -0.3119947016239166,
          -0.3119947016239166,
          -0.3119947016239166,
          -0.250306636095047,
          -0.250306636095047,
          -0.2927725315093994,
          -0.2173997014760971,
          -0.30211594700813293,
          -0.27385181188583374,
          -0.25980448722839355,
          -0.25980448722839355,
          -0.27385181188583374,
          -0.27385181188583374,
          -0.12366396933794022,
          -0.30714312195777893,
          -0.28277093172073364,
          -0.34996697306632996,
          -0.2655784785747528,
          -0.2655784785747528,
          -0.2655784785747528,
          -0.2655784785747528,
          -0.25980448722839355,
          -0.25980448722839355,
          -0.28946271538734436,
          -0.27964821457862854,
          -0.27964821457862854,
          -0.2035432755947113,
          -0.05726340040564537,
          -0.28243348002433777,
          -0.24008703231811523,
          -0.27460193634033203,
          -0.23020529747009277,
          -0.22678624093532562,
          -0.250306636095047,
          -0.276885986328125,
          -0.2311825007200241,
          -0.30432572960853577,
          -0.24395900964736938,
          -0.24395900964736938,
          -0.25231701135635376,
          -0.2860007584095001,
          -0.2860007584095001,
          -0.2860007584095001,
          -0.2678435444831848,
          -0.2832222282886505,
          -0.2832222282886505,
          -0.24644967913627625,
          -0.24644967913627625,
          -0.24644967913627625,
          -0.24644967913627625,
          -0.2162151336669922,
          -0.2162151336669922,
          -0.26075950264930725,
          -0.2994611859321594,
          -0.2162151336669922,
          -0.2656199634075165,
          -0.2259337455034256,
          -0.2312442660331726,
          -0.23020529747009277,
          -0.2904418408870697,
          -0.29840272665023804,
          -0.2712119519710541,
          -0.29275965690612793,
          -0.2860007584095001,
          -0.2860007584095001,
          -0.2860007584095001,
          -0.23020529747009277,
          -0.2259337455034256,
          -0.2259337455034256,
          -0.29742127656936646,
          -0.2656199634075165,
          -0.2832222282886505,
          -0.3181803226470947,
          -0.3172605037689209,
          -0.3172605037689209,
          -0.3172605037689209,
          -0.25231701135635376,
          -0.25231701135635376,
          -0.2860007584095001,
          -0.2860007584095001,
          -0.2860007584095001,
          -0.2860007584095001,
          -0.19557735323905945,
          -0.2162151336669922,
          -0.2162151336669922,
          -0.28499066829681396,
          1.3090496063232422,
          -0.29588815569877625,
          -0.13200336694717407,
          -0.14361906051635742,
          -0.07105232030153275,
          -0.10605446249246597,
          1.3090496063232422,
          -0.09424912184476852,
          -0.09424912184476852,
          1.3090496063232422,
          -0.030119117349386215,
          -0.07105232030153275,
          -0.3185473084449768,
          -0.030119117349386215,
          1.3090496063232422,
          -0.22122707962989807,
          1.3090496063232422,
          -0.22122707962989807,
          -0.07105232030153275,
          -0.09424912184476852,
          1.3090496063232422,
          -0.07105232030153275,
          -0.07105232030153275,
          -0.07105232030153275,
          -0.07105232030153275,
          1.3090496063232422,
          -0.07105232030153275,
          -0.09424912184476852,
          -0.09424912184476852,
          -0.07105232030153275,
          -0.09424912184476852,
          1.3090496063232422,
          -0.13200336694717407,
          -0.13200336694717407,
          -0.22122707962989807,
          -0.09424912184476852,
          1.3090496063232422,
          1.3090496063232422,
          -0.07105232030153275,
          1.3090496063232422,
          -0.07105232030153275,
          1.3090496063232422,
          -0.26733630895614624,
          1.3090496063232422,
          -0.20255805552005768,
          -0.09424912184476852,
          1.3090496063232422,
          1.3090496063232422,
          1.3090496063232422,
          1.3090496063232422,
          1.3090496063232422,
          1.3090496063232422,
          -0.07105232030153275,
          1.3090496063232422,
          -0.07105232030153275,
          -0.07105232030153275,
          -0.07105232030153275,
          -0.07105232030153275,
          1.3090496063232422,
          1.3090496063232422,
          1.3090496063232422,
          -0.09424912184476852,
          1.3090496063232422,
          1.3090496063232422,
          -0.09424912184476852,
          1.3090496063232422,
          1.3090496063232422,
          1.3090496063232422,
          1.3090496063232422,
          -0.22122707962989807,
          1.3090496063232422,
          1.3090496063232422,
          1.3090496063232422,
          1.3090496063232422,
          -0.09424912184476852,
          -0.09424912184476852,
          1.3090496063232422,
          1.3090496063232422,
          -0.07105232030153275,
          -0.07105232030153275,
          -0.09424912184476852,
          1.3090496063232422,
          1.3090496063232422,
          -0.09424912184476852,
          1.3090496063232422,
          1.3090496063232422,
          -0.09424912184476852,
          1.3090496063232422,
          1.3090496063232422,
          1.3090496063232422,
          1.3090496063232422,
          -0.09424912184476852,
          -0.13200336694717407,
          1.3090496063232422,
          -0.16828906536102295,
          -0.07105232030153275,
          -0.20255805552005768,
          -0.18052904307842255,
          -0.0730254203081131,
          1.3090496063232422,
          -0.29588815569877625,
          -0.28499066829681396,
          -0.09424912184476852,
          -0.1620914787054062,
          -0.09424912184476852,
          -0.09424912184476852,
          -0.22122707962989807,
          1.3090496063232422,
          1.3090496063232422,
          -0.16828906536102295,
          1.3090496063232422,
          -0.13200336694717407,
          1.3090496063232422,
          1.3090496063232422,
          1.3090496063232422,
          -0.1620914787054062,
          1.3090496063232422,
          -0.07105232030153275,
          -0.07105232030153275,
          -0.07105232030153275,
          1.3090496063232422,
          1.3090496063232422,
          1.3090496063232422,
          -0.09424912184476852,
          -0.09424912184476852,
          1.3090496063232422
         ]
        },
        {
         "marker": {
          "color": "rgb(81, 110, 177)"
         },
         "mode": "markers+text",
         "name": "Cluster (on), Size: 16",
         "text": [
          "on",
          "on",
          "on",
          "on",
          "on",
          "on",
          "on",
          "on",
          "on",
          "on",
          "on",
          "on",
          "on",
          "on",
          "on",
          "on"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          -0.08364620804786682,
          -0.08364620804786682,
          -0.08364620804786682,
          -0.08364620804786682,
          -0.08364620804786682,
          -0.08364620804786682,
          -0.08364620804786682,
          -0.08364620804786682,
          -0.08364620804786682,
          -0.08364620804786682,
          -0.08364620804786682,
          -0.08364620804786682,
          -0.08364620804786682,
          -0.08364620804786682,
          -0.08364620804786682,
          -0.08364620804786682
         ],
         "y": [
          1.3624180555343628,
          1.3624180555343628,
          1.3624180555343628,
          1.3624180555343628,
          1.3624180555343628,
          1.3624180555343628,
          1.3624180555343628,
          1.3624180555343628,
          1.3624180555343628,
          1.3624180555343628,
          1.3624180555343628,
          1.3624180555343628,
          1.3624180555343628,
          1.3624180555343628,
          1.3624180555343628,
          1.3624180555343628
         ]
        },
        {
         "marker": {
          "color": "rgb(112, 185, 131)"
         },
         "mode": "markers+text",
         "name": "Cluster (of), Size: 251",
         "text": [
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474,
          1.4475423097610474
         ],
         "y": [
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568,
          -0.3436221480369568
         ]
        },
        {
         "marker": {
          "color": "rgb(149, 233, 124)"
         },
         "mode": "markers+text",
         "name": "Cluster (by), Size: 1",
         "text": [
          "by"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          -0.06934183090925217
         ],
         "y": [
          1.0637050867080688
         ]
        },
        {
         "marker": {
          "color": "rgb(15, 204, 116)"
         },
         "mode": "markers+text",
         "name": "Cluster (at), Size: 13",
         "text": [
          "at",
          "at",
          "at",
          "at",
          "at",
          "at",
          "at",
          "at",
          "at",
          "at",
          "at",
          "at",
          "at"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.11996924132108688,
          0.11996924132108688,
          0.11996924132108688,
          0.11996924132108688,
          0.11996924132108688,
          0.11996924132108688,
          0.11996924132108688,
          0.11996924132108688,
          0.11996924132108688,
          0.11996924132108688,
          0.11996924132108688,
          0.11996924132108688,
          0.11996924132108688
         ],
         "y": [
          1.1616935729980469,
          1.1616935729980469,
          1.1616935729980469,
          1.1616935729980469,
          1.1616935729980469,
          1.1616935729980469,
          1.1616935729980469,
          1.1616935729980469,
          1.1616935729980469,
          1.1616935729980469,
          1.1616935729980469,
          1.1616935729980469,
          1.1616935729980469
         ]
        },
        {
         "marker": {
          "color": "rgb(25, 46, 1)"
         },
         "mode": "markers+text",
         "name": "Cluster (a), Size: 24",
         "text": [
          "a",
          "a",
          "a",
          "a",
          "a",
          "a",
          "a",
          "a",
          "a",
          "a",
          "a",
          "a",
          "a",
          "a",
          "a",
          "a",
          "a",
          "a",
          "a",
          "a",
          "a",
          "a",
          "a",
          "a"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083,
          0.1744910031557083
         ],
         "y": [
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478,
          1.2930914163589478
         ]
        },
        {
         "marker": {
          "color": "rgb(1, 167, 89)"
         },
         "mode": "markers+text",
         "name": "Cluster (us), Size: 2",
         "text": [
          "us",
          "us"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          -0.29482302069664,
          -0.29482302069664
         ],
         "y": [
          0.5902990102767944,
          0.5902990102767944
         ]
        },
        {
         "marker": {
          "color": "rgb(111, 164, 65)"
         },
         "mode": "markers+text",
         "name": "Cluster (to), Size: 10",
         "text": [
          "to",
          "to",
          "to",
          "to",
          "to",
          "to",
          "to",
          "to",
          "to",
          "to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          -0.013101885095238686,
          -0.013101885095238686,
          -0.013101885095238686,
          -0.013101885095238686,
          -0.013101885095238686,
          -0.013101885095238686,
          -0.013101885095238686,
          -0.013101885095238686,
          -0.013101885095238686,
          -0.013101885095238686
         ],
         "y": [
          0.6697421073913574,
          0.6697421073913574,
          0.6697421073913574,
          0.6697421073913574,
          0.6697421073913574,
          0.6697421073913574,
          0.6697421073913574,
          0.6697421073913574,
          0.6697421073913574,
          0.6697421073913574
         ]
        },
        {
         "marker": {
          "color": "rgb(160, 146, 186)"
         },
         "mode": "markers+text",
         "name": "Cluster (ha), Size: 4",
         "text": [
          "ha",
          "ha",
          "ha",
          "ha"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          -0.32517296075820923,
          -0.32517296075820923,
          -0.32517296075820923,
          -0.32517296075820923
         ],
         "y": [
          0.6690937280654907,
          0.6690937280654907,
          0.6690937280654907,
          0.6690937280654907
         ]
        }
       ],
       "layout": {
        "hovermode": "closest",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Clusters for Embedding Size 100"
        },
        "xaxis": {
         "title": {
          "text": "PCA Component 1"
         }
        },
        "yaxis": {
         "title": {
          "text": "PCA Component 2"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "rgb(137, 208, 117)"
         },
         "mode": "markers+text",
         "name": "Cluster (view a), Size: 1",
         "text": [
          "view a"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.49013352394104004
         ],
         "y": [
          -1.1652300357818604
         ]
        },
        {
         "marker": {
          "color": "rgb(14, 1, 66)"
         },
         "mode": "markers+text",
         "name": "Cluster (refers to), Size: 1",
         "text": [
          "refers to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.45651447772979736
         ],
         "y": [
          -0.13006417453289032
         ]
        },
        {
         "marker": {
          "color": "rgb(54, 213, 131)"
         },
         "mode": "markers+text",
         "name": "Cluster (integrate to), Size: 1",
         "text": [
          "integrate to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.45666199922561646
         ],
         "y": [
          -0.12979282438755035
         ]
        },
        {
         "marker": {
          "color": "rgb(41, 201, 78)"
         },
         "mode": "markers+text",
         "name": "Cluster (come to), Size: 1",
         "text": [
          "come to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4608478844165802
         ],
         "y": [
          -0.12782670557498932
         ]
        },
        {
         "marker": {
          "color": "rgb(167, 125, 19)"
         },
         "mode": "markers+text",
         "name": "Cluster (demonstrate of), Size: 77",
         "text": [
          "skews of",
          "skews of",
          "make of",
          "have of",
          "pose of",
          "bias of",
          "mitigate of",
          "return of",
          "return of",
          "concern of",
          "concern of",
          "concern of",
          "concern of",
          "assigns of",
          "requires of",
          "emerged of",
          "involve of",
          "consists of",
          "belonging of",
          "create of",
          "see of",
          "oversee of",
          "denote of",
          "arises of",
          "involves of",
          "drop of",
          "ensures of",
          "compute of",
          "consists of",
          "contains of",
          "prof of",
          "span of",
          "include of",
          "depends of",
          "depends of",
          "employ of",
          "employ of",
          "necessitate of",
          "measure of",
          "make of",
          "affect of",
          "affect of",
          "affect of",
          "affect of",
          "increase of",
          "increase of",
          "denotes of",
          "affect of",
          "take of",
          "define of",
          "represents of",
          "represents of",
          "reduces of",
          "reduces of",
          "propose of",
          "integrate of",
          "minimizes of",
          "depends of",
          "depends of",
          "take of",
          "take of",
          "affect of",
          "generate of",
          "generate of",
          "achieves of",
          "achieves of",
          "achieves of",
          "achieves of",
          "achieves of",
          "achieves of",
          "present of",
          "compute of",
          "constitutes of",
          "demonstrate of",
          "affect of",
          "observe of",
          "observe of"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          -1.4458017349243164,
          -1.4458030462265015,
          -1.4397162199020386,
          -1.4269810914993286,
          -1.4377402067184448,
          -1.4437791109085083,
          -1.440600872039795,
          -1.4296700954437256,
          -1.4296700954437256,
          -1.4361718893051147,
          -1.4361718893051147,
          -1.4361718893051147,
          -1.4361718893051147,
          -1.434752345085144,
          -1.4333606958389282,
          -1.4197704792022705,
          -1.4349974393844604,
          -1.426650881767273,
          -1.4251899719238281,
          -1.4308186769485474,
          -1.438602089881897,
          -1.4297986030578613,
          -1.4322915077209473,
          -1.4353917837142944,
          -1.4327237606048584,
          -1.438005805015564,
          -1.4367166757583618,
          -1.4369467496871948,
          -1.426650881767273,
          -1.4279162883758545,
          -1.426953911781311,
          -1.4331787824630737,
          -1.4288244247436523,
          -1.4356930255889893,
          -1.4356930255889893,
          -1.4295165538787842,
          -1.4295165538787842,
          -1.4322381019592285,
          -1.4351578950881958,
          -1.439716100692749,
          -1.4455015659332275,
          -1.4455015659332275,
          -1.4455015659332275,
          -1.4455015659332275,
          -1.4363329410552979,
          -1.4363329410552979,
          -1.4330778121948242,
          -1.4455015659332275,
          -1.437134861946106,
          -1.4350476264953613,
          -1.4309494495391846,
          -1.4309494495391846,
          -1.4440159797668457,
          -1.4440159797668457,
          -1.4342988729476929,
          -1.4292206764221191,
          -1.4405359029769897,
          -1.4356930255889893,
          -1.4356930255889893,
          -1.437134861946106,
          -1.437134861946106,
          -1.4455015659332275,
          -1.4327645301818848,
          -1.4327645301818848,
          -1.4341685771942139,
          -1.4341685771942139,
          -1.4341685771942139,
          -1.4341685771942139,
          -1.4341685771942139,
          -1.4341685771942139,
          -1.4268156290054321,
          -1.4369467496871948,
          -1.4329513311386108,
          -1.4292551279067993,
          -1.4455015659332275,
          -1.4332423210144043,
          -1.4332423210144043
         ],
         "y": [
          0.061745598912239075,
          0.06174140423536301,
          0.05355088412761688,
          0.059411998838186264,
          0.06135329604148865,
          0.06423334032297134,
          0.06423977017402649,
          0.06741844117641449,
          0.06741844117641449,
          0.06787058711051941,
          0.06787058711051941,
          0.06787058711051941,
          0.06787058711051941,
          0.0577886700630188,
          0.06084553152322769,
          0.07306654006242752,
          0.06098546087741852,
          0.0631134882569313,
          0.06265293061733246,
          0.057136017829179764,
          0.04901238903403282,
          0.060402918606996536,
          0.05137640982866287,
          0.06526340544223785,
          0.06296714395284653,
          0.06346070021390915,
          0.0643882006406784,
          0.055905308574438095,
          0.0631134882569313,
          0.06176713481545448,
          0.051547981798648834,
          0.06887604296207428,
          0.06033646687865257,
          0.060507360845804214,
          0.060507360845804214,
          0.05627143383026123,
          0.05627143383026123,
          0.06315473467111588,
          0.06455404311418533,
          0.053550586104393005,
          0.06432708352804184,
          0.06432708352804184,
          0.06432708352804184,
          0.06432708352804184,
          0.06661701947450638,
          0.06661701947450638,
          0.060755208134651184,
          0.06432708352804184,
          0.05701923742890358,
          0.05473586916923523,
          0.06504638493061066,
          0.06504638493061066,
          0.06601002812385559,
          0.06601002812385559,
          0.05672316253185272,
          0.06064160540699959,
          0.06590674072504044,
          0.060507360845804214,
          0.060507360845804214,
          0.05701923742890358,
          0.05701923742890358,
          0.06432708352804184,
          0.061056625097990036,
          0.061056625097990036,
          0.06821154803037643,
          0.06821154803037643,
          0.06821154803037643,
          0.06821154803037643,
          0.06821154803037643,
          0.06821154803037643,
          0.0673261359333992,
          0.055905308574438095,
          0.06390463560819626,
          0.06319424510002136,
          0.06432708352804184,
          0.05895078554749489,
          0.05895078554749489
         ]
        },
        {
         "marker": {
          "color": "rgb(204, 162, 239)"
         },
         "mode": "markers+text",
         "name": "Cluster (ha in), Size: 2",
         "text": [
          "ha in",
          "ha in"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.686222493648529,
          0.686222493648529
         ],
         "y": [
          -0.11117053776979446,
          -0.11117053776979446
         ]
        },
        {
         "marker": {
          "color": "rgb(143, 198, 74)"
         },
         "mode": "markers+text",
         "name": "Cluster (demonstrates to), Size: 3",
         "text": [
          "demonstrates to",
          "demonstrates to",
          "demonstrates to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4562206566333771,
          0.4562206566333771,
          0.4562206566333771
         ],
         "y": [
          -0.1243002861738205,
          -0.1243002861738205,
          -0.1243002861738205
         ]
        },
        {
         "marker": {
          "color": "rgb(253, 49, 139)"
         },
         "mode": "markers+text",
         "name": "Cluster (incorporates to), Size: 1",
         "text": [
          "incorporates to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4587891697883606
         ],
         "y": [
          -0.12468679249286652
         ]
        },
        {
         "marker": {
          "color": "rgb(50, 28, 82)"
         },
         "mode": "markers+text",
         "name": "Cluster (led to), Size: 1",
         "text": [
          "led to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.47203415632247925
         ],
         "y": [
          -0.11834730207920074
         ]
        },
        {
         "marker": {
          "color": "rgb(236, 222, 40)"
         },
         "mode": "markers+text",
         "name": "Cluster (added at), Size: 1",
         "text": [
          "added at"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.44661110639572144
         ],
         "y": [
          -0.49696362018585205
         ]
        },
        {
         "marker": {
          "color": "rgb(34, 46, 14)"
         },
         "mode": "markers+text",
         "name": "Cluster (go in), Size: 2",
         "text": [
          "go in",
          "go in"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.3042806088924408,
          0.3042806088924408
         ],
         "y": [
          -0.6935035586357117,
          -0.6935035586357117
         ]
        },
        {
         "marker": {
          "color": "rgb(107, 169, 60)"
         },
         "mode": "markers+text",
         "name": "Cluster (pose to), Size: 1",
         "text": [
          "pose to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.44814300537109375
         ],
         "y": [
          -0.12908123433589935
         ]
        },
        {
         "marker": {
          "color": "rgb(57, 193, 66)"
         },
         "mode": "markers+text",
         "name": "Cluster (vary at), Size: 1",
         "text": [
          "vary at"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4378063380718231
         ],
         "y": [
          -0.5063533186912537
         ]
        },
        {
         "marker": {
          "color": "rgb(138, 224, 121)"
         },
         "mode": "markers+text",
         "name": "Cluster (serf to), Size: 1",
         "text": [
          "serf to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.46170908212661743
         ],
         "y": [
          -0.14201447367668152
         ]
        },
        {
         "marker": {
          "color": "rgb(75, 189, 27)"
         },
         "mode": "markers+text",
         "name": "Cluster (defined a), Size: 1",
         "text": [
          "defined a"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.49447914958000183
         ],
         "y": [
          -1.1557179689407349
         ]
        },
        {
         "marker": {
          "color": "rgb(84, 77, 95)"
         },
         "mode": "markers+text",
         "name": "Cluster (generates from), Size: 148",
         "text": [
          "make on",
          "hinge on",
          "become towards",
          "deliver for",
          "bias towards",
          "rely on",
          "rely on",
          "delve into",
          "address from",
          "combine in",
          "outperformed in",
          "generates from",
          "determine in",
          "lie in",
          "operates on",
          "operates on",
          "concluded in",
          "guide through",
          "categorise among",
          "embed in",
          "consider in",
          "result in",
          "identified in",
          "split through",
          "offer for",
          "observe in",
          "appears across",
          "appears across",
          "appears across",
          "categorize in",
          "elaborate on",
          "elaborate on",
          "improve over",
          "set for",
          "utilise in",
          "utilise in",
          "utilise in",
          "utilise in",
          "contains in",
          "capture between",
          "gained on",
          "enhances through",
          "depend on",
          "depend on",
          "employ for",
          "focus on",
          "designated for",
          "adjusted on",
          "incorporated into",
          "incorporates for",
          "exhibit for",
          "remain throughout",
          "span from",
          "represents on",
          "indicate in",
          "outperform in",
          "compute in",
          "performed than",
          "performed than",
          "performed than",
          "employed for",
          "require for",
          "require in",
          "proven in",
          "identified in",
          "exhibit from",
          "change over",
          "developed for",
          "trained on",
          "support in",
          "arise from",
          "focus on",
          "gained due",
          "struggle with",
          "exploit in",
          "encounter with",
          "demonstrated over",
          "suffers from",
          "lack in",
          "measure over",
          "conduct on",
          "suffer from",
          "strike between",
          "strike between",
          "relies on",
          "generates for",
          "improve on",
          "give for",
          "show on",
          "result into",
          "include for",
          "drop in",
          "introduced on",
          "requires on",
          "depend on",
          "creates on",
          "partition into",
          "share within",
          "share on",
          "project onto",
          "represents in",
          "result in",
          "separate into",
          "varies with",
          "need in",
          "want for",
          "satisfies through",
          "result in",
          "accepts in",
          "accepts in",
          "generated in",
          "satisfy with",
          "presented in",
          "result in",
          "depend in",
          "result in",
          "notice in",
          "notice in",
          "result with",
          "result with",
          "result with",
          "calculates during",
          "computes on",
          "computes on",
          "have with",
          "assume between",
          "illustrates alongside",
          "illustrates alongside",
          "have with",
          "observe after",
          "affect within",
          "comprises in",
          "present alongside",
          "decay in",
          "decay in",
          "stem from",
          "demonstrate for",
          "achieves than",
          "achieves than",
          "achieves than",
          "achieves than",
          "achieves than",
          "achieves than",
          "observe in",
          "integrates with",
          "achieves in",
          "achieves in",
          "achieves in"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.8068639636039734,
          0.8172590136528015,
          0.6003268361091614,
          0.5813640356063843,
          0.5825821161270142,
          0.8158255219459534,
          0.8158255219459534,
          0.5897998809814453,
          0.5525069236755371,
          0.31360679864883423,
          0.31516698002815247,
          0.5483314394950867,
          0.30930057168006897,
          0.3055921792984009,
          0.8190688490867615,
          0.8190688490867615,
          0.31615960597991943,
          0.6540787816047668,
          0.554412305355072,
          0.31480395793914795,
          0.30984076857566833,
          0.31198909878730774,
          0.3184739053249359,
          0.6478836536407471,
          0.583469808101654,
          0.30884143710136414,
          0.6651293039321899,
          0.6651293039321899,
          0.6651293039321899,
          0.31117871403694153,
          0.8192410469055176,
          0.8192410469055176,
          0.6702252626419067,
          0.5923678874969482,
          0.31491467356681824,
          0.31491467356681824,
          0.31491467356681824,
          0.31491467356681824,
          0.31416723132133484,
          0.569530725479126,
          0.8244494199752808,
          0.635985255241394,
          0.8120668530464172,
          0.8120668530464172,
          0.579512357711792,
          0.8135865330696106,
          0.584739089012146,
          0.8192111849784851,
          0.5911087393760681,
          0.5819355249404907,
          0.5832170844078064,
          0.6499367952346802,
          0.5481578707695007,
          0.8156307339668274,
          0.30991053581237793,
          0.3112223446369171,
          0.3051370084285736,
          0.6303790807723999,
          0.6303790807723999,
          0.6303790807723999,
          0.5857812166213989,
          0.5747894048690796,
          0.30784422159194946,
          0.3164380192756653,
          0.3184739053249359,
          0.555525004863739,
          0.6709221601486206,
          0.5889175534248352,
          0.8288361430168152,
          0.31197911500930786,
          0.5461560487747192,
          0.8135865330696106,
          0.589870810508728,
          0.647174060344696,
          0.3108566701412201,
          0.64873868227005,
          0.6819392442703247,
          0.5455940365791321,
          0.2969154715538025,
          0.6724631190299988,
          0.8166275024414062,
          0.5449846982955933,
          0.5680360198020935,
          0.5680360198020935,
          0.8156653642654419,
          0.5760235786437988,
          0.8091841340065002,
          0.5731552839279175,
          0.8205387592315674,
          0.5837922096252441,
          0.5802044868469238,
          0.30407780408859253,
          0.825173020362854,
          0.8132191896438599,
          0.8120668530464172,
          0.8116469979286194,
          0.586012601852417,
          0.616948664188385,
          0.8187942504882812,
          0.7412673234939575,
          0.3111344277858734,
          0.31198909878730774,
          0.5871809124946594,
          0.6431167721748352,
          0.30624067783355713,
          0.5734207630157471,
          0.643195629119873,
          0.31198909878730774,
          0.3098103106021881,
          0.3098103106021881,
          0.31755146384239197,
          0.6444493532180786,
          0.32148200273513794,
          0.31198909878730774,
          0.3075706362724304,
          0.31198909878730774,
          0.30865269899368286,
          0.30865269899368286,
          0.6463594436645508,
          0.6463594436645508,
          0.6463594436645508,
          0.5867329835891724,
          0.8108317255973816,
          0.8108317255973816,
          0.6494729518890381,
          0.564655065536499,
          0.6582513451576233,
          0.6582513451576233,
          0.6494729518890381,
          0.5955418348312378,
          0.5992329716682434,
          0.3159572184085846,
          0.6616776585578918,
          0.3032272458076477,
          0.3032272458076477,
          0.5474960207939148,
          0.5797737836837769,
          0.6174905300140381,
          0.6174905300140381,
          0.6174905300140381,
          0.6174905300140381,
          0.6174905300140381,
          0.6174905300140381,
          0.30884143710136414,
          0.6484302282333374,
          0.30791497230529785,
          0.30791497230529785,
          0.30791497230529785
         ],
         "y": [
          -0.5930082201957703,
          -0.5809391140937805,
          1.1476691961288452,
          0.9339849352836609,
          1.1448404788970947,
          -0.595941424369812,
          -0.595941424369812,
          0.8464303612709045,
          0.9510029554367065,
          -0.6293531060218811,
          -0.6219777464866638,
          0.9524100422859192,
          -0.6272884607315063,
          -0.6426640748977661,
          -0.5823608636856079,
          -0.5823608636856079,
          -0.6193289756774902,
          1.0623899698257446,
          1.1568456888198853,
          -0.6359157562255859,
          -0.6282622218132019,
          -0.6197043657302856,
          -0.6210073828697205,
          1.0698515176773071,
          0.928169846534729,
          -0.6294780969619751,
          1.079909324645996,
          1.079909324645996,
          1.079909324645996,
          -0.6272028088569641,
          -0.5837143659591675,
          -0.5837143659591675,
          0.9625062942504883,
          0.9308437705039978,
          -0.633847713470459,
          -0.633847713470459,
          -0.633847713470459,
          -0.633847713470459,
          -0.6266616582870483,
          1.1046274900436401,
          -0.5803051590919495,
          1.06948983669281,
          -0.5877741575241089,
          -0.5877741575241089,
          0.9254087805747986,
          -0.583277702331543,
          0.9338676929473877,
          -0.5804153680801392,
          0.856102705001831,
          0.9348852634429932,
          0.9380537271499634,
          1.1592189073562622,
          0.9560627937316895,
          -0.5815125107765198,
          -0.6268036961555481,
          -0.6263096332550049,
          -0.6325234174728394,
          1.0989868640899658,
          1.0989868640899658,
          1.0989868640899658,
          0.9330628514289856,
          0.9269709587097168,
          -0.6305952668190002,
          -0.6234676241874695,
          -0.6210073828697205,
          0.9561030268669128,
          0.9636248350143433,
          0.9365577697753906,
          -0.5833240151405334,
          -0.6232260465621948,
          0.9503315687179565,
          -0.583277702331543,
          0.8893820643424988,
          0.9787924885749817,
          -0.6270028948783875,
          0.9781858325004578,
          0.9657851457595825,
          0.959084153175354,
          -0.6220032572746277,
          0.96269291639328,
          -0.5826480388641357,
          0.9564136862754822,
          1.111303448677063,
          1.111303448677063,
          -0.5854923129081726,
          0.9343608021736145,
          -0.5821914672851562,
          0.9236818552017212,
          -0.5797590017318726,
          0.858925998210907,
          0.929473876953125,
          -0.6249679923057556,
          -0.5780320167541504,
          -0.5857133269309998,
          -0.5877741575241089,
          -0.5820043087005615,
          0.8540546298027039,
          1.0005064010620117,
          -0.5887370109558105,
          0.8805211186408997,
          -0.6233823299407959,
          -0.6197043657302856,
          0.8532180786132812,
          0.9737902283668518,
          -0.6369940042495728,
          0.9193120002746582,
          1.0685386657714844,
          -0.6197043657302856,
          -0.6251510977745056,
          -0.6251510977745056,
          -0.6205788254737854,
          0.9733331203460693,
          -0.6205582618713379,
          -0.6197043657302856,
          -0.6296442151069641,
          -0.6197043657302856,
          -0.625669538974762,
          -0.625669538974762,
          0.9794113039970398,
          0.9794113039970398,
          0.9794113039970398,
          1.0557366609573364,
          -0.5888224244117737,
          -0.5888224244117737,
          0.9700987935066223,
          1.0960444211959839,
          1.1045650243759155,
          1.1045650243759155,
          0.9700987935066223,
          1.0358535051345825,
          1.0070117712020874,
          -0.6258902549743652,
          1.1065789461135864,
          -0.6201016902923584,
          -0.6201016902923584,
          0.9551151394844055,
          0.9323316812515259,
          1.0974701642990112,
          1.0974701642990112,
          1.0974701642990112,
          1.0974701642990112,
          1.0974701642990112,
          1.0974701642990112,
          -0.6294780969619751,
          0.9746925234794617,
          -0.6202174425125122,
          -0.6202174425125122,
          -0.6202174425125122
         ]
        },
        {
         "marker": {
          "color": "rgb(118, 166, 214)"
         },
         "mode": "markers+text",
         "name": "Cluster (gained a), Size: 1",
         "text": [
          "gained a"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4992082417011261
         ],
         "y": [
          -1.1536569595336914
         ]
        },
        {
         "marker": {
          "color": "rgb(201, 9, 123)"
         },
         "mode": "markers+text",
         "name": "Cluster (contains a), Size: 2",
         "text": [
          "contains a",
          "contains a"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4934222102165222,
          0.4934222102165222
         ],
         "y": [
          -1.1581432819366455,
          -1.1581432819366455
         ]
        },
        {
         "marker": {
          "color": "rgb(36, 125, 90)"
         },
         "mode": "markers+text",
         "name": "Cluster (monitor at), Size: 1",
         "text": [
          "monitor at"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4364094138145447
         ],
         "y": [
          -0.49846774339675903
         ]
        },
        {
         "marker": {
          "color": "rgb(90, 112, 232)"
         },
         "mode": "markers+text",
         "name": "Cluster (linked to), Size: 2",
         "text": [
          "linked to",
          "linked to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4628135859966278,
          0.4628135859966278
         ],
         "y": [
          -0.12451725453138351,
          -0.12451725453138351
         ]
        },
        {
         "marker": {
          "color": "rgb(71, 72, 218)"
         },
         "mode": "markers+text",
         "name": "Cluster (assigns to), Size: 1",
         "text": [
          "assigns to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.45113036036491394
         ],
         "y": [
          -0.13264566659927368
         ]
        },
        {
         "marker": {
          "color": "rgb(23, 100, 248)"
         },
         "mode": "markers+text",
         "name": "Cluster (write a), Size: 1",
         "text": [
          "write a"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.49688419699668884
         ],
         "y": [
          -1.164437174797058
         ]
        },
        {
         "marker": {
          "color": "rgb(57, 17, 200)"
         },
         "mode": "markers+text",
         "name": "Cluster (lead to), Size: 1",
         "text": [
          "lead to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4493199288845062
         ],
         "y": [
          -0.12053101509809494
         ]
        },
        {
         "marker": {
          "color": "rgb(48, 65, 90)"
         },
         "mode": "markers+text",
         "name": "Cluster (aim at), Size: 2",
         "text": [
          "aim at",
          "aim at"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.43266966938972473,
          0.43266966938972473
         ],
         "y": [
          -0.5176630616188049,
          -0.5176630616188049
         ]
        },
        {
         "marker": {
          "color": "rgb(95, 30, 155)"
         },
         "mode": "markers+text",
         "name": "Cluster (represent a), Size: 2",
         "text": [
          "represent a",
          "represent a"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4909590184688568,
          0.4909590184688568
         ],
         "y": [
          -1.1579166650772095,
          -1.1579166650772095
         ]
        },
        {
         "marker": {
          "color": "rgb(100, 14, 193)"
         },
         "mode": "markers+text",
         "name": "Cluster (outperform to), Size: 1",
         "text": [
          "outperform to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4550212025642395
         ],
         "y": [
          -0.1283152997493744
         ]
        },
        {
         "marker": {
          "color": "rgb(95, 112, 59)"
         },
         "mode": "markers+text",
         "name": "Cluster (designates to), Size: 1",
         "text": [
          "designates to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4555109739303589
         ],
         "y": [
          -0.12730923295021057
         ]
        },
        {
         "marker": {
          "color": "rgb(102, 65, 211)"
         },
         "mode": "markers+text",
         "name": "Cluster (proceed to), Size: 1",
         "text": [
          "proceed to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.455793559551239
         ],
         "y": [
          -0.12935015559196472
         ]
        },
        {
         "marker": {
          "color": "rgb(217, 130, 23)"
         },
         "mode": "markers+text",
         "name": "Cluster (serf a), Size: 1",
         "text": [
          "serf a"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4971652030944824
         ],
         "y": [
          -1.1714904308319092
         ]
        },
        {
         "marker": {
          "color": "rgb(180, 145, 242)"
         },
         "mode": "markers+text",
         "name": "Cluster (guided by), Size: 1",
         "text": [
          "guided by"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.634800374507904
         ],
         "y": [
          -0.3145520091056824
         ]
        },
        {
         "marker": {
          "color": "rgb(166, 163, 123)"
         },
         "mode": "markers+text",
         "name": "Cluster (produce to), Size: 2",
         "text": [
          "produce to",
          "produce to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4575224220752716,
          0.4575224220752716
         ],
         "y": [
          -0.1262183040380478,
          -0.1262183040380478
         ]
        },
        {
         "marker": {
          "color": "rgb(185, 22, 239)"
         },
         "mode": "markers+text",
         "name": "Cluster (connected to), Size: 2",
         "text": [
          "connected to",
          "connected to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4622129797935486,
          0.4622129797935486
         ],
         "y": [
          -0.1252145618200302,
          -0.1252145618200302
         ]
        },
        {
         "marker": {
          "color": "rgb(225, 246, 75)"
         },
         "mode": "markers+text",
         "name": "Cluster (refer a), Size: 1",
         "text": [
          "refer a"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4950140714645386
         ],
         "y": [
          -1.1661373376846313
         ]
        },
        {
         "marker": {
          "color": "rgb(224, 58, 102)"
         },
         "mode": "markers+text",
         "name": "Cluster (partition a), Size: 1",
         "text": [
          "partition a"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4934648275375366
         ],
         "y": [
          -1.156057596206665
         ]
        },
        {
         "marker": {
          "color": "rgb(122, 104, 180)"
         },
         "mode": "markers+text",
         "name": "Cluster (refer to), Size: 2",
         "text": [
          "refer to",
          "refer to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4595579206943512,
          0.4595579206943512
         ],
         "y": [
          -0.1366613507270813,
          -0.1366613507270813
         ]
        },
        {
         "marker": {
          "color": "rgb(12, 105, 114)"
         },
         "mode": "markers+text",
         "name": "Cluster (corresponds to), Size: 1",
         "text": [
          "corresponds to"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.457194447517395
         ],
         "y": [
          -0.12733955681324005
         ]
        },
        {
         "marker": {
          "color": "rgb(130, 238, 33)"
         },
         "mode": "markers+text",
         "name": "Cluster (integrate up), Size: 2",
         "text": [
          "integrate up",
          "integrate up"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.6568005084991455,
          0.6568005084991455
         ],
         "y": [
          -0.5522929430007935,
          -0.5522929430007935
         ]
        },
        {
         "marker": {
          "color": "rgb(61, 184, 102)"
         },
         "mode": "markers+text",
         "name": "Cluster (approximate a), Size: 4",
         "text": [
          "approximate a",
          "approximate a",
          "approximate a",
          "approximate a"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.49242469668388367,
          0.49242469668388367,
          0.49242469668388367,
          0.49242469668388367
         ],
         "y": [
          -1.156270146369934,
          -1.156270146369934,
          -1.156270146369934,
          -1.156270146369934
         ]
        },
        {
         "marker": {
          "color": "rgb(109, 228, 155)"
         },
         "mode": "markers+text",
         "name": "Cluster (denote a), Size: 1",
         "text": [
          "denote a"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.48904740810394287
         ],
         "y": [
          -1.1685341596603394
         ]
        },
        {
         "marker": {
          "color": "rgb(242, 50, 25)"
         },
         "mode": "markers+text",
         "name": "Cluster (represents a), Size: 1",
         "text": [
          "represents a"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4903896749019623
         ],
         "y": [
          -1.1548641920089722
         ]
        },
        {
         "marker": {
          "color": "rgb(255, 192, 209)"
         },
         "mode": "markers+text",
         "name": "Cluster (combine a), Size: 1",
         "text": [
          "combine a"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4928620457649231
         ],
         "y": [
          -1.160834789276123
         ]
        },
        {
         "marker": {
          "color": "rgb(249, 233, 201)"
         },
         "mode": "markers+text",
         "name": "Cluster (creates a), Size: 3",
         "text": [
          "creates a",
          "creates a",
          "creates a"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.48640578985214233,
          0.48640578985214233,
          0.48640578985214233
         ],
         "y": [
          -1.1553560495376587,
          -1.1553560495376587,
          -1.1553560495376587
         ]
        },
        {
         "marker": {
          "color": "rgb(103, 1, 106)"
         },
         "mode": "markers+text",
         "name": "Cluster (apply a), Size: 1",
         "text": [
          "apply a"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.4840131402015686
         ],
         "y": [
          -1.1675374507904053
         ]
        },
        {
         "marker": {
          "color": "rgb(223, 76, 30)"
         },
         "mode": "markers+text",
         "name": "Cluster (include a), Size: 1",
         "text": [
          "include a"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.49251437187194824
         ],
         "y": [
          -1.159574031829834
         ]
        }
       ],
       "layout": {
        "hovermode": "closest",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Clusters for Embedding Size 200"
        },
        "xaxis": {
         "title": {
          "text": "PCA Component 1"
         }
        },
        "yaxis": {
         "title": {
          "text": "PCA Component 2"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from process_graph.edges_clustering import plot_clusters_with_pca\n",
    "\n",
    "plot_clusters_with_pca(graph.edges, edge_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operands could not be broadcast together with shapes (1800,) (900,) : [[[formula th aggregated network layer]]]; whose parameter matrix\n",
      "operands could not be broadcast together with shapes (1800,) (900,) : [[[formula th large model]]]; whose parameter matrix\n",
      "operands could not be broadcast together with shapes (2700,) (900,) : [[[formula th layer]]]; whose parameter matrix\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cluster vertices\n",
    "\"\"\"\n",
    "\n",
    "from process_graph.squeezing import squeeze\n",
    "\n",
    "(\n",
    "    (words_to_cluster, merged_words_map),\n",
    "    (bigrams_to_cluster, merged_bigrams_map),\n",
    "    (trigrams_to_cluster, merged_trigrams_map),\n",
    ") = squeeze((0.4, 0.1, 0.1), graph.vertices.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cluster edges\n",
    "\"\"\"\n",
    "from process_graph.edges_clustering import cluster_and_evaluate_all_sizes\n",
    "\n",
    "edge_map, metrics = cluster_and_evaluate_all_sizes(graph.edges, with_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_size_300': {'Silhouette Score': np.float32(0.4935592),\n",
       "  'Davies-Bouldin Index': np.float64(1.4662594633483381),\n",
       "  'Calinski-Harabasz Index': np.float32(49.34576)},\n",
       " 'embedding_size_600': {'Silhouette Score': np.float32(0.20228788),\n",
       "  'Davies-Bouldin Index': np.float64(1.5148926834137941),\n",
       "  'Calinski-Harabasz Index': np.float32(7.719379)}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1307/1307 [00:00<00:00, 1377.95it/s]\n"
     ]
    }
   ],
   "source": [
    "clustered_graph = Graph()\n",
    "\n",
    "for new_vertice_words in merged_words_map.keys():\n",
    "    clustered_graph.add_vertex(new_vertice_words, new_vertice_words.split()[:3])\n",
    "for new_vertice_bigram in merged_bigrams_map.keys():\n",
    "    clustered_graph.add_vertex(new_vertice_bigram, new_vertice_bigram.split()[:3])\n",
    "for new_vertice_trigram in merged_trigrams_map.keys():\n",
    "    clustered_graph.add_vertex(new_vertice_trigram, new_vertice_trigram.split()[:3])\n",
    "\n",
    "def match_new_vertice(label: str) -> str:\n",
    "    new_label = str()\n",
    "    if label in words_to_cluster:\n",
    "        new_label = words_to_cluster[label]\n",
    "    elif label in bigrams_to_cluster:\n",
    "        new_label = bigrams_to_cluster[label]\n",
    "    elif label in trigrams_to_cluster:\n",
    "        new_label = trigrams_to_cluster[label]\n",
    "    return new_label\n",
    "\n",
    "added_edges = set()  # keeps added_edges in (agent_1, agent_2, label) format\n",
    "\n",
    "for edge in tqdm.tqdm(graph.edges):\n",
    "    new_edge = (\n",
    "        match_new_vertice(edge.agent_1),\n",
    "        match_new_vertice(edge.agent_2),\n",
    "        edge_map[edge.label] if edge.label in edge_map else edge.label,\n",
    "    )\n",
    "    if new_edge in added_edges:\n",
    "        continue\n",
    "\n",
    "    clustered_graph.add_edge(*new_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(\n",
      "\tvertices=[Vertex(concept='mobile device', words=['mobile', 'device']), Vertex(concept='shared global model', words=['shared', 'global', 'model']), Vertex(concept='client', words=['client']), Vertex(concept='client private data', words=['client', 'private', 'data']), Vertex(concept='server', words=['server']), Vertex(concept='model aggregation', words=['model', 'aggregation']), Vertex(concept='heterogeneous client', words=['heterogeneous', 'client']), Vertex(concept='federated client', words=['federated', 'client']), Vertex(concept='diverse system resource', words=['diverse', 'system', 'resource']), Vertex(concept='heterogeneous model', words=['heterogeneous', 'model']), Vertex(concept='data distribution', words=['data', 'distribution']), Vertex(concept='high end pc', words=['high', 'end', 'pc']), Vertex(concept='large model', words=['large', 'model']), Vertex(concept='sub model', words=['sub', 'model']), Vertex(concept='previous solution', words=['previous', 'solution']), Vertex(concept='knowledge distillation', words=['knowledge', 'distillation']), Vertex(concept='parameter sharing', words=['parameter', 'sharing']), Vertex(concept='kd', words=['kd']), Vertex(concept='knowledge', words=['knowledge']), Vertex(concept='ensemble learning', words=['ensemble', 'learning']), Vertex(concept='heterogeneous client model', words=['heterogeneous', 'client', 'model']), Vertex(concept='additional compute overhead', words=['additional', 'compute', 'overhead']), Vertex(concept='public data', words=['public', 'data']), Vertex(concept='parameter sharing strategy', words=['parameter', 'sharing', 'strategy']), Vertex(concept='different region', words=['different', 'region']), Vertex(concept='global model', words=['global', 'model']), Vertex(concept='parameter pruning method', words=['parameter', 'pruning', 'method']), Vertex(concept='channel or filter level pruning', words=['channel', 'or', 'filter']), Vertex(concept='method', words=['method']), Vertex(concept='information loss', words=['information', 'loss']), Vertex(concept='imbalance issue', words=['imbalance', 'issue']), Vertex(concept='performance degradation', words=['performance', 'degradation']), Vertex(concept='heterogeneous sub model', words=['heterogeneous', 'sub', 'model']), Vertex(concept='information', words=['information']), Vertex(concept='we', words=['we']), Vertex(concept='fedconv', words=['fedconv']), Vertex(concept='all baseline', words=['all', 'baseline']), Vertex(concept='lotteryfl', words=['lotteryfl']), Vertex(concept='convolution', words=['convolution']), Vertex(concept='transposed convolution', words=['transposed', 'convolution']), Vertex(concept='various receptive field', words=['various', 'receptive', 'field']), Vertex(concept='convolutional compression', words=['convolutional', 'compression']), Vertex(concept='transposed convolutional dilation', words=['transposed', 'convolutional', 'dilation']), Vertex(concept='compressed sub model', words=['compressed', 'sub', 'model']), Vertex(concept='different learned weight vector', words=['different', 'learned', 'weight']), Vertex(concept='these dilated model', words=['these', 'dilated', 'model']), Vertex(concept='aggregate vector', words=['aggregate', 'vector']), Vertex(concept='model compression dilation and aggregation process', words=['model', 'compression', 'dilation']), Vertex(concept='our system', words=['our', 'system']), Vertex(concept='extra communication or computation overhead', words=['extra', 'communication', 'or']), Vertex(concept='resource constrained client', words=['resource', 'constrained', 'client']), Vertex(concept='three key technical challenge', words=['three', 'key', 'technical']), Vertex(concept='compression process', words=['compression', 'process']), Vertex(concept='training task', words=['training', 'task']), Vertex(concept='separate tc operation', words=['separate', 'tc', 'operation']), Vertex(concept='each client s model parameter', words=['each', 'client', 's']), Vertex(concept='which', words=['which']), Vertex(concept='model personalized information', words=['model', 'personalized', 'information']), Vertex(concept='residual connection', words=['residual', 'connection']), Vertex(concept='these large model', words=['these', 'large', 'model']), Vertex(concept='different learnable weight vector', words=['different', 'learnable', 'weight']), Vertex(concept='dilated model', words=['dilated', 'model']), Vertex(concept='relative importance', words=['relative', 'importance']), Vertex(concept='each model', words=['each', 'model']), Vertex(concept='six public datasets', words=['six', 'public', 'datasets']), Vertex(concept='sota', words=['sota']), Vertex(concept='term', words=['term']), Vertex(concept='computation overhead', words=['computation', 'overhead']), Vertex(concept='following key contribution', words=['following', 'key', 'contribution']), Vertex(concept='our knowledge', words=['our', 'knowledge']), Vertex(concept='this paradigm', words=['this', 'paradigm']), Vertex(concept='new technology', words=['new', 'technology']), Vertex(concept='convolutional compression module', words=['convolutional', 'compression', 'module']), Vertex(concept='transposed convolutional dilation method', words=['transposed', 'convolutional', 'dilation']), Vertex(concept='flower', words=['flower']), Vertex(concept='result', words=['result']), Vertex(concept='superior performance', words=['superior', 'performance']), Vertex(concept='necessity', words=['necessity']), Vertex(concept='model heterogeneity aware fl system', words=['model', 'heterogeneity', 'aware']), Vertex(concept='knowledge distillation based method', words=['knowledge', 'distillation', 'based']), Vertex(concept='heavy overhead', words=['heavy', 'overhead']), Vertex(concept='§', words=['§']), Vertex(concept='all client', words=['all', 'client']), Vertex(concept='same model architecture', words=['same', 'model', 'architecture']), Vertex(concept='practice', words=['practice']), Vertex(concept='different client', words=['different', 'client']), Vertex(concept='diverse computation and communication resource', words=['diverse', 'computation', 'and']), Vertex(concept='example', words=['example']), Vertex(concept='high end edge pc', words=['high', 'end', 'edge']), Vertex(concept='more resource', words=['more', 'resource']), Vertex(concept='low cost embedded system', words=['low', 'cost', 'embedded']), Vertex(concept='much constrained resource', words=['much', 'constrained', 'resource']), Vertex(concept='one size', words=['one', 'size']), Vertex(concept='all', words=['all']), Vertex(concept='sub optimal performance', words=['sub', 'optimal', 'performance']), Vertex(concept='resnet18 model', words=['resnet18', 'model']), Vertex(concept='mi', words=['mi']), Vertex(concept='cifar10 dataset', words=['cifar10', 'dataset']), Vertex(concept='smaller model', words=['smaller', 'model']), Vertex(concept='larger model', words=['larger', 'model']), Vertex(concept='model exposure', words=['model', 'exposure']), Vertex(concept='instability', words=['instability']), Vertex(concept='this scheme', words=['this', 'scheme']), Vertex(concept='imbalanced performance', words=['imbalanced', 'performance']), Vertex(concept='unexpected performance degradation', words=['unexpected', 'performance', 'degradation']), Vertex(concept='scheme', words=['scheme']), Vertex(concept='distinct part', words=['distinct', 'part']), Vertex(concept='aggregated parameter', words=['aggregated', 'parameter']), Vertex(concept='mixed window', words=['mixed', 'window']), Vertex(concept='diverse sub model', words=['diverse', 'sub', 'model']), Vertex(concept='channel level pruning', words=['channel', 'level', 'pruning']), Vertex(concept='some input channel', words=['some', 'input', 'channel']), Vertex(concept='model parameter', words=['model', 'parameter']), Vertex(concept='filter level pruning', words=['filter', 'level', 'pruning']), Vertex(concept='some output channel', words=['some', 'output', 'channel']), Vertex(concept='these two scheme', words=['these', 'two', 'scheme']), Vertex(concept='some input data channel', words=['some', 'input', 'data']), Vertex(concept='feature map', words=['feature', 'map']), Vertex(concept='channel level and filter level pruning', words=['channel', 'level', 'and']), Vertex(concept='pre trained resnet18 model', words=['pre', 'trained', 'resnet18']), Vertex(concept='mutual information', words=['mutual', 'information']), Vertex(concept='amount', words=['amount']), Vertex(concept='accuracy', words=['accuracy']), Vertex(concept='filter pruned model', words=['filter', 'pruned', 'model']), Vertex(concept='this', words=['this']), Vertex(concept='pruning', words=['pruning']), Vertex(concept='existing pruning based method', words=['existing', 'pruning', 'based']), Vertex(concept='high communication and computation overhead', words=['high', 'communication', 'and']), Vertex(concept='compression method', words=['compression', 'method']), Vertex(concept='novel convolutional compression technique', words=['novel', 'convolutional', 'compression']), Vertex(concept='spatial and hierarchical parameter pattern', words=['spatial', 'and', 'hierarchical']), Vertex(concept='generated sub model', words=['generated', 'sub', 'model']), Vertex(concept='valuable feature', words=['valuable', 'feature']), Vertex(concept='input data', words=['input', 'data']), Vertex(concept='figure reference', words=['figure', 'reference']), Vertex(concept='convolution based compression process', words=['convolution', 'based', 'compression']), Vertex(concept='compressed model', words=['compressed', 'model']), Vertex(concept='feature', words=['feature']), Vertex(concept='pre trained model', words=['pre', 'trained', 'model']), Vertex(concept='channel pruned model', words=['channel', 'pruned', 'model']), Vertex(concept='top4 and top3 feature map', words=['top4', 'and', 'top3']), Vertex(concept='highest importance', words=['highest', 'importance']), Vertex(concept='first two feature map', words=['first', 'two', 'feature']), Vertex(concept='more attention', words=['more', 'attention']), Vertex(concept='map', words=['map']), Vertex(concept='both body', words=['both', 'body']), Vertex(concept='head', words=['head']), Vertex(concept='our proposed convolutional compression method', words=['our', 'proposed', 'convolutional']), Vertex(concept='model compression', words=['model', 'compression']), Vertex(concept='dilation', words=['dilation']), Vertex(concept='small publicly available dataset', words=['small', 'publicly', 'available']), Vertex(concept='conventional fl scheme', words=['conventional', 'fl', 'scheme']), Vertex(concept='comprehensive global view', words=['comprehensive', 'global', 'view']), Vertex(concept='entire fl process', words=['entire', 'fl', 'process']), Vertex(concept='estimated memory requirement', words=['estimated', 'memory', 'requirement']), Vertex(concept='several epoch', words=['several', 'epoch']), Vertex(concept='③', words=['③']), Vertex(concept='local training', words=['local', 'training']), Vertex(concept='weighted average aggregation', words=['weighted', 'average', 'aggregation']), Vertex(concept='set', words=['set']), Vertex(concept='convolutional layer', words=['convolutional', 'layer']), Vertex(concept='compressed parameter', words=['compressed', 'parameter']), Vertex(concept='server side data', words=['server', 'side', 'data']), Vertex(concept='comparable performance', words=['comparable', 'performance']), Vertex(concept='client shrinkage ratio', words=['client', 'shrinkage', 'ratio']), Vertex(concept='size', words=['size']), Vertex(concept='resource budget', words=['resource', 'budget']), Vertex(concept='each client', words=['each', 'client']), Vertex(concept='appropriate sr', words=['appropriate', 'sr']), Vertex(concept='computing resource budget', words=['computing', 'resource', 'budget']), Vertex(concept='no client side sensor data', words=['no', 'client', 'side']), Vertex(concept='corresponding configuration', words=['corresponding', 'configuration']), Vertex(concept='s', words=['s']), Vertex(concept='convolution layer', words=['convolution', 'layer']), Vertex(concept='16 input', words=['16', 'input']), Vertex(concept='32 output channel', words=['32', 'output', 'channel']), Vertex(concept='unit parameter matrix', words=['unit', 'parameter', 'matrix']), Vertex(concept='shape', words=['shape']), Vertex(concept='parameter matrix', words=['parameter', 'matrix']), Vertex(concept='nine separate 2d convolutional layer', words=['nine', 'separate', '2d']), Vertex(concept='stride', words=['stride']), Vertex(concept='padding', words=['padding']), Vertex(concept='stride padding value', words=['stride', 'padding', 'value']), Vertex(concept='kernel size', words=['kernel', 'size']), Vertex(concept='same prediction task', words=['same', 'prediction', 'task']), Vertex(concept='parameter information', words=['parameter', 'information']), Vertex(concept='formula', words=['formula']), Vertex(concept='compression layer', words=['compression', 'layer']), Vertex(concept='global model parameter', words=['global', 'model', 'parameter']), Vertex(concept='output', words=['output']), Vertex(concept='several practical challenge', words=['several', 'practical', 'challenge']), Vertex(concept='this compression process', words=['this', 'compression', 'process']), Vertex(concept='mnist cite dataset', words=['mnist', 'cite', 'dataset']), Vertex(concept='these challenge', words=['these', 'challenge']), Vertex(concept='progress', words=['progress']), Vertex(concept='two formula convolutional layer', words=['two', 'formula', 'convolutional']), Vertex(concept='bias', words=['bias']), Vertex(concept='first conv', words=['first', 'conv']), Vertex(concept='number', words=['number']), Vertex(concept='learning rate', words=['learning', 'rate']), Vertex(concept='output channel', words=['output', 'channel']), Vertex(concept='second conv', words=['second', 'conv']), Vertex(concept='channel number', words=['channel', 'number']), Vertex(concept='parameter', words=['parameter']), Vertex(concept='corresponding weight vector', words=['corresponding', 'weight', 'vector']), Vertex(concept='mlr', words=['mlr']), Vertex(concept='negative parameter', words=['negative', 'parameter']), Vertex(concept='sub model parameter', words=['sub', 'model', 'parameter']), Vertex(concept='similar distribution pattern', words=['similar', 'distribution', 'pattern']), Vertex(concept='value range', words=['value', 'range']), Vertex(concept='significant performance fluctuation', words=['significant', 'performance', 'fluctuation']), Vertex(concept='convolution process', words=['convolution', 'process']), Vertex(concept='performance', words=['performance']), Vertex(concept='much higher sensitivity', words=['much', 'higher', 'sensitivity']), Vertex(concept='change', words=['change']), Vertex(concept='weight normalization', words=['weight', 'normalization']), Vertex(concept='learning rate scheduler', words=['learning', 'rate', 'scheduler']), Vertex(concept='convolution parameter', words=['convolution', 'parameter']), Vertex(concept='convergence', words=['convergence']), Vertex(concept='fine grained way', words=['fine', 'grained', 'way']), Vertex(concept='cosine annealing learning rate scheduler', words=['cosine', 'annealing', 'learning']), Vertex(concept='cosine function decay', words=['cosine', 'function', 'decay']), Vertex(concept='around 20 epoch', words=['around', '20', 'epoch']), Vertex(concept='corresponding client', words=['corresponding', 'client']), Vertex(concept='significant computational and communication overhead', words=['significant', 'computational', 'and']), Vertex(concept='reverse operation', words=['reverse', 'operation']), Vertex(concept='convolution compression', words=['convolution', 'compression']), Vertex(concept='different tc layer', words=['different', 'tc', 'layer']), Vertex(concept='each', words=['each']), Vertex(concept='client model', words=['client', 'model']), Vertex(concept='12 input', words=['12', 'input']), Vertex(concept='24 output channel', words=['24', 'output', 'channel']), Vertex(concept='learnable variable', words=['learnable', 'variable']), Vertex(concept='[[[formula]]]', words=['[[[formula]]]']), Vertex(concept='tc parameter', words=['tc', 'parameter']), Vertex(concept='tc operation', words=['tc', 'operation']), Vertex(concept='two tc formula layer', words=['two', 'tc', 'formula']), Vertex(concept='model', words=['model']), Vertex(concept='magnitude', words=['magnitude']), Vertex(concept='dilated model parameter', words=['dilated', 'model', 'parameter']), Vertex(concept='personalized information', words=['personalized', 'information']), Vertex(concept='that', words=['that']), Vertex(concept='aggregation process', words=['aggregation', 'process']), Vertex(concept='all dilated model', words=['all', 'dilated', 'model']), Vertex(concept='gradient descent', words=['gradient', 'descent']), Vertex(concept='kullback leibler divergence', words=['kullback', 'leibler', 'divergence']), Vertex(concept='more contribution', words=['more', 'contribution']), Vertex(concept='aggregation', words=['aggregation']), Vertex(concept='aggregated global model', words=['aggregated', 'global', 'model']), Vertex(concept='higher generalizability', words=['higher', 'generalizability']), Vertex(concept='more comprehensive global perspective', words=['more', 'comprehensive', 'global']), Vertex(concept='pytorch', words=['pytorch']), Vertex(concept='gradient', words=['gradient']), Vertex(concept='convolution / tc parameter', words=['convolution', '/', 'tc']), Vertex(concept='weight vector tuning', words=['weight', 'vector', 'tuning']), Vertex(concept='cloud server', words=['cloud', 'server']), Vertex(concept='router', words=['router']), Vertex(concept='these edge device', words=['these', 'edge', 'device']), Vertex(concept='our office', words=['our', 'office']), Vertex(concept='laboratory', words=['laboratory']), Vertex(concept='two representative mobile application', words=['two', 'representative', 'mobile']), Vertex(concept='three datasets', words=['three', 'datasets']), Vertex(concept='1 mnist', words=['1', 'mnist']), Vertex(concept='60000 formula gray scale image', words=['60000', 'formula', 'gray']), Vertex(concept='convolutional neural network', words=['convolutional', 'neural', 'network']), Vertex(concept='2 cifar10', words=['2', 'cifar10']), Vertex(concept='60000 32 formula', words=['60000', '32', 'formula']), Vertex(concept='resnet18', words=['resnet18']), Vertex(concept='3 cinic10', words=['3', 'cinic10']), Vertex(concept='180000 32 formula 32 color image', words=['180000', '32', 'formula']), Vertex(concept='ten class', words=['ten', 'class']), Vertex(concept='googlenet', words=['googlenet']), Vertex(concept='evaluation', words=['evaluation']), Vertex(concept='1 wiar', words=['1', 'wiar']), Vertex(concept='480 90 formula 250 wi fi csi sample', words=['480', '90', 'formula']), Vertex(concept='16 activity', words=['16', 'activity']), Vertex(concept='dataset', words=['dataset']), Vertex(concept='64000 sample', words=['64000', 'sample']), Vertex(concept='3 harbox', words=['3', 'harbox']), Vertex(concept='9 axis imu data', words=['9', 'axis', 'imu']), Vertex(concept='five daily activity', words=['five', 'daily', 'activity']), Vertex(concept='cnn model', words=['cnn', 'model']), Vertex(concept='three conv layer', words=['three', 'conv', 'layer']), Vertex(concept='one fc layer', words=['one', 'fc', 'layer']), Vertex(concept='these datasets', words=['these', 'datasets']), Vertex(concept='four part', words=['four', 'part']), Vertex(concept='each part', words=['each', 'part']), Vertex(concept='5 %', words=['5', '%']), Vertex(concept='20 %', words=['20', '%']), Vertex(concept='different datasets', words=['different', 'datasets']), Vertex(concept='following baseline', words=['following', 'baseline']), Vertex(concept='serveralone', words=['serveralone']), Vertex(concept='one model', words=['one', 'model']), Vertex(concept='only server side global data', words=['only', 'server', 'side']), Vertex(concept='affordable model', words=['affordable', 'model']), Vertex(concept='smallest affordable model', words=['smallest', 'affordable', 'model']), Vertex(concept='fedmd', words=['fedmd']), Vertex(concept='5 lotteryfl', words=['5', 'lotteryfl']), Vertex(concept='6 hermes', words=['6', 'hermes']), Vertex(concept='sparse sub model', words=['sparse', 'sub', 'model']), Vertex(concept='7 tailorfl', words=['7', 'tailorfl']), Vertex(concept='subset', words=['subset']), Vertex(concept='9 fedrolex', words=['9', 'fedrolex']), Vertex(concept='dynamic rolling window', words=['dynamic', 'rolling', 'window']), Vertex(concept='four sr', words=['four', 'sr']), Vertex(concept='resource profile', words=['resource', 'profile']), Vertex(concept='larger sr', words=['larger', 'sr']), Vertex(concept='laptop', words=['laptop']), Vertex(concept='smaller sr', words=['smaller', 'sr']), Vertex(concept='raspberry pi', words=['raspberry', 'pi']), Vertex(concept='disjoint non iid client side data', words=['disjoint', 'non', 'iid']), Vertex(concept='communication round', words=['communication', 'round']), Vertex(concept='5 local training epoch', words=['5', 'local', 'training']), Vertex(concept='global model accuracy', words=['global', 'model', 'accuracy']), Vertex(concept='server side test dataset', words=['server', 'side', 'test']), Vertex(concept='average client model accuracy', words=['average', 'client', 'model']), Vertex(concept='client side private test datasets', words=['client', 'side', 'private']), Vertex(concept='pympler library', words=['pympler', 'library']), Vertex(concept='each client s process id', words=['each', 'client', 's']), Vertex(concept='100 communication round', words=['100', 'communication', 'round']), Vertex(concept='execution time', words=['execution', 'time']), Vertex(concept='overall performance', words=['overall', 'performance']), Vertex(concept='standalone fedmd', words=['standalone', 'fedmd']), Vertex(concept='same degree', words=['same', 'degree']), Vertex(concept='higher global model accuracy', words=['higher', 'global', 'model']), Vertex(concept='baseline', words=['baseline']), Vertex(concept='average improvement', words=['average', 'improvement']), Vertex(concept='205 %', words=['205', '%']), Vertex(concept='138 %', words=['138', '%']), Vertex(concept='insufficient number', words=['insufficient', 'number']), Vertex(concept='fedavg', words=['fedavg']), Vertex(concept='iid data', words=['iid', 'data']), Vertex(concept='superior generalization performance', words=['superior', 'generalization', 'performance']), Vertex(concept='performance enhancement', words=['performance', 'enhancement']), Vertex(concept='increased data heterogeneity', words=['increased', 'data', 'heterogeneity']), Vertex(concept='homogeneous data', words=['homogeneous', 'data']), Vertex(concept='better generalizability', words=['better', 'generalizability']), Vertex(concept='robustness', words=['robustness']), Vertex(concept='better personalization performance', words=['better', 'personalization', 'performance']), Vertex(concept='performance improvement', words=['performance', 'improvement']), Vertex(concept='each client model', words=['each', 'client', 'model']), Vertex(concept='same heterogeneous data setting', words=['same', 'heterogeneous', 'data']), Vertex(concept='small portion', words=['small', 'portion']), Vertex(concept='serveralone s global model', words=['serveralone', 's', 'global']), Vertex(concept='sufficient data', words=['sufficient', 'data']), Vertex(concept='degraded performance', words=['degraded', 'performance']), Vertex(concept='longer convergence time', words=['longer', 'convergence', 'time']), Vertex(concept='client model accuracy', words=['client', 'model', 'accuracy']), Vertex(concept='this performance gain', words=['this', 'performance', 'gain']), Vertex(concept='tc dilation process', words=['tc', 'dilation', 'process']), Vertex(concept='rescaled large model', words=['rescaled', 'large', 'model']), Vertex(concept='personalization information', words=['personalization', 'information']), Vertex(concept='sensing heterogeneity', words=['sensing', 'heterogeneity']), Vertex(concept='better and more stable performance', words=['better', 'and', 'more']), Vertex(concept='cifar10', words=['cifar10']), Vertex(concept='cinic10', words=['cinic10']), Vertex(concept='harbox', words=['harbox']), Vertex(concept='better performance', words=['better', 'performance']), Vertex(concept='distilled knowledge', words=['distilled', 'knowledge']), Vertex(concept='downside', words=['downside']), Vertex(concept='excessive communication', words=['excessive', 'communication']), Vertex(concept='computational overhead', words=['computational', 'overhead']), Vertex(concept='comparable personalization performance', words=['comparable', 'personalization', 'performance']), Vertex(concept='extra burden', words=['extra', 'burden']), Vertex(concept='personalization performance', words=['personalization', 'performance']), Vertex(concept='significant performance gain', words=['significant', 'performance', 'gain']), Vertex(concept='both global and client model', words=['both', 'global', 'and']), Vertex(concept='memory footprint', words=['memory', 'footprint']), Vertex(concept='wall clock time', words=['wall', 'clock', 'time']), Vertex(concept='table', words=['table']), Vertex(concept='overview', words=['overview']), Vertex(concept='average memory usage', words=['average', 'memory', 'usage']), Vertex(concept='average wall clock time', words=['average', 'wall', 'clock']), Vertex(concept='average saving', words=['average', 'saving']), Vertex(concept='406 %', words=['406', '%']), Vertex(concept='546 %', words=['546', '%']), Vertex(concept='approximately half', words=['approximately', 'half']), Vertex(concept='memory and training time', words=['memory', 'and', 'training']), Vertex(concept='2 gb less memory', words=['2', 'gb', 'less']), Vertex(concept='less memory', words=['less', 'memory']), Vertex(concept='total size', words=['total', 'size']), Vertex(concept='data packet', words=['data', 'packet']), Vertex(concept='fedconv lotteryfl heterofl', words=['fedconv', 'lotteryfl', 'heterofl']), Vertex(concept='extra content', words=['extra', 'content']), Vertex(concept='heterofl', words=['heterofl']), Vertex(concept='significant potential', words=['significant', 'potential']), Vertex(concept='fedrolex', words=['fedrolex']), Vertex(concept='more system resource', words=['more', 'system', 'resource']), Vertex(concept='100 client', words=['100', 'client']), Vertex(concept='upward trend', words=['upward', 'trend']), Vertex(concept='scalability', words=['scalability']), Vertex(concept='superiority', words=['superiority']), Vertex(concept='sr', words=['sr']), Vertex(concept='model performance', words=['model', 'performance']), Vertex(concept='10 client', words=['10', 'client']), Vertex(concept='certain threshold', words=['certain', 'threshold']), Vertex(concept='even lightweight device', words=['even', 'lightweight', 'device']), Vertex(concept='googlenet model', words=['googlenet', 'model']), Vertex(concept='corresponding threshold', words=['corresponding', 'threshold']), Vertex(concept='much higher accuracy', words=['much', 'higher', 'accuracy']), Vertex(concept='larger amount', words=['larger', 'amount']), Vertex(concept='sample number ratio', words=['sample', 'number', 'ratio']), Vertex(concept='two key observation', words=['two', 'key', 'observation']), Vertex(concept='ratio', words=['ratio']), Vertex(concept='richer information', words=['richer', 'information']), Vertex(concept='default sample ratio', words=['default', 'sample', 'ratio']), Vertex(concept='actual turning point', words=['actual', 'turning', 'point']), Vertex(concept='epoch', words=['epoch']), Vertex(concept='two datasets', words=['two', 'datasets']), Vertex(concept='20 th and 40 th epoch', words=['20', 'th', 'and']), Vertex(concept='tuning epoch', words=['tuning', 'epoch']), Vertex(concept='stride length', words=['stride', 'length']), Vertex(concept='whose parameter matrix', words=['whose', 'parameter', 'matrix']), Vertex(concept='compressed parameter matrix', words=['compressed', 'parameter', 'matrix']), Vertex(concept='larger kernel', words=['larger', 'kernel']), Vertex(concept='more comprehensive parameter information', words=['more', 'comprehensive', 'parameter']), Vertex(concept='smaller stride', words=['smaller', 'stride']), Vertex(concept='more fine grained information', words=['more', 'fine', 'grained']), Vertex(concept='high computational complexity', words=['high', 'computational', 'complexity']), Vertex(concept='ablation study', words=['ablation', 'study']), Vertex(concept='impact', words=['impact']), Vertex(concept='higher average accuracy', words=['higher', 'average', 'accuracy']), Vertex(concept='fl server', words=['fl', 'server']), Vertex(concept='communication computation and energy cost', words=['communication', 'computation', 'and']), Vertex(concept='training process', words=['training', 'process']), Vertex(concept='weight', words=['weight']), Vertex(concept='respect', words=['respect']), Vertex(concept='effect', words=['effect']), Vertex(concept='varying skewness', words=['varying', 'skewness']), Vertex(concept='parameter local data distribution', words=['parameter', 'local', 'data']), Vertex(concept='different parameter information', words=['different', 'parameter', 'information']), Vertex(concept='client own personal layer', words=['client', 'own', 'personal']), Vertex(concept='average accuracy', words=['average', 'accuracy']), Vertex(concept='five datasets', words=['five', 'datasets']), Vertex(concept='highest client model accuracy', words=['highest', 'client', 'model']), Vertex(concept='both server side and client side datasets', words=['both', 'server', 'side']), Vertex(concept='same domain', words=['same', 'domain']), Vertex(concept='case study', words=['case', 'study']), Vertex(concept='chars74 k dataset', words=['chars74', 'k', 'dataset']), Vertex(concept='image', words=['image']), Vertex(concept='digit', words=['digit']), Vertex(concept='large global model', words=['large', 'global', 'model']), Vertex(concept='tc', words=['tc']), Vertex(concept='locally trained heterogeneous client model', words=['locally', 'trained', 'heterogeneous']), Vertex(concept='transfer learning strategy', words=['transfer', 'learning', 'strategy']), Vertex(concept='higher accuracy', words=['higher', 'accuracy']), Vertex(concept='resource profiling', words=['resource', 'profiling']), Vertex(concept='flower cite framework', words=['flower', 'cite', 'framework']), Vertex(concept='stable and robust simulated environment', words=['stable', 'and', 'robust']), Vertex(concept='fl', words=['fl']), Vertex(concept='these', words=['these']), Vertex(concept='technical challenge', words=['technical', 'challenge']), Vertex(concept='issue', words=['issue']), Vertex(concept='recent advancement', words=['recent', 'advancement']), Vertex(concept='federated learning setup', words=['federated', 'learning', 'setup']), Vertex(concept='android client', words=['android', 'client']), Vertex(concept='pre training and fine tuning process', words=['pre', 'training', 'and']), Vertex(concept='clusterfl', words=['clusterfl']), Vertex(concept='intrinsic clustering pattern', words=['intrinsic', 'clustering', 'pattern']), Vertex(concept='personalized fl', words=['personalized', 'fl']), Vertex(concept='local fine tuning', words=['local', 'fine', 'tuning']), Vertex(concept='pfedme', words=['pfedme']), Vertex(concept='moreau envelope', words=['moreau', 'envelope']), Vertex(concept='regularized loss function', words=['regularized', 'loss', 'function']), Vertex(concept='lower layer', words=['lower', 'layer']), Vertex(concept='more general feature', words=['more', 'general', 'feature']), Vertex(concept='recent work', words=['recent', 'work']), Vertex(concept='average consensus', words=['average', 'consensus']), Vertex(concept='part', words=['part']), Vertex(concept='sharing strategy', words=['sharing', 'strategy']), Vertex(concept='3 pruning based method', words=['3', 'pruning', 'based']), Vertex(concept='popularity', words=['popularity']), Vertex(concept='heterogeneous fl', words=['heterogeneous', 'fl']), Vertex(concept='hermes', words=['hermes']), Vertex(concept='channel level pruning method', words=['channel', 'level', 'pruning']), Vertex(concept='tailorfl', words=['tailorfl']), Vertex(concept='importance value based filter level pruning scheme', words=['importance', 'value', 'based']), Vertex(concept='these work', words=['these', 'work']), Vertex(concept='system overhead', words=['system', 'overhead']), Vertex(concept='useful feature', words=['useful', 'feature']), Vertex(concept='key information', words=['key', 'information']), Vertex(concept='three key technical module', words=['three', 'key', 'technical']), Vertex(concept='sota baseline', words=['sota', 'baseline']), Vertex(concept='different size', words=['different', 'size']), Vertex(concept='removal', words=['removal']), Vertex(concept='entire channel', words=['entire', 'channel']), Vertex(concept='overhead', words=['overhead']), Vertex(concept='client friendly fl framework', words=['client', 'friendly', 'fl']), Vertex(concept='same size', words=['same', 'size']), Vertex(concept='small dataset', words=['small', 'dataset']), Vertex(concept='transfer', words=['transfer']), Vertex(concept='imbalanced contribution', words=['imbalanced', 'contribution']), Vertex(concept='heterogeneous federated client', words=['heterogeneous', 'federated', 'client']), Vertex(concept='user friendly fl framework', words=['user', 'friendly', 'fl']), Vertex(concept='two representative fl task', words=['two', 'representative', 'fl']), Vertex(concept='inference accuracy', words=['inference', 'accuracy']), Vertex(concept='more than 35 %', words=['more', 'than', '35']), Vertex(concept='uniform size', words=['uniform', 'size']), Vertex(concept='client contribution', words=['client', 'contribution']), Vertex(concept='final aggregation', words=['final', 'aggregation']), Vertex(concept='both inference accuracy', words=['both', 'inference', 'accuracy']), Vertex(concept='least system resource', words=['least', 'system', 'resource']), Vertex(concept='conventional fl', words=['conventional', 'fl']), Vertex(concept='weaker client', words=['weaker', 'client']), Vertex(concept='synchronized fl', words=['synchronized', 'fl']), Vertex(concept='full use', words=['full', 'use']), Vertex(concept='more powerful client', words=['more', 'powerful', 'client']), Vertex(concept='varied parameter size', words=['varied', 'parameter', 'size']), Vertex(concept='diverse resource', words=['diverse', 'resource']), Vertex(concept='problem', words=['problem']), Vertex(concept='overlapped part', words=['overlapped', 'part']), Vertex(concept='other client', words=['other', 'client']), Vertex(concept='larger volume', words=['larger', 'volume']), Vertex(concept='data', words=['data']), Vertex(concept='different part', words=['different', 'part']), Vertex(concept='global model s parameter', words=['global', 'model', 's']), Vertex(concept='distribution', words=['distribution']), Vertex(concept='client workload', words=['client', 'workload']), Vertex(concept='model pruning', words=['model', 'pruning']), Vertex(concept='corresponding channel', words=['corresponding', 'channel']), Vertex(concept='certain weight', words=['certain', 'weight']), Vertex(concept='connection', words=['connection']), Vertex(concept='accuracy drop', words=['accuracy', 'drop']), Vertex(concept='8404 %', words=['8404', '%']), Vertex(concept='7336 %', words=['7336', '%']), Vertex(concept='all parameter', words=['all', 'parameter']), Vertex(concept='crucial information', words=['crucial', 'information']), Vertex(concept='shrinkage ratio', words=['shrinkage', 'ratio']), Vertex(concept='075', words=['075']), Vertex(concept='fusion', words=['fusion']), Vertex(concept='last two feature map', words=['last', 'two', 'feature']), Vertex(concept='deer', words=['deer']), Vertex(concept='feature extraction capability', words=['feature', 'extraction', 'capability']), Vertex(concept='iterative refining', words=['iterative', 'refining']), Vertex(concept='architecture', words=['architecture']), Vertex(concept='better global view', words=['better', 'global', 'view']), Vertex(concept='fine tuned convolution parameter', words=['fine', 'tuned', 'convolution']), Vertex(concept='i e parameter', words=['i', 'e', 'parameter']), Vertex(concept='local data', words=['local', 'data']), Vertex(concept='personalization', words=['personalization']), Vertex(concept='each element', words=['each', 'element']), Vertex(concept='kernel', words=['kernel']), Vertex(concept='other type', words=['other', 'type']), Vertex(concept='layer', words=['layer']), Vertex(concept='input channel', words=['input', 'channel']), Vertex(concept='first layer', words=['first', 'layer']), Vertex(concept='all channel', words=['all', 'channel']), Vertex(concept='raw data', words=['raw', 'data']), Vertex(concept='last layer', words=['last', 'layer']), Vertex(concept='loss', words=['loss']), Vertex(concept='ground truth', words=['ground', 'truth']), Vertex(concept='prediction result', words=['prediction', 'result']), Vertex(concept='forward function', words=['forward', 'function']), Vertex(concept='corresponding label', words=['corresponding', 'label']), Vertex(concept='[[[formula th layer]]]', words=['[[[formula', 'th', 'layer]]]']), Vertex(concept='sub model output', words=['sub', 'model', 'output']), Vertex(concept='9904 %', words=['9904', '%']), Vertex(concept='limited capability', words=['limited', 'capability']), Vertex(concept='simple compression layer', words=['simple', 'compression', 'layer']), Vertex(concept='lower accuracy', words=['lower', 'accuracy']), Vertex(concept='compression', words=['compression']), Vertex(concept='slope', words=['slope']), Vertex(concept='negative and positive value', words=['negative', 'and', 'positive']), Vertex(concept='lower and upper bound', words=['lower', 'and', 'upper']), Vertex(concept='maximum number', words=['maximum', 'number']), Vertex(concept='iteration', words=['iteration']), Vertex(concept='non iid data', words=['non', 'iid', 'data']), Vertex(concept='different sensing heterogeneity', words=['different', 'sensing', 'heterogeneity']), Vertex(concept='tc layer', words=['tc', 'layer']), Vertex(concept='configuration', words=['configuration']), Vertex(concept='each tc layer', words=['each', 'tc', 'layer']), Vertex(concept='other kind', words=['other', 'kind']), Vertex(concept='network layer', words=['network', 'layer']), Vertex(concept='input channel number', words=['input', 'channel', 'number']), Vertex(concept='output channel number', words=['output', 'channel', 'number']), Vertex(concept='all client model', words=['all', 'client', 'model']), Vertex(concept='dilated large model', words=['dilated', 'large', 'model']), Vertex(concept='integration', words=['integration']), Vertex(concept='aggregated model', words=['aggregated', 'model']), Vertex(concept='only 476 %', words=['only', '476', '%']), Vertex(concept='mnist dataset', words=['mnist', 'dataset']), Vertex(concept='client side data distribution', words=['client', 'side', 'data']), Vertex(concept='diverse personalized information', words=['diverse', 'personalized', 'information']), Vertex(concept='every network layer', words=['every', 'network', 'layer']), Vertex(concept='each dilated model', words=['each', 'dilated', 'model']), Vertex(concept='[[[formula th aggregated network layer]]]', words=['[[[formula', 'th', 'aggregated']), Vertex(concept='[[[formula th large model]]]', words=['[[[formula', 'th', 'large']), Vertex(concept='data sample', words=['data', 'sample']), Vertex(concept='different contribution', words=['different', 'contribution']), Vertex(concept='similarity', words=['similarity']), Vertex(concept='kld', words=['kld']), Vertex(concept='th dilated model', words=['th', 'dilated', 'model']), Vertex(concept='previous communication round', words=['previous', 'communication', 'round']), Vertex(concept='optimization', words=['optimization']), Vertex(concept='weight vector', words=['weight', 'vector']), Vertex(concept='cross entropy loss', words=['cross', 'entropy', 'loss']), Vertex(concept='model output', words=['model', 'output']), Vertex(concept='coefficient', words=['coefficient']), Vertex(concept='balance', words=['balance']), Vertex(concept='load_state_dict function', words=['load_state_dict', 'function']), Vertex(concept='20 heterogeneous mobile device', words=['20', 'heterogeneous', 'mobile']), Vertex(concept='different hardware and network condition', words=['different', 'hardware', 'and']), Vertex(concept='detailed configuration', words=['detailed', 'configuration']), Vertex(concept='heterogeneous device', words=['heterogeneous', 'device']), Vertex(concept='popular computer vision application', words=['popular', 'computer', 'vision']), Vertex(concept='ten handwritten digit', words=['ten', 'handwritten', 'digit']), Vertex(concept='two convolutional layer', words=['two', 'convolutional', 'layer']), Vertex(concept='32 color image', words=['32', 'color', 'image']), Vertex(concept='different type', words=['different', 'type']), Vertex(concept='sensor data', words=['sensor', 'data']), Vertex(concept='channel state information', words=['channel', 'state', 'information']), Vertex(concept='wifi signal', words=['wifi', 'signal']), Vertex(concept='5000 36 formula 36 gray scale depth image', words=['5000', '36', 'formula']), Vertex(concept='five common gesture', words=['five', 'common', 'gesture']), Vertex(concept='sliding window', words=['sliding', 'window']), Vertex(concept='2 second', words=['2', 'second']), Vertex(concept='900 dimensional feature', words=['900', 'dimensional', 'feature']), Vertex(concept='121 user', words=['121', 'user']), Vertex(concept='77 different smartphones', words=['77', 'different', 'smartphones']), Vertex(concept='degree', words=['degree']), Vertex(concept='no standard model', words=['no', 'standard', 'model']), Vertex(concept='1 iid server side global data', words=['1', 'iid', 'server']), Vertex(concept='2 iid test data', words=['2', 'iid', 'test']), Vertex(concept='total dataset', words=['total', 'dataset']), Vertex(concept='first and second part', words=['first', 'and', 'second']), Vertex(concept='constrained resource', words=['constrained', 'resource']), Vertex(concept='some device', words=['some', 'device']), Vertex(concept='consensus', words=['consensus']), Vertex(concept='learned importance value', words=['learned', 'importance', 'value']), Vertex(concept='each filter', words=['each', 'filter']), Vertex(concept='sample distribution', words=['sample', 'distribution']), Vertex(concept='different class', words=['different', 'class']), Vertex(concept='0001', words=['0001']), Vertex(concept='all convolution parameter', words=['all', 'convolution', 'parameter']), Vertex(concept='generalizability', words=['generalizability']), Vertex(concept='effectiveness', words=['effectiveness']), Vertex(concept='network traffic', words=['network', 'traffic']), Vertex(concept='each round', words=['each', 'round']), Vertex(concept='heterogeneous data', words=['heterogeneous', 'data']), Vertex(concept='training', words=['training']), Vertex(concept='different data heterogeneity', words=['different', 'data', 'heterogeneity']), Vertex(concept='all datasets', words=['all', 'datasets']), Vertex(concept='client side test datasets', words=['client', 'side', 'test']), Vertex(concept='entire dataset', words=['entire', 'dataset']), Vertex(concept='client side non iid data', words=['client', 'side', 'non']), Vertex(concept='each uploaded client model', words=['each', 'uploaded', 'client']), Vertex(concept='harbox dataset', words=['harbox', 'dataset']), Vertex(concept='performance instability', words=['performance', 'instability']), Vertex(concept='some baseline', words=['some', 'baseline']), Vertex(concept='heterogeneous formula = 005 data', words=['heterogeneous', 'formula', '=']), Vertex(concept='same set', words=['same', 'set']), Vertex(concept='memory cost', words=['memory', 'cost']), Vertex(concept='around 90 minute', words=['around', '90', 'minute']), Vertex(concept='significant saving', words=['significant', 'saving']), Vertex(concept='memory computation and communication resource', words=['memory', 'computation', 'and']), Vertex(concept='communication cost', words=['communication', 'cost']), Vertex(concept='selected participating client', words=['selected', 'participating', 'client']), Vertex(concept='client model performance', words=['client', 'model', 'performance']), Vertex(concept='varying client number', words=['varying', 'client', 'number']), Vertex(concept='trade off', words=['trade', 'off']), Vertex(concept='remaining 10 client', words=['remaining', '10', 'client']), Vertex(concept='notable accuracy drop', words=['notable', 'accuracy', 'drop']), Vertex(concept='step', words=['step']), Vertex(concept='05 %', words=['05', '%']), Vertex(concept='compression dilation aggregation impact', words=['compression', 'dilation', 'aggregation']), Vertex(concept='client performance', words=['client', 'performance']), Vertex(concept='importance', words=['importance']), Vertex(concept='server side pre training process', words=['server', 'side', 'pre']), Vertex(concept='our learned weight vector', words=['our', 'learned', 'weight']), Vertex(concept='sample number', words=['sample', 'number']), Vertex(concept='potential', words=['potential']), Vertex(concept='computer font', words=['computer', 'font']), Vertex(concept='variation', words=['variation']), Vertex(concept='e g different shape', words=['e', 'g', 'different']), Vertex(concept='e g various writing style', words=['e', 'g', 'various']), Vertex(concept='transformation', words=['transformation']), Vertex(concept='one data domain', words=['one', 'data', 'domain']), Vertex(concept='another', words=['another']), Vertex(concept='client side data', words=['client', 'side', 'data']), Vertex(concept='domain gap', words=['domain', 'gap']), Vertex(concept='server side', words=['server', 'side']), Vertex(concept='decrease', words=['decrease']), Vertex(concept='both global model', words=['both', 'global', 'model']), Vertex(concept='privacy protection', words=['privacy', 'protection']), Vertex(concept='practicality', words=['practicality']), Vertex(concept='compatibility', words=['compatibility']), Vertex(concept='flower framework', words=['flower', 'framework']), Vertex(concept='android system', words=['android', 'system']), Vertex(concept='client s perspective', words=['client', 's', 'perspective']), Vertex(concept='view', words=['view']), Vertex(concept='client data', words=['client', 'data']), Vertex(concept='clustered multi task federated learning', words=['clustered', 'multi', 'task']), Vertex(concept='upper layer', words=['upper', 'layer']), Vertex(concept='minimal modification', words=['minimal', 'modification']), Vertex(concept='existing fl system', words=['existing', 'fl', 'system']), Vertex(concept='tuning', words=['tuning']), Vertex(concept='shared dataset', words=['shared', 'dataset']), Vertex(concept='fixed subset', words=['fixed', 'subset']), Vertex(concept='global parameter', words=['global', 'parameter']), Vertex(concept='existing fl framework', words=['existing', 'fl', 'framework']), Vertex(concept='client friendly federated learning framework', words=['client', 'friendly', 'federated']), Vertex(concept='resource constrained mobile device', words=['resource', 'constrained', 'mobile']), Vertex(concept='unified size', words=['unified', 'size']), Vertex(concept='much lower computation and communication overhead', words=['much', 'lower', 'computation']), Vertex(concept='fl client', words=['fl', 'client'])],\n",
      "\tedges=[Edge(mobile device <--[train]--> shared global model), Edge(client <--[keep]--> client private data), Edge(server <--[orchestrates]--> model aggregation), Edge(client <--[orchestrates]--> model aggregation), Edge(heterogeneous client <--[orchestrates]--> model aggregation), Edge(federated client <--[have]--> diverse system resource), Edge(federated client <--[have for]--> heterogeneous model), Edge(federated client <--[have for]--> data distribution), Edge(high end pc <--[support]--> large model), Edge(high end pc <--[support]--> sub model), Edge(previous solution <--[include]--> knowledge distillation), Edge(previous solution <--[include]--> parameter sharing), Edge(kd <--[distills]--> knowledge), Edge(ensemble learning <--[distills]--> knowledge), Edge(kd <--[distills from]--> heterogeneous client model), Edge(ensemble learning <--[distills from]--> heterogeneous client model), Edge(kd <--[imposes]--> additional compute overhead), Edge(ensemble learning <--[imposes]--> additional compute overhead), Edge(kd <--[imposes on]--> client), Edge(ensemble learning <--[imposes on]--> client), Edge(client <--[train on]--> public data), Edge(parameter sharing strategy <--[distribute]--> different region), Edge(parameter sharing strategy <--[distribute of]--> global model), Edge(parameter sharing strategy <--[distribute of]--> sub model), Edge(parameter pruning method <--[utilize]--> channel or filter level pruning), Edge(method <--[suffer from]--> information loss), Edge(method <--[suffer from]--> imbalance issue), Edge(method <--[suffer from]--> performance degradation), Edge(heterogeneous sub model <--[retain]--> information), Edge(heterogeneous sub model <--[retain of]--> global model), Edge(heterogeneous sub model <--[retain of]--> sub model), Edge(we <--[propose]--> fedconv), Edge(we <--[propose]--> all baseline), Edge(we <--[propose]--> lotteryfl), Edge(convolution <--[compress]--> large model), Edge(convolution <--[compress]--> sub model), Edge(transposed convolution <--[compress]--> large model), Edge(transposed convolution <--[compress]--> sub model), Edge(convolution <--[compress via]--> various receptive field), Edge(transposed convolution <--[compress via]--> various receptive field), Edge(server <--[performs]--> convolutional compression), Edge(server <--[performs]--> transposed convolutional dilation), Edge(client <--[performs]--> convolutional compression), Edge(client <--[performs]--> transposed convolutional dilation), Edge(heterogeneous client <--[performs]--> convolutional compression), Edge(heterogeneous client <--[performs]--> transposed convolutional dilation), Edge(server <--[performs on]--> global model), Edge(server <--[performs on]--> sub model), Edge(client <--[performs on]--> global model), Edge(client <--[performs on]--> sub model), Edge(heterogeneous client <--[performs on]--> global model), Edge(heterogeneous client <--[performs on]--> sub model), Edge(client <--[train on]--> compressed sub model), Edge(server <--[uses]--> transposed convolution), Edge(client <--[uses]--> transposed convolution), Edge(heterogeneous client <--[uses]--> transposed convolution), Edge(server <--[assigns]--> different learned weight vector), Edge(client <--[assigns]--> different learned weight vector), Edge(heterogeneous client <--[assigns]--> different learned weight vector), Edge(server <--[assigns to]--> these dilated model), Edge(client <--[assigns to]--> these dilated model), Edge(heterogeneous client <--[assigns to]--> these dilated model), Edge(server <--[assigns]--> aggregate vector), Edge(client <--[assigns]--> aggregate vector), Edge(heterogeneous client <--[assigns]--> aggregate vector), Edge(fedconv <--[optimizes]--> model compression dilation and aggregation process), Edge(all baseline <--[optimizes]--> model compression dilation and aggregation process), Edge(lotteryfl <--[optimizes]--> model compression dilation and aggregation process), Edge(our system <--[incur]--> extra communication or computation overhead), Edge(our system <--[incur for]--> resource constrained client), Edge(we <--[address]--> three key technical challenge), Edge(we <--[formulate]--> compression process), Edge(we <--[formulate as]--> training task), Edge(we <--[apply]--> separate tc operation), Edge(we <--[apply on]--> each client s model parameter), Edge(which <--[inherit]--> model personalized information), Edge(we <--[add]--> residual connection), Edge(these large model <--[lead to]--> performance degradation), Edge(we <--[set]--> different learnable weight vector), Edge(we <--[set for]--> dilated model), Edge(server <--[learn]--> relative importance), Edge(client <--[learn]--> relative importance), Edge(heterogeneous client <--[learn]--> relative importance), Edge(server <--[learn of]--> each model), Edge(client <--[learn of]--> each model), Edge(heterogeneous client <--[learn of]--> each model), Edge(we <--[implement]--> fedconv), Edge(we <--[implement]--> all baseline), Edge(we <--[implement]--> lotteryfl), Edge(we <--[evaluate]--> fedconv), Edge(we <--[evaluate]--> all baseline), Edge(we <--[evaluate]--> lotteryfl), Edge(we <--[evaluate on]--> six public datasets), Edge(fedconv <--[outperforms]--> sota), Edge(all baseline <--[outperforms]--> sota), Edge(lotteryfl <--[outperforms]--> sota), Edge(fedconv <--[outperforms in]--> term), Edge(all baseline <--[outperforms in]--> term), Edge(lotteryfl <--[outperforms in]--> term), Edge(fedconv <--[reduces]--> computation overhead), Edge(all baseline <--[reduces]--> computation overhead), Edge(lotteryfl <--[reduces]--> computation overhead), Edge(fedconv <--[reduces for]--> federated client), Edge(all baseline <--[reduces for]--> federated client), Edge(lotteryfl <--[reduces for]--> federated client), Edge(we <--[make]--> following key contribution), Edge(we <--[make To]--> our knowledge), Edge(this paradigm <--[compress]--> global model), Edge(this paradigm <--[compress]--> sub model), Edge(fedconv <--[handles]--> heterogeneous model), Edge(fedconv <--[handles]--> data distribution), Edge(all baseline <--[handles]--> heterogeneous model), Edge(all baseline <--[handles]--> data distribution), Edge(lotteryfl <--[handles]--> heterogeneous model), Edge(lotteryfl <--[handles]--> data distribution), Edge(fedconv <--[handles with]--> new technology), Edge(all baseline <--[handles with]--> new technology), Edge(lotteryfl <--[handles with]--> new technology), Edge(we <--[propose]--> convolutional compression module), Edge(we <--[design]--> transposed convolutional dilation method), Edge(we <--[evaluate on]--> flower), Edge(result <--[demonstrate]--> superior performance), Edge(result <--[demonstrate of]--> fedconv), Edge(result <--[demonstrate of]--> all baseline), Edge(result <--[demonstrate of]--> lotteryfl), Edge(we <--[underscore]--> necessity), Edge(we <--[underscore of]--> model heterogeneity aware fl system), Edge(knowledge distillation based method <--[incur]--> heavy overhead), Edge(knowledge distillation based method <--[incur on]--> client), Edge(knowledge distillation based method <--[incur]--> §), Edge(all client <--[share]--> same model architecture), Edge(all client <--[share In]--> practice), Edge(different client <--[have]--> diverse computation and communication resource), Edge(different client <--[have For]--> example), Edge(high end edge pc <--[have]--> more resource), Edge(low cost embedded system <--[have]--> much constrained resource), Edge(one size <--[fits]--> all), Edge(one size <--[fits to]--> sub optimal performance), Edge(client <--[suffer with]--> more resource), Edge(client <--[share]--> different region), Edge(client <--[share of]--> global model), Edge(client <--[share of]--> sub model), Edge(we <--[train]--> resnet18 model), Edge(we <--[train]--> mi), Edge(we <--[train on]--> cifar10 dataset), Edge(smaller model <--[outperform]--> larger model), Edge(smaller model <--[outperform due]--> model exposure), Edge(global model <--[exhibits]--> instability), Edge(sub model <--[exhibits]--> instability), Edge(global model <--[exhibits than]--> large model), Edge(global model <--[exhibits than]--> sub model), Edge(sub model <--[exhibits than]--> large model), Edge(sub model <--[exhibits than]--> sub model), Edge(this scheme <--[lead to]--> imbalanced performance), Edge(this scheme <--[lead to]--> unexpected performance degradation), Edge(scheme <--[enables]--> sub model), Edge(scheme <--[enables]--> global model), Edge(different client <--[contribute]--> distinct part), Edge(aggregated parameter <--[comprise]--> mixed window), Edge(aggregated parameter <--[comprise from]--> diverse sub model), Edge(channel level pruning <--[removes]--> some input channel), Edge(channel level pruning <--[removes from]--> model parameter), Edge(filter level pruning <--[prunes]--> some output channel), Edge(these two scheme <--[suffer from]--> information loss), Edge(these two scheme <--[suffer from]--> imbalance issue), Edge(these two scheme <--[suffer from]--> performance degradation), Edge(scheme <--[discard]--> some input data channel), Edge(scheme <--[discard]--> feature map), Edge(we <--[apply]--> channel level and filter level pruning), Edge(we <--[apply to]--> pre trained resnet18 model), Edge(we <--[measure]--> mutual information), Edge(which <--[quantifies]--> amount), Edge(which <--[quantifies of]--> information), Edge(accuracy <--[drops of]--> filter pruned model), Edge(this <--[indicates]--> information loss), Edge(this <--[indicates]--> imbalance issue), Edge(this <--[indicates]--> performance degradation), Edge(this <--[indicates due]--> pruning), Edge(existing pruning based method <--[require]--> server), Edge(existing pruning based method <--[require]--> client), Edge(existing pruning based method <--[require]--> heterogeneous client), Edge(which <--[incurs]--> high communication and computation overhead), Edge(which <--[incurs for]--> client), Edge(compression method <--[minimize]--> information loss), Edge(compression method <--[minimize]--> imbalance issue), Edge(compression method <--[minimize]--> performance degradation), Edge(compression method <--[minimize of]--> model parameter), Edge(we <--[propose]--> novel convolutional compression technique), Edge(sub model <--[inherit]--> spatial and hierarchical parameter pattern), Edge(global model <--[inherit]--> spatial and hierarchical parameter pattern), Edge(sub model <--[inherit from]--> global model), Edge(sub model <--[inherit from]--> sub model), Edge(global model <--[inherit from]--> global model), Edge(global model <--[inherit from]--> sub model), Edge(generated sub model <--[extract]--> valuable feature), Edge(generated sub model <--[extract from]--> input data), Edge(figure reference <--[shows]--> convolution based compression process), Edge(compressed model <--[extract by]--> convolutional compression), Edge(compressed model <--[extract by]--> transposed convolutional dilation), Edge(compressed model <--[extract]--> feature), Edge(compressed model <--[extract from]--> input data), Edge(we <--[compress]--> pre trained model), Edge(we <--[compress]--> channel pruned model), Edge(we <--[compress in]--> §), Edge(we <--[select]--> top4 and top3 feature map), Edge(we <--[select with]--> highest importance), Edge(first two feature map <--[pay from]--> sub model), Edge(first two feature map <--[pay from]--> global model), Edge(first two feature map <--[pay]--> more attention), Edge(map <--[focuses on]--> both body), Edge(map <--[focuses on]--> head), Edge(accuracy <--[decreases of]--> sub model), Edge(accuracy <--[decreases of]--> global model), Edge(our proposed convolutional compression method <--[minimize]--> information loss), Edge(our proposed convolutional compression method <--[minimize]--> imbalance issue), Edge(our proposed convolutional compression method <--[minimize]--> performance degradation), Edge(our proposed convolutional compression method <--[minimize after]--> model compression), Edge(our proposed convolutional compression method <--[minimize after]--> dilation), Edge(we <--[maintain]--> small publicly available dataset), Edge(we <--[maintain on]--> server), Edge(we <--[maintain on]--> client), Edge(we <--[maintain on]--> heterogeneous client), Edge(we <--[note as]--> conventional fl scheme), Edge(server <--[gain]--> comprehensive global view), Edge(client <--[gain]--> comprehensive global view), Edge(heterogeneous client <--[gain]--> comprehensive global view), Edge(server <--[gain of]--> entire fl process), Edge(client <--[gain of]--> entire fl process), Edge(heterogeneous client <--[gain of]--> entire fl process), Edge(server <--[initializes]--> global model), Edge(server <--[initializes]--> sub model), Edge(client <--[initializes]--> global model), Edge(client <--[initializes]--> sub model), Edge(heterogeneous client <--[initializes]--> global model), Edge(heterogeneous client <--[initializes]--> sub model), Edge(server <--[initializes with]--> estimated memory requirement), Edge(client <--[initializes with]--> estimated memory requirement), Edge(heterogeneous client <--[initializes with]--> estimated memory requirement), Edge(server <--[trains]--> global model), Edge(server <--[trains]--> sub model), Edge(client <--[trains]--> global model), Edge(client <--[trains]--> sub model), Edge(heterogeneous client <--[trains]--> global model), Edge(heterogeneous client <--[trains]--> sub model), Edge(server <--[trains for]--> several epoch), Edge(client <--[trains for]--> several epoch), Edge(heterogeneous client <--[trains for]--> several epoch), Edge(server <--[sends]--> heterogeneous sub model), Edge(client <--[sends]--> heterogeneous sub model), Edge(heterogeneous client <--[sends]--> heterogeneous sub model), Edge(server <--[sends to]--> federated client), Edge(client <--[sends to]--> federated client), Edge(heterogeneous client <--[sends to]--> federated client), Edge(server <--[sends]--> ③), Edge(client <--[sends]--> ③), Edge(heterogeneous client <--[sends]--> ③), Edge(client <--[perform]--> several epoch), Edge(client <--[perform of]--> local training), Edge(server <--[performs]--> weighted average aggregation), Edge(client <--[performs]--> weighted average aggregation), Edge(heterogeneous client <--[performs]--> weighted average aggregation), Edge(server <--[applies]--> weighted average aggregation), Edge(client <--[applies]--> weighted average aggregation), Edge(heterogeneous client <--[applies]--> weighted average aggregation), Edge(convolutional compression module <--[leverages]--> set), Edge(convolutional compression module <--[leverages of]--> convolutional layer), Edge(compressed parameter <--[become of]--> sub model), Edge(compressed parameter <--[become of]--> global model), Edge(we <--[use]--> server side data), Edge(sub model <--[achieve]--> comparable performance), Edge(global model <--[achieve]--> comparable performance), Edge(sub model <--[achieve to]--> global model), Edge(sub model <--[achieve to]--> sub model), Edge(global model <--[achieve to]--> global model), Edge(global model <--[achieve to]--> sub model), Edge(client <--[specify]--> client shrinkage ratio), Edge(server <--[broadcasts]--> size), Edge(server <--[broadcasts]--> resource budget), Edge(client <--[broadcasts]--> size), Edge(client <--[broadcasts]--> resource budget), Edge(heterogeneous client <--[broadcasts]--> size), Edge(heterogeneous client <--[broadcasts]--> resource budget), Edge(server <--[broadcasts of]--> global model), Edge(server <--[broadcasts of]--> sub model), Edge(client <--[broadcasts of]--> global model), Edge(client <--[broadcasts of]--> sub model), Edge(heterogeneous client <--[broadcasts of]--> global model), Edge(heterogeneous client <--[broadcasts of]--> sub model), Edge(each client <--[determine]--> appropriate sr), Edge(each client <--[determine]--> computing resource budget), Edge(no client side sensor data <--[needs to]--> server), Edge(no client side sensor data <--[needs to]--> client), Edge(no client side sensor data <--[needs to]--> heterogeneous client), Edge(server <--[determines]--> corresponding configuration), Edge(client <--[determines]--> corresponding configuration), Edge(heterogeneous client <--[determines]--> corresponding configuration), Edge(size <--[match of]--> generated sub model), Edge(resource budget <--[match of]--> generated sub model), Edge(s <--[take]--> convolution layer), Edge(s <--[take as]--> example), Edge(convolutional layer <--[has in]--> global model), Edge(convolutional layer <--[has in]--> sub model), Edge(convolutional layer <--[has]--> 16 input), Edge(convolutional layer <--[has]--> 32 output channel), Edge(we <--[reshape]--> unit parameter matrix), Edge(shape <--[becomes of]--> parameter matrix), Edge(we <--[use]--> nine separate 2d convolutional layer), Edge(we <--[set]--> stride), Edge(we <--[set]--> padding), Edge(we <--[vary]--> stride padding value), Edge(we <--[vary]--> kernel size), Edge(sub model <--[have]--> same prediction task), Edge(global model <--[have]--> same prediction task), Edge(generated sub model <--[inherit]--> parameter information), Edge(generated sub model <--[inherit from]--> global model), Edge(generated sub model <--[inherit from]--> sub model), Edge(we <--[use]--> formula), Edge(server <--[applies]--> compression layer), Edge(client <--[applies]--> compression layer), Edge(heterogeneous client <--[applies]--> compression layer), Edge(server <--[applies on]--> global model parameter), Edge(server <--[applies on]--> output), Edge(client <--[applies on]--> global model parameter), Edge(client <--[applies on]--> output), Edge(heterogeneous client <--[applies on]--> global model parameter), Edge(heterogeneous client <--[applies on]--> output), Edge(several practical challenge <--[emerge during]--> this compression process), Edge(we <--[use]--> pre trained model), Edge(we <--[use]--> channel pruned model), Edge(we <--[use on]--> mnist cite dataset), Edge(we <--[address]--> these challenge), Edge(we <--[address]--> progress), Edge(we <--[add]--> two formula convolutional layer), Edge(we <--[add with]--> bias), Edge(first conv <--[increases]--> number), Edge(first conv <--[increases]--> learning rate), Edge(first conv <--[increases of]--> output channel), Edge(second conv <--[decreases]--> channel number), Edge(we <--[add between]--> global model parameter), Edge(we <--[add between]--> output), Edge(we <--[add]--> formula), Edge(accuracy <--[increases of]--> sub model), Edge(accuracy <--[increases of]--> global model), Edge(parameter <--[skew in]--> sub model), Edge(parameter <--[skew in]--> global model), Edge(corresponding weight vector <--[skew in]--> sub model), Edge(corresponding weight vector <--[skew in]--> global model), Edge(dilated model <--[skew in]--> sub model), Edge(dilated model <--[skew in]--> global model), Edge(mlr <--[suppress]--> negative parameter), Edge(sub model parameter <--[exhibit]--> similar distribution pattern), Edge(sub model parameter <--[exhibit]--> value range), Edge(we <--[observe]--> significant performance fluctuation), Edge(we <--[observe of]--> sub model), Edge(we <--[observe of]--> global model), Edge(which <--[generate]--> sub model parameter), Edge(which <--[generate via]--> convolution process), Edge(performance <--[exhibits of]--> sub model), Edge(performance <--[exhibits of]--> global model), Edge(performance <--[exhibits]--> much higher sensitivity), Edge(performance <--[exhibits to]--> change), Edge(we <--[apply]--> weight normalization), Edge(we <--[apply]--> learning rate scheduler), Edge(we <--[apply on]--> convolution parameter), Edge(which <--[stabilizes]--> convergence), Edge(which <--[stabilizes in]--> fine grained way), Edge(we <--[apply]--> cosine annealing learning rate scheduler), Edge(learning rate <--[undergoes]--> cosine function decay), Edge(accuracy <--[improves of]--> sub model), Edge(accuracy <--[improves of]--> global model), Edge(sub model <--[converges after]--> around 20 epoch), Edge(global model <--[converges after]--> around 20 epoch), Edge(compressed model <--[have]--> comparable performance), Edge(compressed model <--[have to]--> global model), Edge(compressed model <--[have to]--> sub model), Edge(server <--[sends]--> compressed parameter), Edge(client <--[sends]--> compressed parameter), Edge(heterogeneous client <--[sends]--> compressed parameter), Edge(server <--[sends to]--> corresponding client), Edge(client <--[sends to]--> corresponding client), Edge(heterogeneous client <--[sends to]--> corresponding client), Edge(method <--[impose]--> significant computational and communication overhead), Edge(method <--[impose on]--> client), Edge(we <--[use]--> reverse operation), Edge(we <--[use to]--> convolution compression), Edge(we <--[apply]--> different tc layer), Edge(we <--[apply to]--> each), Edge(convolutional layer <--[has in]--> client model), Edge(convolutional layer <--[has]--> 12 input), Edge(convolutional layer <--[has]--> 24 output channel), Edge(we <--[set]--> parameter), Edge(we <--[set]--> corresponding weight vector), Edge(we <--[set]--> dilated model), Edge(we <--[set as]--> learnable variable), Edge([[[formula]]] <--[denotes]--> tc parameter), Edge(formula <--[represents]--> tc operation), Edge(we <--[add]--> two tc formula layer), Edge(we <--[add with]--> residual connection), Edge(server <--[aggregates]--> model), Edge(client <--[aggregates]--> model), Edge(heterogeneous client <--[aggregates]--> model), Edge(magnitude <--[varies of]--> dilated model parameter), Edge(parameter <--[carry of]--> dilated model), Edge(corresponding weight vector <--[carry of]--> dilated model), Edge(dilated model <--[carry of]--> dilated model), Edge(parameter <--[carry]--> personalized information), Edge(corresponding weight vector <--[carry]--> personalized information), Edge(dilated model <--[carry]--> personalized information), Edge(parameter <--[carry from]--> different client), Edge(corresponding weight vector <--[carry from]--> different client), Edge(dilated model <--[carry from]--> different client), Edge(heterogeneous client <--[make]--> that), Edge(heterogeneous client <--[make in]--> aggregation process), Edge(we <--[normalize]--> parameter), Edge(we <--[normalize]--> corresponding weight vector), Edge(we <--[normalize]--> dilated model), Edge(we <--[normalize of]--> all dilated model), Edge(we <--[optimize]--> formula), Edge(we <--[optimize via]--> gradient descent), Edge(we <--[use]--> kullback leibler divergence), Edge(large model <--[make]--> more contribution), Edge(sub model <--[make]--> more contribution), Edge(large model <--[make to]--> aggregation), Edge(sub model <--[make to]--> aggregation), Edge(aggregated global model <--[attain]--> higher generalizability), Edge(aggregated global model <--[attain]--> more comprehensive global perspective), Edge(we <--[implement with]--> pytorch), Edge(we <--[implement with]--> flower), Edge(gradient <--[propagate to]--> convolution / tc parameter), Edge(gradient <--[propagate to]--> weight vector tuning), Edge(we <--[evaluate with]--> cloud server), Edge(we <--[evaluate with]--> router), Edge(we <--[deploy]--> these edge device), Edge(we <--[deploy in]--> our office), Edge(we <--[deploy in]--> laboratory), Edge(we <--[select]--> two representative mobile application), Edge(we <--[choose]--> three datasets), Edge(1 mnist <--[consists of]--> 60000 formula gray scale image), Edge(we <--[use]--> convolutional neural network), Edge(2 cifar10 <--[consists of]--> 60000 32 formula), Edge(we <--[use]--> resnet18), Edge(3 cinic10 <--[contains]--> 180000 32 formula 32 color image), Edge(3 cinic10 <--[contains in]--> ten class), Edge(we <--[use]--> googlenet), Edge(we <--[use for]--> evaluation), Edge(we <--[select]--> three datasets), Edge(1 wiar <--[contains]--> 480 90 formula 250 wi fi csi sample), Edge(1 wiar <--[contains of]--> 16 activity), Edge(we <--[augment]--> dataset), Edge(we <--[augment to]--> 64000 sample), Edge(3 harbox <--[captures]--> 9 axis imu data), Edge(3 harbox <--[captures of]--> five daily activity), Edge(we <--[use]--> cnn model), Edge(we <--[use with]--> three conv layer), Edge(we <--[use with]--> one fc layer), Edge(we <--[divide]--> these datasets), Edge(we <--[divide into]--> four part), Edge(each part <--[counts for]--> 5 %), Edge(each part <--[counts for]--> 20 %), Edge(we <--[employ]--> different datasets), Edge(we <--[employ on]--> server), Edge(we <--[employ on]--> client), Edge(we <--[employ on]--> heterogeneous client), Edge(we <--[employ]--> §), Edge(we <--[compare]--> fedconv), Edge(we <--[compare]--> all baseline), Edge(we <--[compare]--> lotteryfl), Edge(we <--[compare with]--> following baseline), Edge(serveralone <--[trains]--> one model), Edge(serveralone <--[trains with]--> only server side global data), Edge(we <--[evaluate]--> model), Edge(each client <--[train]--> affordable model), Edge(client <--[train]--> shared global model), Edge(we <--[assign]--> smallest affordable model), Edge(we <--[assign to]--> all client), Edge(fedmd <--[utilizes]--> knowledge distillation), Edge(fedmd <--[utilizes]--> parameter sharing), Edge(5 lotteryfl <--[generates]--> sub model), Edge(5 lotteryfl <--[generates]--> global model), Edge(6 hermes <--[finds]--> sparse sub model), Edge(6 hermes <--[finds for]--> each client), Edge(7 tailorfl <--[produces]--> sub model), Edge(7 tailorfl <--[produces]--> global model), Edge(7 tailorfl <--[produces by]--> filter level pruning), Edge(each client <--[select]--> subset), Edge(each client <--[select of]--> parameter), Edge(each client <--[select of]--> corresponding weight vector), Edge(each client <--[select of]--> dilated model), Edge(9 fedrolex <--[adopts]--> dynamic rolling window), Edge(we <--[consider]--> four sr), Edge(we <--[consider to]--> resource profile), Edge(we <--[assign]--> larger sr), Edge(we <--[assign for]--> laptop), Edge(we <--[assign]--> smaller sr), Edge(we <--[assign for]--> raspberry pi), Edge(we <--[sample]--> disjoint non iid client side data), Edge(we <--[sample]--> formula), Edge(we <--[set]--> number), Edge(we <--[set]--> learning rate), Edge(we <--[set of]--> communication round), Edge(each client <--[performs]--> 5 local training epoch), Edge(each client <--[performs with]--> learning rate), Edge(we <--[measure]--> global model accuracy), Edge(we <--[measure]--> all baseline), Edge(we <--[measure with]--> server side test dataset), Edge(we <--[report]--> average client model accuracy), Edge(we <--[report with]--> client side private test datasets), Edge(we <--[use]--> pympler library), Edge(we <--[track]--> each client s process id), Edge(we <--[track over]--> 100 communication round), Edge(we <--[measure]--> execution time), Edge(we <--[measure of]--> each client), Edge(we <--[evaluate]--> overall performance), Edge(we <--[evaluate of]--> fedconv), Edge(we <--[evaluate of]--> all baseline), Edge(we <--[evaluate of]--> lotteryfl), Edge(we <--[evaluate]--> accuracy), Edge(we <--[evaluate of]--> aggregated global model), Edge(standalone fedmd <--[create]--> global model), Edge(standalone fedmd <--[create]--> sub model), Edge(figure reference <--[shows]--> global model accuracy), Edge(figure reference <--[shows]--> all baseline), Edge(figure reference <--[shows under]--> same degree), Edge(serveralone <--[achieves]--> higher global model accuracy), Edge(serveralone <--[achieves than]--> baseline), Edge(serveralone <--[achieves than]--> fedconv), Edge(fedconv <--[achieves]--> average improvement), Edge(all baseline <--[achieves]--> average improvement), Edge(lotteryfl <--[achieves]--> average improvement), Edge(fedconv <--[achieves of]--> 205 %), Edge(fedconv <--[achieves of]--> 138 %), Edge(all baseline <--[achieves of]--> 205 %), Edge(all baseline <--[achieves of]--> 138 %), Edge(lotteryfl <--[achieves of]--> 205 %), Edge(lotteryfl <--[achieves of]--> 138 %), Edge(client model <--[have]--> insufficient number), Edge(client model <--[have of]--> parameter), Edge(client model <--[have of]--> corresponding weight vector), Edge(client model <--[have of]--> dilated model), Edge(fedconv <--[outperform]--> fedavg), Edge(fedconv <--[outperform]--> lotteryfl), Edge(all baseline <--[outperform]--> fedavg), Edge(all baseline <--[outperform]--> lotteryfl), Edge(lotteryfl <--[outperform]--> fedavg), Edge(lotteryfl <--[outperform]--> lotteryfl), Edge(fedconv <--[outperform with]--> iid data), Edge(all baseline <--[outperform with]--> iid data), Edge(lotteryfl <--[outperform with]--> iid data), Edge(this <--[shows]--> superior generalization performance), Edge(this <--[shows of]--> fedconv), Edge(this <--[shows of]--> all baseline), Edge(this <--[shows of]--> lotteryfl), Edge(figure reference <--[shows of]--> fedconv), Edge(figure reference <--[shows of]--> all baseline), Edge(figure reference <--[shows of]--> lotteryfl), Edge(performance enhancement <--[becomes of]--> fedconv), Edge(performance enhancement <--[becomes of]--> all baseline), Edge(performance enhancement <--[becomes of]--> lotteryfl), Edge(fedconv <--[cope with]--> increased data heterogeneity), Edge(all baseline <--[cope with]--> increased data heterogeneity), Edge(lotteryfl <--[cope with]--> increased data heterogeneity), Edge(fedconv <--[outperform with]--> homogeneous data), Edge(all baseline <--[outperform with]--> homogeneous data), Edge(lotteryfl <--[outperform with]--> homogeneous data), Edge(fedconv <--[exhibits]--> better generalizability), Edge(fedconv <--[exhibits]--> robustness), Edge(all baseline <--[exhibits]--> better generalizability), Edge(all baseline <--[exhibits]--> robustness), Edge(lotteryfl <--[exhibits]--> better generalizability), Edge(lotteryfl <--[exhibits]--> robustness), Edge(fedconv <--[provides]--> better personalization performance), Edge(all baseline <--[provides]--> better personalization performance), Edge(lotteryfl <--[provides]--> better personalization performance), Edge(fedconv <--[provides for]--> client), Edge(all baseline <--[provides for]--> client), Edge(lotteryfl <--[provides for]--> client), Edge(performance improvement <--[stem of]--> global model), Edge(performance improvement <--[stem of]--> sub model), Edge(we <--[measure]--> accuracy), Edge(we <--[measure of]--> each client model), Edge(figure reference <--[shows with]--> same heterogeneous data setting), Edge(fedconv <--[outperforms]--> baseline), Edge(fedconv <--[outperforms]--> fedconv), Edge(all baseline <--[outperforms]--> baseline), Edge(all baseline <--[outperforms]--> fedconv), Edge(lotteryfl <--[outperforms]--> baseline), Edge(lotteryfl <--[outperforms]--> fedconv), Edge(accuracy <--[drops of]--> client model), Edge(server side data <--[occupies]--> small portion), Edge(serveralone s global model <--[seen]--> sufficient data), Edge(serveralone s global model <--[seen to]--> degraded performance), Edge(serveralone s global model <--[seen to]--> longer convergence time), Edge(figure reference <--[shows]--> client model accuracy), Edge(this performance gain <--[stems from]--> tc dilation process), Edge(rescaled large model <--[preserve]--> personalization information), Edge(rescaled large model <--[preserve from]--> client), Edge(figure reference <--[shows with]--> sensing heterogeneity), Edge(fedconv <--[achieves]--> better and more stable performance), Edge(all baseline <--[achieves]--> better and more stable performance), Edge(lotteryfl <--[achieves]--> better and more stable performance), Edge(fedconv <--[achieves on]--> cifar10), Edge(fedconv <--[achieves on]--> cinic10), Edge(fedconv <--[achieves on]--> harbox), Edge(all baseline <--[achieves on]--> cifar10), Edge(all baseline <--[achieves on]--> cinic10), Edge(all baseline <--[achieves on]--> harbox), Edge(lotteryfl <--[achieves on]--> cifar10), Edge(lotteryfl <--[achieves on]--> cinic10), Edge(lotteryfl <--[achieves on]--> harbox), Edge(better performance <--[stems from]--> distilled knowledge), Edge(downside <--[imposes]--> excessive communication), Edge(downside <--[imposes]--> computational overhead), Edge(fedconv <--[achieve]--> comparable personalization performance), Edge(all baseline <--[achieve]--> comparable personalization performance), Edge(lotteryfl <--[achieve]--> comparable personalization performance), Edge(fedconv <--[achieve without]--> extra burden), Edge(all baseline <--[achieve without]--> extra burden), Edge(lotteryfl <--[achieve without]--> extra burden), Edge(we <--[improve]--> personalization performance), Edge(fedconv <--[exhibits]--> significant performance gain), Edge(all baseline <--[exhibits]--> significant performance gain), Edge(lotteryfl <--[exhibits]--> significant performance gain), Edge(fedconv <--[exhibits in]--> both global and client model), Edge(all baseline <--[exhibits in]--> both global and client model), Edge(lotteryfl <--[exhibits in]--> both global and client model), Edge(we <--[evaluate]--> memory footprint), Edge(we <--[evaluate]--> wall clock time), Edge(we <--[evaluate]--> baseline), Edge(table <--[provides]--> overview), Edge(table <--[provides of]--> average memory usage), Edge(table <--[provides of]--> average wall clock time), Edge(fedconv <--[achieves]--> average saving), Edge(all baseline <--[achieves]--> average saving), Edge(lotteryfl <--[achieves]--> average saving), Edge(fedconv <--[achieves of]--> 406 %), Edge(fedconv <--[achieves of]--> 546 %), Edge(all baseline <--[achieves of]--> 406 %), Edge(all baseline <--[achieves of]--> 546 %), Edge(lotteryfl <--[achieves of]--> 406 %), Edge(lotteryfl <--[achieves of]--> 546 %), Edge(fedconv <--[needs]--> approximately half), Edge(all baseline <--[needs]--> approximately half), Edge(lotteryfl <--[needs]--> approximately half), Edge(fedconv <--[needs of]--> memory and training time), Edge(all baseline <--[needs of]--> memory and training time), Edge(lotteryfl <--[needs of]--> memory and training time), Edge(fedconv <--[needs]--> 2 gb less memory), Edge(all baseline <--[needs]--> 2 gb less memory), Edge(lotteryfl <--[needs]--> 2 gb less memory), Edge(client <--[need in]--> fedconv), Edge(client <--[need in]--> all baseline), Edge(client <--[need in]--> lotteryfl), Edge(fedavg <--[consumes]--> less memory), Edge(fedavg <--[consumes]--> wall clock time), Edge(lotteryfl <--[consumes]--> less memory), Edge(lotteryfl <--[consumes]--> wall clock time), Edge(table <--[lists]--> total size), Edge(table <--[lists of]--> data packet), Edge(fedconv lotteryfl heterofl <--[transmit]--> sub model parameter), Edge(fedconv lotteryfl heterofl <--[transmit without]--> extra content), Edge(heterofl <--[holds]--> significant potential), Edge(fedrolex <--[holds]--> significant potential), Edge(fedconv <--[saves]--> more system resource), Edge(all baseline <--[saves]--> more system resource), Edge(lotteryfl <--[saves]--> more system resource), Edge(we <--[simulate]--> 100 client), Edge(client model accuracy <--[exhibits in]--> fedconv), Edge(client model accuracy <--[exhibits in]--> all baseline), Edge(client model accuracy <--[exhibits in]--> lotteryfl), Edge(client model accuracy <--[exhibits]--> upward trend), Edge(number <--[increases of]--> client), Edge(learning rate <--[increases of]--> client), Edge(client model accuracy <--[increases on]--> harbox), Edge(we <--[select]--> cifar10), Edge(we <--[select]--> cinic10), Edge(we <--[select]--> harbox), Edge(fedconv <--[attains]--> average client model accuracy), Edge(all baseline <--[attains]--> average client model accuracy), Edge(lotteryfl <--[attains]--> average client model accuracy), Edge(result <--[demonstrate]--> scalability), Edge(result <--[demonstrate]--> superiority), Edge(we <--[set]--> sr), Edge(we <--[set]--> model performance), Edge(we <--[set for]--> 10 client), Edge(we <--[vary]--> formula), Edge(sr <--[decreases below]--> certain threshold), Edge(model performance <--[decreases below]--> certain threshold), Edge(even lightweight device <--[afford]--> googlenet model), Edge(even lightweight device <--[afford on]--> cinic10), Edge(even lightweight device <--[afford on]--> harbox), Edge(sr <--[remains above]--> corresponding threshold), Edge(model performance <--[remains above]--> corresponding threshold), Edge(we <--[use]--> cifar10), Edge(we <--[use]--> cinic10), Edge(we <--[use]--> harbox), Edge(accuracy <--[decreases of]--> fedconv), Edge(accuracy <--[decreases of]--> all baseline), Edge(accuracy <--[decreases of]--> lotteryfl), Edge(accuracy <--[retain]--> much higher accuracy), Edge(accuracy <--[retain than]--> baseline), Edge(accuracy <--[retain than]--> fedconv), Edge(baseline <--[discard]--> larger amount), Edge(fedconv <--[discard]--> larger amount), Edge(baseline <--[discard of]--> parameter information), Edge(fedconv <--[discard of]--> parameter information), Edge(fedconv <--[preserve]--> parameter information), Edge(all baseline <--[preserve]--> parameter information), Edge(lotteryfl <--[preserve]--> parameter information), Edge(fedconv <--[preserve of]--> global model), Edge(fedconv <--[preserve of]--> sub model), Edge(all baseline <--[preserve of]--> global model), Edge(all baseline <--[preserve of]--> sub model), Edge(lotteryfl <--[preserve of]--> global model), Edge(lotteryfl <--[preserve of]--> sub model), Edge(we <--[vary]--> sample number ratio), Edge(we <--[vary of]--> server side data), Edge(we <--[obtain]--> two key observation), Edge(ratio <--[varies of]--> server side data), Edge(client model <--[have]--> better performance), Edge(client model <--[have due]--> richer information), Edge(global model <--[tends to]--> server side data), Edge(sub model <--[tends to]--> server side data), Edge(we <--[set]--> default sample ratio), Edge(we <--[set of]--> server side data), Edge(actual turning point <--[differ in]--> practice), Edge(we <--[vary]--> number), Edge(we <--[vary]--> learning rate), Edge(we <--[vary of]--> epoch), Edge(we <--[select]--> two datasets), Edge(client model <--[achieve]--> better and more stable performance), Edge(client model <--[achieve After]--> 20 th and 40 th epoch), Edge(number <--[exceeds of]--> tuning epoch), Edge(learning rate <--[exceeds of]--> tuning epoch), Edge(accuracy <--[decreases of]--> aggregated global model), Edge(we <--[set of]--> epoch), Edge(we <--[vary]--> stride length), Edge(we <--[vary]--> stride), Edge(we <--[select]--> convolutional layer), Edge(we <--[select from]--> large model), Edge(we <--[select from]--> sub model), Edge(whose parameter matrix <--[has]--> shape), Edge(whose parameter matrix <--[has of]--> formula), Edge(compressed parameter matrix <--[have]--> shape), Edge(compressed parameter matrix <--[have of]--> formula), Edge(kernel size <--[satisfy]--> formula), Edge(stride length <--[satisfy]--> formula), Edge(stride <--[satisfy]--> formula), Edge(larger kernel <--[capture]--> more comprehensive parameter information), Edge(smaller stride <--[capture]--> more fine grained information), Edge(smaller stride <--[capture in]--> figure reference), Edge(larger kernel <--[incurs]--> high computational complexity), Edge(we <--[conduct]--> ablation study), Edge(figure reference <--[shows]--> impact), Edge(figure reference <--[shows on]--> global model accuracy), Edge(figure reference <--[shows on]--> all baseline), Edge(global model <--[achieves]--> higher average accuracy), Edge(sub model <--[achieves]--> higher average accuracy), Edge(fl server <--[save]--> communication computation and energy cost), Edge(client <--[save]--> communication computation and energy cost), Edge(fl server <--[save in]--> training process), Edge(client <--[save in]--> training process), Edge(we <--[assign]--> weight), Edge(we <--[assign with]--> respect), Edge(figure reference <--[shows]--> effect), Edge(parameter <--[exhibit from]--> heterogeneous client model), Edge(corresponding weight vector <--[exhibit from]--> heterogeneous client model), Edge(dilated model <--[exhibit from]--> heterogeneous client model), Edge(parameter <--[exhibit]--> varying skewness), Edge(corresponding weight vector <--[exhibit]--> varying skewness), Edge(dilated model <--[exhibit]--> varying skewness), Edge(parameter <--[exhibit toward]--> parameter local data distribution), Edge(corresponding weight vector <--[exhibit toward]--> parameter local data distribution), Edge(dilated model <--[exhibit toward]--> parameter local data distribution), Edge(client <--[contribute]--> different parameter information), Edge(client <--[contribute to]--> aggregated global model), Edge(we <--[extend]--> fedconv), Edge(we <--[extend]--> all baseline), Edge(we <--[extend]--> lotteryfl), Edge(each client <--[appends]--> client own personal layer), Edge(each client <--[appends to]--> sub model), Edge(each client <--[appends to]--> global model), Edge(we <--[record]--> average accuracy), Edge(we <--[record of]--> client model), Edge(figure reference <--[shows]--> performance improvement), Edge(figure reference <--[shows on]--> five datasets), Edge(which <--[achieves]--> highest client model accuracy), Edge(which <--[achieves]--> §), Edge(both server side and client side datasets <--[originate from]--> same domain), Edge(we <--[conduct]--> case study), Edge(chars74 k dataset <--[contains]--> image), Edge(chars74 k dataset <--[contains of]--> digit), Edge(heterogeneous client <--[tune]--> compressed model), Edge(generated sub model <--[contain via]--> convolutional compression), Edge(generated sub model <--[contain via]--> transposed convolutional dilation), Edge(generated sub model <--[contain]--> parameter information), Edge(generated sub model <--[contain from]--> large global model), Edge(server <--[applies]--> tc), Edge(client <--[applies]--> tc), Edge(heterogeneous client <--[applies]--> tc), Edge(server <--[applies to]--> locally trained heterogeneous client model), Edge(client <--[applies to]--> locally trained heterogeneous client model), Edge(heterogeneous client <--[applies to]--> locally trained heterogeneous client model), Edge(this <--[facilitates]--> aggregation process), Edge(fedmd <--[achieves]--> comparable performance), Edge(fedmd <--[achieves to]--> fedconv), Edge(fedmd <--[achieves to]--> all baseline), Edge(fedmd <--[achieves to]--> lotteryfl), Edge(we <--[enhance]--> fedconv), Edge(we <--[enhance]--> all baseline), Edge(we <--[enhance]--> lotteryfl), Edge(we <--[enhance with]--> transfer learning strategy), Edge(client model <--[achieve]--> higher accuracy), Edge(fedconv <--[requires]--> all client), Edge(all baseline <--[requires]--> all client), Edge(lotteryfl <--[requires]--> all client), Edge(client <--[perform]--> resource profiling), Edge(client <--[perform to]--> server), Edge(client <--[perform to]--> client), Edge(client <--[perform to]--> heterogeneous client), Edge(we <--[use]--> flower cite framework), Edge(flower <--[offers]--> stable and robust simulated environment), Edge(flower <--[offers for]--> fl), Edge(these <--[include]--> technical challenge), Edge(these <--[include]--> issue), Edge(recent advancement <--[support in]--> flower), Edge(recent advancement <--[support]--> federated learning setup), Edge(recent advancement <--[support with]--> android client), Edge(client <--[need in]--> pre training and fine tuning process), Edge(clusterfl <--[captures]--> intrinsic clustering pattern), Edge(clusterfl <--[captures among]--> client), Edge(personalized fl <--[adopts]--> local fine tuning), Edge(pfedme <--[uses]--> moreau envelope), Edge(pfedme <--[uses as]--> regularized loss function), Edge(lower layer <--[capture]--> more general feature), Edge(recent work <--[compress]--> global model), Edge(recent work <--[compress]--> sub model), Edge(fedmd <--[computes]--> average consensus), Edge(sub model <--[share]--> part), Edge(global model <--[share]--> part), Edge(sub model <--[share of]--> global model parameter), Edge(sub model <--[share of]--> output), Edge(global model <--[share of]--> global model parameter), Edge(global model <--[share of]--> output), Edge(sharing strategy <--[suffers from]--> imbalance issue), Edge(3 pruning based method <--[gained]--> popularity), Edge(3 pruning based method <--[gained in]--> heterogeneous fl), Edge(hermes <--[applies]--> channel level pruning method), Edge(tailorfl <--[applies]--> channel level pruning method), Edge(tailorfl <--[proposes]--> importance value based filter level pruning scheme), Edge(heterofl <--[proposes]--> importance value based filter level pruning scheme), Edge(we <--[compress]--> global model), Edge(we <--[compress]--> sub model), Edge(we <--[compress with]--> convolutional compression), Edge(we <--[compress with]--> transposed convolutional dilation), Edge(these work <--[reduce]--> system overhead), Edge(these work <--[reduce of]--> client), Edge(convolution <--[extract]--> useful feature), Edge(transposed convolution <--[extract]--> useful feature), Edge(convolution <--[extract from]--> input data), Edge(transposed convolution <--[extract from]--> input data), Edge(we <--[exploit]--> novel convolutional compression technique), Edge(which <--[capture]--> key information), Edge(which <--[capture in]--> global model), Edge(which <--[capture in]--> sub model), Edge(we <--[leverage]--> tc), Edge(fedconv <--[contributes]--> three key technical module), Edge(all baseline <--[contributes]--> three key technical module), Edge(lotteryfl <--[contributes]--> three key technical module), Edge(fedconv <--[outperforms]--> sota baseline), Edge(all baseline <--[outperforms]--> sota baseline), Edge(lotteryfl <--[outperforms]--> sota baseline), Edge(we <--[believe on]--> model), Edge(heterogeneous model <--[with]--> different size), Edge(data distribution <--[with]--> different size), Edge(global model <--[for]--> aggregation), Edge(sub model <--[for]--> aggregation), Edge(different region <--[of]--> global model), Edge(small portion <--[of]--> dataset), Edge(removal <--[of]--> entire channel), Edge(overhead <--[of]--> client), Edge(information <--[of]--> global model), Edge(client friendly fl framework <--[for]--> heterogeneous model), Edge(parameter <--[of]--> diverse sub model), Edge(corresponding weight vector <--[of]--> diverse sub model), Edge(dilated model <--[of]--> diverse sub model), Edge(same size <--[as]--> global model), Edge(small dataset <--[on]--> server), Edge(parameter <--[of]--> heterogeneous sub model), Edge(corresponding weight vector <--[of]--> heterogeneous sub model), Edge(dilated model <--[of]--> heterogeneous sub model), Edge(set <--[of]--> dilated model), Edge(transfer <--[of]--> personalized information), Edge(transfer <--[from]--> client model), Edge(transfer <--[to]--> dilated model), Edge(imbalanced contribution <--[of]--> heterogeneous federated client), Edge(different learnable weight vector <--[for]--> dilated model), Edge(relative importance <--[of]--> each model), Edge(user friendly fl framework <--[with]--> two representative fl task), Edge(term <--[of]--> inference accuracy), Edge(inference accuracy <--[by]--> more than 35 %), Edge(computation overhead <--[for]--> federated client), Edge(model <--[with]--> uniform size), Edge(client contribution <--[for]--> final aggregation), Edge(superior performance <--[of]--> fedconv), Edge(superior performance <--[in]--> term), Edge(term <--[of]--> both inference accuracy), Edge(necessity <--[of]--> model heterogeneity aware fl system), Edge(heavy overhead <--[on]--> client), Edge(size <--[of]--> global model), Edge(resource budget <--[of]--> global model), Edge(client <--[with]--> least system resource), Edge(client <--[in]--> conventional fl), Edge(client <--[with]--> more resource), Edge(weaker client <--[in]--> synchronized fl), Edge(full use <--[of]--> more powerful client), Edge(heterogeneous model <--[with]--> varied parameter size), Edge(data distribution <--[with]--> varied parameter size), Edge(all client <--[with]--> diverse resource), Edge(problem <--[in]--> parameter sharing), Edge(overlapped part <--[across]--> different size), Edge(different size <--[of]--> model), Edge(information <--[from]--> other client), Edge(model exposure <--[to]--> larger volume), Edge(larger volume <--[of]--> data), Edge(imbalanced performance <--[among]--> client), Edge(unexpected performance degradation <--[among]--> client), Edge(different part <--[of]--> global model s parameter), Edge(mixed window <--[from]--> diverse sub model), Edge(distribution <--[of]--> global model s parameter), Edge(client workload <--[in]--> model pruning), Edge(corresponding channel <--[of]--> input data), Edge(certain weight <--[in]--> model parameter), Edge(connection <--[in]--> model parameter), Edge(amount <--[of]--> information), Edge(mi <--[between]--> parameter), Edge(parameter <--[of]--> resnet18 model), Edge(corresponding weight vector <--[of]--> resnet18 model), Edge(dilated model <--[of]--> resnet18 model), Edge(parameter <--[of]--> pre trained model), Edge(corresponding weight vector <--[of]--> pre trained model), Edge(dilated model <--[of]--> pre trained model), Edge(accuracy drop <--[from]--> 8404 %), Edge(accuracy drop <--[to]--> 7336 %), Edge(accuracy <--[of]--> filter pruned model), Edge(information loss <--[due]--> pruning), Edge(imbalance issue <--[due]--> pruning), Edge(performance degradation <--[due]--> pruning), Edge(all parameter <--[of]--> global model), Edge(information loss <--[of]--> model parameter), Edge(imbalance issue <--[of]--> model parameter), Edge(performance degradation <--[of]--> model parameter), Edge(crucial information <--[of]--> global model), Edge(shrinkage ratio <--[of]--> 075), Edge(top4 and top3 feature map <--[with]--> highest importance), Edge(first two feature map <--[from]--> sub model), Edge(fusion <--[of]--> last two feature map), Edge(last two feature map <--[from]--> large model), Edge(both body <--[of]--> deer), Edge(head <--[of]--> deer), Edge(feature extraction capability <--[of]--> large model), Edge(accuracy <--[of]--> sub model), Edge(mutual information <--[between]--> parameter), Edge(parameter <--[of]--> large model), Edge(corresponding weight vector <--[of]--> large model), Edge(dilated model <--[of]--> large model), Edge(iterative refining <--[of]--> compression process), Edge(architecture <--[of]--> fedconv), Edge(global model <--[with]--> estimated memory requirement), Edge(sub model <--[with]--> estimated memory requirement), Edge(set <--[of]--> shrinkage ratio), Edge(better global view <--[of]--> data distribution), Edge(set <--[of]--> fine tuned convolution parameter), Edge(several epoch <--[of]--> local training), Edge(set <--[of]--> large model), Edge(set <--[of]--> convolutional layer), Edge(compressed parameter <--[of]--> sub model), Edge(i e parameter <--[of]--> compression layer), Edge(comparable performance <--[to]--> global model), Edge(local data <--[for]--> personalization), Edge(size <--[of]--> sub model), Edge(resource budget <--[of]--> sub model), Edge(size <--[of]--> generated sub model), Edge(resource budget <--[of]--> generated sub model), Edge(convolutional layer <--[in]--> global model), Edge(16 input <--[with]--> kernel size), Edge(32 output channel <--[with]--> kernel size), Edge(each element <--[in]--> kernel), Edge(shape <--[of]--> parameter matrix), Edge(other type <--[of]--> layer), Edge(input channel <--[of]--> first layer), Edge(all channel <--[of]--> raw data), Edge(output channel <--[of]--> last layer), Edge(loss <--[between]--> ground truth), Edge(prediction result <--[of]--> compressed model), Edge(forward function <--[of]--> compressed model), Edge(data <--[in]--> server side data), Edge(corresponding label <--[in]--> server side data), Edge(parameter <--[of]--> [[[formula th layer]]]), Edge(corresponding weight vector <--[of]--> [[[formula th layer]]]), Edge(dilated model <--[of]--> [[[formula th layer]]]), Edge([[[formula th layer]]] <--[in]--> global model), Edge(i e parameter <--[of]--> global model), Edge(parameter <--[of]--> compression layer), Edge(corresponding weight vector <--[of]--> compression layer), Edge(dilated model <--[of]--> compression layer), Edge(loss <--[between]--> sub model output), Edge(pre trained model <--[on]--> mnist cite dataset), Edge(channel pruned model <--[on]--> mnist cite dataset), Edge(accuracy <--[of]--> 9904 %), Edge(amount <--[of]--> parameter information), Edge(parameter information <--[in]--> sub model), Edge(parameter <--[of]--> global model), Edge(corresponding weight vector <--[of]--> global model), Edge(dilated model <--[of]--> global model), Edge(limited capability <--[of]--> simple compression layer), Edge(lower accuracy <--[of]--> sub model), Edge(two formula convolutional layer <--[with]--> bias), Edge(bias <--[before]--> compression), Edge(number <--[of]--> output channel), Edge(learning rate <--[of]--> output channel), Edge(residual connection <--[between]--> global model parameter), Edge(output <--[of]--> second conv), Edge(transfer <--[of]--> parameter information), Edge(transfer <--[from]--> global model), Edge(transfer <--[to]--> sub model), Edge(distribution <--[of]--> parameter), Edge(parameter <--[in]--> sub model), Edge(corresponding weight vector <--[in]--> sub model), Edge(dilated model <--[in]--> sub model), Edge(slope <--[for]--> negative and positive value), Edge(similar distribution pattern <--[to]--> global model), Edge(value range <--[to]--> global model), Edge(significant performance fluctuation <--[of]--> sub model), Edge(performance <--[of]--> sub model), Edge(much higher sensitivity <--[to]--> change), Edge(change <--[in]--> convolution parameter), Edge(lower and upper bound <--[of]--> learning rate), Edge(maximum number <--[of]--> iteration), Edge(reverse operation <--[to]--> convolution compression), Edge(non iid data <--[with]--> different sensing heterogeneity), Edge(i e parameter <--[of]--> tc layer), Edge(heterogeneous model <--[from]--> different client), Edge(data distribution <--[from]--> different client), Edge(configuration <--[of]--> each tc layer), Edge(configuration <--[for]--> dilation), Edge(convolutional layer <--[in]--> client model), Edge(sr <--[as]--> 075), Edge(model performance <--[as]--> 075), Edge(configuration <--[of]--> tc layer), Edge(other kind <--[of]--> network layer), Edge(input channel number <--[of]--> first layer), Edge(output channel number <--[of]--> first layer), Edge(output channel number <--[of]--> last layer), Edge(input channel number <--[in]--> all client model), Edge(output channel number <--[in]--> all client model), Edge(prediction result <--[of]--> dilated large model), Edge(forward function <--[of]--> dilated large model), Edge(parameter <--[of]--> client model), Edge(corresponding weight vector <--[of]--> client model), Edge(dilated model <--[of]--> client model), Edge(integration <--[of]--> personalized information), Edge(integration <--[into]--> dilated model), Edge(two tc formula layer <--[with]--> residual connection), Edge(set <--[of]--> dilated large model), Edge(parameter <--[of]--> all dilated model), Edge(corresponding weight vector <--[of]--> all dilated model), Edge(dilated model <--[of]--> all dilated model), Edge(accuracy <--[of]--> aggregated model), Edge(only 476 % <--[on]--> mnist dataset), Edge(magnitude <--[of]--> dilated model parameter), Edge(parameter <--[of]--> dilated model), Edge(corresponding weight vector <--[of]--> dilated model), Edge(dilated model <--[of]--> dilated model), Edge(parameter <--[through]--> tc operation), Edge(corresponding weight vector <--[through]--> tc operation), Edge(dilated model <--[through]--> tc operation), Edge(personalized information <--[from]--> different client), Edge(varying skewness <--[toward]--> client side data distribution), Edge(diverse personalized information <--[from]--> dilated model), Edge(every network layer <--[in]--> each dilated model), Edge(parameter <--[of]--> [[[formula th aggregated network layer]]]), Edge(corresponding weight vector <--[of]--> [[[formula th aggregated network layer]]]), Edge(dilated model <--[of]--> [[[formula th aggregated network layer]]]), Edge(number <--[of]--> large model), Edge(learning rate <--[of]--> large model), Edge([[[formula th layer]]] <--[in]--> [[[formula th large model]]]), Edge(number <--[of]--> data sample), Edge(learning rate <--[of]--> data sample), Edge(different contribution <--[of]--> heterogeneous client), Edge(similarity <--[between]--> parameter), Edge(kld <--[for]--> th dilated model), Edge(global model parameter <--[from]--> previous communication round), Edge(output <--[from]--> previous communication round), Edge(optimization <--[of]--> weight vector), Edge(cross entropy loss <--[for]--> model output), Edge(coefficient <--[for]--> balance), Edge(load_state_dict function <--[in]--> pytorch), Edge(20 heterogeneous mobile device <--[with]--> different hardware and network condition), Edge(detailed configuration <--[of]--> heterogeneous device), Edge(popular computer vision application <--[for]--> fl), Edge(60000 formula gray scale image <--[of]--> ten handwritten digit), Edge(convolutional neural network <--[with]--> two convolutional layer), Edge(32 color image <--[in]--> ten class), Edge(180000 32 formula 32 color image <--[in]--> ten class), Edge(different type <--[of]--> sensor data), Edge(channel state information <--[of]--> sensor data), Edge(channel state information <--[of]--> wifi signal), Edge(480 90 formula 250 wi fi csi sample <--[of]--> 16 activity), Edge(5000 36 formula 36 gray scale depth image <--[of]--> five common gesture), Edge(9 axis imu data <--[of]--> five daily activity), Edge(sliding window <--[of]--> 2 second), Edge(900 dimensional feature <--[for]--> each), Edge(121 user <--[with]--> 77 different smartphones), Edge(degree <--[of]--> sensing heterogeneity), Edge(no standard model <--[for]--> these datasets), Edge(cnn model <--[with]--> three conv layer), Edge(1 iid server side global data <--[for]--> convolution / tc parameter), Edge(2 iid test data <--[for]--> convolution / tc parameter), Edge(5 % <--[of]--> total dataset), Edge(20 % <--[of]--> total dataset), Edge(first and second part <--[of]--> dataset), Edge(constrained resource <--[of]--> some device), Edge(consensus <--[among]--> heterogeneous client model), Edge(sparse sub model <--[for]--> each client), Edge(learned importance value <--[of]--> each filter), Edge(subset <--[of]--> parameter), Edge(sub model <--[for]--> heterogeneous client), Edge(global model <--[for]--> heterogeneous client), Edge(resource profile <--[of]--> heterogeneous client), Edge(sr <--[for]--> each client), Edge(model performance <--[for]--> each client), Edge(sample distribution <--[among]--> different class), Edge(number <--[of]--> communication round), Edge(learning rate <--[of]--> communication round), Edge(learning rate <--[of]--> 0001), Edge(stride <--[of]--> all convolution parameter), Edge(padding <--[of]--> all convolution parameter), Edge(number <--[of]--> epoch), Edge(learning rate <--[of]--> epoch), Edge(generalizability <--[of]--> global model), Edge(effectiveness <--[of]--> personalization), Edge(network traffic <--[of]--> all client), Edge(execution time <--[of]--> each client), Edge(average wall clock time <--[in]--> each round), Edge(overall performance <--[of]--> fedconv), Edge(accuracy <--[of]--> aggregated global model), Edge(same degree <--[of]--> heterogeneous data), Edge(higher global model accuracy <--[than]--> baseline), Edge(server side data <--[for]--> training), Edge(average improvement <--[of]--> 205 %), Edge(all client <--[in]--> fedavg), Edge(insufficient number <--[of]--> parameter), Edge(parameter <--[for]--> training), Edge(corresponding weight vector <--[for]--> training), Edge(dilated model <--[for]--> training), Edge(superior generalization performance <--[of]--> fedconv), Edge(global model accuracy <--[of]--> fedconv), Edge(all baseline <--[of]--> fedconv), Edge(all baseline <--[across]--> different data heterogeneity), Edge(different data heterogeneity <--[on]--> all datasets), Edge(performance enhancement <--[of]--> fedconv), Edge(better personalization performance <--[for]--> client), Edge(performance improvement <--[of]--> global model), Edge(accuracy <--[of]--> each client model), Edge(accuracy <--[with]--> client side test datasets), Edge(accuracy <--[of]--> client model), Edge(small portion <--[of]--> entire dataset), Edge(degraded performance <--[on]--> client side non iid data), Edge(longer convergence time <--[on]--> client side non iid data), Edge(client model accuracy <--[of]--> fedconv), Edge(all baseline <--[with]--> different data heterogeneity), Edge(each uploaded client model <--[on]--> server), Edge(personalization information <--[from]--> client), Edge(sensing heterogeneity <--[in]--> harbox dataset), Edge(client model accuracy <--[of]--> fedmd), Edge(extra burden <--[on]--> client), Edge(significant performance gain <--[in]--> both global and client model), Edge(parameter information <--[of]--> global model), Edge(performance instability <--[of]--> some baseline), Edge(information loss <--[in]--> model pruning), Edge(imbalance issue <--[in]--> model pruning), Edge(performance degradation <--[in]--> model pruning), Edge(imbalance issue <--[in]--> parameter sharing), Edge(memory footprint <--[of]--> each client), Edge(wall clock time <--[of]--> each client), Edge(baseline <--[of]--> each client), Edge(memory footprint <--[in]--> fedconv), Edge(wall clock time <--[in]--> fedconv), Edge(baseline <--[in]--> fedconv), Edge(baseline <--[with]--> heterogeneous formula = 005 data), Edge(fedconv <--[with]--> heterogeneous formula = 005 data), Edge(heterogeneous formula = 005 data <--[across]--> client), Edge(overview <--[of]--> average memory usage), Edge(average wall clock time <--[of]--> each client), Edge(same set <--[of]--> sr), Edge(average saving <--[of]--> 406 %), Edge(406 % <--[in]--> memory cost), Edge(546 % <--[in]--> memory cost), Edge(546 % <--[in]--> computation overhead), Edge(approximately half <--[of]--> memory and training time), Edge(around 90 minute <--[of]--> wall clock time), Edge(around 90 minute <--[than]--> hermes), Edge(client <--[in]--> fedconv), Edge(significant saving <--[in]--> term), Edge(term <--[of]--> memory computation and communication resource), Edge(total size <--[of]--> data packet), Edge(communication cost <--[of]--> fedconv), Edge(number <--[of]--> selected participating client), Edge(learning rate <--[of]--> selected participating client), Edge(client model accuracy <--[in]--> fedconv), Edge(number <--[of]--> client), Edge(learning rate <--[of]--> client), Edge(client model accuracy <--[on]--> harbox), Edge(client model performance <--[of]--> fedconv), Edge(scalability <--[of]--> fedconv), Edge(superiority <--[of]--> fedconv), Edge(scalability <--[with]--> varying client number), Edge(superiority <--[with]--> varying client number), Edge(trade off <--[between]--> sr), Edge(sr <--[for]--> 10 client), Edge(model performance <--[for]--> 10 client), Edge(sr <--[for]--> remaining 10 client), Edge(model performance <--[for]--> remaining 10 client), Edge(notable accuracy drop <--[in]--> client model), Edge(googlenet model <--[on]--> cinic10), Edge(accuracy <--[of]--> fedconv), Edge(much higher accuracy <--[than]--> baseline), Edge(larger amount <--[of]--> parameter information), Edge(impact <--[of]--> server side data), Edge(sample number ratio <--[of]--> server side data), Edge(step <--[of]--> 05 %), Edge(ratio <--[of]--> server side data), Edge(default sample ratio <--[of]--> server side data), Edge(compression dilation aggregation impact <--[on]--> personalization performance), Edge(personalization performance <--[of]--> client model), Edge(number <--[of]--> convolution / tc parameter), Edge(learning rate <--[of]--> convolution / tc parameter), Edge(number <--[of]--> tuning epoch), Edge(learning rate <--[of]--> tuning epoch), Edge(epoch <--[for]--> model compression), Edge(kernel size <--[of]--> compression layer), Edge(stride length <--[of]--> compression layer), Edge(stride <--[of]--> compression layer), Edge(impact <--[on]--> client performance), Edge(convolutional layer <--[from]--> large model), Edge(shape <--[of]--> formula), Edge(importance <--[of]--> server side pre training process), Edge(impact <--[on]--> global model accuracy), Edge(integration <--[of]--> training), Edge(impact <--[of]--> our learned weight vector), Edge(impact <--[for]--> model aggregation), Edge(weight <--[with]--> respect), Edge(respect <--[to]--> sample number), Edge(effect <--[on]--> global model accuracy), Edge(parameter <--[from]--> heterogeneous client model), Edge(corresponding weight vector <--[from]--> heterogeneous client model), Edge(dilated model <--[from]--> heterogeneous client model), Edge(varying skewness <--[toward]--> parameter local data distribution), Edge(potential <--[in]--> personalization), Edge(personalization performance <--[of]--> each client), Edge(average accuracy <--[of]--> client model), Edge(performance improvement <--[on]--> five datasets), Edge(image <--[of]--> digit), Edge(digit <--[from]--> computer font), Edge(computer font <--[with]--> variation), Edge(e g different shape <--[of]--> digit), Edge(e g different shape <--[from]--> chars74 k dataset), Edge(e g various writing style <--[of]--> digit), Edge(e g various writing style <--[from]--> mnist dataset), Edge(transformation <--[from]--> one data domain), Edge(transformation <--[to]--> another), Edge(generated sub model <--[via]--> convolutional compression), Edge(parameter information <--[from]--> large global model), Edge(personalization information <--[of]--> client side data), Edge(domain gap <--[between]--> server side), Edge(decrease <--[in]--> both global model), Edge(comparable performance <--[to]--> fedconv), Edge(privacy protection <--[of]--> conventional fl scheme), Edge(practicality <--[of]--> fedconv), Edge(stable and robust simulated environment <--[for]--> fl), Edge(compatibility <--[of]--> flower framework), Edge(compatibility <--[with]--> android system), Edge(recent advancement <--[in]--> flower), Edge(federated learning setup <--[with]--> android client), Edge(client s perspective <--[of]--> view), Edge(distribution <--[of]--> client data), Edge(intrinsic clustering pattern <--[among]--> client), Edge(similarity <--[of]--> client model), Edge(clustered multi task federated learning <--[on]--> non iid data), Edge(upper layer <--[of]--> global model), Edge(minimal modification <--[to]--> client), Edge(integration <--[into]--> existing fl system), Edge(knowledge <--[from]--> heterogeneous client model), Edge(tuning <--[of]--> kd), Edge(client <--[with]--> shared dataset), Edge(part <--[of]--> global model parameter), Edge(fixed subset <--[of]--> global parameter), Edge(minimal modification <--[to]--> existing fl framework), Edge(system overhead <--[of]--> client), Edge(client friendly federated learning framework <--[for]--> heterogeneous client), Edge(system overhead <--[on]--> resource constrained mobile device), Edge(heterogeneous sub model <--[with]--> convolutional compression), Edge(heterogeneous sub model <--[on]--> global model), Edge(large model <--[with]--> unified size), Edge(sub model <--[with]--> unified size), Edge(personalization information <--[of]--> client model), Edge(much lower computation and communication overhead <--[for]--> fl client)]\n",
      ")\n",
      "Graph(\n",
      "\tvertices=[Vertex(concept='0001', words=['0001']), Vertex(concept='075', words=['075']), Vertex(concept='[[[formula]]]', words=['[[[formula]]]']), Vertex(concept='accuracy', words=['accuracy']), Vertex(concept='aggregation', words=['aggregation']), Vertex(concept='all', words=['all']), Vertex(concept='amount', words=['amount']), Vertex(concept='another', words=['another']), Vertex(concept='architecture', words=['architecture']), Vertex(concept='balance', words=['balance']), Vertex(concept='baseline', words=['baseline']), Vertex(concept='bias', words=['bias']), Vertex(concept='change', words=['change']), Vertex(concept='cifar10', words=['cifar10']), Vertex(concept='cinic10', words=['cinic10']), Vertex(concept='client', words=['client']), Vertex(concept='clusterfl', words=['clusterfl']), Vertex(concept='coefficient', words=['coefficient']), Vertex(concept='compatibility', words=['compatibility']), Vertex(concept='compression', words=['compression']), Vertex(concept='configuration', words=['configuration']), Vertex(concept='connection', words=['connection']), Vertex(concept='consensus', words=['consensus']), Vertex(concept='convergence', words=['convergence']), Vertex(concept='convolution', words=['convolution']), Vertex(concept='data', words=['data']), Vertex(concept='dataset', words=['dataset']), Vertex(concept='decrease', words=['decrease']), Vertex(concept='deer', words=['deer']), Vertex(concept='degree', words=['degree']), Vertex(concept='digit', words=['digit']), Vertex(concept='dilation', words=['dilation']), Vertex(concept='distribution', words=['distribution']), Vertex(concept='downside', words=['downside']), Vertex(concept='each', words=['each']), Vertex(concept='effect', words=['effect']), Vertex(concept='effectiveness', words=['effectiveness']), Vertex(concept='epoch', words=['epoch']), Vertex(concept='evaluation', words=['evaluation']), Vertex(concept='example', words=['example']), Vertex(concept='feature', words=['feature']), Vertex(concept='fedavg', words=['fedavg']), Vertex(concept='fedconv', words=['fedconv']), Vertex(concept='fedmd', words=['fedmd']), Vertex(concept='fedrolex', words=['fedrolex']), Vertex(concept='fl', words=['fl']), Vertex(concept='flower', words=['flower']), Vertex(concept='formula', words=['formula']), Vertex(concept='fusion', words=['fusion']), Vertex(concept='generalizability', words=['generalizability']), Vertex(concept='googlenet', words=['googlenet']), Vertex(concept='gradient', words=['gradient']), Vertex(concept='harbox', words=['harbox']), Vertex(concept='head', words=['head']), Vertex(concept='hermes', words=['hermes']), Vertex(concept='heterofl', words=['heterofl']), Vertex(concept='image', words=['image']), Vertex(concept='impact', words=['impact']), Vertex(concept='importance', words=['importance']), Vertex(concept='information', words=['information']), Vertex(concept='instability', words=['instability']), Vertex(concept='integration', words=['integration']), Vertex(concept='issue', words=['issue']), Vertex(concept='iteration', words=['iteration']), Vertex(concept='kd', words=['kd']), Vertex(concept='kernel', words=['kernel']), Vertex(concept='kld', words=['kld']), Vertex(concept='knowledge', words=['knowledge']), Vertex(concept='laboratory', words=['laboratory']), Vertex(concept='laptop', words=['laptop']), Vertex(concept='layer', words=['layer']), Vertex(concept='loss', words=['loss']), Vertex(concept='lotteryfl', words=['lotteryfl']), Vertex(concept='magnitude', words=['magnitude']), Vertex(concept='map', words=['map']), Vertex(concept='method', words=['method']), Vertex(concept='mi', words=['mi']), Vertex(concept='mlr', words=['mlr']), Vertex(concept='model', words=['model']), Vertex(concept='necessity', words=['necessity']), Vertex(concept='number', words=['number']), Vertex(concept='optimization', words=['optimization']), Vertex(concept='output', words=['output']), Vertex(concept='overhead', words=['overhead']), Vertex(concept='overview', words=['overview']), Vertex(concept='padding', words=['padding']), Vertex(concept='parameter', words=['parameter']), Vertex(concept='part', words=['part']), Vertex(concept='performance', words=['performance']), Vertex(concept='personalization', words=['personalization']), Vertex(concept='pfedme', words=['pfedme']), Vertex(concept='popularity', words=['popularity']), Vertex(concept='potential', words=['potential']), Vertex(concept='practicality', words=['practicality']), Vertex(concept='practice', words=['practice']), Vertex(concept='problem', words=['problem']), Vertex(concept='progress', words=['progress']), Vertex(concept='pruning', words=['pruning']), Vertex(concept='pytorch', words=['pytorch']), Vertex(concept='ratio', words=['ratio']), Vertex(concept='removal', words=['removal']), Vertex(concept='resnet18', words=['resnet18']), Vertex(concept='respect', words=['respect']), Vertex(concept='result', words=['result']), Vertex(concept='robustness', words=['robustness']), Vertex(concept='router', words=['router']), Vertex(concept='s', words=['s']), Vertex(concept='scalability', words=['scalability']), Vertex(concept='scheme', words=['scheme']), Vertex(concept='server', words=['server']), Vertex(concept='serveralone', words=['serveralone']), Vertex(concept='set', words=['set']), Vertex(concept='shape', words=['shape']), Vertex(concept='similarity', words=['similarity']), Vertex(concept='size', words=['size']), Vertex(concept='slope', words=['slope']), Vertex(concept='sota', words=['sota']), Vertex(concept='sr', words=['sr']), Vertex(concept='step', words=['step']), Vertex(concept='stride', words=['stride']), Vertex(concept='subset', words=['subset']), Vertex(concept='superiority', words=['superiority']), Vertex(concept='table', words=['table']), Vertex(concept='tailorfl', words=['tailorfl']), Vertex(concept='tc', words=['tc']), Vertex(concept='term', words=['term']), Vertex(concept='that', words=['that']), Vertex(concept='these', words=['these']), Vertex(concept='this', words=['this']), Vertex(concept='training', words=['training']), Vertex(concept='transfer', words=['transfer']), Vertex(concept='transformation', words=['transformation']), Vertex(concept='tuning', words=['tuning']), Vertex(concept='variation', words=['variation']), Vertex(concept='view', words=['view']), Vertex(concept='we', words=['we']), Vertex(concept='weight', words=['weight']), Vertex(concept='which', words=['which']), Vertex(concept='§', words=['§']), Vertex(concept='③', words=['③']), Vertex(concept='05 %', words=['05', '%']), Vertex(concept='1 mnist', words=['1', 'mnist']), Vertex(concept='1 wiar', words=['1', 'wiar']), Vertex(concept='10 client', words=['10', 'client']), Vertex(concept='100 client', words=['100', 'client']), Vertex(concept='12 input', words=['12', 'input']), Vertex(concept='121 user', words=['121', 'user']), Vertex(concept='138 %', words=['138', '%']), Vertex(concept='16 activity', words=['16', 'activity']), Vertex(concept='16 input', words=['16', 'input']), Vertex(concept='2 cifar10', words=['2', 'cifar10']), Vertex(concept='2 second', words=['2', 'second']), Vertex(concept='20 %', words=['20', '%']), Vertex(concept='205 %', words=['205', '%']), Vertex(concept='3 cinic10', words=['3', 'cinic10']), Vertex(concept='3 harbox', words=['3', 'harbox']), Vertex(concept='406 %', words=['406', '%']), Vertex(concept='5 %', words=['5', '%']), Vertex(concept='5 lotteryfl', words=['5', 'lotteryfl']), Vertex(concept='546 %', words=['546', '%']), Vertex(concept='6 hermes', words=['6', 'hermes']), Vertex(concept='64000 sample', words=['64000', 'sample']), Vertex(concept='7 tailorfl', words=['7', 'tailorfl']), Vertex(concept='7336 %', words=['7336', '%']), Vertex(concept='8404 %', words=['8404', '%']), Vertex(concept='9 fedrolex', words=['9', 'fedrolex']), Vertex(concept='9904 %', words=['9904', '%']), Vertex(concept='ablation study', words=['ablation', 'study']), Vertex(concept='accuracy drop', words=['accuracy', 'drop']), Vertex(concept='affordable model', words=['affordable', 'model']), Vertex(concept='aggregate vector', words=['aggregate', 'vector']), Vertex(concept='aggregated model', words=['aggregated', 'model']), Vertex(concept='aggregated parameter', words=['aggregated', 'parameter']), Vertex(concept='aggregation process', words=['aggregation', 'process']), Vertex(concept='all baseline', words=['all', 'baseline']), Vertex(concept='all channel', words=['all', 'channel']), Vertex(concept='all client', words=['all', 'client']), Vertex(concept='all datasets', words=['all', 'datasets']), Vertex(concept='all parameter', words=['all', 'parameter']), Vertex(concept='android client', words=['android', 'client']), Vertex(concept='android system', words=['android', 'system']), Vertex(concept='appropriate sr', words=['appropriate', 'sr']), Vertex(concept='approximately half', words=['approximately', 'half']), Vertex(concept='average accuracy', words=['average', 'accuracy']), Vertex(concept='average consensus', words=['average', 'consensus']), Vertex(concept='average improvement', words=['average', 'improvement']), Vertex(concept='average saving', words=['average', 'saving']), Vertex(concept='better generalizability', words=['better', 'generalizability']), Vertex(concept='better performance', words=['better', 'performance']), Vertex(concept='both body', words=['both', 'body']), Vertex(concept='case study', words=['case', 'study']), Vertex(concept='certain threshold', words=['certain', 'threshold']), Vertex(concept='certain weight', words=['certain', 'weight']), Vertex(concept='channel number', words=['channel', 'number']), Vertex(concept='cifar10 dataset', words=['cifar10', 'dataset']), Vertex(concept='client contribution', words=['client', 'contribution']), Vertex(concept='client data', words=['client', 'data']), Vertex(concept='client model', words=['client', 'model']), Vertex(concept='client performance', words=['client', 'performance']), Vertex(concept='client workload', words=['client', 'workload']), Vertex(concept='cloud server', words=['cloud', 'server']), Vertex(concept='cnn model', words=['cnn', 'model']), Vertex(concept='communication cost', words=['communication', 'cost']), Vertex(concept='communication round', words=['communication', 'round']), Vertex(concept='comparable performance', words=['comparable', 'performance']), Vertex(concept='compressed model', words=['compressed', 'model']), Vertex(concept='compressed parameter', words=['compressed', 'parameter']), Vertex(concept='compression layer', words=['compression', 'layer']), Vertex(concept='compression method', words=['compression', 'method']), Vertex(concept='compression process', words=['compression', 'process']), Vertex(concept='computation overhead', words=['computation', 'overhead']), Vertex(concept='computational overhead', words=['computational', 'overhead']), Vertex(concept='computer font', words=['computer', 'font']), Vertex(concept='constrained resource', words=['constrained', 'resource']), Vertex(concept='conventional fl', words=['conventional', 'fl']), Vertex(concept='convolution compression', words=['convolution', 'compression']), Vertex(concept='convolution layer', words=['convolution', 'layer']), Vertex(concept='convolution parameter', words=['convolution', 'parameter']), Vertex(concept='convolution process', words=['convolution', 'process']), Vertex(concept='convolutional compression', words=['convolutional', 'compression']), Vertex(concept='convolutional layer', words=['convolutional', 'layer']), Vertex(concept='corresponding channel', words=['corresponding', 'channel']), Vertex(concept='corresponding client', words=['corresponding', 'client']), Vertex(concept='corresponding configuration', words=['corresponding', 'configuration']), Vertex(concept='corresponding label', words=['corresponding', 'label']), Vertex(concept='corresponding threshold', words=['corresponding', 'threshold']), Vertex(concept='crucial information', words=['crucial', 'information']), Vertex(concept='data distribution', words=['data', 'distribution']), Vertex(concept='data packet', words=['data', 'packet']), Vertex(concept='data sample', words=['data', 'sample']), Vertex(concept='degraded performance', words=['degraded', 'performance']), Vertex(concept='detailed configuration', words=['detailed', 'configuration']), Vertex(concept='different class', words=['different', 'class']), Vertex(concept='different client', words=['different', 'client']), Vertex(concept='different contribution', words=['different', 'contribution']), Vertex(concept='different datasets', words=['different', 'datasets']), Vertex(concept='different part', words=['different', 'part']), Vertex(concept='different region', words=['different', 'region']), Vertex(concept='different size', words=['different', 'size']), Vertex(concept='different type', words=['different', 'type']), Vertex(concept='dilated model', words=['dilated', 'model']), Vertex(concept='distilled knowledge', words=['distilled', 'knowledge']), Vertex(concept='distinct part', words=['distinct', 'part']), Vertex(concept='diverse resource', words=['diverse', 'resource']), Vertex(concept='domain gap', words=['domain', 'gap']), Vertex(concept='each client', words=['each', 'client']), Vertex(concept='each element', words=['each', 'element']), Vertex(concept='each filter', words=['each', 'filter']), Vertex(concept='each model', words=['each', 'model']), Vertex(concept='each part', words=['each', 'part']), Vertex(concept='each round', words=['each', 'round']), Vertex(concept='ensemble learning', words=['ensemble', 'learning']), Vertex(concept='entire channel', words=['entire', 'channel']), Vertex(concept='entire dataset', words=['entire', 'dataset']), Vertex(concept='excessive communication', words=['excessive', 'communication']), Vertex(concept='execution time', words=['execution', 'time']), Vertex(concept='extra burden', words=['extra', 'burden']), Vertex(concept='extra content', words=['extra', 'content']), Vertex(concept='feature map', words=['feature', 'map']), Vertex(concept='federated client', words=['federated', 'client']), Vertex(concept='figure reference', words=['figure', 'reference']), Vertex(concept='final aggregation', words=['final', 'aggregation']), Vertex(concept='first conv', words=['first', 'conv']), Vertex(concept='first layer', words=['first', 'layer']), Vertex(concept='five datasets', words=['five', 'datasets']), Vertex(concept='fixed subset', words=['fixed', 'subset']), Vertex(concept='fl client', words=['fl', 'client']), Vertex(concept='fl server', words=['fl', 'server']), Vertex(concept='flower framework', words=['flower', 'framework']), Vertex(concept='following baseline', words=['following', 'baseline']), Vertex(concept='forward function', words=['forward', 'function']), Vertex(concept='four part', words=['four', 'part']), Vertex(concept='four sr', words=['four', 'sr']), Vertex(concept='full use', words=['full', 'use']), Vertex(concept='global model', words=['global', 'model']), Vertex(concept='global parameter', words=['global', 'parameter']), Vertex(concept='googlenet model', words=['googlenet', 'model']), Vertex(concept='gradient descent', words=['gradient', 'descent']), Vertex(concept='ground truth', words=['ground', 'truth']), Vertex(concept='harbox dataset', words=['harbox', 'dataset']), Vertex(concept='heavy overhead', words=['heavy', 'overhead']), Vertex(concept='heterogeneous client', words=['heterogeneous', 'client']), Vertex(concept='heterogeneous data', words=['heterogeneous', 'data']), Vertex(concept='heterogeneous device', words=['heterogeneous', 'device']), Vertex(concept='heterogeneous fl', words=['heterogeneous', 'fl']), Vertex(concept='heterogeneous model', words=['heterogeneous', 'model']), Vertex(concept='higher accuracy', words=['higher', 'accuracy']), Vertex(concept='higher generalizability', words=['higher', 'generalizability']), Vertex(concept='highest importance', words=['highest', 'importance']), Vertex(concept='homogeneous data', words=['homogeneous', 'data']), Vertex(concept='iid data', words=['iid', 'data']), Vertex(concept='imbalance issue', words=['imbalance', 'issue']), Vertex(concept='imbalanced contribution', words=['imbalanced', 'contribution']), Vertex(concept='imbalanced performance', words=['imbalanced', 'performance']), Vertex(concept='inference accuracy', words=['inference', 'accuracy']), Vertex(concept='information loss', words=['information', 'loss']), Vertex(concept='input channel', words=['input', 'channel']), Vertex(concept='input data', words=['input', 'data']), Vertex(concept='insufficient number', words=['insufficient', 'number']), Vertex(concept='iterative refining', words=['iterative', 'refining']), Vertex(concept='kernel size', words=['kernel', 'size']), Vertex(concept='key information', words=['key', 'information']), Vertex(concept='knowledge distillation', words=['knowledge', 'distillation']), Vertex(concept='large model', words=['large', 'model']), Vertex(concept='larger amount', words=['larger', 'amount']), Vertex(concept='larger kernel', words=['larger', 'kernel']), Vertex(concept='larger model', words=['larger', 'model']), Vertex(concept='larger sr', words=['larger', 'sr']), Vertex(concept='larger volume', words=['larger', 'volume']), Vertex(concept='last layer', words=['last', 'layer']), Vertex(concept='learnable variable', words=['learnable', 'variable']), Vertex(concept='learning rate', words=['learning', 'rate']), Vertex(concept='less memory', words=['less', 'memory']), Vertex(concept='limited capability', words=['limited', 'capability']), Vertex(concept='load_state_dict function', words=['load_state_dict', 'function']), Vertex(concept='local data', words=['local', 'data']), Vertex(concept='local training', words=['local', 'training']), Vertex(concept='lower accuracy', words=['lower', 'accuracy']), Vertex(concept='lower layer', words=['lower', 'layer']), Vertex(concept='maximum number', words=['maximum', 'number']), Vertex(concept='memory cost', words=['memory', 'cost']), Vertex(concept='memory footprint', words=['memory', 'footprint']), Vertex(concept='minimal modification', words=['minimal', 'modification']), Vertex(concept='mixed window', words=['mixed', 'window']), Vertex(concept='mnist dataset', words=['mnist', 'dataset']), Vertex(concept='mobile device', words=['mobile', 'device']), Vertex(concept='model aggregation', words=['model', 'aggregation']), Vertex(concept='model compression', words=['model', 'compression']), Vertex(concept='model exposure', words=['model', 'exposure']), Vertex(concept='model output', words=['model', 'output']), Vertex(concept='model parameter', words=['model', 'parameter']), Vertex(concept='model performance', words=['model', 'performance']), Vertex(concept='model pruning', words=['model', 'pruning']), Vertex(concept='more attention', words=['more', 'attention']), Vertex(concept='more contribution', words=['more', 'contribution']), Vertex(concept='more resource', words=['more', 'resource']), Vertex(concept='moreau envelope', words=['moreau', 'envelope']), Vertex(concept='mutual information', words=['mutual', 'information']), Vertex(concept='negative parameter', words=['negative', 'parameter']), Vertex(concept='network layer', words=['network', 'layer']), Vertex(concept='network traffic', words=['network', 'traffic']), Vertex(concept='new technology', words=['new', 'technology']), Vertex(concept='one model', words=['one', 'model']), Vertex(concept='one size', words=['one', 'size']), Vertex(concept='other client', words=['other', 'client']), Vertex(concept='other kind', words=['other', 'kind']), Vertex(concept='other type', words=['other', 'type']), Vertex(concept='our knowledge', words=['our', 'knowledge']), Vertex(concept='our office', words=['our', 'office']), Vertex(concept='our system', words=['our', 'system']), Vertex(concept='output channel', words=['output', 'channel']), Vertex(concept='overall performance', words=['overall', 'performance']), Vertex(concept='overlapped part', words=['overlapped', 'part']), Vertex(concept='parameter information', words=['parameter', 'information']), Vertex(concept='parameter matrix', words=['parameter', 'matrix']), Vertex(concept='parameter sharing', words=['parameter', 'sharing']), Vertex(concept='performance degradation', words=['performance', 'degradation']), Vertex(concept='performance enhancement', words=['performance', 'enhancement']), Vertex(concept='performance improvement', words=['performance', 'improvement']), Vertex(concept='performance instability', words=['performance', 'instability']), Vertex(concept='personalization information', words=['personalization', 'information']), Vertex(concept='personalization performance', words=['personalization', 'performance']), Vertex(concept='personalized fl', words=['personalized', 'fl']), Vertex(concept='personalized information', words=['personalized', 'information']), Vertex(concept='prediction result', words=['prediction', 'result']), Vertex(concept='previous solution', words=['previous', 'solution']), Vertex(concept='privacy protection', words=['privacy', 'protection']), Vertex(concept='public data', words=['public', 'data']), Vertex(concept='pympler library', words=['pympler', 'library']), Vertex(concept='raspberry pi', words=['raspberry', 'pi']), Vertex(concept='raw data', words=['raw', 'data']), Vertex(concept='recent advancement', words=['recent', 'advancement']), Vertex(concept='recent work', words=['recent', 'work']), Vertex(concept='relative importance', words=['relative', 'importance']), Vertex(concept='residual connection', words=['residual', 'connection']), Vertex(concept='resnet18 model', words=['resnet18', 'model']), Vertex(concept='resource budget', words=['resource', 'budget']), Vertex(concept='resource profile', words=['resource', 'profile']), Vertex(concept='resource profiling', words=['resource', 'profiling']), Vertex(concept='reverse operation', words=['reverse', 'operation']), Vertex(concept='richer information', words=['richer', 'information']), Vertex(concept='same degree', words=['same', 'degree']), Vertex(concept='same domain', words=['same', 'domain']), Vertex(concept='same set', words=['same', 'set']), Vertex(concept='same size', words=['same', 'size']), Vertex(concept='sample distribution', words=['sample', 'distribution']), Vertex(concept='sample number', words=['sample', 'number']), Vertex(concept='second conv', words=['second', 'conv']), Vertex(concept='sensing heterogeneity', words=['sensing', 'heterogeneity']), Vertex(concept='sensor data', words=['sensor', 'data']), Vertex(concept='server side', words=['server', 'side']), Vertex(concept='several epoch', words=['several', 'epoch']), Vertex(concept='shared dataset', words=['shared', 'dataset']), Vertex(concept='sharing strategy', words=['sharing', 'strategy']), Vertex(concept='shrinkage ratio', words=['shrinkage', 'ratio']), Vertex(concept='significant potential', words=['significant', 'potential']), Vertex(concept='significant saving', words=['significant', 'saving']), Vertex(concept='sliding window', words=['sliding', 'window']), Vertex(concept='small dataset', words=['small', 'dataset']), Vertex(concept='small portion', words=['small', 'portion']), Vertex(concept='smaller model', words=['smaller', 'model']), Vertex(concept='smaller sr', words=['smaller', 'sr']), Vertex(concept='smaller stride', words=['smaller', 'stride']), Vertex(concept='some baseline', words=['some', 'baseline']), Vertex(concept='some device', words=['some', 'device']), Vertex(concept='sota baseline', words=['sota', 'baseline']), Vertex(concept='standalone fedmd', words=['standalone', 'fedmd']), Vertex(concept='stride length', words=['stride', 'length']), Vertex(concept='sub model', words=['sub', 'model']), Vertex(concept='sufficient data', words=['sufficient', 'data']), Vertex(concept='superior performance', words=['superior', 'performance']), Vertex(concept='synchronized fl', words=['synchronized', 'fl']), Vertex(concept='system overhead', words=['system', 'overhead']), Vertex(concept='tc layer', words=['tc', 'layer']), Vertex(concept='tc operation', words=['tc', 'operation']), Vertex(concept='tc parameter', words=['tc', 'parameter']), Vertex(concept='technical challenge', words=['technical', 'challenge']), Vertex(concept='ten class', words=['ten', 'class']), Vertex(concept='these challenge', words=['these', 'challenge']), Vertex(concept='these datasets', words=['these', 'datasets']), Vertex(concept='these work', words=['these', 'work']), Vertex(concept='this paradigm', words=['this', 'paradigm']), Vertex(concept='this scheme', words=['this', 'scheme']), Vertex(concept='three datasets', words=['three', 'datasets']), Vertex(concept='total dataset', words=['total', 'dataset']), Vertex(concept='total size', words=['total', 'size']), Vertex(concept='trade off', words=['trade', 'off']), Vertex(concept='training process', words=['training', 'process']), Vertex(concept='training task', words=['training', 'task']), Vertex(concept='transposed convolution', words=['transposed', 'convolution']), Vertex(concept='tuning epoch', words=['tuning', 'epoch']), Vertex(concept='two datasets', words=['two', 'datasets']), Vertex(concept='unified size', words=['unified', 'size']), Vertex(concept='uniform size', words=['uniform', 'size']), Vertex(concept='upper layer', words=['upper', 'layer']), Vertex(concept='upward trend', words=['upward', 'trend']), Vertex(concept='useful feature', words=['useful', 'feature']), Vertex(concept='valuable feature', words=['valuable', 'feature']), Vertex(concept='value range', words=['value', 'range']), Vertex(concept='varying skewness', words=['varying', 'skewness']), Vertex(concept='weaker client', words=['weaker', 'client']), Vertex(concept='weight normalization', words=['weight', 'normalization']), Vertex(concept='weight vector', words=['weight', 'vector']), Vertex(concept='wifi signal', words=['wifi', 'signal']), Vertex(concept='1 iid server side global data', words=['1', 'iid', 'server']), Vertex(concept='100 communication round', words=['100', 'communication', 'round']), Vertex(concept='180000 32 formula 32 color image', words=['180000', '32', 'formula']), Vertex(concept='2 gb less memory', words=['2', 'gb', 'less']), Vertex(concept='2 iid test data', words=['2', 'iid', 'test']), Vertex(concept='20 heterogeneous mobile device', words=['20', 'heterogeneous', 'mobile']), Vertex(concept='20 th and 40 th epoch', words=['20', 'th', 'and']), Vertex(concept='24 output channel', words=['24', 'output', 'channel']), Vertex(concept='3 pruning based method', words=['3', 'pruning', 'based']), Vertex(concept='32 color image', words=['32', 'color', 'image']), Vertex(concept='32 output channel', words=['32', 'output', 'channel']), Vertex(concept='480 90 formula 250 wi fi csi sample', words=['480', '90', 'formula']), Vertex(concept='5 local training epoch', words=['5', 'local', 'training']), Vertex(concept='5000 36 formula 36 gray scale depth image', words=['5000', '36', 'formula']), Vertex(concept='60000 32 formula', words=['60000', '32', 'formula']), Vertex(concept='60000 formula gray scale image', words=['60000', 'formula', 'gray']), Vertex(concept='77 different smartphones', words=['77', 'different', 'smartphones']), Vertex(concept='9 axis imu data', words=['9', 'axis', 'imu']), Vertex(concept='900 dimensional feature', words=['900', 'dimensional', 'feature']), Vertex(concept='[[[formula th aggregated network layer]]]', words=['[[[formula', 'th', 'aggregated']), Vertex(concept='[[[formula th large model]]]', words=['[[[formula', 'th', 'large']), Vertex(concept='[[[formula th layer]]]', words=['[[[formula', 'th', 'layer]]]']), Vertex(concept='actual turning point', words=['actual', 'turning', 'point']), Vertex(concept='additional compute overhead', words=['additional', 'compute', 'overhead']), Vertex(concept='aggregated global model', words=['aggregated', 'global', 'model']), Vertex(concept='all client model', words=['all', 'client', 'model']), Vertex(concept='all convolution parameter', words=['all', 'convolution', 'parameter']), Vertex(concept='all dilated model', words=['all', 'dilated', 'model']), Vertex(concept='around 20 epoch', words=['around', '20', 'epoch']), Vertex(concept='around 90 minute', words=['around', '90', 'minute']), Vertex(concept='average client model accuracy', words=['average', 'client', 'model']), Vertex(concept='average memory usage', words=['average', 'memory', 'usage']), Vertex(concept='average wall clock time', words=['average', 'wall', 'clock']), Vertex(concept='better and more stable performance', words=['better', 'and', 'more']), Vertex(concept='better global view', words=['better', 'global', 'view']), Vertex(concept='better personalization performance', words=['better', 'personalization', 'performance']), Vertex(concept='both global and client model', words=['both', 'global', 'and']), Vertex(concept='both global model', words=['both', 'global', 'model']), Vertex(concept='both inference accuracy', words=['both', 'inference', 'accuracy']), Vertex(concept='both server side and client side datasets', words=['both', 'server', 'side']), Vertex(concept='channel level and filter level pruning', words=['channel', 'level', 'and']), Vertex(concept='channel level pruning', words=['channel', 'level', 'pruning']), Vertex(concept='channel level pruning method', words=['channel', 'level', 'pruning']), Vertex(concept='channel or filter level pruning', words=['channel', 'or', 'filter']), Vertex(concept='channel pruned model', words=['channel', 'pruned', 'model']), Vertex(concept='channel state information', words=['channel', 'state', 'information']), Vertex(concept='chars74 k dataset', words=['chars74', 'k', 'dataset']), Vertex(concept='client friendly federated learning framework', words=['client', 'friendly', 'federated']), Vertex(concept='client friendly fl framework', words=['client', 'friendly', 'fl']), Vertex(concept='client model accuracy', words=['client', 'model', 'accuracy']), Vertex(concept='client model performance', words=['client', 'model', 'performance']), Vertex(concept='client own personal layer', words=['client', 'own', 'personal']), Vertex(concept='client private data', words=['client', 'private', 'data']), Vertex(concept='client s perspective', words=['client', 's', 'perspective']), Vertex(concept='client shrinkage ratio', words=['client', 'shrinkage', 'ratio']), Vertex(concept='client side data', words=['client', 'side', 'data']), Vertex(concept='client side data distribution', words=['client', 'side', 'data']), Vertex(concept='client side non iid data', words=['client', 'side', 'non']), Vertex(concept='client side private test datasets', words=['client', 'side', 'private']), Vertex(concept='client side test datasets', words=['client', 'side', 'test']), Vertex(concept='clustered multi task federated learning', words=['clustered', 'multi', 'task']), Vertex(concept='communication computation and energy cost', words=['communication', 'computation', 'and']), Vertex(concept='comparable personalization performance', words=['comparable', 'personalization', 'performance']), Vertex(concept='comprehensive global view', words=['comprehensive', 'global', 'view']), Vertex(concept='compressed parameter matrix', words=['compressed', 'parameter', 'matrix']), Vertex(concept='compressed sub model', words=['compressed', 'sub', 'model']), Vertex(concept='compression dilation aggregation impact', words=['compression', 'dilation', 'aggregation']), Vertex(concept='computing resource budget', words=['computing', 'resource', 'budget']), Vertex(concept='conventional fl scheme', words=['conventional', 'fl', 'scheme']), Vertex(concept='convolution / tc parameter', words=['convolution', '/', 'tc']), Vertex(concept='convolution based compression process', words=['convolution', 'based', 'compression']), Vertex(concept='convolutional compression module', words=['convolutional', 'compression', 'module']), Vertex(concept='convolutional neural network', words=['convolutional', 'neural', 'network']), Vertex(concept='corresponding weight vector', words=['corresponding', 'weight', 'vector']), Vertex(concept='cosine annealing learning rate scheduler', words=['cosine', 'annealing', 'learning']), Vertex(concept='cosine function decay', words=['cosine', 'function', 'decay']), Vertex(concept='cross entropy loss', words=['cross', 'entropy', 'loss']), Vertex(concept='default sample ratio', words=['default', 'sample', 'ratio']), Vertex(concept='different data heterogeneity', words=['different', 'data', 'heterogeneity']), Vertex(concept='different hardware and network condition', words=['different', 'hardware', 'and']), Vertex(concept='different learnable weight vector', words=['different', 'learnable', 'weight']), Vertex(concept='different learned weight vector', words=['different', 'learned', 'weight']), Vertex(concept='different parameter information', words=['different', 'parameter', 'information']), Vertex(concept='different sensing heterogeneity', words=['different', 'sensing', 'heterogeneity']), Vertex(concept='different tc layer', words=['different', 'tc', 'layer']), Vertex(concept='dilated large model', words=['dilated', 'large', 'model']), Vertex(concept='dilated model parameter', words=['dilated', 'model', 'parameter']), Vertex(concept='disjoint non iid client side data', words=['disjoint', 'non', 'iid']), Vertex(concept='diverse computation and communication resource', words=['diverse', 'computation', 'and']), Vertex(concept='diverse personalized information', words=['diverse', 'personalized', 'information']), Vertex(concept='diverse sub model', words=['diverse', 'sub', 'model']), Vertex(concept='diverse system resource', words=['diverse', 'system', 'resource']), Vertex(concept='dynamic rolling window', words=['dynamic', 'rolling', 'window']), Vertex(concept='e g different shape', words=['e', 'g', 'different']), Vertex(concept='e g various writing style', words=['e', 'g', 'various']), Vertex(concept='each client model', words=['each', 'client', 'model']), Vertex(concept='each client s model parameter', words=['each', 'client', 's']), Vertex(concept='each client s process id', words=['each', 'client', 's']), Vertex(concept='each dilated model', words=['each', 'dilated', 'model']), Vertex(concept='each tc layer', words=['each', 'tc', 'layer']), Vertex(concept='each uploaded client model', words=['each', 'uploaded', 'client']), Vertex(concept='entire fl process', words=['entire', 'fl', 'process']), Vertex(concept='estimated memory requirement', words=['estimated', 'memory', 'requirement']), Vertex(concept='even lightweight device', words=['even', 'lightweight', 'device']), Vertex(concept='every network layer', words=['every', 'network', 'layer']), Vertex(concept='existing fl framework', words=['existing', 'fl', 'framework']), Vertex(concept='existing fl system', words=['existing', 'fl', 'system']), Vertex(concept='existing pruning based method', words=['existing', 'pruning', 'based']), Vertex(concept='extra communication or computation overhead', words=['extra', 'communication', 'or']), Vertex(concept='feature extraction capability', words=['feature', 'extraction', 'capability']), Vertex(concept='fedconv lotteryfl heterofl', words=['fedconv', 'lotteryfl', 'heterofl']), Vertex(concept='federated learning setup', words=['federated', 'learning', 'setup']), Vertex(concept='filter level pruning', words=['filter', 'level', 'pruning']), Vertex(concept='filter pruned model', words=['filter', 'pruned', 'model']), Vertex(concept='fine grained way', words=['fine', 'grained', 'way']), Vertex(concept='fine tuned convolution parameter', words=['fine', 'tuned', 'convolution']), Vertex(concept='first and second part', words=['first', 'and', 'second']), Vertex(concept='first two feature map', words=['first', 'two', 'feature']), Vertex(concept='five common gesture', words=['five', 'common', 'gesture']), Vertex(concept='five daily activity', words=['five', 'daily', 'activity']), Vertex(concept='flower cite framework', words=['flower', 'cite', 'framework']), Vertex(concept='following key contribution', words=['following', 'key', 'contribution']), Vertex(concept='generated sub model', words=['generated', 'sub', 'model']), Vertex(concept='global model accuracy', words=['global', 'model', 'accuracy']), Vertex(concept='global model parameter', words=['global', 'model', 'parameter']), Vertex(concept='global model s parameter', words=['global', 'model', 's']), Vertex(concept='heterogeneous client model', words=['heterogeneous', 'client', 'model']), Vertex(concept='heterogeneous federated client', words=['heterogeneous', 'federated', 'client']), Vertex(concept='heterogeneous formula = 005 data', words=['heterogeneous', 'formula', '=']), Vertex(concept='heterogeneous sub model', words=['heterogeneous', 'sub', 'model']), Vertex(concept='high communication and computation overhead', words=['high', 'communication', 'and']), Vertex(concept='high computational complexity', words=['high', 'computational', 'complexity']), Vertex(concept='high end edge pc', words=['high', 'end', 'edge']), Vertex(concept='high end pc', words=['high', 'end', 'pc']), Vertex(concept='higher average accuracy', words=['higher', 'average', 'accuracy']), Vertex(concept='higher global model accuracy', words=['higher', 'global', 'model']), Vertex(concept='highest client model accuracy', words=['highest', 'client', 'model']), Vertex(concept='i e parameter', words=['i', 'e', 'parameter']), Vertex(concept='importance value based filter level pruning scheme', words=['importance', 'value', 'based']), Vertex(concept='increased data heterogeneity', words=['increased', 'data', 'heterogeneity']), Vertex(concept='input channel number', words=['input', 'channel', 'number']), Vertex(concept='intrinsic clustering pattern', words=['intrinsic', 'clustering', 'pattern']), Vertex(concept='knowledge distillation based method', words=['knowledge', 'distillation', 'based']), Vertex(concept='kullback leibler divergence', words=['kullback', 'leibler', 'divergence']), Vertex(concept='large global model', words=['large', 'global', 'model']), Vertex(concept='last two feature map', words=['last', 'two', 'feature']), Vertex(concept='learned importance value', words=['learned', 'importance', 'value']), Vertex(concept='learning rate scheduler', words=['learning', 'rate', 'scheduler']), Vertex(concept='least system resource', words=['least', 'system', 'resource']), Vertex(concept='local fine tuning', words=['local', 'fine', 'tuning']), Vertex(concept='locally trained heterogeneous client model', words=['locally', 'trained', 'heterogeneous']), Vertex(concept='longer convergence time', words=['longer', 'convergence', 'time']), Vertex(concept='low cost embedded system', words=['low', 'cost', 'embedded']), Vertex(concept='lower and upper bound', words=['lower', 'and', 'upper']), Vertex(concept='memory and training time', words=['memory', 'and', 'training']), Vertex(concept='memory computation and communication resource', words=['memory', 'computation', 'and']), Vertex(concept='mnist cite dataset', words=['mnist', 'cite', 'dataset']), Vertex(concept='model compression dilation and aggregation process', words=['model', 'compression', 'dilation']), Vertex(concept='model heterogeneity aware fl system', words=['model', 'heterogeneity', 'aware']), Vertex(concept='model personalized information', words=['model', 'personalized', 'information']), Vertex(concept='more comprehensive global perspective', words=['more', 'comprehensive', 'global']), Vertex(concept='more comprehensive parameter information', words=['more', 'comprehensive', 'parameter']), Vertex(concept='more fine grained information', words=['more', 'fine', 'grained']), Vertex(concept='more general feature', words=['more', 'general', 'feature']), Vertex(concept='more powerful client', words=['more', 'powerful', 'client']), Vertex(concept='more system resource', words=['more', 'system', 'resource']), Vertex(concept='more than 35 %', words=['more', 'than', '35']), Vertex(concept='much constrained resource', words=['much', 'constrained', 'resource']), Vertex(concept='much higher accuracy', words=['much', 'higher', 'accuracy']), Vertex(concept='much higher sensitivity', words=['much', 'higher', 'sensitivity']), Vertex(concept='much lower computation and communication overhead', words=['much', 'lower', 'computation']), Vertex(concept='negative and positive value', words=['negative', 'and', 'positive']), Vertex(concept='nine separate 2d convolutional layer', words=['nine', 'separate', '2d']), Vertex(concept='no client side sensor data', words=['no', 'client', 'side']), Vertex(concept='no standard model', words=['no', 'standard', 'model']), Vertex(concept='non iid data', words=['non', 'iid', 'data']), Vertex(concept='notable accuracy drop', words=['notable', 'accuracy', 'drop']), Vertex(concept='novel convolutional compression technique', words=['novel', 'convolutional', 'compression']), Vertex(concept='one data domain', words=['one', 'data', 'domain']), Vertex(concept='one fc layer', words=['one', 'fc', 'layer']), Vertex(concept='only 476 %', words=['only', '476', '%']), Vertex(concept='only server side global data', words=['only', 'server', 'side']), Vertex(concept='our learned weight vector', words=['our', 'learned', 'weight']), Vertex(concept='our proposed convolutional compression method', words=['our', 'proposed', 'convolutional']), Vertex(concept='output channel number', words=['output', 'channel', 'number']), Vertex(concept='parameter local data distribution', words=['parameter', 'local', 'data']), Vertex(concept='parameter pruning method', words=['parameter', 'pruning', 'method']), Vertex(concept='parameter sharing strategy', words=['parameter', 'sharing', 'strategy']), Vertex(concept='popular computer vision application', words=['popular', 'computer', 'vision']), Vertex(concept='pre trained model', words=['pre', 'trained', 'model']), Vertex(concept='pre trained resnet18 model', words=['pre', 'trained', 'resnet18']), Vertex(concept='pre training and fine tuning process', words=['pre', 'training', 'and']), Vertex(concept='previous communication round', words=['previous', 'communication', 'round']), Vertex(concept='regularized loss function', words=['regularized', 'loss', 'function']), Vertex(concept='remaining 10 client', words=['remaining', '10', 'client']), Vertex(concept='rescaled large model', words=['rescaled', 'large', 'model']), Vertex(concept='resource constrained client', words=['resource', 'constrained', 'client']), Vertex(concept='resource constrained mobile device', words=['resource', 'constrained', 'mobile']), Vertex(concept='same heterogeneous data setting', words=['same', 'heterogeneous', 'data']), Vertex(concept='same model architecture', words=['same', 'model', 'architecture']), Vertex(concept='same prediction task', words=['same', 'prediction', 'task']), Vertex(concept='sample number ratio', words=['sample', 'number', 'ratio']), Vertex(concept='selected participating client', words=['selected', 'participating', 'client']), Vertex(concept='separate tc operation', words=['separate', 'tc', 'operation']), Vertex(concept='server side data', words=['server', 'side', 'data']), Vertex(concept='server side pre training process', words=['server', 'side', 'pre']), Vertex(concept='server side test dataset', words=['server', 'side', 'test']), Vertex(concept='serveralone s global model', words=['serveralone', 's', 'global']), Vertex(concept='several practical challenge', words=['several', 'practical', 'challenge']), Vertex(concept='shared global model', words=['shared', 'global', 'model']), Vertex(concept='significant computational and communication overhead', words=['significant', 'computational', 'and']), Vertex(concept='significant performance fluctuation', words=['significant', 'performance', 'fluctuation']), Vertex(concept='significant performance gain', words=['significant', 'performance', 'gain']), Vertex(concept='similar distribution pattern', words=['similar', 'distribution', 'pattern']), Vertex(concept='simple compression layer', words=['simple', 'compression', 'layer']), Vertex(concept='six public datasets', words=['six', 'public', 'datasets']), Vertex(concept='small publicly available dataset', words=['small', 'publicly', 'available']), Vertex(concept='smallest affordable model', words=['smallest', 'affordable', 'model']), Vertex(concept='some input channel', words=['some', 'input', 'channel']), Vertex(concept='some input data channel', words=['some', 'input', 'data']), Vertex(concept='some output channel', words=['some', 'output', 'channel']), Vertex(concept='sparse sub model', words=['sparse', 'sub', 'model']), Vertex(concept='spatial and hierarchical parameter pattern', words=['spatial', 'and', 'hierarchical']), Vertex(concept='stable and robust simulated environment', words=['stable', 'and', 'robust']), Vertex(concept='stride padding value', words=['stride', 'padding', 'value']), Vertex(concept='sub model output', words=['sub', 'model', 'output']), Vertex(concept='sub model parameter', words=['sub', 'model', 'parameter']), Vertex(concept='sub optimal performance', words=['sub', 'optimal', 'performance']), Vertex(concept='superior generalization performance', words=['superior', 'generalization', 'performance']), Vertex(concept='tc dilation process', words=['tc', 'dilation', 'process']), Vertex(concept='ten handwritten digit', words=['ten', 'handwritten', 'digit']), Vertex(concept='th dilated model', words=['th', 'dilated', 'model']), Vertex(concept='these dilated model', words=['these', 'dilated', 'model']), Vertex(concept='these edge device', words=['these', 'edge', 'device']), Vertex(concept='these large model', words=['these', 'large', 'model']), Vertex(concept='these two scheme', words=['these', 'two', 'scheme']), Vertex(concept='this compression process', words=['this', 'compression', 'process']), Vertex(concept='this performance gain', words=['this', 'performance', 'gain']), Vertex(concept='three conv layer', words=['three', 'conv', 'layer']), Vertex(concept='three key technical challenge', words=['three', 'key', 'technical']), Vertex(concept='three key technical module', words=['three', 'key', 'technical']), Vertex(concept='top4 and top3 feature map', words=['top4', 'and', 'top3']), Vertex(concept='transfer learning strategy', words=['transfer', 'learning', 'strategy']), Vertex(concept='transposed convolutional dilation', words=['transposed', 'convolutional', 'dilation']), Vertex(concept='transposed convolutional dilation method', words=['transposed', 'convolutional', 'dilation']), Vertex(concept='two convolutional layer', words=['two', 'convolutional', 'layer']), Vertex(concept='two formula convolutional layer', words=['two', 'formula', 'convolutional']), Vertex(concept='two key observation', words=['two', 'key', 'observation']), Vertex(concept='two representative fl task', words=['two', 'representative', 'fl']), Vertex(concept='two representative mobile application', words=['two', 'representative', 'mobile']), Vertex(concept='two tc formula layer', words=['two', 'tc', 'formula']), Vertex(concept='unexpected performance degradation', words=['unexpected', 'performance', 'degradation']), Vertex(concept='unit parameter matrix', words=['unit', 'parameter', 'matrix']), Vertex(concept='user friendly fl framework', words=['user', 'friendly', 'fl']), Vertex(concept='varied parameter size', words=['varied', 'parameter', 'size']), Vertex(concept='various receptive field', words=['various', 'receptive', 'field']), Vertex(concept='varying client number', words=['varying', 'client', 'number']), Vertex(concept='wall clock time', words=['wall', 'clock', 'time']), Vertex(concept='weight vector tuning', words=['weight', 'vector', 'tuning']), Vertex(concept='weighted average aggregation', words=['weighted', 'average', 'aggregation']), Vertex(concept='whose parameter matrix', words=['whose', 'parameter', 'matrix'])],\n",
      "\tedges=[Edge(mobile device <--[trains]--> shared global model), Edge(client <--[uses]--> client private data), Edge(server <--[uses]--> model aggregation), Edge(client <--[uses]--> model aggregation), Edge(heterogeneous client <--[uses]--> model aggregation), Edge(federated client <--[have]--> diverse system resource), Edge(federated client <--[demonstrate of]--> heterogeneous model), Edge(federated client <--[demonstrate of]--> data distribution), Edge(high end pc <--[support]--> large model), Edge(high end pc <--[support]--> sub model), Edge(previous solution <--[uses]--> knowledge distillation), Edge(previous solution <--[uses]--> parameter sharing), Edge(kd <--[captures]--> knowledge), Edge(ensemble learning <--[captures]--> knowledge), Edge(kd <--[demonstrate of]--> heterogeneous client model), Edge(ensemble learning <--[demonstrate of]--> heterogeneous client model), Edge(kd <--[uses]--> additional compute overhead), Edge(ensemble learning <--[uses]--> additional compute overhead), Edge(kd <--[demonstrate of]--> client), Edge(ensemble learning <--[demonstrate of]--> client), Edge(client <--[demonstrate of]--> public data), Edge(parameter sharing strategy <--[transmit]--> different region), Edge(parameter sharing strategy <--[demonstrate of]--> global model), Edge(parameter sharing strategy <--[demonstrate of]--> sub model), Edge(parameter pruning method <--[uses]--> channel or filter level pruning), Edge(method <--[demonstrate of]--> information loss), Edge(method <--[demonstrate of]--> imbalance issue), Edge(method <--[demonstrate of]--> performance degradation), Edge(heterogeneous sub model <--[uses]--> information), Edge(heterogeneous sub model <--[demonstrate of]--> global model), Edge(heterogeneous sub model <--[demonstrate of]--> sub model), Edge(we <--[uses]--> fedconv), Edge(we <--[uses]--> all baseline), Edge(we <--[uses]--> lotteryfl), Edge(convolution <--[compress]--> large model), Edge(convolution <--[compress]--> sub model), Edge(transposed convolution <--[compress]--> large model), Edge(transposed convolution <--[compress]--> sub model), Edge(convolution <--[contain via]--> various receptive field), Edge(transposed convolution <--[contain via]--> various receptive field), Edge(server <--[uses]--> convolutional compression), Edge(server <--[uses]--> transposed convolutional dilation), Edge(client <--[uses]--> convolutional compression), Edge(client <--[uses]--> transposed convolutional dilation), Edge(heterogeneous client <--[uses]--> convolutional compression), Edge(heterogeneous client <--[uses]--> transposed convolutional dilation), Edge(server <--[demonstrate of]--> global model), Edge(server <--[demonstrate of]--> sub model), Edge(client <--[demonstrate of]--> global model), Edge(client <--[demonstrate of]--> sub model), Edge(heterogeneous client <--[demonstrate of]--> global model), Edge(heterogeneous client <--[demonstrate of]--> sub model), Edge(client <--[demonstrate of]--> compressed sub model), Edge(server <--[uses]--> transposed convolution), Edge(client <--[uses]--> transposed convolution), Edge(heterogeneous client <--[uses]--> transposed convolution), Edge(server <--[uses]--> different learned weight vector), Edge(client <--[uses]--> different learned weight vector), Edge(heterogeneous client <--[uses]--> different learned weight vector), Edge(server <--[demonstrate of]--> these dilated model), Edge(client <--[demonstrate of]--> these dilated model), Edge(heterogeneous client <--[demonstrate of]--> these dilated model), Edge(server <--[uses]--> aggregate vector), Edge(client <--[uses]--> aggregate vector), Edge(heterogeneous client <--[uses]--> aggregate vector), Edge(fedconv <--[uses]--> model compression dilation and aggregation process), Edge(all baseline <--[uses]--> model compression dilation and aggregation process), Edge(lotteryfl <--[uses]--> model compression dilation and aggregation process), Edge(our system <--[uses]--> extra communication or computation overhead), Edge(our system <--[demonstrate of]--> resource constrained client), Edge(we <--[address]--> three key technical challenge), Edge(we <--[uses]--> compression process), Edge(we <--[demonstrate of]--> training task), Edge(we <--[applies]--> separate tc operation), Edge(we <--[demonstrate of]--> each client s model parameter), Edge(which <--[inherit]--> model personalized information), Edge(we <--[uses]--> residual connection), Edge(these large model <--[demonstrate of]--> performance degradation), Edge(we <--[set]--> different learnable weight vector), Edge(we <--[demonstrate of]--> dilated model), Edge(server <--[learn]--> relative importance), Edge(client <--[learn]--> relative importance), Edge(heterogeneous client <--[learn]--> relative importance), Edge(server <--[demonstrate of]--> each model), Edge(client <--[demonstrate of]--> each model), Edge(heterogeneous client <--[demonstrate of]--> each model), Edge(we <--[uses]--> fedconv), Edge(we <--[uses]--> all baseline), Edge(we <--[uses]--> lotteryfl), Edge(we <--[uses]--> fedconv), Edge(we <--[uses]--> all baseline), Edge(we <--[uses]--> lotteryfl), Edge(we <--[demonstrate of]--> six public datasets), Edge(fedconv <--[outperforms]--> sota), Edge(all baseline <--[outperforms]--> sota), Edge(lotteryfl <--[outperforms]--> sota), Edge(fedconv <--[demonstrate of]--> term), Edge(all baseline <--[demonstrate of]--> term), Edge(lotteryfl <--[demonstrate of]--> term), Edge(fedconv <--[uses]--> computation overhead), Edge(all baseline <--[uses]--> computation overhead), Edge(lotteryfl <--[uses]--> computation overhead), Edge(fedconv <--[demonstrate of]--> federated client), Edge(all baseline <--[demonstrate of]--> federated client), Edge(lotteryfl <--[demonstrate of]--> federated client), Edge(we <--[uses]--> following key contribution), Edge(we <--[demonstrate of]--> our knowledge), Edge(this paradigm <--[compress]--> global model), Edge(this paradigm <--[compress]--> sub model), Edge(fedconv <--[handles]--> heterogeneous model), Edge(fedconv <--[handles]--> data distribution), Edge(all baseline <--[handles]--> heterogeneous model), Edge(all baseline <--[handles]--> data distribution), Edge(lotteryfl <--[handles]--> heterogeneous model), Edge(lotteryfl <--[handles]--> data distribution), Edge(fedconv <--[demonstrate of]--> new technology), Edge(all baseline <--[demonstrate of]--> new technology), Edge(lotteryfl <--[demonstrate of]--> new technology), Edge(we <--[uses]--> convolutional compression module), Edge(we <--[design]--> transposed convolutional dilation method), Edge(we <--[demonstrate of]--> flower), Edge(result <--[uses]--> superior performance), Edge(result <--[demonstrate of]--> fedconv), Edge(result <--[demonstrate of]--> all baseline), Edge(result <--[demonstrate of]--> lotteryfl), Edge(we <--[underscore]--> necessity), Edge(we <--[demonstrate of]--> model heterogeneity aware fl system), Edge(knowledge distillation based method <--[uses]--> heavy overhead), Edge(knowledge distillation based method <--[demonstrate of]--> client), Edge(knowledge distillation based method <--[uses]--> §), Edge(all client <--[share]--> same model architecture), Edge(all client <--[demonstrate of]--> practice), Edge(different client <--[have]--> diverse computation and communication resource), Edge(different client <--[demonstrate of]--> example), Edge(high end edge pc <--[have]--> more resource), Edge(low cost embedded system <--[have]--> much constrained resource), Edge(one size <--[fits]--> all), Edge(one size <--[demonstrate of]--> sub optimal performance), Edge(client <--[demonstrate of]--> more resource), Edge(client <--[share]--> different region), Edge(client <--[demonstrate of]--> global model), Edge(client <--[demonstrate of]--> sub model), Edge(we <--[trains]--> resnet18 model), Edge(we <--[trains]--> mi), Edge(we <--[demonstrate of]--> cifar10 dataset), Edge(smaller model <--[outperforms]--> larger model), Edge(smaller model <--[outperform due]--> model exposure), Edge(global model <--[exhibits]--> instability), Edge(sub model <--[exhibits]--> instability), Edge(global model <--[exhibits than]--> large model), Edge(global model <--[exhibits than]--> sub model), Edge(sub model <--[exhibits than]--> large model), Edge(sub model <--[exhibits than]--> sub model), Edge(this scheme <--[demonstrate of]--> imbalanced performance), Edge(this scheme <--[demonstrate of]--> unexpected performance degradation), Edge(scheme <--[uses]--> sub model), Edge(scheme <--[uses]--> global model), Edge(different client <--[uses]--> distinct part), Edge(aggregated parameter <--[uses]--> mixed window), Edge(aggregated parameter <--[demonstrate of]--> diverse sub model), Edge(channel level pruning <--[uses]--> some input channel), Edge(channel level pruning <--[demonstrate of]--> model parameter), Edge(filter level pruning <--[prunes]--> some output channel), Edge(these two scheme <--[demonstrate of]--> information loss), Edge(these two scheme <--[demonstrate of]--> imbalance issue), Edge(these two scheme <--[demonstrate of]--> performance degradation), Edge(scheme <--[discard]--> some input data channel), Edge(scheme <--[discard]--> feature map), Edge(we <--[applies]--> channel level and filter level pruning), Edge(we <--[demonstrate of]--> pre trained resnet18 model), Edge(we <--[uses]--> mutual information), Edge(which <--[uses]--> amount), Edge(which <--[demonstrate of]--> information), Edge(accuracy <--[demonstrate of]--> filter pruned model), Edge(this <--[uses]--> information loss), Edge(this <--[uses]--> imbalance issue), Edge(this <--[uses]--> performance degradation), Edge(this <--[outperform due]--> pruning), Edge(existing pruning based method <--[uses]--> server), Edge(existing pruning based method <--[uses]--> client), Edge(existing pruning based method <--[uses]--> heterogeneous client), Edge(which <--[uses]--> high communication and computation overhead), Edge(which <--[demonstrate of]--> client), Edge(compression method <--[uses]--> information loss), Edge(compression method <--[uses]--> imbalance issue), Edge(compression method <--[uses]--> performance degradation), Edge(compression method <--[demonstrate of]--> model parameter), Edge(we <--[uses]--> novel convolutional compression technique), Edge(sub model <--[inherit]--> spatial and hierarchical parameter pattern), Edge(global model <--[inherit]--> spatial and hierarchical parameter pattern), Edge(sub model <--[demonstrate of]--> global model), Edge(sub model <--[demonstrate of]--> sub model), Edge(global model <--[demonstrate of]--> global model), Edge(global model <--[demonstrate of]--> sub model), Edge(generated sub model <--[extract]--> valuable feature), Edge(generated sub model <--[demonstrate of]--> input data), Edge(figure reference <--[uses]--> convolution based compression process), Edge(compressed model <--[extract by]--> convolutional compression), Edge(compressed model <--[extract by]--> transposed convolutional dilation), Edge(compressed model <--[extract]--> feature), Edge(compressed model <--[demonstrate of]--> input data), Edge(we <--[compress]--> pre trained model), Edge(we <--[compress]--> channel pruned model), Edge(we <--[demonstrate of]--> §), Edge(we <--[uses]--> top4 and top3 feature map), Edge(we <--[demonstrate of]--> highest importance), Edge(first two feature map <--[demonstrate of]--> sub model), Edge(first two feature map <--[demonstrate of]--> global model), Edge(first two feature map <--[pay]--> more attention), Edge(map <--[demonstrate of]--> both body), Edge(map <--[demonstrate of]--> head), Edge(accuracy <--[demonstrate of]--> sub model), Edge(accuracy <--[demonstrate of]--> global model), Edge(our proposed convolutional compression method <--[uses]--> information loss), Edge(our proposed convolutional compression method <--[uses]--> imbalance issue), Edge(our proposed convolutional compression method <--[uses]--> performance degradation), Edge(our proposed convolutional compression method <--[minimize after]--> model compression), Edge(our proposed convolutional compression method <--[minimize after]--> dilation), Edge(we <--[uses]--> small publicly available dataset), Edge(we <--[demonstrate of]--> server), Edge(we <--[demonstrate of]--> client), Edge(we <--[demonstrate of]--> heterogeneous client), Edge(we <--[demonstrate of]--> conventional fl scheme), Edge(server <--[uses]--> comprehensive global view), Edge(client <--[uses]--> comprehensive global view), Edge(heterogeneous client <--[uses]--> comprehensive global view), Edge(server <--[demonstrate of]--> entire fl process), Edge(client <--[demonstrate of]--> entire fl process), Edge(heterogeneous client <--[demonstrate of]--> entire fl process), Edge(server <--[uses]--> global model), Edge(server <--[uses]--> sub model), Edge(client <--[uses]--> global model), Edge(client <--[uses]--> sub model), Edge(heterogeneous client <--[uses]--> global model), Edge(heterogeneous client <--[uses]--> sub model), Edge(server <--[demonstrate of]--> estimated memory requirement), Edge(client <--[demonstrate of]--> estimated memory requirement), Edge(heterogeneous client <--[demonstrate of]--> estimated memory requirement), Edge(server <--[trains]--> global model), Edge(server <--[trains]--> sub model), Edge(client <--[trains]--> global model), Edge(client <--[trains]--> sub model), Edge(heterogeneous client <--[trains]--> global model), Edge(heterogeneous client <--[trains]--> sub model), Edge(server <--[demonstrate of]--> several epoch), Edge(client <--[demonstrate of]--> several epoch), Edge(heterogeneous client <--[demonstrate of]--> several epoch), Edge(server <--[uses]--> heterogeneous sub model), Edge(client <--[uses]--> heterogeneous sub model), Edge(heterogeneous client <--[uses]--> heterogeneous sub model), Edge(server <--[demonstrate of]--> federated client), Edge(client <--[demonstrate of]--> federated client), Edge(heterogeneous client <--[demonstrate of]--> federated client), Edge(server <--[uses]--> ③), Edge(client <--[uses]--> ③), Edge(heterogeneous client <--[uses]--> ③), Edge(client <--[uses]--> several epoch), Edge(client <--[demonstrate of]--> local training), Edge(server <--[uses]--> weighted average aggregation), Edge(client <--[uses]--> weighted average aggregation), Edge(heterogeneous client <--[uses]--> weighted average aggregation), Edge(server <--[applies]--> weighted average aggregation), Edge(client <--[applies]--> weighted average aggregation), Edge(heterogeneous client <--[applies]--> weighted average aggregation), Edge(convolutional compression module <--[uses]--> set), Edge(convolutional compression module <--[demonstrate of]--> convolutional layer), Edge(compressed parameter <--[demonstrate of]--> sub model), Edge(compressed parameter <--[demonstrate of]--> global model), Edge(we <--[uses]--> server side data), Edge(sub model <--[uses]--> comparable performance), Edge(global model <--[uses]--> comparable performance), Edge(sub model <--[demonstrate of]--> global model), Edge(sub model <--[demonstrate of]--> sub model), Edge(global model <--[demonstrate of]--> global model), Edge(global model <--[demonstrate of]--> sub model), Edge(client <--[uses]--> client shrinkage ratio), Edge(server <--[broadcasts]--> size), Edge(server <--[broadcasts]--> resource budget), Edge(client <--[broadcasts]--> size), Edge(client <--[broadcasts]--> resource budget), Edge(heterogeneous client <--[broadcasts]--> size), Edge(heterogeneous client <--[broadcasts]--> resource budget), Edge(server <--[demonstrate of]--> global model), Edge(server <--[demonstrate of]--> sub model), Edge(client <--[demonstrate of]--> global model), Edge(client <--[demonstrate of]--> sub model), Edge(heterogeneous client <--[demonstrate of]--> global model), Edge(heterogeneous client <--[demonstrate of]--> sub model), Edge(each client <--[uses]--> appropriate sr), Edge(each client <--[uses]--> computing resource budget), Edge(no client side sensor data <--[demonstrate of]--> server), Edge(no client side sensor data <--[demonstrate of]--> client), Edge(no client side sensor data <--[demonstrate of]--> heterogeneous client), Edge(server <--[uses]--> corresponding configuration), Edge(client <--[uses]--> corresponding configuration), Edge(heterogeneous client <--[uses]--> corresponding configuration), Edge(size <--[demonstrate of]--> generated sub model), Edge(resource budget <--[demonstrate of]--> generated sub model), Edge(s <--[uses]--> convolution layer), Edge(s <--[demonstrate of]--> example), Edge(convolutional layer <--[skew in]--> global model), Edge(convolutional layer <--[skew in]--> sub model), Edge(convolutional layer <--[have]--> 16 input), Edge(convolutional layer <--[have]--> 32 output channel), Edge(we <--[reshape]--> unit parameter matrix), Edge(shape <--[demonstrate of]--> parameter matrix), Edge(we <--[uses]--> nine separate 2d convolutional layer), Edge(we <--[set]--> stride), Edge(we <--[set]--> padding), Edge(we <--[vary]--> stride padding value), Edge(we <--[vary]--> kernel size), Edge(sub model <--[have]--> same prediction task), Edge(global model <--[have]--> same prediction task), Edge(generated sub model <--[inherit]--> parameter information), Edge(generated sub model <--[demonstrate of]--> global model), Edge(generated sub model <--[demonstrate of]--> sub model), Edge(we <--[uses]--> formula), Edge(server <--[applies]--> compression layer), Edge(client <--[applies]--> compression layer), Edge(heterogeneous client <--[applies]--> compression layer), Edge(server <--[demonstrate of]--> global model parameter), Edge(server <--[demonstrate of]--> output), Edge(client <--[demonstrate of]--> global model parameter), Edge(client <--[demonstrate of]--> output), Edge(heterogeneous client <--[demonstrate of]--> global model parameter), Edge(heterogeneous client <--[demonstrate of]--> output), Edge(several practical challenge <--[emerge during]--> this compression process), Edge(we <--[uses]--> pre trained model), Edge(we <--[uses]--> channel pruned model), Edge(we <--[demonstrate of]--> mnist cite dataset), Edge(we <--[address]--> these challenge), Edge(we <--[address]--> progress), Edge(we <--[uses]--> two formula convolutional layer), Edge(we <--[demonstrate of]--> bias), Edge(first conv <--[uses]--> number), Edge(first conv <--[uses]--> learning rate), Edge(first conv <--[demonstrate of]--> output channel), Edge(second conv <--[uses]--> channel number), Edge(we <--[demonstrate of]--> global model parameter), Edge(we <--[demonstrate of]--> output), Edge(we <--[uses]--> formula), Edge(accuracy <--[demonstrate of]--> sub model), Edge(accuracy <--[demonstrate of]--> global model), Edge(parameter <--[skew in]--> sub model), Edge(parameter <--[skew in]--> global model), Edge(corresponding weight vector <--[skew in]--> sub model), Edge(corresponding weight vector <--[skew in]--> global model), Edge(dilated model <--[skew in]--> sub model), Edge(dilated model <--[skew in]--> global model), Edge(mlr <--[suppress]--> negative parameter), Edge(sub model parameter <--[exhibits]--> similar distribution pattern), Edge(sub model parameter <--[exhibits]--> value range), Edge(we <--[learn]--> significant performance fluctuation), Edge(we <--[demonstrate of]--> sub model), Edge(we <--[demonstrate of]--> global model), Edge(which <--[uses]--> sub model parameter), Edge(which <--[contain via]--> convolution process), Edge(performance <--[demonstrate of]--> sub model), Edge(performance <--[demonstrate of]--> global model), Edge(performance <--[exhibits]--> much higher sensitivity), Edge(performance <--[demonstrate of]--> change), Edge(we <--[applies]--> weight normalization), Edge(we <--[applies]--> learning rate scheduler), Edge(we <--[demonstrate of]--> convolution parameter), Edge(which <--[uses]--> convergence), Edge(which <--[demonstrate of]--> fine grained way), Edge(we <--[applies]--> cosine annealing learning rate scheduler), Edge(learning rate <--[undergoes]--> cosine function decay), Edge(accuracy <--[demonstrate of]--> sub model), Edge(accuracy <--[demonstrate of]--> global model), Edge(sub model <--[minimize after]--> around 20 epoch), Edge(global model <--[minimize after]--> around 20 epoch), Edge(compressed model <--[have]--> comparable performance), Edge(compressed model <--[demonstrate of]--> global model), Edge(compressed model <--[demonstrate of]--> sub model), Edge(server <--[uses]--> compressed parameter), Edge(client <--[uses]--> compressed parameter), Edge(heterogeneous client <--[uses]--> compressed parameter), Edge(server <--[demonstrate of]--> corresponding client), Edge(client <--[demonstrate of]--> corresponding client), Edge(heterogeneous client <--[demonstrate of]--> corresponding client), Edge(method <--[uses]--> significant computational and communication overhead), Edge(method <--[demonstrate of]--> client), Edge(we <--[uses]--> reverse operation), Edge(we <--[demonstrate of]--> convolution compression), Edge(we <--[applies]--> different tc layer), Edge(we <--[demonstrate of]--> each), Edge(convolutional layer <--[skew in]--> client model), Edge(convolutional layer <--[have]--> 12 input), Edge(convolutional layer <--[have]--> 24 output channel), Edge(we <--[set]--> parameter), Edge(we <--[set]--> corresponding weight vector), Edge(we <--[set]--> dilated model), Edge(we <--[demonstrate of]--> learnable variable), Edge([[[formula]]] <--[uses]--> tc parameter), Edge(formula <--[uses]--> tc operation), Edge(we <--[uses]--> two tc formula layer), Edge(we <--[demonstrate of]--> residual connection), Edge(server <--[aggregates]--> model), Edge(client <--[aggregates]--> model), Edge(heterogeneous client <--[aggregates]--> model), Edge(magnitude <--[demonstrate of]--> dilated model parameter), Edge(parameter <--[demonstrate of]--> dilated model), Edge(corresponding weight vector <--[demonstrate of]--> dilated model), Edge(dilated model <--[demonstrate of]--> dilated model), Edge(parameter <--[carry]--> personalized information), Edge(corresponding weight vector <--[carry]--> personalized information), Edge(dilated model <--[carry]--> personalized information), Edge(parameter <--[demonstrate of]--> different client), Edge(corresponding weight vector <--[demonstrate of]--> different client), Edge(dilated model <--[demonstrate of]--> different client), Edge(heterogeneous client <--[uses]--> that), Edge(heterogeneous client <--[demonstrate of]--> aggregation process), Edge(we <--[normalize]--> parameter), Edge(we <--[normalize]--> corresponding weight vector), Edge(we <--[normalize]--> dilated model), Edge(we <--[demonstrate of]--> all dilated model), Edge(we <--[uses]--> formula), Edge(we <--[contain via]--> gradient descent), Edge(we <--[uses]--> kullback leibler divergence), Edge(large model <--[uses]--> more contribution), Edge(sub model <--[uses]--> more contribution), Edge(large model <--[demonstrate of]--> aggregation), Edge(sub model <--[demonstrate of]--> aggregation), Edge(aggregated global model <--[uses]--> higher generalizability), Edge(aggregated global model <--[uses]--> more comprehensive global perspective), Edge(we <--[demonstrate of]--> pytorch), Edge(we <--[demonstrate of]--> flower), Edge(gradient <--[demonstrate of]--> convolution / tc parameter), Edge(gradient <--[demonstrate of]--> weight vector tuning), Edge(we <--[demonstrate of]--> cloud server), Edge(we <--[demonstrate of]--> router), Edge(we <--[uses]--> these edge device), Edge(we <--[demonstrate of]--> our office), Edge(we <--[demonstrate of]--> laboratory), Edge(we <--[uses]--> two representative mobile application), Edge(we <--[uses]--> three datasets), Edge(1 mnist <--[demonstrate of]--> 60000 formula gray scale image), Edge(we <--[uses]--> convolutional neural network), Edge(2 cifar10 <--[demonstrate of]--> 60000 32 formula), Edge(we <--[uses]--> resnet18), Edge(3 cinic10 <--[uses]--> 180000 32 formula 32 color image), Edge(3 cinic10 <--[demonstrate of]--> ten class), Edge(we <--[uses]--> googlenet), Edge(we <--[demonstrate of]--> evaluation), Edge(we <--[uses]--> three datasets), Edge(1 wiar <--[uses]--> 480 90 formula 250 wi fi csi sample), Edge(1 wiar <--[demonstrate of]--> 16 activity), Edge(we <--[uses]--> dataset), Edge(we <--[demonstrate of]--> 64000 sample), Edge(3 harbox <--[captures]--> 9 axis imu data), Edge(3 harbox <--[demonstrate of]--> five daily activity), Edge(we <--[uses]--> cnn model), Edge(we <--[demonstrate of]--> three conv layer), Edge(we <--[demonstrate of]--> one fc layer), Edge(we <--[divide]--> these datasets), Edge(we <--[divide into]--> four part), Edge(each part <--[demonstrate of]--> 5 %), Edge(each part <--[demonstrate of]--> 20 %), Edge(we <--[uses]--> different datasets), Edge(we <--[demonstrate of]--> server), Edge(we <--[demonstrate of]--> client), Edge(we <--[demonstrate of]--> heterogeneous client), Edge(we <--[uses]--> §), Edge(we <--[uses]--> fedconv), Edge(we <--[uses]--> all baseline), Edge(we <--[uses]--> lotteryfl), Edge(we <--[demonstrate of]--> following baseline), Edge(serveralone <--[trains]--> one model), Edge(serveralone <--[demonstrate of]--> only server side global data), Edge(we <--[uses]--> model), Edge(each client <--[trains]--> affordable model), Edge(client <--[trains]--> shared global model), Edge(we <--[uses]--> smallest affordable model), Edge(we <--[demonstrate of]--> all client), Edge(fedmd <--[uses]--> knowledge distillation), Edge(fedmd <--[uses]--> parameter sharing), Edge(5 lotteryfl <--[uses]--> sub model), Edge(5 lotteryfl <--[uses]--> global model), Edge(6 hermes <--[uses]--> sparse sub model), Edge(6 hermes <--[demonstrate of]--> each client), Edge(7 tailorfl <--[uses]--> sub model), Edge(7 tailorfl <--[uses]--> global model), Edge(7 tailorfl <--[extract by]--> filter level pruning), Edge(each client <--[uses]--> subset), Edge(each client <--[demonstrate of]--> parameter), Edge(each client <--[demonstrate of]--> corresponding weight vector), Edge(each client <--[demonstrate of]--> dilated model), Edge(9 fedrolex <--[uses]--> dynamic rolling window), Edge(we <--[uses]--> four sr), Edge(we <--[demonstrate of]--> resource profile), Edge(we <--[uses]--> larger sr), Edge(we <--[demonstrate of]--> laptop), Edge(we <--[uses]--> smaller sr), Edge(we <--[demonstrate of]--> raspberry pi), Edge(we <--[sample]--> disjoint non iid client side data), Edge(we <--[sample]--> formula), Edge(we <--[set]--> number), Edge(we <--[set]--> learning rate), Edge(we <--[demonstrate of]--> communication round), Edge(each client <--[uses]--> 5 local training epoch), Edge(each client <--[demonstrate of]--> learning rate), Edge(we <--[uses]--> global model accuracy), Edge(we <--[uses]--> all baseline), Edge(we <--[demonstrate of]--> server side test dataset), Edge(we <--[report]--> average client model accuracy), Edge(we <--[demonstrate of]--> client side private test datasets), Edge(we <--[uses]--> pympler library), Edge(we <--[track]--> each client s process id), Edge(we <--[track over]--> 100 communication round), Edge(we <--[uses]--> execution time), Edge(we <--[demonstrate of]--> each client), Edge(we <--[uses]--> overall performance), Edge(we <--[demonstrate of]--> fedconv), Edge(we <--[demonstrate of]--> all baseline), Edge(we <--[demonstrate of]--> lotteryfl), Edge(we <--[uses]--> accuracy), Edge(we <--[demonstrate of]--> aggregated global model), Edge(standalone fedmd <--[uses]--> global model), Edge(standalone fedmd <--[uses]--> sub model), Edge(figure reference <--[uses]--> global model accuracy), Edge(figure reference <--[uses]--> all baseline), Edge(figure reference <--[demonstrate of]--> same degree), Edge(serveralone <--[uses]--> higher global model accuracy), Edge(serveralone <--[exhibits than]--> baseline), Edge(serveralone <--[exhibits than]--> fedconv), Edge(fedconv <--[uses]--> average improvement), Edge(all baseline <--[uses]--> average improvement), Edge(lotteryfl <--[uses]--> average improvement), Edge(fedconv <--[demonstrate of]--> 205 %), Edge(fedconv <--[demonstrate of]--> 138 %), Edge(all baseline <--[demonstrate of]--> 205 %), Edge(all baseline <--[demonstrate of]--> 138 %), Edge(lotteryfl <--[demonstrate of]--> 205 %), Edge(lotteryfl <--[demonstrate of]--> 138 %), Edge(client model <--[have]--> insufficient number), Edge(client model <--[demonstrate of]--> parameter), Edge(client model <--[demonstrate of]--> corresponding weight vector), Edge(client model <--[demonstrate of]--> dilated model), Edge(fedconv <--[outperforms]--> fedavg), Edge(fedconv <--[outperforms]--> lotteryfl), Edge(all baseline <--[outperforms]--> fedavg), Edge(all baseline <--[outperforms]--> lotteryfl), Edge(lotteryfl <--[outperforms]--> fedavg), Edge(lotteryfl <--[outperforms]--> lotteryfl), Edge(fedconv <--[demonstrate of]--> iid data), Edge(all baseline <--[demonstrate of]--> iid data), Edge(lotteryfl <--[demonstrate of]--> iid data), Edge(this <--[uses]--> superior generalization performance), Edge(this <--[demonstrate of]--> fedconv), Edge(this <--[demonstrate of]--> all baseline), Edge(this <--[demonstrate of]--> lotteryfl), Edge(figure reference <--[demonstrate of]--> fedconv), Edge(figure reference <--[demonstrate of]--> all baseline), Edge(figure reference <--[demonstrate of]--> lotteryfl), Edge(performance enhancement <--[demonstrate of]--> fedconv), Edge(performance enhancement <--[demonstrate of]--> all baseline), Edge(performance enhancement <--[demonstrate of]--> lotteryfl), Edge(fedconv <--[demonstrate of]--> increased data heterogeneity), Edge(all baseline <--[demonstrate of]--> increased data heterogeneity), Edge(lotteryfl <--[demonstrate of]--> increased data heterogeneity), Edge(fedconv <--[demonstrate of]--> homogeneous data), Edge(all baseline <--[demonstrate of]--> homogeneous data), Edge(lotteryfl <--[demonstrate of]--> homogeneous data), Edge(fedconv <--[exhibits]--> better generalizability), Edge(fedconv <--[exhibits]--> robustness), Edge(all baseline <--[exhibits]--> better generalizability), Edge(all baseline <--[exhibits]--> robustness), Edge(lotteryfl <--[exhibits]--> better generalizability), Edge(lotteryfl <--[exhibits]--> robustness), Edge(fedconv <--[uses]--> better personalization performance), Edge(all baseline <--[uses]--> better personalization performance), Edge(lotteryfl <--[uses]--> better personalization performance), Edge(fedconv <--[demonstrate of]--> client), Edge(all baseline <--[demonstrate of]--> client), Edge(lotteryfl <--[demonstrate of]--> client), Edge(performance improvement <--[demonstrate of]--> global model), Edge(performance improvement <--[demonstrate of]--> sub model), Edge(we <--[uses]--> accuracy), Edge(we <--[demonstrate of]--> each client model), Edge(figure reference <--[demonstrate of]--> same heterogeneous data setting), Edge(fedconv <--[outperforms]--> baseline), Edge(fedconv <--[outperforms]--> fedconv), Edge(all baseline <--[outperforms]--> baseline), Edge(all baseline <--[outperforms]--> fedconv), Edge(lotteryfl <--[outperforms]--> baseline), Edge(lotteryfl <--[outperforms]--> fedconv), Edge(accuracy <--[demonstrate of]--> client model), Edge(server side data <--[occupies]--> small portion), Edge(serveralone s global model <--[have]--> sufficient data), Edge(serveralone s global model <--[demonstrate of]--> degraded performance), Edge(serveralone s global model <--[demonstrate of]--> longer convergence time), Edge(figure reference <--[uses]--> client model accuracy), Edge(this performance gain <--[demonstrate of]--> tc dilation process), Edge(rescaled large model <--[uses]--> personalization information), Edge(rescaled large model <--[demonstrate of]--> client), Edge(figure reference <--[demonstrate of]--> sensing heterogeneity), Edge(fedconv <--[uses]--> better and more stable performance), Edge(all baseline <--[uses]--> better and more stable performance), Edge(lotteryfl <--[uses]--> better and more stable performance), Edge(fedconv <--[demonstrate of]--> cifar10), Edge(fedconv <--[demonstrate of]--> cinic10), Edge(fedconv <--[demonstrate of]--> harbox), Edge(all baseline <--[demonstrate of]--> cifar10), Edge(all baseline <--[demonstrate of]--> cinic10), Edge(all baseline <--[demonstrate of]--> harbox), Edge(lotteryfl <--[demonstrate of]--> cifar10), Edge(lotteryfl <--[demonstrate of]--> cinic10), Edge(lotteryfl <--[demonstrate of]--> harbox), Edge(better performance <--[demonstrate of]--> distilled knowledge), Edge(downside <--[uses]--> excessive communication), Edge(downside <--[uses]--> computational overhead), Edge(fedconv <--[uses]--> comparable personalization performance), Edge(all baseline <--[uses]--> comparable personalization performance), Edge(lotteryfl <--[uses]--> comparable personalization performance), Edge(fedconv <--[minimize after]--> extra burden), Edge(all baseline <--[minimize after]--> extra burden), Edge(lotteryfl <--[minimize after]--> extra burden), Edge(we <--[uses]--> personalization performance), Edge(fedconv <--[exhibits]--> significant performance gain), Edge(all baseline <--[exhibits]--> significant performance gain), Edge(lotteryfl <--[exhibits]--> significant performance gain), Edge(fedconv <--[demonstrate of]--> both global and client model), Edge(all baseline <--[demonstrate of]--> both global and client model), Edge(lotteryfl <--[demonstrate of]--> both global and client model), Edge(we <--[uses]--> memory footprint), Edge(we <--[uses]--> wall clock time), Edge(we <--[uses]--> baseline), Edge(table <--[uses]--> overview), Edge(table <--[demonstrate of]--> average memory usage), Edge(table <--[demonstrate of]--> average wall clock time), Edge(fedconv <--[uses]--> average saving), Edge(all baseline <--[uses]--> average saving), Edge(lotteryfl <--[uses]--> average saving), Edge(fedconv <--[demonstrate of]--> 406 %), Edge(fedconv <--[demonstrate of]--> 546 %), Edge(all baseline <--[demonstrate of]--> 406 %), Edge(all baseline <--[demonstrate of]--> 546 %), Edge(lotteryfl <--[demonstrate of]--> 406 %), Edge(lotteryfl <--[demonstrate of]--> 546 %), Edge(fedconv <--[needs]--> approximately half), Edge(all baseline <--[needs]--> approximately half), Edge(lotteryfl <--[needs]--> approximately half), Edge(fedconv <--[demonstrate of]--> memory and training time), Edge(all baseline <--[demonstrate of]--> memory and training time), Edge(lotteryfl <--[demonstrate of]--> memory and training time), Edge(fedconv <--[needs]--> 2 gb less memory), Edge(all baseline <--[needs]--> 2 gb less memory), Edge(lotteryfl <--[needs]--> 2 gb less memory), Edge(client <--[demonstrate of]--> fedconv), Edge(client <--[demonstrate of]--> all baseline), Edge(client <--[demonstrate of]--> lotteryfl), Edge(fedavg <--[uses]--> less memory), Edge(fedavg <--[uses]--> wall clock time), Edge(lotteryfl <--[uses]--> less memory), Edge(lotteryfl <--[uses]--> wall clock time), Edge(table <--[lists]--> total size), Edge(table <--[demonstrate of]--> data packet), Edge(fedconv lotteryfl heterofl <--[transmit]--> sub model parameter), Edge(fedconv lotteryfl heterofl <--[minimize after]--> extra content), Edge(heterofl <--[holds]--> significant potential), Edge(fedrolex <--[holds]--> significant potential), Edge(fedconv <--[uses]--> more system resource), Edge(all baseline <--[uses]--> more system resource), Edge(lotteryfl <--[uses]--> more system resource), Edge(we <--[simulate]--> 100 client), Edge(client model accuracy <--[demonstrate of]--> fedconv), Edge(client model accuracy <--[demonstrate of]--> all baseline), Edge(client model accuracy <--[demonstrate of]--> lotteryfl), Edge(client model accuracy <--[exhibits]--> upward trend), Edge(number <--[demonstrate of]--> client), Edge(learning rate <--[demonstrate of]--> client), Edge(client model accuracy <--[demonstrate of]--> harbox), Edge(we <--[uses]--> cifar10), Edge(we <--[uses]--> cinic10), Edge(we <--[uses]--> harbox), Edge(fedconv <--[uses]--> average client model accuracy), Edge(all baseline <--[uses]--> average client model accuracy), Edge(lotteryfl <--[uses]--> average client model accuracy), Edge(result <--[uses]--> scalability), Edge(result <--[uses]--> superiority), Edge(we <--[set]--> sr), Edge(we <--[set]--> model performance), Edge(we <--[demonstrate of]--> 10 client), Edge(we <--[vary]--> formula), Edge(sr <--[decreases below]--> certain threshold), Edge(model performance <--[decreases below]--> certain threshold), Edge(even lightweight device <--[pay]--> googlenet model), Edge(even lightweight device <--[demonstrate of]--> cinic10), Edge(even lightweight device <--[demonstrate of]--> harbox), Edge(sr <--[decreases below]--> corresponding threshold), Edge(model performance <--[decreases below]--> corresponding threshold), Edge(we <--[uses]--> cifar10), Edge(we <--[uses]--> cinic10), Edge(we <--[uses]--> harbox), Edge(accuracy <--[demonstrate of]--> fedconv), Edge(accuracy <--[demonstrate of]--> all baseline), Edge(accuracy <--[demonstrate of]--> lotteryfl), Edge(accuracy <--[uses]--> much higher accuracy), Edge(accuracy <--[exhibits than]--> baseline), Edge(accuracy <--[exhibits than]--> fedconv), Edge(baseline <--[discard]--> larger amount), Edge(fedconv <--[discard]--> larger amount), Edge(baseline <--[demonstrate of]--> parameter information), Edge(fedconv <--[demonstrate of]--> parameter information), Edge(fedconv <--[uses]--> parameter information), Edge(all baseline <--[uses]--> parameter information), Edge(lotteryfl <--[uses]--> parameter information), Edge(fedconv <--[demonstrate of]--> global model), Edge(fedconv <--[demonstrate of]--> sub model), Edge(all baseline <--[demonstrate of]--> global model), Edge(all baseline <--[demonstrate of]--> sub model), Edge(lotteryfl <--[demonstrate of]--> global model), Edge(lotteryfl <--[demonstrate of]--> sub model), Edge(we <--[vary]--> sample number ratio), Edge(we <--[demonstrate of]--> server side data), Edge(we <--[uses]--> two key observation), Edge(ratio <--[demonstrate of]--> server side data), Edge(client model <--[have]--> better performance), Edge(client model <--[have due]--> richer information), Edge(global model <--[demonstrate of]--> server side data), Edge(sub model <--[demonstrate of]--> server side data), Edge(we <--[set]--> default sample ratio), Edge(we <--[demonstrate of]--> server side data), Edge(actual turning point <--[demonstrate of]--> practice), Edge(we <--[vary]--> number), Edge(we <--[vary]--> learning rate), Edge(we <--[demonstrate of]--> epoch), Edge(we <--[uses]--> two datasets), Edge(client model <--[uses]--> better and more stable performance), Edge(client model <--[minimize after]--> 20 th and 40 th epoch), Edge(number <--[demonstrate of]--> tuning epoch), Edge(learning rate <--[demonstrate of]--> tuning epoch), Edge(accuracy <--[demonstrate of]--> aggregated global model), Edge(we <--[demonstrate of]--> epoch), Edge(we <--[vary]--> stride length), Edge(we <--[vary]--> stride), Edge(we <--[uses]--> convolutional layer), Edge(we <--[demonstrate of]--> large model), Edge(we <--[demonstrate of]--> sub model), Edge(whose parameter matrix <--[have]--> shape), Edge(whose parameter matrix <--[skew in]--> formula), Edge(compressed parameter matrix <--[have]--> shape), Edge(compressed parameter matrix <--[demonstrate of]--> formula), Edge(kernel size <--[needs]--> formula), Edge(stride length <--[needs]--> formula), Edge(stride <--[needs]--> formula), Edge(larger kernel <--[captures]--> more comprehensive parameter information), Edge(smaller stride <--[captures]--> more fine grained information), Edge(smaller stride <--[demonstrate of]--> figure reference), Edge(larger kernel <--[uses]--> high computational complexity), Edge(we <--[conduct]--> ablation study), Edge(figure reference <--[uses]--> impact), Edge(figure reference <--[demonstrate of]--> global model accuracy), Edge(figure reference <--[demonstrate of]--> all baseline), Edge(global model <--[uses]--> higher average accuracy), Edge(sub model <--[uses]--> higher average accuracy), Edge(fl server <--[uses]--> communication computation and energy cost), Edge(client <--[uses]--> communication computation and energy cost), Edge(fl server <--[demonstrate of]--> training process), Edge(client <--[demonstrate of]--> training process), Edge(we <--[uses]--> weight), Edge(we <--[demonstrate of]--> respect), Edge(figure reference <--[uses]--> effect), Edge(parameter <--[demonstrate of]--> heterogeneous client model), Edge(corresponding weight vector <--[demonstrate of]--> heterogeneous client model), Edge(dilated model <--[demonstrate of]--> heterogeneous client model), Edge(parameter <--[exhibits]--> varying skewness), Edge(corresponding weight vector <--[exhibits]--> varying skewness), Edge(dilated model <--[exhibits]--> varying skewness), Edge(parameter <--[demonstrate of]--> parameter local data distribution), Edge(corresponding weight vector <--[demonstrate of]--> parameter local data distribution), Edge(dilated model <--[demonstrate of]--> parameter local data distribution), Edge(client <--[uses]--> different parameter information), Edge(client <--[demonstrate of]--> aggregated global model), Edge(we <--[uses]--> fedconv), Edge(we <--[uses]--> all baseline), Edge(we <--[uses]--> lotteryfl), Edge(each client <--[uses]--> client own personal layer), Edge(each client <--[demonstrate of]--> sub model), Edge(each client <--[demonstrate of]--> global model), Edge(we <--[track]--> average accuracy), Edge(we <--[demonstrate of]--> client model), Edge(figure reference <--[uses]--> performance improvement), Edge(figure reference <--[demonstrate of]--> five datasets), Edge(which <--[uses]--> highest client model accuracy), Edge(which <--[uses]--> §), Edge(both server side and client side datasets <--[demonstrate of]--> same domain), Edge(we <--[conduct]--> case study), Edge(chars74 k dataset <--[uses]--> image), Edge(chars74 k dataset <--[demonstrate of]--> digit), Edge(heterogeneous client <--[tune]--> compressed model), Edge(generated sub model <--[contain via]--> convolutional compression), Edge(generated sub model <--[contain via]--> transposed convolutional dilation), Edge(generated sub model <--[uses]--> parameter information), Edge(generated sub model <--[demonstrate of]--> large global model), Edge(server <--[applies]--> tc), Edge(client <--[applies]--> tc), Edge(heterogeneous client <--[applies]--> tc), Edge(server <--[demonstrate of]--> locally trained heterogeneous client model), Edge(client <--[demonstrate of]--> locally trained heterogeneous client model), Edge(heterogeneous client <--[demonstrate of]--> locally trained heterogeneous client model), Edge(this <--[uses]--> aggregation process), Edge(fedmd <--[uses]--> comparable performance), Edge(fedmd <--[demonstrate of]--> fedconv), Edge(fedmd <--[demonstrate of]--> all baseline), Edge(fedmd <--[demonstrate of]--> lotteryfl), Edge(we <--[uses]--> fedconv), Edge(we <--[uses]--> all baseline), Edge(we <--[uses]--> lotteryfl), Edge(we <--[demonstrate of]--> transfer learning strategy), Edge(client model <--[uses]--> higher accuracy), Edge(fedconv <--[uses]--> all client), Edge(all baseline <--[uses]--> all client), Edge(lotteryfl <--[uses]--> all client), Edge(client <--[uses]--> resource profiling), Edge(client <--[demonstrate of]--> server), Edge(client <--[demonstrate of]--> client), Edge(client <--[demonstrate of]--> heterogeneous client), Edge(we <--[uses]--> flower cite framework), Edge(flower <--[uses]--> stable and robust simulated environment), Edge(flower <--[demonstrate of]--> fl), Edge(these <--[uses]--> technical challenge), Edge(these <--[uses]--> issue), Edge(recent advancement <--[demonstrate of]--> flower), Edge(recent advancement <--[support]--> federated learning setup), Edge(recent advancement <--[demonstrate of]--> android client), Edge(client <--[demonstrate of]--> pre training and fine tuning process), Edge(clusterfl <--[captures]--> intrinsic clustering pattern), Edge(clusterfl <--[captures among]--> client), Edge(personalized fl <--[uses]--> local fine tuning), Edge(pfedme <--[uses]--> moreau envelope), Edge(pfedme <--[demonstrate of]--> regularized loss function), Edge(lower layer <--[captures]--> more general feature), Edge(recent work <--[compress]--> global model), Edge(recent work <--[compress]--> sub model), Edge(fedmd <--[uses]--> average consensus), Edge(sub model <--[share]--> part), Edge(global model <--[share]--> part), Edge(sub model <--[demonstrate of]--> global model parameter), Edge(sub model <--[demonstrate of]--> output), Edge(global model <--[demonstrate of]--> global model parameter), Edge(global model <--[demonstrate of]--> output), Edge(sharing strategy <--[demonstrate of]--> imbalance issue), Edge(3 pruning based method <--[uses]--> popularity), Edge(3 pruning based method <--[demonstrate of]--> heterogeneous fl), Edge(hermes <--[applies]--> channel level pruning method), Edge(tailorfl <--[applies]--> channel level pruning method), Edge(tailorfl <--[uses]--> importance value based filter level pruning scheme), Edge(heterofl <--[uses]--> importance value based filter level pruning scheme), Edge(we <--[compress]--> global model), Edge(we <--[compress]--> sub model), Edge(we <--[demonstrate of]--> convolutional compression), Edge(we <--[demonstrate of]--> transposed convolutional dilation), Edge(these work <--[uses]--> system overhead), Edge(these work <--[demonstrate of]--> client), Edge(convolution <--[extract]--> useful feature), Edge(transposed convolution <--[extract]--> useful feature), Edge(convolution <--[demonstrate of]--> input data), Edge(transposed convolution <--[demonstrate of]--> input data), Edge(we <--[exploit]--> novel convolutional compression technique), Edge(which <--[captures]--> key information), Edge(which <--[demonstrate of]--> global model), Edge(which <--[demonstrate of]--> sub model), Edge(we <--[uses]--> tc), Edge(fedconv <--[uses]--> three key technical module), Edge(all baseline <--[uses]--> three key technical module), Edge(lotteryfl <--[uses]--> three key technical module), Edge(fedconv <--[outperforms]--> sota baseline), Edge(all baseline <--[outperforms]--> sota baseline), Edge(lotteryfl <--[outperforms]--> sota baseline), Edge(we <--[demonstrate of]--> model), Edge(heterogeneous model <--[with]--> different size), Edge(data distribution <--[with]--> different size), Edge(global model <--[for]--> aggregation), Edge(sub model <--[for]--> aggregation), Edge(different region <--[of]--> global model), Edge(small portion <--[of]--> dataset), Edge(removal <--[of]--> entire channel), Edge(overhead <--[of]--> client), Edge(information <--[of]--> global model), Edge(client friendly fl framework <--[for]--> heterogeneous model), Edge(parameter <--[of]--> diverse sub model), Edge(corresponding weight vector <--[of]--> diverse sub model), Edge(dilated model <--[of]--> diverse sub model), Edge(same size <--[as]--> global model), Edge(small dataset <--[of]--> server), Edge(parameter <--[of]--> heterogeneous sub model), Edge(corresponding weight vector <--[of]--> heterogeneous sub model), Edge(dilated model <--[of]--> heterogeneous sub model), Edge(set <--[of]--> dilated model), Edge(transfer <--[of]--> personalized information), Edge(transfer <--[from]--> client model), Edge(transfer <--[to]--> dilated model), Edge(imbalanced contribution <--[of]--> heterogeneous federated client), Edge(different learnable weight vector <--[for]--> dilated model), Edge(relative importance <--[of]--> each model), Edge(user friendly fl framework <--[with]--> two representative fl task), Edge(term <--[of]--> inference accuracy), Edge(inference accuracy <--[by]--> more than 35 %), Edge(computation overhead <--[for]--> federated client), Edge(model <--[with]--> uniform size), Edge(client contribution <--[for]--> final aggregation), Edge(superior performance <--[of]--> fedconv), Edge(superior performance <--[of]--> term), Edge(term <--[of]--> both inference accuracy), Edge(necessity <--[of]--> model heterogeneity aware fl system), Edge(heavy overhead <--[of]--> client), Edge(size <--[of]--> global model), Edge(resource budget <--[of]--> global model), Edge(client <--[with]--> least system resource), Edge(client <--[of]--> conventional fl), Edge(client <--[with]--> more resource), Edge(weaker client <--[of]--> synchronized fl), Edge(full use <--[of]--> more powerful client), Edge(heterogeneous model <--[with]--> varied parameter size), Edge(data distribution <--[with]--> varied parameter size), Edge(all client <--[with]--> diverse resource), Edge(problem <--[of]--> parameter sharing), Edge(overlapped part <--[from]--> different size), Edge(different size <--[of]--> model), Edge(information <--[from]--> other client), Edge(model exposure <--[to]--> larger volume), Edge(larger volume <--[of]--> data), Edge(imbalanced performance <--[among]--> client), Edge(unexpected performance degradation <--[among]--> client), Edge(different part <--[of]--> global model s parameter), Edge(mixed window <--[from]--> diverse sub model), Edge(distribution <--[of]--> global model s parameter), Edge(client workload <--[of]--> model pruning), Edge(corresponding channel <--[of]--> input data), Edge(certain weight <--[of]--> model parameter), Edge(connection <--[of]--> model parameter), Edge(amount <--[of]--> information), Edge(mi <--[between]--> parameter), Edge(parameter <--[of]--> resnet18 model), Edge(corresponding weight vector <--[of]--> resnet18 model), Edge(dilated model <--[of]--> resnet18 model), Edge(parameter <--[of]--> pre trained model), Edge(corresponding weight vector <--[of]--> pre trained model), Edge(dilated model <--[of]--> pre trained model), Edge(accuracy drop <--[from]--> 8404 %), Edge(accuracy drop <--[to]--> 7336 %), Edge(accuracy <--[of]--> filter pruned model), Edge(information loss <--[due]--> pruning), Edge(imbalance issue <--[due]--> pruning), Edge(performance degradation <--[due]--> pruning), Edge(all parameter <--[of]--> global model), Edge(information loss <--[of]--> model parameter), Edge(imbalance issue <--[of]--> model parameter), Edge(performance degradation <--[of]--> model parameter), Edge(crucial information <--[of]--> global model), Edge(shrinkage ratio <--[of]--> 075), Edge(top4 and top3 feature map <--[with]--> highest importance), Edge(first two feature map <--[from]--> sub model), Edge(fusion <--[of]--> last two feature map), Edge(last two feature map <--[from]--> large model), Edge(both body <--[of]--> deer), Edge(head <--[of]--> deer), Edge(feature extraction capability <--[of]--> large model), Edge(accuracy <--[of]--> sub model), Edge(mutual information <--[between]--> parameter), Edge(parameter <--[of]--> large model), Edge(corresponding weight vector <--[of]--> large model), Edge(dilated model <--[of]--> large model), Edge(iterative refining <--[of]--> compression process), Edge(architecture <--[of]--> fedconv), Edge(global model <--[with]--> estimated memory requirement), Edge(sub model <--[with]--> estimated memory requirement), Edge(set <--[of]--> shrinkage ratio), Edge(better global view <--[of]--> data distribution), Edge(set <--[of]--> fine tuned convolution parameter), Edge(several epoch <--[of]--> local training), Edge(set <--[of]--> large model), Edge(set <--[of]--> convolutional layer), Edge(compressed parameter <--[of]--> sub model), Edge(i e parameter <--[of]--> compression layer), Edge(comparable performance <--[to]--> global model), Edge(local data <--[for]--> personalization), Edge(size <--[of]--> sub model), Edge(resource budget <--[of]--> sub model), Edge(size <--[of]--> generated sub model), Edge(resource budget <--[of]--> generated sub model), Edge(convolutional layer <--[of]--> global model), Edge(16 input <--[with]--> kernel size), Edge(32 output channel <--[with]--> kernel size), Edge(each element <--[of]--> kernel), Edge(shape <--[of]--> parameter matrix), Edge(other type <--[of]--> layer), Edge(input channel <--[of]--> first layer), Edge(all channel <--[of]--> raw data), Edge(output channel <--[of]--> last layer), Edge(loss <--[between]--> ground truth), Edge(prediction result <--[of]--> compressed model), Edge(forward function <--[of]--> compressed model), Edge(data <--[of]--> server side data), Edge(corresponding label <--[of]--> server side data), Edge(parameter <--[of]--> [[[formula th layer]]]), Edge(corresponding weight vector <--[of]--> [[[formula th layer]]]), Edge(dilated model <--[of]--> [[[formula th layer]]]), Edge([[[formula th layer]]] <--[of]--> global model), Edge(i e parameter <--[of]--> global model), Edge(parameter <--[of]--> compression layer), Edge(corresponding weight vector <--[of]--> compression layer), Edge(dilated model <--[of]--> compression layer), Edge(loss <--[between]--> sub model output), Edge(pre trained model <--[of]--> mnist cite dataset), Edge(channel pruned model <--[of]--> mnist cite dataset), Edge(accuracy <--[of]--> 9904 %), Edge(amount <--[of]--> parameter information), Edge(parameter information <--[of]--> sub model), Edge(parameter <--[of]--> global model), Edge(corresponding weight vector <--[of]--> global model), Edge(dilated model <--[of]--> global model), Edge(limited capability <--[of]--> simple compression layer), Edge(lower accuracy <--[of]--> sub model), Edge(two formula convolutional layer <--[with]--> bias), Edge(bias <--[before]--> compression), Edge(number <--[of]--> output channel), Edge(learning rate <--[of]--> output channel), Edge(residual connection <--[between]--> global model parameter), Edge(output <--[of]--> second conv), Edge(transfer <--[of]--> parameter information), Edge(transfer <--[from]--> global model), Edge(transfer <--[to]--> sub model), Edge(distribution <--[of]--> parameter), Edge(parameter <--[of]--> sub model), Edge(corresponding weight vector <--[of]--> sub model), Edge(dilated model <--[of]--> sub model), Edge(slope <--[for]--> negative and positive value), Edge(similar distribution pattern <--[to]--> global model), Edge(value range <--[to]--> global model), Edge(significant performance fluctuation <--[of]--> sub model), Edge(performance <--[of]--> sub model), Edge(much higher sensitivity <--[to]--> change), Edge(change <--[of]--> convolution parameter), Edge(lower and upper bound <--[of]--> learning rate), Edge(maximum number <--[of]--> iteration), Edge(reverse operation <--[to]--> convolution compression), Edge(non iid data <--[with]--> different sensing heterogeneity), Edge(i e parameter <--[of]--> tc layer), Edge(heterogeneous model <--[from]--> different client), Edge(data distribution <--[from]--> different client), Edge(configuration <--[of]--> each tc layer), Edge(configuration <--[for]--> dilation), Edge(convolutional layer <--[of]--> client model), Edge(sr <--[as]--> 075), Edge(model performance <--[as]--> 075), Edge(configuration <--[of]--> tc layer), Edge(other kind <--[of]--> network layer), Edge(input channel number <--[of]--> first layer), Edge(output channel number <--[of]--> first layer), Edge(output channel number <--[of]--> last layer), Edge(input channel number <--[of]--> all client model), Edge(output channel number <--[of]--> all client model), Edge(prediction result <--[of]--> dilated large model), Edge(forward function <--[of]--> dilated large model), Edge(parameter <--[of]--> client model), Edge(corresponding weight vector <--[of]--> client model), Edge(dilated model <--[of]--> client model), Edge(integration <--[of]--> personalized information), Edge(integration <--[from]--> dilated model), Edge(two tc formula layer <--[with]--> residual connection), Edge(set <--[of]--> dilated large model), Edge(parameter <--[of]--> all dilated model), Edge(corresponding weight vector <--[of]--> all dilated model), Edge(dilated model <--[of]--> all dilated model), Edge(accuracy <--[of]--> aggregated model), Edge(only 476 % <--[of]--> mnist dataset), Edge(magnitude <--[of]--> dilated model parameter), Edge(parameter <--[of]--> dilated model), Edge(corresponding weight vector <--[of]--> dilated model), Edge(dilated model <--[of]--> dilated model), Edge(parameter <--[from]--> tc operation), Edge(corresponding weight vector <--[from]--> tc operation), Edge(dilated model <--[from]--> tc operation), Edge(personalized information <--[from]--> different client), Edge(varying skewness <--[toward]--> client side data distribution), Edge(diverse personalized information <--[from]--> dilated model), Edge(every network layer <--[of]--> each dilated model), Edge(parameter <--[of]--> [[[formula th aggregated network layer]]]), Edge(corresponding weight vector <--[of]--> [[[formula th aggregated network layer]]]), Edge(dilated model <--[of]--> [[[formula th aggregated network layer]]]), Edge(number <--[of]--> large model), Edge(learning rate <--[of]--> large model), Edge([[[formula th layer]]] <--[of]--> [[[formula th large model]]]), Edge(number <--[of]--> data sample), Edge(learning rate <--[of]--> data sample), Edge(different contribution <--[of]--> heterogeneous client), Edge(similarity <--[between]--> parameter), Edge(kld <--[for]--> th dilated model), Edge(global model parameter <--[from]--> previous communication round), Edge(output <--[from]--> previous communication round), Edge(optimization <--[of]--> weight vector), Edge(cross entropy loss <--[for]--> model output), Edge(coefficient <--[for]--> balance), Edge(load_state_dict function <--[of]--> pytorch), Edge(20 heterogeneous mobile device <--[with]--> different hardware and network condition), Edge(detailed configuration <--[of]--> heterogeneous device), Edge(popular computer vision application <--[for]--> fl), Edge(60000 formula gray scale image <--[of]--> ten handwritten digit), Edge(convolutional neural network <--[with]--> two convolutional layer), Edge(32 color image <--[of]--> ten class), Edge(180000 32 formula 32 color image <--[of]--> ten class), Edge(different type <--[of]--> sensor data), Edge(channel state information <--[of]--> sensor data), Edge(channel state information <--[of]--> wifi signal), Edge(480 90 formula 250 wi fi csi sample <--[of]--> 16 activity), Edge(5000 36 formula 36 gray scale depth image <--[of]--> five common gesture), Edge(9 axis imu data <--[of]--> five daily activity), Edge(sliding window <--[of]--> 2 second), Edge(900 dimensional feature <--[for]--> each), Edge(121 user <--[with]--> 77 different smartphones), Edge(degree <--[of]--> sensing heterogeneity), Edge(no standard model <--[for]--> these datasets), Edge(cnn model <--[with]--> three conv layer), Edge(1 iid server side global data <--[for]--> convolution / tc parameter), Edge(2 iid test data <--[for]--> convolution / tc parameter), Edge(5 % <--[of]--> total dataset), Edge(20 % <--[of]--> total dataset), Edge(first and second part <--[of]--> dataset), Edge(constrained resource <--[of]--> some device), Edge(consensus <--[among]--> heterogeneous client model), Edge(sparse sub model <--[for]--> each client), Edge(learned importance value <--[of]--> each filter), Edge(subset <--[of]--> parameter), Edge(sub model <--[for]--> heterogeneous client), Edge(global model <--[for]--> heterogeneous client), Edge(resource profile <--[of]--> heterogeneous client), Edge(sr <--[for]--> each client), Edge(model performance <--[for]--> each client), Edge(sample distribution <--[among]--> different class), Edge(number <--[of]--> communication round), Edge(learning rate <--[of]--> communication round), Edge(learning rate <--[of]--> 0001), Edge(stride <--[of]--> all convolution parameter), Edge(padding <--[of]--> all convolution parameter), Edge(number <--[of]--> epoch), Edge(learning rate <--[of]--> epoch), Edge(generalizability <--[of]--> global model), Edge(effectiveness <--[of]--> personalization), Edge(network traffic <--[of]--> all client), Edge(execution time <--[of]--> each client), Edge(average wall clock time <--[of]--> each round), Edge(overall performance <--[of]--> fedconv), Edge(accuracy <--[of]--> aggregated global model), Edge(same degree <--[of]--> heterogeneous data), Edge(higher global model accuracy <--[than]--> baseline), Edge(server side data <--[for]--> training), Edge(average improvement <--[of]--> 205 %), Edge(all client <--[of]--> fedavg), Edge(insufficient number <--[of]--> parameter), Edge(parameter <--[for]--> training), Edge(corresponding weight vector <--[for]--> training), Edge(dilated model <--[for]--> training), Edge(superior generalization performance <--[of]--> fedconv), Edge(global model accuracy <--[of]--> fedconv), Edge(all baseline <--[of]--> fedconv), Edge(all baseline <--[from]--> different data heterogeneity), Edge(different data heterogeneity <--[of]--> all datasets), Edge(performance enhancement <--[of]--> fedconv), Edge(better personalization performance <--[for]--> client), Edge(performance improvement <--[of]--> global model), Edge(accuracy <--[of]--> each client model), Edge(accuracy <--[with]--> client side test datasets), Edge(accuracy <--[of]--> client model), Edge(small portion <--[of]--> entire dataset), Edge(degraded performance <--[of]--> client side non iid data), Edge(longer convergence time <--[of]--> client side non iid data), Edge(client model accuracy <--[of]--> fedconv), Edge(all baseline <--[with]--> different data heterogeneity), Edge(each uploaded client model <--[of]--> server), Edge(personalization information <--[from]--> client), Edge(sensing heterogeneity <--[of]--> harbox dataset), Edge(client model accuracy <--[of]--> fedmd), Edge(extra burden <--[of]--> client), Edge(significant performance gain <--[of]--> both global and client model), Edge(parameter information <--[of]--> global model), Edge(performance instability <--[of]--> some baseline), Edge(information loss <--[of]--> model pruning), Edge(imbalance issue <--[of]--> model pruning), Edge(performance degradation <--[of]--> model pruning), Edge(imbalance issue <--[of]--> parameter sharing), Edge(memory footprint <--[of]--> each client), Edge(wall clock time <--[of]--> each client), Edge(baseline <--[of]--> each client), Edge(memory footprint <--[of]--> fedconv), Edge(wall clock time <--[of]--> fedconv), Edge(baseline <--[of]--> fedconv), Edge(baseline <--[with]--> heterogeneous formula = 005 data), Edge(fedconv <--[with]--> heterogeneous formula = 005 data), Edge(heterogeneous formula = 005 data <--[from]--> client), Edge(overview <--[of]--> average memory usage), Edge(average wall clock time <--[of]--> each client), Edge(same set <--[of]--> sr), Edge(average saving <--[of]--> 406 %), Edge(406 % <--[of]--> memory cost), Edge(546 % <--[of]--> memory cost), Edge(546 % <--[of]--> computation overhead), Edge(approximately half <--[of]--> memory and training time), Edge(around 90 minute <--[of]--> wall clock time), Edge(around 90 minute <--[than]--> hermes), Edge(client <--[of]--> fedconv), Edge(significant saving <--[of]--> term), Edge(term <--[of]--> memory computation and communication resource), Edge(total size <--[of]--> data packet), Edge(communication cost <--[of]--> fedconv), Edge(number <--[of]--> selected participating client), Edge(learning rate <--[of]--> selected participating client), Edge(client model accuracy <--[of]--> fedconv), Edge(number <--[of]--> client), Edge(learning rate <--[of]--> client), Edge(client model accuracy <--[of]--> harbox), Edge(client model performance <--[of]--> fedconv), Edge(scalability <--[of]--> fedconv), Edge(superiority <--[of]--> fedconv), Edge(scalability <--[with]--> varying client number), Edge(superiority <--[with]--> varying client number), Edge(trade off <--[between]--> sr), Edge(sr <--[for]--> 10 client), Edge(model performance <--[for]--> 10 client), Edge(sr <--[for]--> remaining 10 client), Edge(model performance <--[for]--> remaining 10 client), Edge(notable accuracy drop <--[of]--> client model), Edge(googlenet model <--[of]--> cinic10), Edge(accuracy <--[of]--> fedconv), Edge(much higher accuracy <--[than]--> baseline), Edge(larger amount <--[of]--> parameter information), Edge(impact <--[of]--> server side data), Edge(sample number ratio <--[of]--> server side data), Edge(step <--[of]--> 05 %), Edge(ratio <--[of]--> server side data), Edge(default sample ratio <--[of]--> server side data), Edge(compression dilation aggregation impact <--[of]--> personalization performance), Edge(personalization performance <--[of]--> client model), Edge(number <--[of]--> convolution / tc parameter), Edge(learning rate <--[of]--> convolution / tc parameter), Edge(number <--[of]--> tuning epoch), Edge(learning rate <--[of]--> tuning epoch), Edge(epoch <--[for]--> model compression), Edge(kernel size <--[of]--> compression layer), Edge(stride length <--[of]--> compression layer), Edge(stride <--[of]--> compression layer), Edge(impact <--[of]--> client performance), Edge(convolutional layer <--[from]--> large model), Edge(shape <--[of]--> formula), Edge(importance <--[of]--> server side pre training process), Edge(impact <--[of]--> global model accuracy), Edge(integration <--[of]--> training), Edge(impact <--[of]--> our learned weight vector), Edge(impact <--[for]--> model aggregation), Edge(weight <--[with]--> respect), Edge(respect <--[to]--> sample number), Edge(effect <--[of]--> global model accuracy), Edge(parameter <--[from]--> heterogeneous client model), Edge(corresponding weight vector <--[from]--> heterogeneous client model), Edge(dilated model <--[from]--> heterogeneous client model), Edge(varying skewness <--[toward]--> parameter local data distribution), Edge(potential <--[of]--> personalization), Edge(personalization performance <--[of]--> each client), Edge(average accuracy <--[of]--> client model), Edge(performance improvement <--[of]--> five datasets), Edge(image <--[of]--> digit), Edge(digit <--[from]--> computer font), Edge(computer font <--[with]--> variation), Edge(e g different shape <--[of]--> digit), Edge(e g different shape <--[from]--> chars74 k dataset), Edge(e g various writing style <--[of]--> digit), Edge(e g various writing style <--[from]--> mnist dataset), Edge(transformation <--[from]--> one data domain), Edge(transformation <--[to]--> another), Edge(generated sub model <--[from]--> convolutional compression), Edge(parameter information <--[from]--> large global model), Edge(personalization information <--[of]--> client side data), Edge(domain gap <--[between]--> server side), Edge(decrease <--[of]--> both global model), Edge(comparable performance <--[to]--> fedconv), Edge(privacy protection <--[of]--> conventional fl scheme), Edge(practicality <--[of]--> fedconv), Edge(stable and robust simulated environment <--[for]--> fl), Edge(compatibility <--[of]--> flower framework), Edge(compatibility <--[with]--> android system), Edge(recent advancement <--[of]--> flower), Edge(federated learning setup <--[with]--> android client), Edge(client s perspective <--[of]--> view), Edge(distribution <--[of]--> client data), Edge(intrinsic clustering pattern <--[among]--> client), Edge(similarity <--[of]--> client model), Edge(clustered multi task federated learning <--[of]--> non iid data), Edge(upper layer <--[of]--> global model), Edge(minimal modification <--[to]--> client), Edge(integration <--[from]--> existing fl system), Edge(knowledge <--[from]--> heterogeneous client model), Edge(tuning <--[of]--> kd), Edge(client <--[with]--> shared dataset), Edge(part <--[of]--> global model parameter), Edge(fixed subset <--[of]--> global parameter), Edge(minimal modification <--[to]--> existing fl framework), Edge(system overhead <--[of]--> client), Edge(client friendly federated learning framework <--[for]--> heterogeneous client), Edge(system overhead <--[of]--> resource constrained mobile device), Edge(heterogeneous sub model <--[with]--> convolutional compression), Edge(heterogeneous sub model <--[of]--> global model), Edge(large model <--[with]--> unified size), Edge(sub model <--[with]--> unified size), Edge(personalization information <--[of]--> client model), Edge(much lower computation and communication overhead <--[for]--> fl client)]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(graph)\n",
    "\n",
    "print(clustered_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded vertices due to inconsistent embedding dimensions: {'[[[formula th aggregated network layer]]]', '[[[formula th large model]]]', '[[[formula th layer]]]'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "gray",
          "width": 2
         },
         "mode": "lines",
         "name": "Edges",
         "type": "scatter3d",
         "x": [
          -0.29892784357070923,
          -0.4117111563682556,
          null,
          -0.19078172743320465,
          -0.4328693747520447,
          null,
          -0.14433220028877258,
          -0.38971206545829773,
          null,
          -0.19078172743320465,
          -0.38971206545829773,
          null,
          -0.336235910654068,
          -0.38971206545829773,
          null,
          -0.3290537893772125,
          -0.44997164607048035,
          null,
          -0.3290537893772125,
          -0.4316566288471222,
          null,
          -0.3290537893772125,
          -0.4082096815109253,
          null,
          0.040945135056972504,
          -0.3763519823551178,
          null,
          0.040945135056972504,
          -0.1563851684331894,
          null,
          -0.3527279496192932,
          -0.42336010932922363,
          null,
          -0.3527279496192932,
          -0.38419967889785767,
          null,
          2.5126051902770996,
          -0.24297906458377838,
          null,
          -0.39202407002449036,
          -0.24297906458377838,
          null,
          2.5126051902770996,
          -0.4602380394935608,
          null,
          -0.39202407002449036,
          -0.4602380394935608,
          null,
          2.5126051902770996,
          -0.35416004061698914,
          null,
          -0.39202407002449036,
          -0.35416004061698914,
          null,
          2.5126051902770996,
          -0.19078172743320465,
          null,
          -0.39202407002449036,
          -0.19078172743320465,
          null,
          -0.19078172743320465,
          -0.413530558347702,
          null,
          -0.4696792662143707,
          -0.35716545581817627,
          null,
          -0.4696792662143707,
          -0.4013250470161438,
          null,
          -0.4696792662143707,
          -0.1563851684331894,
          null,
          -0.469063937664032,
          0.05133674293756485,
          null,
          -0.2344702035188675,
          -0.3146917521953583,
          null,
          -0.2344702035188675,
          -0.4118274748325348,
          null,
          -0.2344702035188675,
          -0.35606247186660767,
          null,
          -0.45638954639434814,
          -0.22173690795898438,
          null,
          -0.45638954639434814,
          -0.4013250470161438,
          null,
          -0.45638954639434814,
          -0.1563851684331894,
          null,
          0.77921462059021,
          -0.18713244795799255,
          null,
          0.77921462059021,
          -0.25057464838027954,
          null,
          0.77921462059021,
          -0.20611241459846497,
          null,
          -0.14172573387622833,
          -0.3763519823551178,
          null,
          -0.14172573387622833,
          -0.1563851684331894,
          null,
          -0.4023062288761139,
          -0.3763519823551178,
          null,
          -0.4023062288761139,
          -0.1563851684331894,
          null,
          -0.14172573387622833,
          -0.4562217891216278,
          null,
          -0.4023062288761139,
          -0.4562217891216278,
          null,
          -0.14433220028877258,
          -0.29411807656288147,
          null,
          -0.14433220028877258,
          -0.36189407110214233,
          null,
          -0.19078172743320465,
          -0.29411807656288147,
          null,
          -0.19078172743320465,
          -0.36189407110214233,
          null,
          -0.336235910654068,
          -0.29411807656288147,
          null,
          -0.336235910654068,
          -0.36189407110214233,
          null,
          -0.14433220028877258,
          -0.4013250470161438,
          null,
          -0.14433220028877258,
          -0.1563851684331894,
          null,
          -0.19078172743320465,
          -0.4013250470161438,
          null,
          -0.19078172743320465,
          -0.1563851684331894,
          null,
          -0.336235910654068,
          -0.4013250470161438,
          null,
          -0.336235910654068,
          -0.1563851684331894,
          null,
          -0.19078172743320465,
          -0.4648168683052063,
          null,
          -0.14433220028877258,
          -0.4023062288761139,
          null,
          -0.19078172743320465,
          -0.4023062288761139,
          null,
          -0.336235910654068,
          -0.4023062288761139,
          null,
          -0.14433220028877258,
          -0.41612109541893005,
          null,
          -0.19078172743320465,
          -0.41612109541893005,
          null,
          -0.336235910654068,
          -0.41612109541893005,
          null,
          -0.14433220028877258,
          -0.31921032071113586,
          null,
          -0.19078172743320465,
          -0.31921032071113586,
          null,
          -0.336235910654068,
          -0.31921032071113586,
          null,
          -0.14433220028877258,
          -0.33939236402511597,
          null,
          -0.19078172743320465,
          -0.33939236402511597,
          null,
          -0.336235910654068,
          -0.33939236402511597,
          null,
          -0.18713244795799255,
          -0.4249405264854431,
          null,
          -0.25057464838027954,
          -0.4249405264854431,
          null,
          -0.20611241459846497,
          -0.4249405264854431,
          null,
          -0.23404204845428467,
          0.040011703968048096,
          null,
          -0.23404204845428467,
          -0.4775387942790985,
          null,
          0.77921462059021,
          -0.09295151382684708,
          null,
          0.77921462059021,
          -0.4064701497554779,
          null,
          0.77921462059021,
          -0.4665999710559845,
          null,
          0.77921462059021,
          1.018332600593567,
          null,
          0.77921462059021,
          -0.2289937138557434,
          null,
          -0.15461517870426178,
          -0.4621870219707489,
          null,
          0.77921462059021,
          -0.372873455286026,
          null,
          -0.3330538272857666,
          -0.35606247186660767,
          null,
          0.77921462059021,
          -0.4050523638725281,
          null,
          0.77921462059021,
          -0.3145896792411804,
          null,
          -0.14433220028877258,
          -0.40264517068862915,
          null,
          -0.19078172743320465,
          -0.40264517068862915,
          null,
          -0.336235910654068,
          -0.40264517068862915,
          null,
          -0.14433220028877258,
          -0.29189473390579224,
          null,
          -0.19078172743320465,
          -0.29189473390579224,
          null,
          -0.336235910654068,
          -0.29189473390579224,
          null,
          0.77921462059021,
          -0.18713244795799255,
          null,
          0.77921462059021,
          -0.25057464838027954,
          null,
          0.77921462059021,
          -0.20611241459846497,
          null,
          0.77921462059021,
          -0.18713244795799255,
          null,
          0.77921462059021,
          -0.25057464838027954,
          null,
          0.77921462059021,
          -0.20611241459846497,
          null,
          0.77921462059021,
          0.48073095083236694,
          null,
          -0.18713244795799255,
          0.3791048228740692,
          null,
          -0.25057464838027954,
          0.3791048228740692,
          null,
          -0.20611241459846497,
          0.3791048228740692,
          null,
          -0.18713244795799255,
          -0.1520339548587799,
          null,
          -0.25057464838027954,
          -0.1520339548587799,
          null,
          -0.20611241459846497,
          -0.1520339548587799,
          null,
          -0.18713244795799255,
          -0.3977019786834717,
          null,
          -0.25057464838027954,
          -0.3977019786834717,
          null,
          -0.20611241459846497,
          -0.3977019786834717,
          null,
          -0.18713244795799255,
          -0.3290537893772125,
          null,
          -0.25057464838027954,
          -0.3290537893772125,
          null,
          -0.20611241459846497,
          -0.3290537893772125,
          null,
          0.77921462059021,
          -0.38230210542678833,
          null,
          0.77921462059021,
          -0.20607368648052216,
          null,
          -0.3397347927093506,
          -0.4013250470161438,
          null,
          -0.3397347927093506,
          -0.1563851684331894,
          null,
          -0.18713244795799255,
          -0.4316566288471222,
          null,
          -0.18713244795799255,
          -0.4082096815109253,
          null,
          -0.25057464838027954,
          -0.4316566288471222,
          null,
          -0.25057464838027954,
          -0.4082096815109253,
          null,
          -0.20611241459846497,
          -0.4316566288471222,
          null,
          -0.20611241459846497,
          -0.4082096815109253,
          null,
          -0.18713244795799255,
          -0.3561292588710785,
          null,
          -0.25057464838027954,
          -0.3561292588710785,
          null,
          -0.20611241459846497,
          -0.3561292588710785,
          null,
          0.77921462059021,
          -0.36569589376449585,
          null,
          0.77921462059021,
          -0.36189407110214233,
          null,
          0.77921462059021,
          -0.1693044751882553,
          null,
          -0.2846773862838745,
          -0.4063625931739807,
          null,
          -0.2846773862838745,
          -0.18713244795799255,
          null,
          -0.2846773862838745,
          -0.25057464838027954,
          null,
          -0.2846773862838745,
          -0.20611241459846497,
          null,
          0.77921462059021,
          -0.27802595496177673,
          null,
          0.77921462059021,
          -0.5191138982772827,
          null,
          -0.4869278073310852,
          -0.37930062413215637,
          null,
          -0.4869278073310852,
          -0.19078172743320465,
          null,
          -0.4869278073310852,
          3.6365485191345215,
          null,
          -0.24309520423412323,
          -0.30230751633644104,
          null,
          -0.24309520423412323,
          -0.26444950699806213,
          null,
          -0.3311408758163452,
          -0.37498152256011963,
          null,
          -0.3311408758163452,
          -0.20018215477466583,
          null,
          -0.31587597727775574,
          -0.3745192289352417,
          null,
          -0.2397831231355667,
          -0.47568657994270325,
          null,
          -0.16430090367794037,
          -0.23264338076114655,
          null,
          -0.16430090367794037,
          -0.13831102848052979,
          null,
          -0.19078172743320465,
          -0.3745192289352417,
          null,
          -0.19078172743320465,
          -0.35716545581817627,
          null,
          -0.19078172743320465,
          -0.4013250470161438,
          null,
          -0.19078172743320465,
          -0.1563851684331894,
          null,
          0.77921462059021,
          -0.4330805838108063,
          null,
          0.77921462059021,
          4.052042484283447,
          null,
          0.77921462059021,
          -0.29730474948883057,
          null,
          -0.4057043790817261,
          -0.4256265163421631,
          null,
          -0.4057043790817261,
          -0.36380571126937866,
          null,
          -0.4013250470161438,
          -0.21905949711799622,
          null,
          -0.1563851684331894,
          -0.21905949711799622,
          null,
          -0.4013250470161438,
          -0.3763519823551178,
          null,
          -0.4013250470161438,
          -0.1563851684331894,
          null,
          -0.1563851684331894,
          -0.3763519823551178,
          null,
          -0.1563851684331894,
          -0.1563851684331894,
          null,
          -0.3570714592933655,
          -0.38119739294052124,
          null,
          -0.3570714592933655,
          -0.4557967483997345,
          null,
          -0.26912206411361694,
          -0.1563851684331894,
          null,
          -0.26912206411361694,
          -0.4013250470161438,
          null,
          -0.3311408758163452,
          -0.41657862067222595,
          null,
          -0.35303887724876404,
          -0.37033331394195557,
          null,
          -0.35303887724876404,
          -0.462936133146286,
          null,
          -0.41075989603996277,
          -0.2569751739501953,
          null,
          -0.41075989603996277,
          -0.37454313039779663,
          null,
          -0.4032643139362335,
          -0.2488565891981125,
          null,
          0.20894458889961243,
          -0.3146917521953583,
          null,
          0.20894458889961243,
          -0.4118274748325348,
          null,
          0.20894458889961243,
          -0.35606247186660767,
          null,
          -0.26912206411361694,
          -0.26643458008766174,
          null,
          -0.26912206411361694,
          -0.4762248396873474,
          null,
          0.77921462059021,
          -0.39188113808631897,
          null,
          0.77921462059021,
          -0.4664028584957123,
          null,
          0.77921462059021,
          -0.4002639055252075,
          null,
          -0.15461517870426178,
          -0.23057080805301666,
          null,
          -0.15461517870426178,
          -0.22173690795898438,
          null,
          -0.2065650075674057,
          -0.42798566818237305,
          null,
          -0.21130487322807312,
          -0.3146917521953583,
          null,
          -0.21130487322807312,
          -0.4118274748325348,
          null,
          -0.21130487322807312,
          -0.35606247186660767,
          null,
          -0.21130487322807312,
          -0.2121078372001648,
          null,
          -0.4601176381111145,
          -0.14433220028877258,
          null,
          -0.4601176381111145,
          -0.19078172743320465,
          null,
          -0.4601176381111145,
          -0.336235910654068,
          null,
          -0.15461517870426178,
          -0.3934854567050934,
          null,
          -0.15461517870426178,
          -0.19078172743320465,
          null,
          -0.3825852572917938,
          -0.3146917521953583,
          null,
          -0.3825852572917938,
          -0.4118274748325348,
          null,
          -0.3825852572917938,
          -0.35606247186660767,
          null,
          -0.3825852572917938,
          -0.37454313039779663,
          null,
          0.77921462059021,
          -0.3837509751319885,
          null,
          -0.1563851684331894,
          -0.3874531388282776,
          null,
          -0.4013250470161438,
          -0.3874531388282776,
          null,
          -0.1563851684331894,
          -0.4013250470161438,
          null,
          -0.1563851684331894,
          -0.1563851684331894,
          null,
          -0.4013250470161438,
          -0.4013250470161438,
          null,
          -0.4013250470161438,
          -0.1563851684331894,
          null,
          -0.4280901551246643,
          -0.44526931643486023,
          null,
          -0.4280901551246643,
          -0.44581183791160583,
          null,
          -0.438457727432251,
          -0.4605691432952881,
          null,
          -0.4442349970340729,
          -0.29411807656288147,
          null,
          -0.4442349970340729,
          -0.36189407110214233,
          null,
          -0.4442349970340729,
          -0.26476529240608215,
          null,
          -0.4442349970340729,
          -0.44581183791160583,
          null,
          0.77921462059021,
          -0.38678157329559326,
          null,
          0.77921462059021,
          -0.4354811906814575,
          null,
          0.77921462059021,
          3.6365485191345215,
          null,
          0.77921462059021,
          -0.32655760645866394,
          null,
          0.77921462059021,
          -0.3286322057247162,
          null,
          0.19688217341899872,
          -0.1563851684331894,
          null,
          0.19688217341899872,
          -0.4013250470161438,
          null,
          0.19688217341899872,
          -0.34771081805229187,
          null,
          -0.08209985494613647,
          -0.2566058933734894,
          null,
          -0.08209985494613647,
          -0.22054865956306458,
          null,
          -0.2065650075674057,
          -0.1563851684331894,
          null,
          -0.2065650075674057,
          -0.4013250470161438,
          null,
          -0.19813932478427887,
          -0.3146917521953583,
          null,
          -0.19813932478427887,
          -0.4118274748325348,
          null,
          -0.19813932478427887,
          -0.35606247186660767,
          null,
          -0.19813932478427887,
          -0.37008407711982727,
          null,
          -0.19813932478427887,
          -0.13196995854377747,
          null,
          0.77921462059021,
          -0.360376238822937,
          null,
          0.77921462059021,
          -0.14433220028877258,
          null,
          0.77921462059021,
          -0.19078172743320465,
          null,
          0.77921462059021,
          -0.336235910654068,
          null,
          0.77921462059021,
          -0.3848789930343628,
          null,
          -0.14433220028877258,
          -0.41637229919433594,
          null,
          -0.19078172743320465,
          -0.41637229919433594,
          null,
          -0.336235910654068,
          -0.41637229919433594,
          null,
          -0.14433220028877258,
          -0.31005534529685974,
          null,
          -0.19078172743320465,
          -0.31005534529685974,
          null,
          -0.336235910654068,
          -0.31005534529685974,
          null,
          -0.14433220028877258,
          -0.4013250470161438,
          null,
          -0.14433220028877258,
          -0.1563851684331894,
          null,
          -0.19078172743320465,
          -0.4013250470161438,
          null,
          -0.19078172743320465,
          -0.1563851684331894,
          null,
          -0.336235910654068,
          -0.4013250470161438,
          null,
          -0.336235910654068,
          -0.1563851684331894,
          null,
          -0.14433220028877258,
          -0.3966740369796753,
          null,
          -0.19078172743320465,
          -0.3966740369796753,
          null,
          -0.336235910654068,
          -0.3966740369796753,
          null,
          -0.14433220028877258,
          -0.4013250470161438,
          null,
          -0.14433220028877258,
          -0.1563851684331894,
          null,
          -0.19078172743320465,
          -0.4013250470161438,
          null,
          -0.19078172743320465,
          -0.1563851684331894,
          null,
          -0.336235910654068,
          -0.4013250470161438,
          null,
          -0.336235910654068,
          -0.1563851684331894,
          null,
          -0.14433220028877258,
          -0.26713827252388,
          null,
          -0.19078172743320465,
          -0.26713827252388,
          null,
          -0.336235910654068,
          -0.26713827252388,
          null,
          -0.14433220028877258,
          -0.45638954639434814,
          null,
          -0.19078172743320465,
          -0.45638954639434814,
          null,
          -0.336235910654068,
          -0.45638954639434814,
          null,
          -0.14433220028877258,
          -0.3290537893772125,
          null,
          -0.19078172743320465,
          -0.3290537893772125,
          null,
          -0.336235910654068,
          -0.3290537893772125,
          null,
          -0.14433220028877258,
          4.055788516998291,
          null,
          -0.19078172743320465,
          4.055788516998291,
          null,
          -0.336235910654068,
          4.055788516998291,
          null,
          -0.19078172743320465,
          -0.26713827252388,
          null,
          -0.19078172743320465,
          -0.35738545656204224,
          null,
          -0.14433220028877258,
          -0.32129302620887756,
          null,
          -0.19078172743320465,
          -0.32129302620887756,
          null,
          -0.336235910654068,
          -0.32129302620887756,
          null,
          -0.14433220028877258,
          -0.32129302620887756,
          null,
          -0.19078172743320465,
          -0.32129302620887756,
          null,
          -0.336235910654068,
          -0.32129302620887756,
          null,
          -0.36569589376449585,
          -0.2849453091621399,
          null,
          -0.36569589376449585,
          -0.30490225553512573,
          null,
          -0.3757368326187134,
          -0.1563851684331894,
          null,
          -0.3757368326187134,
          -0.4013250470161438,
          null,
          0.77921462059021,
          -0.4531129002571106,
          null,
          -0.1563851684331894,
          -0.39501020312309265,
          null,
          -0.4013250470161438,
          -0.39501020312309265,
          null,
          -0.1563851684331894,
          -0.4013250470161438,
          null,
          -0.1563851684331894,
          -0.1563851684331894,
          null,
          -0.4013250470161438,
          -0.4013250470161438,
          null,
          -0.4013250470161438,
          -0.1563851684331894,
          null,
          -0.19078172743320465,
          -0.430012047290802,
          null,
          -0.14433220028877258,
          -0.2382820099592209,
          null,
          -0.14433220028877258,
          -0.4079287350177765,
          null,
          -0.19078172743320465,
          -0.2382820099592209,
          null,
          -0.19078172743320465,
          -0.4079287350177765,
          null,
          -0.336235910654068,
          -0.2382820099592209,
          null,
          -0.336235910654068,
          -0.4079287350177765,
          null,
          -0.14433220028877258,
          -0.4013250470161438,
          null,
          -0.14433220028877258,
          -0.1563851684331894,
          null,
          -0.19078172743320465,
          -0.4013250470161438,
          null,
          -0.19078172743320465,
          -0.1563851684331894,
          null,
          -0.336235910654068,
          -0.4013250470161438,
          null,
          -0.336235910654068,
          -0.1563851684331894,
          null,
          -0.19647401571273804,
          0.638736367225647,
          null,
          -0.19647401571273804,
          -0.4394821524620056,
          null,
          0.9356509447097778,
          -0.14433220028877258,
          null,
          0.9356509447097778,
          -0.19078172743320465,
          null,
          0.9356509447097778,
          -0.336235910654068,
          null,
          -0.14433220028877258,
          -0.3944622874259949,
          null,
          -0.19078172743320465,
          -0.3944622874259949,
          null,
          -0.336235910654068,
          -0.3944622874259949,
          null,
          -0.2382820099592209,
          -0.4280901551246643,
          null,
          -0.4079287350177765,
          -0.4280901551246643,
          null,
          0.8404133915901184,
          -0.35558032989501953,
          null,
          0.8404133915901184,
          -0.20018215477466583,
          null,
          -0.30490225553512573,
          -0.4013250470161438,
          null,
          -0.30490225553512573,
          -0.1563851684331894,
          null,
          -0.30490225553512573,
          2.7742249965667725,
          null,
          -0.30490225553512573,
          3.719235897064209,
          null,
          0.77921462059021,
          -0.4239879846572876,
          null,
          -0.3132747411727905,
          -0.37592166662216187,
          null,
          0.77921462059021,
          0.566757082939148,
          null,
          0.77921462059021,
          -0.22491301596164703,
          null,
          0.77921462059021,
          -0.2203851044178009,
          null,
          0.77921462059021,
          -0.45111513137817383,
          null,
          0.77921462059021,
          -0.3465925455093384,
          null,
          -0.1563851684331894,
          -0.3302881121635437,
          null,
          -0.4013250470161438,
          -0.3302881121635437,
          null,
          -0.4280901551246643,
          -0.3858230710029602,
          null,
          -0.4280901551246643,
          -0.4013250470161438,
          null,
          -0.4280901551246643,
          -0.1563851684331894,
          null,
          0.77921462059021,
          -0.18511761724948883,
          null,
          -0.14433220028877258,
          -0.37489399313926697,
          null,
          -0.19078172743320465,
          -0.37489399313926697,
          null,
          -0.336235910654068,
          -0.37489399313926697,
          null,
          -0.14433220028877258,
          -0.39288923144340515,
          null,
          -0.14433220028877258,
          -0.18555043637752533,
          null,
          -0.19078172743320465,
          -0.39288923144340515,
          null,
          -0.19078172743320465,
          -0.18555043637752533,
          null,
          -0.336235910654068,
          -0.39288923144340515,
          null,
          -0.336235910654068,
          -0.18555043637752533,
          null,
          -0.4617006778717041,
          -0.3247928321361542,
          null,
          0.77921462059021,
          -0.38678157329559326,
          null,
          0.77921462059021,
          -0.4354811906814575,
          null,
          0.77921462059021,
          -0.4022720456123352,
          null,
          0.77921462059021,
          -0.34613361954689026,
          null,
          0.77921462059021,
          -0.2532028257846832,
          null,
          0.77921462059021,
          0.24069277942180634,
          null,
          0.77921462059021,
          -0.203455850481987,
          null,
          -0.1704195737838745,
          -0.24551264941692352,
          null,
          -0.1704195737838745,
          -0.24929125607013702,
          null,
          -0.1704195737838745,
          -0.3826235830783844,
          null,
          -0.1404333859682083,
          -0.3553406596183777,
          null,
          0.77921462059021,
          -0.39288923144340515,
          null,
          0.77921462059021,
          -0.18555043637752533,
          null,
          0.77921462059021,
          -0.18511761724948883,
          null,
          -0.2065650075674057,
          -0.1563851684331894,
          null,
          -0.2065650075674057,
          -0.4013250470161438,
          null,
          -0.11680853366851807,
          -0.1563851684331894,
          null,
          -0.11680853366851807,
          -0.4013250470161438,
          null,
          -0.39078325033187866,
          -0.1563851684331894,
          null,
          -0.39078325033187866,
          -0.4013250470161438,
          null,
          -0.3145896792411804,
          -0.1563851684331894,
          null,
          -0.3145896792411804,
          -0.4013250470161438,
          null,
          0.7709515690803528,
          -0.36314961314201355,
          null,
          -0.44577521085739136,
          -0.4717462360858917,
          null,
          -0.44577521085739136,
          -0.31754422187805176,
          null,
          0.77921462059021,
          -0.4334908425807953,
          null,
          0.77921462059021,
          -0.1563851684331894,
          null,
          0.77921462059021,
          -0.4013250470161438,
          null,
          -0.15461517870426178,
          -0.44577521085739136,
          null,
          -0.15461517870426178,
          -0.38715654611587524,
          null,
          -0.22472740709781647,
          -0.1563851684331894,
          null,
          -0.22472740709781647,
          -0.4013250470161438,
          null,
          -0.22472740709781647,
          -0.38803616166114807,
          null,
          -0.22472740709781647,
          -0.21245864033699036,
          null,
          0.77921462059021,
          -0.32872143387794495,
          null,
          0.77921462059021,
          -0.47087204456329346,
          null,
          0.77921462059021,
          -0.3492552638053894,
          null,
          -0.15461517870426178,
          -0.23057781159877777,
          null,
          -0.15461517870426178,
          -0.4221605956554413,
          null,
          0.77921462059021,
          -0.42206594347953796,
          null,
          -0.24929125607013702,
          -0.4350427985191345,
          null,
          -0.2065650075674057,
          -0.1563851684331894,
          null,
          -0.2065650075674057,
          -0.4013250470161438,
          null,
          -0.1563851684331894,
          3.389488697052002,
          null,
          -0.4013250470161438,
          3.389488697052002,
          null,
          -0.4442349970340729,
          -0.39501020312309265,
          null,
          -0.4442349970340729,
          -0.4013250470161438,
          null,
          -0.4442349970340729,
          -0.1563851684331894,
          null,
          -0.14433220028877258,
          -0.3757368326187134,
          null,
          -0.19078172743320465,
          -0.3757368326187134,
          null,
          -0.336235910654068,
          -0.3757368326187134,
          null,
          -0.14433220028877258,
          -0.3313111662864685,
          null,
          -0.19078172743320465,
          -0.3313111662864685,
          null,
          -0.336235910654068,
          -0.3313111662864685,
          null,
          -0.2344702035188675,
          -0.3774597942829132,
          null,
          -0.2344702035188675,
          -0.19078172743320465,
          null,
          0.77921462059021,
          -0.3953375518321991,
          null,
          0.77921462059021,
          -0.34479615092277527,
          null,
          0.77921462059021,
          -0.13546526432037354,
          null,
          0.77921462059021,
          -0.18827500939369202,
          null,
          -0.30490225553512573,
          -0.44848594069480896,
          null,
          -0.30490225553512573,
          2.7728490829467773,
          null,
          -0.30490225553512573,
          3.351423978805542,
          null,
          0.77921462059021,
          -0.11680853366851807,
          null,
          0.77921462059021,
          -0.39078325033187866,
          null,
          0.77921462059021,
          -0.3145896792411804,
          null,
          0.77921462059021,
          -0.33146509528160095,
          null,
          -0.24076588451862335,
          1.0923655033111572,
          null,
          -0.18511761724948883,
          1.0708444118499756,
          null,
          0.77921462059021,
          0.4931749105453491,
          null,
          0.77921462059021,
          -0.372873455286026,
          null,
          -0.14433220028877258,
          -0.22848264873027802,
          null,
          -0.19078172743320465,
          -0.22848264873027802,
          null,
          -0.336235910654068,
          -0.22848264873027802,
          null,
          -0.1785692721605301,
          -0.3044790029525757,
          null,
          -0.11680853366851807,
          -0.3145896792411804,
          null,
          -0.39078325033187866,
          -0.3145896792411804,
          null,
          -0.3145896792411804,
          -0.3145896792411804,
          null,
          -0.11680853366851807,
          -0.4009389877319336,
          null,
          -0.39078325033187866,
          -0.4009389877319336,
          null,
          -0.3145896792411804,
          -0.4009389877319336,
          null,
          -0.11680853366851807,
          -0.3311408758163452,
          null,
          -0.39078325033187866,
          -0.3311408758163452,
          null,
          -0.3145896792411804,
          -0.3311408758163452,
          null,
          -0.336235910654068,
          -0.1922614723443985,
          null,
          -0.336235910654068,
          -0.41495630145072937,
          null,
          0.77921462059021,
          -0.11680853366851807,
          null,
          0.77921462059021,
          -0.39078325033187866,
          null,
          0.77921462059021,
          -0.3145896792411804,
          null,
          0.77921462059021,
          -0.20804035663604736,
          null,
          0.77921462059021,
          -0.18511761724948883,
          null,
          0.77921462059021,
          -0.32205408811569214,
          null,
          0.77921462059021,
          -0.44035351276397705,
          null,
          -0.3763519823551178,
          -0.3501236140727997,
          null,
          -0.1563851684331894,
          -0.3501236140727997,
          null,
          -0.3763519823551178,
          -0.2181958705186844,
          null,
          -0.1563851684331894,
          -0.2181958705186844,
          null,
          -0.39676856994628906,
          -0.3214751183986664,
          null,
          -0.39676856994628906,
          -0.4443855583667755,
          null,
          0.77921462059021,
          -0.2075643092393875,
          null,
          0.77921462059021,
          -0.1693044751882553,
          null,
          -0.14034321904182434,
          1.400133490562439,
          null,
          -0.14034321904182434,
          -0.3863079249858856,
          null,
          0.77921462059021,
          -0.3710010051727295,
          null,
          0.77921462059021,
          -0.07273076474666595,
          null,
          0.77921462059021,
          -0.3082584738731384,
          null,
          0.77921462059021,
          -0.22336310148239136,
          null,
          0.77921462059021,
          -0.19883306324481964,
          null,
          0.77921462059021,
          0.23794837296009064,
          null,
          0.77921462059021,
          -0.12149672210216522,
          null,
          2.3847849369049072,
          0.04129659757018089,
          null,
          0.77921462059021,
          -0.3782137632369995,
          null,
          2.445047616958618,
          3.8076188564300537,
          null,
          0.77921462059021,
          -0.29526907205581665,
          null,
          2.458759069442749,
          3.7893331050872803,
          null,
          2.458759069442749,
          0.33335989713668823,
          null,
          0.77921462059021,
          -0.23231138288974762,
          null,
          0.77921462059021,
          -0.2177920788526535,
          null,
          0.77921462059021,
          -0.12149672210216522,
          null,
          2.388746500015259,
          2.9943063259124756,
          null,
          2.388746500015259,
          2.7619822025299072,
          null,
          0.77921462059021,
          -0.17755120992660522,
          null,
          0.77921462059021,
          0.02498847432434559,
          null,
          2.44697642326355,
          3.6091411113739014,
          null,
          2.44697642326355,
          0.157850444316864,
          null,
          0.77921462059021,
          -0.024762006476521492,
          null,
          0.77921462059021,
          -0.02130325697362423,
          null,
          0.77921462059021,
          0.09330374747514725,
          null,
          0.77921462059021,
          -0.3149547278881073,
          null,
          0.77921462059021,
          -0.03459852933883667,
          null,
          -0.26211366057395935,
          5.133536338806152,
          null,
          -0.26211366057395935,
          5.1554646492004395,
          null,
          0.77921462059021,
          -0.3701118528842926,
          null,
          0.77921462059021,
          -0.14433220028877258,
          null,
          0.77921462059021,
          -0.19078172743320465,
          null,
          0.77921462059021,
          -0.336235910654068,
          null,
          0.77921462059021,
          3.6365485191345215,
          null,
          0.77921462059021,
          -0.18713244795799255,
          null,
          0.77921462059021,
          -0.25057464838027954,
          null,
          0.77921462059021,
          -0.20611241459846497,
          null,
          0.77921462059021,
          -0.32278284430503845,
          null,
          -0.2013840526342392,
          -0.2638987898826599,
          null,
          -0.2013840526342392,
          -0.2795238494873047,
          null,
          0.77921462059021,
          -0.22848264873027802,
          null,
          -0.19647401571273804,
          -0.4509764611721039,
          null,
          -0.19078172743320465,
          -0.4117111563682556,
          null,
          0.77921462059021,
          -0.4658333957195282,
          null,
          0.77921462059021,
          -0.24309520423412323,
          null,
          -0.19027727842330933,
          -0.42336010932922363,
          null,
          -0.19027727842330933,
          -0.38419967889785767,
          null,
          2.626448392868042,
          -0.1563851684331894,
          null,
          2.626448392868042,
          -0.4013250470161438,
          null,
          2.73553729057312,
          -0.45186349749565125,
          null,
          2.73553729057312,
          -0.19647401571273804,
          null,
          2.6492116451263428,
          -0.1563851684331894,
          null,
          2.6492116451263428,
          -0.4013250470161438,
          null,
          2.6492116451263428,
          -0.4032643139362335,
          null,
          -0.19647401571273804,
          -0.20838013291358948,
          null,
          -0.19647401571273804,
          -0.11680853366851807,
          null,
          -0.19647401571273804,
          -0.39078325033187866,
          null,
          -0.19647401571273804,
          -0.3145896792411804,
          null,
          2.727800130844116,
          -0.4563048481941223,
          null,
          0.77921462059021,
          1.0172346830368042,
          null,
          0.77921462059021,
          -0.42943885922431946,
          null,
          0.77921462059021,
          0.6559876203536987,
          null,
          0.77921462059021,
          -0.14314505457878113,
          null,
          0.77921462059021,
          0.6759098172187805,
          null,
          0.77921462059021,
          0.5073480606079102,
          null,
          0.77921462059021,
          -0.07937533408403397,
          null,
          0.77921462059021,
          -0.18511761724948883,
          null,
          0.77921462059021,
          -0.24551264941692352,
          null,
          0.77921462059021,
          -0.24929125607013702,
          null,
          0.77921462059021,
          -0.36644238233566284,
          null,
          -0.19647401571273804,
          3.119036912918091,
          null,
          -0.19647401571273804,
          -0.24929125607013702,
          null,
          0.77921462059021,
          -0.44367122650146484,
          null,
          0.77921462059021,
          -0.25057464838027954,
          null,
          0.77921462059021,
          -0.40615665912628174,
          null,
          0.77921462059021,
          -0.3595740795135498,
          null,
          0.77921462059021,
          -0.45961570739746094,
          null,
          0.77921462059021,
          -0.39298760890960693,
          null,
          0.77921462059021,
          -0.2289937138557434,
          null,
          0.77921462059021,
          0.7730562090873718,
          null,
          0.77921462059021,
          -0.37809693813323975,
          null,
          0.77921462059021,
          -0.19647401571273804,
          null,
          0.77921462059021,
          -0.3228030502796173,
          null,
          0.77921462059021,
          -0.18713244795799255,
          null,
          0.77921462059021,
          -0.25057464838027954,
          null,
          0.77921462059021,
          -0.20611241459846497,
          null,
          0.77921462059021,
          -0.2065650075674057,
          null,
          0.77921462059021,
          -0.39676856994628906,
          null,
          -0.369003564119339,
          -0.4013250470161438,
          null,
          -0.369003564119339,
          -0.1563851684331894,
          null,
          -0.438457727432251,
          -0.44367122650146484,
          null,
          -0.438457727432251,
          -0.25057464838027954,
          null,
          -0.438457727432251,
          -0.256418377161026,
          null,
          -0.2013840526342392,
          -0.4049573838710785,
          null,
          -0.2013840526342392,
          -0.20490533113479614,
          null,
          -0.2013840526342392,
          -0.18713244795799255,
          null,
          -0.18713244795799255,
          -0.28421661257743835,
          null,
          -0.25057464838027954,
          -0.28421661257743835,
          null,
          -0.20611241459846497,
          -0.28421661257743835,
          null,
          -0.18713244795799255,
          3.2222323417663574,
          null,
          -0.18713244795799255,
          3.3319807052612305,
          null,
          -0.25057464838027954,
          3.2222323417663574,
          null,
          -0.25057464838027954,
          3.3319807052612305,
          null,
          -0.20611241459846497,
          3.2222323417663574,
          null,
          -0.20611241459846497,
          3.3319807052612305,
          null,
          -0.44848594069480896,
          -0.3343993127346039,
          null,
          -0.44848594069480896,
          -0.11680853366851807,
          null,
          -0.44848594069480896,
          -0.39078325033187866,
          null,
          -0.44848594069480896,
          -0.3145896792411804,
          null,
          -0.18713244795799255,
          -0.10543763637542725,
          null,
          -0.18713244795799255,
          -0.20611241459846497,
          null,
          -0.25057464838027954,
          -0.10543763637542725,
          null,
          -0.25057464838027954,
          -0.20611241459846497,
          null,
          -0.20611241459846497,
          -0.10543763637542725,
          null,
          -0.20611241459846497,
          -0.20611241459846497,
          null,
          -0.18713244795799255,
          0.17622002959251404,
          null,
          -0.25057464838027954,
          0.17622002959251404,
          null,
          -0.20611241459846497,
          0.17622002959251404,
          null,
          -0.21130487322807312,
          -0.48330581188201904,
          null,
          -0.21130487322807312,
          -0.18713244795799255,
          null,
          -0.21130487322807312,
          -0.25057464838027954,
          null,
          -0.21130487322807312,
          -0.20611241459846497,
          null,
          -0.438457727432251,
          -0.18713244795799255,
          null,
          -0.438457727432251,
          -0.25057464838027954,
          null,
          -0.438457727432251,
          -0.20611241459846497,
          null,
          -0.3937024772167206,
          -0.18713244795799255,
          null,
          -0.3937024772167206,
          -0.25057464838027954,
          null,
          -0.3937024772167206,
          -0.20611241459846497,
          null,
          -0.18713244795799255,
          -0.4415583312511444,
          null,
          -0.25057464838027954,
          -0.4415583312511444,
          null,
          -0.20611241459846497,
          -0.4415583312511444,
          null,
          -0.18713244795799255,
          -0.3979059159755707,
          null,
          -0.25057464838027954,
          -0.3979059159755707,
          null,
          -0.20611241459846497,
          -0.3979059159755707,
          null,
          -0.18713244795799255,
          -0.38132745027542114,
          null,
          -0.18713244795799255,
          -0.24894845485687256,
          null,
          -0.25057464838027954,
          -0.38132745027542114,
          null,
          -0.25057464838027954,
          -0.24894845485687256,
          null,
          -0.20611241459846497,
          -0.38132745027542114,
          null,
          -0.20611241459846497,
          -0.24894845485687256,
          null,
          -0.18713244795799255,
          -0.46685072779655457,
          null,
          -0.25057464838027954,
          -0.46685072779655457,
          null,
          -0.20611241459846497,
          -0.46685072779655457,
          null,
          -0.18713244795799255,
          -0.19078172743320465,
          null,
          -0.25057464838027954,
          -0.19078172743320465,
          null,
          -0.20611241459846497,
          -0.19078172743320465,
          null,
          -0.36755189299583435,
          -0.4013250470161438,
          null,
          -0.36755189299583435,
          -0.1563851684331894,
          null,
          0.77921462059021,
          -0.2065650075674057,
          null,
          0.77921462059021,
          -0.24857307970523834,
          null,
          -0.438457727432251,
          -0.41024792194366455,
          null,
          -0.18713244795799255,
          -0.20490533113479614,
          null,
          -0.18713244795799255,
          -0.18713244795799255,
          null,
          -0.25057464838027954,
          -0.20490533113479614,
          null,
          -0.25057464838027954,
          -0.18713244795799255,
          null,
          -0.20611241459846497,
          -0.20490533113479614,
          null,
          -0.20611241459846497,
          -0.18713244795799255,
          null,
          -0.2065650075674057,
          -0.44848594069480896,
          null,
          -0.4531129002571106,
          -0.2719423770904541,
          null,
          -0.08708123862743378,
          -0.38775911927223206,
          null,
          -0.08708123862743378,
          -0.39728283882141113,
          null,
          -0.08708123862743378,
          -0.4410001039505005,
          null,
          -0.438457727432251,
          -0.46851131319999695,
          null,
          -0.3367779850959778,
          1.0217852592468262,
          null,
          -0.343284547328949,
          -0.3920506536960602,
          null,
          -0.343284547328949,
          -0.19078172743320465,
          null,
          -0.438457727432251,
          -0.38663390278816223,
          null,
          -0.18713244795799255,
          -0.3748640716075897,
          null,
          -0.25057464838027954,
          -0.3748640716075897,
          null,
          -0.20611241459846497,
          -0.3748640716075897,
          null,
          -0.18713244795799255,
          -0.14213161170482635,
          null,
          -0.18713244795799255,
          -0.22780567407608032,
          null,
          -0.18713244795799255,
          -0.25219476222991943,
          null,
          -0.25057464838027954,
          -0.14213161170482635,
          null,
          -0.25057464838027954,
          -0.22780567407608032,
          null,
          -0.25057464838027954,
          -0.25219476222991943,
          null,
          -0.20611241459846497,
          -0.14213161170482635,
          null,
          -0.20611241459846497,
          -0.22780567407608032,
          null,
          -0.20611241459846497,
          -0.25219476222991943,
          null,
          -0.40498292446136475,
          -0.3507192134857178,
          null,
          -0.30032646656036377,
          -0.39102399349212646,
          null,
          -0.30032646656036377,
          -0.36548590660095215,
          null,
          -0.18713244795799255,
          -0.46494269371032715,
          null,
          -0.25057464838027954,
          -0.46494269371032715,
          null,
          -0.20611241459846497,
          -0.46494269371032715,
          null,
          -0.18713244795799255,
          -0.25647208094596863,
          null,
          -0.25057464838027954,
          -0.25647208094596863,
          null,
          -0.20611241459846497,
          -0.25647208094596863,
          null,
          0.77921462059021,
          -0.3713628649711609,
          null,
          -0.18713244795799255,
          -0.440655916929245,
          null,
          -0.25057464838027954,
          -0.440655916929245,
          null,
          -0.20611241459846497,
          -0.440655916929245,
          null,
          -0.18713244795799255,
          -0.30277499556541443,
          null,
          -0.25057464838027954,
          -0.30277499556541443,
          null,
          -0.20611241459846497,
          -0.30277499556541443,
          null,
          0.77921462059021,
          -0.40094128251075745,
          null,
          0.77921462059021,
          -0.3463955223560333,
          null,
          0.77921462059021,
          -0.20490533113479614,
          null,
          -0.2259628027677536,
          -0.23677243292331696,
          null,
          -0.2259628027677536,
          -0.33933448791503906,
          null,
          -0.2259628027677536,
          -0.32609793543815613,
          null,
          -0.18713244795799255,
          -0.25734367966651917,
          null,
          -0.25057464838027954,
          -0.25734367966651917,
          null,
          -0.20611241459846497,
          -0.25734367966651917,
          null,
          -0.18713244795799255,
          3.1300723552703857,
          null,
          -0.18713244795799255,
          3.199669122695923,
          null,
          -0.25057464838027954,
          3.1300723552703857,
          null,
          -0.25057464838027954,
          3.199669122695923,
          null,
          -0.20611241459846497,
          3.1300723552703857,
          null,
          -0.20611241459846497,
          3.199669122695923,
          null,
          -0.18713244795799255,
          -0.088998943567276,
          null,
          -0.25057464838027954,
          -0.088998943567276,
          null,
          -0.20611241459846497,
          -0.088998943567276,
          null,
          -0.18713244795799255,
          -0.37282073497772217,
          null,
          -0.25057464838027954,
          -0.37282073497772217,
          null,
          -0.20611241459846497,
          -0.37282073497772217,
          null,
          -0.18713244795799255,
          3.7673227787017822,
          null,
          -0.25057464838027954,
          3.7673227787017822,
          null,
          -0.20611241459846497,
          3.7673227787017822,
          null,
          -0.19078172743320465,
          -0.18713244795799255,
          null,
          -0.19078172743320465,
          -0.25057464838027954,
          null,
          -0.19078172743320465,
          -0.20611241459846497,
          null,
          -0.10543763637542725,
          -0.2943912744522095,
          null,
          -0.10543763637542725,
          -0.3463955223560333,
          null,
          -0.20611241459846497,
          -0.2943912744522095,
          null,
          -0.20611241459846497,
          -0.3463955223560333,
          null,
          -0.2259628027677536,
          -0.12146300077438354,
          null,
          -0.2259628027677536,
          -0.40659335255622864,
          null,
          -0.4035072326660156,
          -0.44577521085739136,
          null,
          -0.4035072326660156,
          -0.24039003252983093,
          null,
          -0.2686671018600464,
          -0.3691391050815582,
          null,
          -0.20487791299819946,
          -0.3691391050815582,
          null,
          -0.18713244795799255,
          -0.3946457803249359,
          null,
          -0.25057464838027954,
          -0.3946457803249359,
          null,
          -0.20611241459846497,
          -0.3946457803249359,
          null,
          0.77921462059021,
          0.5345849990844727,
          null,
          -0.46851131319999695,
          -0.18713244795799255,
          null,
          -0.46851131319999695,
          -0.25057464838027954,
          null,
          -0.46851131319999695,
          -0.20611241459846497,
          null,
          -0.46851131319999695,
          -0.3408474922180176,
          null,
          -0.24551264941692352,
          -0.19078172743320465,
          null,
          -0.24929125607013702,
          -0.19078172743320465,
          null,
          -0.46851131319999695,
          -0.25219476222991943,
          null,
          0.77921462059021,
          -0.14213161170482635,
          null,
          0.77921462059021,
          -0.22780567407608032,
          null,
          0.77921462059021,
          -0.25219476222991943,
          null,
          -0.18713244795799255,
          -0.3595740795135498,
          null,
          -0.25057464838027954,
          -0.3595740795135498,
          null,
          -0.20611241459846497,
          -0.3595740795135498,
          null,
          -0.2846773862838745,
          -0.2366710752248764,
          null,
          -0.2846773862838745,
          -0.22429904341697693,
          null,
          0.77921462059021,
          2.4730043411254883,
          null,
          0.77921462059021,
          -0.37775132060050964,
          null,
          0.77921462059021,
          2.6596386432647705,
          null,
          0.77921462059021,
          -0.18511761724948883,
          null,
          2.4730043411254883,
          -0.32592931389808655,
          null,
          -0.37775132060050964,
          -0.32592931389808655,
          null,
          -0.4273715913295746,
          -0.3971827030181885,
          null,
          -0.4273715913295746,
          -0.22780567407608032,
          null,
          -0.4273715913295746,
          -0.25219476222991943,
          null,
          2.4730043411254883,
          -0.33716729283332825,
          null,
          -0.37775132060050964,
          -0.33716729283332825,
          null,
          0.77921462059021,
          -0.14213161170482635,
          null,
          0.77921462059021,
          -0.22780567407608032,
          null,
          0.77921462059021,
          -0.25219476222991943,
          null,
          -0.2065650075674057,
          -0.18713244795799255,
          null,
          -0.2065650075674057,
          -0.25057464838027954,
          null,
          -0.2065650075674057,
          -0.20611241459846497,
          null,
          -0.2065650075674057,
          -0.3998945653438568,
          null,
          -0.2065650075674057,
          -0.20490533113479614,
          null,
          -0.2065650075674057,
          -0.18713244795799255,
          null,
          -0.20490533113479614,
          -0.30617713928222656,
          null,
          -0.18713244795799255,
          -0.30617713928222656,
          null,
          -0.20490533113479614,
          -0.3858230710029602,
          null,
          -0.18713244795799255,
          -0.3858230710029602,
          null,
          -0.18713244795799255,
          -0.3858230710029602,
          null,
          -0.25057464838027954,
          -0.3858230710029602,
          null,
          -0.20611241459846497,
          -0.3858230710029602,
          null,
          -0.18713244795799255,
          -0.4013250470161438,
          null,
          -0.18713244795799255,
          -0.1563851684331894,
          null,
          -0.25057464838027954,
          -0.4013250470161438,
          null,
          -0.25057464838027954,
          -0.1563851684331894,
          null,
          -0.20611241459846497,
          -0.4013250470161438,
          null,
          -0.20611241459846497,
          -0.1563851684331894,
          null,
          0.77921462059021,
          -0.28375157713890076,
          null,
          0.77921462059021,
          -0.4531129002571106,
          null,
          0.77921462059021,
          0.18772955238819122,
          null,
          -0.14662082493305206,
          -0.4531129002571106,
          null,
          -0.44848594069480896,
          -0.40498292446136475,
          null,
          -0.44848594069480896,
          -0.42760276794433594,
          null,
          -0.4013250470161438,
          -0.4531129002571106,
          null,
          -0.1563851684331894,
          -0.4531129002571106,
          null,
          0.77921462059021,
          -0.3837820291519165,
          null,
          0.77921462059021,
          -0.4531129002571106,
          null,
          -0.40307721495628357,
          -0.26444950699806213,
          null,
          0.77921462059021,
          -0.24551264941692352,
          null,
          0.77921462059021,
          -0.24929125607013702,
          null,
          0.77921462059021,
          -0.03981778770685196,
          null,
          0.77921462059021,
          0.06836844235658646,
          null,
          -0.44848594069480896,
          -0.3748640716075897,
          null,
          -0.44848594069480896,
          1.2278838157653809,
          null,
          -0.24551264941692352,
          -0.42359447479248047,
          null,
          -0.24929125607013702,
          -0.42359447479248047,
          null,
          -0.2065650075674057,
          -0.39676856994628906,
          null,
          0.77921462059021,
          -0.03981778770685196,
          null,
          0.77921462059021,
          -0.3644024729728699,
          null,
          0.77921462059021,
          -0.22491301596164703,
          null,
          0.77921462059021,
          -0.30490225553512573,
          null,
          0.77921462059021,
          -0.3763519823551178,
          null,
          0.77921462059021,
          -0.1563851684331894,
          null,
          -0.31647583842277527,
          -0.3132747411727905,
          null,
          -0.31647583842277527,
          -0.18511761724948883,
          null,
          -0.41428881883621216,
          -0.3132747411727905,
          null,
          -0.41428881883621216,
          -0.18511761724948883,
          null,
          -0.3465925455093384,
          -0.18511761724948883,
          null,
          -0.3644024729728699,
          -0.18511761724948883,
          null,
          -0.22491301596164703,
          -0.18511761724948883,
          null,
          -0.320833295583725,
          -0.4435606598854065,
          null,
          -0.3518505394458771,
          -0.40711623430252075,
          null,
          -0.3518505394458771,
          -0.438457727432251,
          null,
          -0.320833295583725,
          -0.4395645260810852,
          null,
          0.77921462059021,
          -0.3551540672779083,
          null,
          -0.438457727432251,
          -0.3355262279510498,
          null,
          -0.438457727432251,
          -0.44367122650146484,
          null,
          -0.438457727432251,
          -0.25057464838027954,
          null,
          -0.4013250470161438,
          -0.3472999334335327,
          null,
          -0.1563851684331894,
          -0.3472999334335327,
          null,
          1.6799345016479492,
          -0.3825821280479431,
          null,
          -0.19078172743320465,
          -0.3825821280479431,
          null,
          1.6799345016479492,
          -0.43135398626327515,
          null,
          -0.19078172743320465,
          -0.43135398626327515,
          null,
          0.77921462059021,
          -0.16772669553756714,
          null,
          0.77921462059021,
          -0.21676914393901825,
          null,
          -0.438457727432251,
          -0.2813956141471863,
          null,
          -0.11680853366851807,
          -0.4602380394935608,
          null,
          -0.39078325033187866,
          -0.4602380394935608,
          null,
          -0.3145896792411804,
          -0.4602380394935608,
          null,
          -0.11680853366851807,
          -0.2536211311817169,
          null,
          -0.39078325033187866,
          -0.2536211311817169,
          null,
          -0.3145896792411804,
          -0.2536211311817169,
          null,
          -0.11680853366851807,
          -0.3636963665485382,
          null,
          -0.39078325033187866,
          -0.3636963665485382,
          null,
          -0.3145896792411804,
          -0.3636963665485382,
          null,
          -0.19078172743320465,
          -0.40493643283843994,
          null,
          -0.19078172743320465,
          -0.39676856994628906,
          null,
          0.77921462059021,
          -0.18713244795799255,
          null,
          0.77921462059021,
          -0.25057464838027954,
          null,
          0.77921462059021,
          -0.20611241459846497,
          null,
          -0.19647401571273804,
          -0.4526509642601013,
          null,
          -0.19647401571273804,
          -0.1563851684331894,
          null,
          -0.19647401571273804,
          -0.4013250470161438,
          null,
          0.77921462059021,
          -0.24215251207351685,
          null,
          0.77921462059021,
          -0.44848594069480896,
          null,
          -0.438457727432251,
          -0.36755189299583435,
          null,
          -0.438457727432251,
          0.03513864800333977,
          null,
          -0.15461517870426178,
          -0.39087748527526855,
          null,
          -0.15461517870426178,
          3.6365485191345215,
          null,
          -0.33217790722846985,
          -0.2924654185771942,
          null,
          0.77921462059021,
          -0.44350484013557434,
          null,
          1.201676368713379,
          -0.20678871870040894,
          null,
          1.201676368713379,
          -0.11836996674537659,
          null,
          -0.336235910654068,
          -0.4442349970340729,
          null,
          -0.4280901551246643,
          -0.29411807656288147,
          null,
          -0.4280901551246643,
          -0.36189407110214233,
          null,
          -0.4280901551246643,
          -0.3858230710029602,
          null,
          -0.4280901551246643,
          -0.39528247714042664,
          null,
          -0.14433220028877258,
          2.450235605239868,
          null,
          -0.19078172743320465,
          2.450235605239868,
          null,
          -0.336235910654068,
          2.450235605239868,
          null,
          -0.14433220028877258,
          -0.4476192593574524,
          null,
          -0.19078172743320465,
          -0.4476192593574524,
          null,
          -0.336235910654068,
          -0.4476192593574524,
          null,
          -0.21130487322807312,
          -0.41495630145072937,
          null,
          -0.19027727842330933,
          -0.39501020312309265,
          null,
          -0.19027727842330933,
          -0.18713244795799255,
          null,
          -0.19027727842330933,
          -0.25057464838027954,
          null,
          -0.19027727842330933,
          -0.20611241459846497,
          null,
          0.77921462059021,
          -0.18713244795799255,
          null,
          0.77921462059021,
          -0.25057464838027954,
          null,
          0.77921462059021,
          -0.20611241459846497,
          null,
          0.77921462059021,
          -0.47625499963760376,
          null,
          -0.44848594069480896,
          -0.2961190342903137,
          null,
          -0.18713244795799255,
          -0.24309520423412323,
          null,
          -0.25057464838027954,
          -0.24309520423412323,
          null,
          -0.20611241459846497,
          -0.24309520423412323,
          null,
          -0.19078172743320465,
          -0.4339887499809265,
          null,
          -0.19078172743320465,
          -0.14433220028877258,
          null,
          -0.19078172743320465,
          -0.19078172743320465,
          null,
          -0.19078172743320465,
          -0.336235910654068,
          null,
          0.77921462059021,
          -0.427303671836853,
          null,
          -0.1693044751882553,
          -0.3897252380847931,
          null,
          -0.1693044751882553,
          3.2170605659484863,
          null,
          -0.26647070050239563,
          -0.44165608286857605,
          null,
          -0.26647070050239563,
          -0.3222001791000366,
          null,
          -0.3455379605293274,
          -0.1693044751882553,
          null,
          -0.3455379605293274,
          -0.47152188420295715,
          null,
          -0.3455379605293274,
          -0.2894885838031769,
          null,
          -0.19078172743320465,
          -0.39074358344078064,
          null,
          -0.19756096601486206,
          -0.4606528580188751,
          null,
          -0.19756096601486206,
          -0.19078172743320465,
          null,
          0.5669098496437073,
          -0.42158243060112,
          null,
          -0.21248289942741394,
          -0.2878672480583191,
          null,
          -0.21248289942741394,
          -0.46045050024986267,
          null,
          -0.3524651825428009,
          -0.4268761873245239,
          null,
          -0.3626464307308197,
          -0.4013250470161438,
          null,
          -0.3626464307308197,
          -0.1563851684331894,
          null,
          -0.19027727842330933,
          -0.28517934679985046,
          null,
          -0.1563851684331894,
          -0.2726221978664398,
          null,
          -0.4013250470161438,
          -0.2726221978664398,
          null,
          -0.1563851684331894,
          -0.39288923144340515,
          null,
          -0.1563851684331894,
          -0.18555043637752533,
          null,
          -0.4013250470161438,
          -0.39288923144340515,
          null,
          -0.4013250470161438,
          -0.18555043637752533,
          null,
          -0.4444885551929474,
          -0.4118274748325348,
          null,
          2.9535293579101562,
          -0.24584197998046875,
          null,
          2.9535293579101562,
          1.6513246297836304,
          null,
          0.0621141716837883,
          -0.41075989603996277,
          null,
          -0.22581976652145386,
          -0.41075989603996277,
          null,
          -0.22581976652145386,
          -0.4933568835258484,
          null,
          -0.2686671018600464,
          -0.4933568835258484,
          null,
          0.77921462059021,
          -0.4013250470161438,
          null,
          0.77921462059021,
          -0.1563851684331894,
          null,
          0.77921462059021,
          -0.29411807656288147,
          null,
          0.77921462059021,
          -0.36189407110214233,
          null,
          -0.33044224977493286,
          -0.4112301170825958,
          null,
          -0.33044224977493286,
          -0.19078172743320465,
          null,
          -0.14172573387622833,
          -0.46435534954071045,
          null,
          -0.4023062288761139,
          -0.46435534954071045,
          null,
          -0.14172573387622833,
          -0.44581183791160583,
          null,
          -0.4023062288761139,
          -0.44581183791160583,
          null,
          0.77921462059021,
          -0.3837509751319885,
          null,
          -0.15461517870426178,
          -0.3935699164867401,
          null,
          -0.15461517870426178,
          -0.4013250470161438,
          null,
          -0.15461517870426178,
          -0.1563851684331894,
          null,
          0.77921462059021,
          2.450235605239868,
          null,
          -0.18713244795799255,
          -0.09295151382684708,
          null,
          -0.25057464838027954,
          -0.09295151382684708,
          null,
          -0.20611241459846497,
          -0.09295151382684708,
          null,
          -0.18713244795799255,
          -0.10157553106546402,
          null,
          -0.25057464838027954,
          -0.10157553106546402,
          null,
          -0.20611241459846497,
          -0.10157553106546402,
          null,
          0.77921462059021,
          -0.22848264873027802,
          null,
          -0.4316566288471222,
          -0.3269636929035187,
          null,
          -0.4082096815109253,
          -0.3269636929035187,
          null,
          -0.4013250470161438,
          -0.2181958705186844,
          null,
          -0.1563851684331894,
          -0.2181958705186844,
          null,
          -0.35716545581817627,
          -0.4013250470161438,
          null,
          -0.2719423770904541,
          -0.17755120992660522,
          null,
          -0.1790398508310318,
          -0.3394008278846741,
          null,
          -0.2530515789985657,
          -0.19078172743320465,
          null,
          -0.22173690795898438,
          -0.4013250470161438,
          null,
          -0.38908207416534424,
          -0.4316566288471222,
          null,
          -0.11680853366851807,
          -0.462936133146286,
          null,
          -0.39078325033187866,
          -0.462936133146286,
          null,
          -0.3145896792411804,
          -0.462936133146286,
          null,
          -0.2741954028606415,
          -0.4013250470161438,
          null,
          -0.31682345271110535,
          -0.14433220028877258,
          null,
          -0.11680853366851807,
          -0.45638954639434814,
          null,
          -0.39078325033187866,
          -0.45638954639434814,
          null,
          -0.3145896792411804,
          -0.45638954639434814,
          null,
          -0.2849453091621399,
          -0.3145896792411804,
          null,
          -0.1816958487033844,
          -0.4009389877319336,
          null,
          -0.1816958487033844,
          -0.44848594069480896,
          null,
          -0.1816958487033844,
          -0.3145896792411804,
          null,
          -0.38141024112701416,
          -0.4294705390930176,
          null,
          -0.4050523638725281,
          -0.3145896792411804,
          null,
          -0.40264517068862915,
          -0.29189473390579224,
          null,
          -0.12380795180797577,
          0.5345343947410583,
          null,
          -0.1520339548587799,
          -0.3428748548030853,
          null,
          -0.3428748548030853,
          -0.11184483766555786,
          null,
          -0.3977019786834717,
          -0.3290537893772125,
          null,
          -0.22848264873027802,
          -0.37661755084991455,
          null,
          -0.38340887427330017,
          -0.3025570213794708,
          null,
          -0.4063625931739807,
          -0.18713244795799255,
          null,
          -0.4063625931739807,
          -0.1520339548587799,
          null,
          -0.1520339548587799,
          -0.3216798007488251,
          null,
          -0.27802595496177673,
          -0.5191138982772827,
          null,
          -0.37930062413215637,
          -0.19078172743320465,
          null,
          -0.2382820099592209,
          -0.4013250470161438,
          null,
          -0.4079287350177765,
          -0.4013250470161438,
          null,
          -0.19078172743320465,
          -0.25339505076408386,
          null,
          -0.19078172743320465,
          1.6463334560394287,
          null,
          -0.19078172743320465,
          -0.3745192289352417,
          null,
          -0.3289012610912323,
          0.5607339143753052,
          null,
          -0.2341119349002838,
          -0.4644649624824524,
          null,
          -0.4316566288471222,
          -0.45081573724746704,
          null,
          -0.4082096815109253,
          -0.45081573724746704,
          null,
          -0.24309520423412323,
          -0.40609073638916016,
          null,
          -0.2868480980396271,
          -0.38419967889785767,
          null,
          -0.4214174449443817,
          -0.3269636929035187,
          null,
          -0.3269636929035187,
          -0.22848264873027802,
          null,
          -0.22173690795898438,
          -0.32044652104377747,
          null,
          -0.36380571126937866,
          -0.33070212602615356,
          null,
          -0.33070212602615356,
          -0.22274990379810333,
          null,
          -0.38119739294052124,
          -0.19078172743320465,
          null,
          -0.4557967483997345,
          -0.19078172743320465,
          null,
          -0.3967806398868561,
          -0.294003963470459,
          null,
          -0.37033331394195557,
          -0.462936133146286,
          null,
          -0.23898346722126007,
          -0.294003963470459,
          null,
          -0.3882427215576172,
          -0.41491127014160156,
          null,
          -0.3754117488861084,
          -0.44581183791160583,
          null,
          -0.27948060631752014,
          -0.37454313039779663,
          null,
          -0.24813072383403778,
          -0.37454313039779663,
          null,
          -0.23057080805301666,
          -0.22173690795898438,
          null,
          4.052042484283447,
          -0.11680853366851807,
          null,
          -0.11680853366851807,
          -0.4330805838108063,
          null,
          -0.39078325033187866,
          -0.4330805838108063,
          null,
          -0.3145896792411804,
          -0.4330805838108063,
          null,
          -0.11680853366851807,
          -0.38678157329559326,
          null,
          -0.39078325033187866,
          -0.38678157329559326,
          null,
          -0.3145896792411804,
          -0.38678157329559326,
          null,
          -0.2813604772090912,
          2.5981833934783936,
          null,
          -0.2813604772090912,
          2.6841495037078857,
          null,
          -0.2065650075674057,
          -0.42798566818237305,
          null,
          -0.3146917521953583,
          -0.2121078372001648,
          null,
          -0.4118274748325348,
          -0.2121078372001648,
          null,
          -0.35606247186660767,
          -0.2121078372001648,
          null,
          -0.27001774311065674,
          -0.4013250470161438,
          null,
          -0.3146917521953583,
          -0.37454313039779663,
          null,
          -0.4118274748325348,
          -0.37454313039779663,
          null,
          -0.35606247186660767,
          -0.37454313039779663,
          null,
          -0.4155997335910797,
          -0.4013250470161438,
          null,
          -0.2265467345714569,
          0.981150209903717,
          null,
          -0.32655760645866394,
          -0.3286322057247162,
          null,
          0.19688217341899872,
          -0.1563851684331894,
          null,
          -0.2040061354637146,
          0.20268774032592773,
          null,
          0.20268774032592773,
          -0.3763519823551178,
          null,
          -0.2566058933734894,
          -0.04647110775113106,
          null,
          -0.22054865956306458,
          -0.04647110775113106,
          null,
          -0.4934520721435547,
          -0.3763519823551178,
          null,
          -0.2065650075674057,
          -0.1563851684331894,
          null,
          -0.4002639055252075,
          -0.11680853366851807,
          null,
          -0.11680853366851807,
          -0.3763519823551178,
          null,
          -0.39078325033187866,
          -0.3763519823551178,
          null,
          -0.3145896792411804,
          -0.3763519823551178,
          null,
          -0.39148107171058655,
          -0.4064701497554779,
          null,
          -0.22729657590389252,
          -0.18713244795799255,
          null,
          -0.4013250470161438,
          -0.3966740369796753,
          null,
          -0.1563851684331894,
          -0.3966740369796753,
          null,
          -0.2849453091621399,
          -0.2265467345714569,
          null,
          -0.4215938150882721,
          -0.4082096815109253,
          null,
          -0.2849453091621399,
          -0.4795970916748047,
          null,
          -0.26713827252388,
          -0.35738545656204224,
          null,
          -0.2849453091621399,
          -0.3763519823551178,
          null,
          -0.2849453091621399,
          -0.30490225553512573,
          null,
          -0.3757368326187134,
          -0.1563851684331894,
          null,
          0.7856631875038147,
          -0.37489399313926697,
          null,
          -0.39501020312309265,
          -0.4013250470161438,
          null,
          -0.3589669167995453,
          -0.20658208429813385,
          null,
          -0.2382820099592209,
          -0.1563851684331894,
          null,
          -0.4079287350177765,
          -0.1563851684331894,
          null,
          -0.2382820099592209,
          -0.4280901551246643,
          null,
          -0.4079287350177765,
          -0.4280901551246643,
          null,
          -0.30490225553512573,
          -0.4013250470161438,
          null,
          2.7742249965667725,
          -0.3465925455093384,
          null,
          3.719235897064209,
          -0.3465925455093384,
          null,
          -0.24204786121845245,
          -0.11813946068286896,
          null,
          -0.3132747411727905,
          -0.37592166662216187,
          null,
          -0.36820024251937866,
          -0.15014944970607758,
          null,
          -0.4318200349807739,
          -0.30923208594322205,
          null,
          -0.28719577193260193,
          -0.4312690496444702,
          null,
          -0.3826235830783844,
          -0.20981112122535706,
          null,
          -0.17201104760169983,
          -0.3989904820919037,
          null,
          -0.3914228081703186,
          -0.4442349970340729,
          null,
          -0.4328012764453888,
          -0.4442349970340729,
          null,
          -0.22274990379810333,
          -0.4531129002571106,
          null,
          -0.3551577031612396,
          -0.4531129002571106,
          null,
          0.7856631875038147,
          -0.4013250470161438,
          null,
          -0.11680853366851807,
          -0.37489399313926697,
          null,
          -0.39078325033187866,
          -0.37489399313926697,
          null,
          -0.3145896792411804,
          -0.37489399313926697,
          null,
          -0.17201104760169983,
          -0.44734129309654236,
          null,
          -0.38678157329559326,
          -0.4022720456123352,
          null,
          -0.4354811906814575,
          -0.4022720456123352,
          null,
          -0.2065650075674057,
          2.732795238494873,
          null,
          -0.23057080805301666,
          -0.3858230710029602,
          null,
          -0.3858230710029602,
          -0.1563851684331894,
          null,
          -0.11680853366851807,
          -0.4013250470161438,
          null,
          -0.39078325033187866,
          -0.4013250470161438,
          null,
          -0.3145896792411804,
          -0.4013250470161438,
          null,
          -0.3863222301006317,
          -0.44961288571357727,
          null,
          -0.3003368079662323,
          -0.1563851684331894,
          null,
          0.24069277942180634,
          -0.203455850481987,
          null,
          -0.203455850481987,
          -0.20983630418777466,
          null,
          -0.24551264941692352,
          -0.3826235830783844,
          null,
          -0.24929125607013702,
          -0.3826235830783844,
          null,
          -0.372873455286026,
          -0.39288923144340515,
          null,
          -0.18555043637752533,
          -0.1404333859682083,
          null,
          -0.1816958487033844,
          -0.3858230710029602,
          null,
          -0.1816958487033844,
          -0.4013250470161438,
          null,
          -0.1816958487033844,
          -0.1563851684331894,
          null,
          -0.23898346722126007,
          -0.11680853366851807,
          null,
          -0.11680853366851807,
          -0.1563851684331894,
          null,
          -0.39078325033187866,
          -0.1563851684331894,
          null,
          -0.3145896792411804,
          -0.1563851684331894,
          null,
          -0.06245706230401993,
          -0.3873838484287262,
          null,
          -0.4717462360858917,
          -0.4013250470161438,
          null,
          -0.31754422187805176,
          -0.4013250470161438,
          null,
          -0.4334908425807953,
          -0.1563851684331894,
          null,
          -0.22472740709781647,
          -0.1563851684331894,
          null,
          -0.38803616166114807,
          -0.21245864033699036,
          null,
          -0.21245864033699036,
          -0.3492552638053894,
          null,
          -0.3914957046508789,
          -0.24929125607013702,
          null,
          -0.2566664516925812,
          -0.19783899188041687,
          null,
          -0.3953375518321991,
          -0.34479615092277527,
          null,
          0.18637502193450928,
          -0.4151816666126251,
          null,
          0.7856631875038147,
          1.0860406160354614,
          null,
          -0.4316566288471222,
          -0.3311408758163452,
          null,
          -0.4082096815109253,
          -0.3311408758163452,
          null,
          -0.2563638389110565,
          0.05558530613780022,
          null,
          -0.2563638389110565,
          -0.13196995854377747,
          null,
          -0.30490225553512573,
          -0.44848594069480896,
          null,
          2.4730043411254883,
          0.981150209903717,
          null,
          -0.37775132060050964,
          0.981150209903717,
          null,
          -0.2563638389110565,
          1.0860406160354614,
          null,
          -0.40182849764823914,
          -0.38246214389801025,
          null,
          -0.4448050558567047,
          -0.30923208594322205,
          null,
          -0.4366864860057831,
          -0.30923208594322205,
          null,
          -0.4366864860057831,
          -0.20981112122535706,
          null,
          -0.4448050558567047,
          -0.24787285923957825,
          null,
          -0.4366864860057831,
          -0.24787285923957825,
          null,
          -0.3914228081703186,
          -0.34494277834892273,
          null,
          -0.4328012764453888,
          -0.34494277834892273,
          null,
          -0.11680853366851807,
          -0.44848594069480896,
          null,
          -0.39078325033187866,
          -0.44848594069480896,
          null,
          -0.3145896792411804,
          -0.44848594069480896,
          null,
          -0.22764956951141357,
          -0.4009389877319336,
          null,
          -0.22764956951141357,
          -0.3145896792411804,
          null,
          0.4931749105453491,
          -0.372873455286026,
          null,
          -0.2849453091621399,
          -0.34494277834892273,
          null,
          -0.11680853366851807,
          -0.20804035663604736,
          null,
          -0.39078325033187866,
          -0.20804035663604736,
          null,
          -0.3145896792411804,
          -0.20804035663604736,
          null,
          -0.2065650075674057,
          -0.4215370714664459,
          null,
          0.9513493180274963,
          -0.34995973110198975,
          null,
          -0.1785692721605301,
          -0.3044790029525757,
          null,
          -0.11680853366851807,
          -0.3145896792411804,
          null,
          -0.39078325033187866,
          -0.3145896792411804,
          null,
          -0.3145896792411804,
          -0.3145896792411804,
          null,
          -0.11680853366851807,
          1.0708444118499756,
          null,
          -0.39078325033187866,
          1.0708444118499756,
          null,
          -0.3145896792411804,
          1.0708444118499756,
          null,
          -0.4009389877319336,
          -0.3311408758163452,
          null,
          -0.2536211311817169,
          -0.47899293899536133,
          null,
          -0.44642961025238037,
          -0.3145896792411804,
          null,
          -0.2274320423603058,
          -0.20874062180519104,
          null,
          -0.24551264941692352,
          -0.3763519823551178,
          null,
          -0.24929125607013702,
          -0.3763519823551178,
          null,
          -0.24551264941692352,
          -0.3632795214653015,
          null,
          -0.24929125607013702,
          -0.3632795214653015,
          null,
          -0.3614845275878906,
          -0.336235910654068,
          null,
          -0.26513004302978516,
          -0.11680853366851807,
          null,
          -0.1781844049692154,
          1.0013710260391235,
          null,
          -0.39288923144340515,
          -0.3785509467124939,
          null,
          -0.18555043637752533,
          -0.3785509467124939,
          null,
          -0.21397796273231506,
          -0.33428955078125,
          null,
          -0.4788881242275238,
          -0.3354363441467285,
          null,
          -0.13203363120555878,
          -0.2612731158733368,
          null,
          -0.3172403573989868,
          -0.2075643092393875,
          null,
          3.3704569339752197,
          -0.36677849292755127,
          null,
          -0.43539953231811523,
          -0.37071335315704346,
          null,
          -0.4772302806377411,
          3.2170605659484863,
          null,
          0.04129659757018089,
          0.5529747009277344,
          null,
          -0.3782137632369995,
          0.233501598238945,
          null,
          3.719896078109741,
          0.33335989713668823,
          null,
          3.7893331050872803,
          0.33335989713668823,
          null,
          -0.37889471650123596,
          -0.3543994128704071,
          null,
          -0.4282054901123047,
          -0.3543994128704071,
          null,
          -0.4282054901123047,
          -0.29590103030204773,
          null,
          2.9943063259124756,
          2.7619822025299072,
          null,
          3.8342480659484863,
          0.14932763576507568,
          null,
          3.6091411113739014,
          0.157850444316864,
          null,
          -0.36354753375053406,
          2.4416439533233643,
          null,
          0.5173392295837402,
          -0.18827500939369202,
          null,
          0.8727547526359558,
          3.1473608016967773,
          null,
          -0.13887380063533783,
          -0.38663390278816223,
          null,
          0.9681019186973572,
          -0.3149547278881073,
          null,
          -0.024762006476521492,
          -0.02130325697362423,
          null,
          3.0325276851654053,
          1.400133490562439,
          null,
          3.109830141067505,
          1.400133490562439,
          null,
          5.133536338806152,
          -0.16589471697807312,
          null,
          5.1554646492004395,
          -0.16589471697807312,
          null,
          -0.3809400796890259,
          -0.17755120992660522,
          null,
          -0.4266420602798462,
          -0.29576537013053894,
          null,
          -0.24247343838214874,
          -0.4602380394935608,
          null,
          -0.45186349749565125,
          -0.19647401571273804,
          null,
          -0.45132964849472046,
          -0.25440406799316406,
          null,
          -0.20838013291358948,
          -0.11680853366851807,
          null,
          -0.1563851684331894,
          -0.336235910654068,
          null,
          -0.4013250470161438,
          -0.336235910654068,
          null,
          -0.42943885922431946,
          -0.336235910654068,
          null,
          2.4730043411254883,
          -0.19647401571273804,
          null,
          -0.37775132060050964,
          -0.19647401571273804,
          null,
          -0.3526751697063446,
          -0.331317275762558,
          null,
          -0.24551264941692352,
          -0.36644238233566284,
          null,
          -0.24929125607013702,
          -0.36644238233566284,
          null,
          -0.24929125607013702,
          0.38434505462646484,
          null,
          -0.22491301596164703,
          -0.2015811800956726,
          null,
          -0.2203851044178009,
          -0.2015811800956726,
          null,
          -0.24551264941692352,
          -0.03981778770685196,
          null,
          -0.24929125607013702,
          -0.03981778770685196,
          null,
          -0.20057038962841034,
          -0.4013250470161438,
          null,
          -0.23073787987232208,
          -0.20658208429813385,
          null,
          -0.37026843428611755,
          -0.24309520423412323,
          null,
          -0.37809693813323975,
          -0.19647401571273804,
          null,
          -0.32609793543815613,
          -0.20797963440418243,
          null,
          -0.3228030502796173,
          -0.18713244795799255,
          null,
          -0.2065650075674057,
          -0.39676856994628906,
          null,
          -0.256418377161026,
          -0.3943283259868622,
          null,
          -0.4049573838710785,
          -0.20490533113479614,
          null,
          -0.4531129002571106,
          -0.23261812329292297,
          null,
          -0.28421661257743835,
          3.2222323417663574,
          null,
          -0.24309520423412323,
          -0.10543763637542725,
          null,
          -0.3343993127346039,
          -0.11680853366851807,
          null,
          -0.11680853366851807,
          -0.23261812329292297,
          null,
          -0.39078325033187866,
          -0.23261812329292297,
          null,
          -0.3145896792411804,
          -0.23261812329292297,
          null,
          -0.48330581188201904,
          -0.18713244795799255,
          null,
          -0.44367122650146484,
          -0.18713244795799255,
          null,
          -0.25057464838027954,
          -0.18713244795799255,
          null,
          -0.25057464838027954,
          -0.4198969006538391,
          null,
          -0.4198969006538391,
          -0.28206610679626465,
          null,
          -0.3937024772167206,
          -0.18713244795799255,
          null,
          -0.46685072779655457,
          -0.19078172743320465,
          null,
          -0.36755189299583435,
          -0.4013250470161438,
          null,
          -0.2065650075674057,
          -0.24857307970523834,
          null,
          -0.2065650075674057,
          -0.4670450985431671,
          null,
          -0.2065650075674057,
          -0.44848594069480896,
          null,
          -0.2719423770904541,
          -0.33555471897125244,
          null,
          -0.39728283882141113,
          -0.42860105633735657,
          null,
          -0.4410001039505005,
          -0.42860105633735657,
          null,
          -0.46851131319999695,
          -0.18713244795799255,
          null,
          -0.25057464838027954,
          -0.4198969006538391,
          null,
          -0.21504180133342743,
          -0.14433220028877258,
          null,
          -0.3920506536960602,
          -0.19078172743320465,
          null,
          -0.38663390278816223,
          -0.38447585701942444,
          null,
          -0.46851131319999695,
          -0.19027727842330933,
          null,
          -0.25647208094596863,
          -0.19078172743320465,
          null,
          -0.440655916929245,
          -0.30277499556541443,
          null,
          -0.3858230710029602,
          -0.4013250470161438,
          null,
          -0.3879346549510956,
          -0.2687675356864929,
          null,
          -0.3146917521953583,
          -0.41491127014160156,
          null,
          -0.4118274748325348,
          -0.41491127014160156,
          null,
          -0.35606247186660767,
          -0.41491127014160156,
          null,
          -0.4118274748325348,
          -0.38419967889785767,
          null,
          -0.40094128251075745,
          -0.19647401571273804,
          null,
          -0.3463955223560333,
          -0.19647401571273804,
          null,
          -0.20490533113479614,
          -0.19647401571273804,
          null,
          -0.40094128251075745,
          -0.18713244795799255,
          null,
          -0.3463955223560333,
          -0.18713244795799255,
          null,
          -0.20490533113479614,
          -0.18713244795799255,
          null,
          -0.20490533113479614,
          -0.2144104391336441,
          null,
          -0.18713244795799255,
          -0.2144104391336441,
          null,
          -0.2144104391336441,
          -0.19078172743320465,
          null,
          -0.23677243292331696,
          -0.33933448791503906,
          null,
          -0.32609793543815613,
          -0.19647401571273804,
          null,
          -0.3983023762702942,
          2.4730043411254883,
          null,
          -0.25734367966651917,
          3.1300723552703857,
          null,
          3.1300723552703857,
          -0.33717072010040283,
          null,
          3.199669122695923,
          -0.33717072010040283,
          null,
          3.199669122695923,
          -0.3977019786834717,
          null,
          -0.088998943567276,
          -0.37282073497772217,
          null,
          2.8535916805267334,
          -0.3463955223560333,
          null,
          2.8535916805267334,
          0.0621141716837883,
          null,
          -0.19078172743320465,
          -0.18713244795799255,
          null,
          -0.33840781450271606,
          -0.1520339548587799,
          null,
          -0.1520339548587799,
          -0.387966513633728,
          null,
          -0.12146300077438354,
          -0.40659335255622864,
          null,
          -0.3194373846054077,
          -0.18713244795799255,
          null,
          -0.24551264941692352,
          -0.4389159381389618,
          null,
          -0.24929125607013702,
          -0.4389159381389618,
          null,
          -0.46851131319999695,
          -0.18713244795799255,
          null,
          -0.24551264941692352,
          -0.19078172743320465,
          null,
          -0.24929125607013702,
          -0.19078172743320465,
          null,
          -0.46851131319999695,
          -0.25219476222991943,
          null,
          -0.459083616733551,
          -0.18713244795799255,
          null,
          -0.2366710752248764,
          -0.18713244795799255,
          null,
          -0.22429904341697693,
          -0.18713244795799255,
          null,
          -0.2366710752248764,
          -0.34781262278556824,
          null,
          -0.22429904341697693,
          -0.34781262278556824,
          null,
          -0.22445626556873322,
          2.4730043411254883,
          null,
          2.4730043411254883,
          2.6596386432647705,
          null,
          -0.37775132060050964,
          2.6596386432647705,
          null,
          2.4730043411254883,
          3.2727842330932617,
          null,
          -0.37775132060050964,
          3.2727842330932617,
          null,
          -0.47925442457199097,
          -0.44848594069480896,
          null,
          -0.3971827030181885,
          -0.22780567407608032,
          null,
          -0.2065650075674057,
          -0.18713244795799255,
          null,
          -0.3998945653438568,
          -0.20490533113479614,
          null,
          -0.30617713928222656,
          -0.3858230710029602,
          null,
          -0.3355262279510498,
          -0.4531129002571106,
          null,
          -0.28375157713890076,
          -0.4531129002571106,
          null,
          -0.22675921022891998,
          5.2661519050598145,
          null,
          -0.14662082493305206,
          -0.4531129002571106,
          null,
          -0.3837820291519165,
          -0.4531129002571106,
          null,
          -0.40325528383255005,
          -0.3713628649711609,
          null,
          -0.3713628649711609,
          -0.44848594069480896,
          null,
          -0.24551264941692352,
          1.400133490562439,
          null,
          -0.24929125607013702,
          1.400133490562439,
          null,
          -0.24551264941692352,
          -0.42359447479248047,
          null,
          -0.24929125607013702,
          -0.42359447479248047,
          null,
          -0.03981778770685196,
          -0.37008407711982727,
          null,
          -0.3465925455093384,
          -0.37489399313926697,
          null,
          -0.3644024729728699,
          -0.37489399313926697,
          null,
          -0.22491301596164703,
          -0.37489399313926697,
          null,
          -0.3355262279510498,
          -0.38319599628448486,
          null,
          -0.30490225553512573,
          -0.3763519823551178,
          null,
          -0.3132747411727905,
          -0.18511761724948883,
          null,
          -0.26964008808135986,
          -0.11393105983734131,
          null,
          -0.3355262279510498,
          -0.44367122650146484,
          null,
          -0.22764956951141357,
          -0.23261812329292297,
          null,
          -0.3355262279510498,
          -0.22765986621379852,
          null,
          -0.3355262279510498,
          -0.38971206545829773,
          null,
          -0.16772669553756714,
          -0.21676914393901825,
          null,
          -0.21676914393901825,
          -0.3162766396999359,
          null,
          -0.2813956141471863,
          -0.44367122650146484,
          null,
          -0.11680853366851807,
          -0.4602380394935608,
          null,
          -0.39078325033187866,
          -0.4602380394935608,
          null,
          -0.3145896792411804,
          -0.4602380394935608,
          null,
          -0.2536211311817169,
          -0.3636963665485382,
          null,
          -0.27539458870887756,
          -0.20658208429813385,
          null,
          -0.3713628649711609,
          -0.19647401571273804,
          null,
          -0.24215251207351685,
          -0.44848594069480896,
          null,
          -0.36755189299583435,
          0.03513864800333977,
          null,
          -0.20678871870040894,
          -0.11836996674537659,
          null,
          -0.11836996674537659,
          -0.3647884428501129,
          null,
          -0.3647884428501129,
          -0.24329045414924622,
          null,
          -0.038836803287267685,
          -0.11836996674537659,
          null,
          -0.038836803287267685,
          1.201676368713379,
          null,
          -0.00766439363360405,
          -0.11836996674537659,
          null,
          -0.00766439363360405,
          -0.34995973110198975,
          null,
          -0.23632381856441498,
          -0.1386936902999878,
          null,
          -0.23632381856441498,
          -0.20807309448719025,
          null,
          -0.4280901551246643,
          -0.29411807656288147,
          null,
          -0.3858230710029602,
          -0.39528247714042664,
          null,
          -0.3920506536960602,
          -0.47899293899536133,
          null,
          -0.4083673357963562,
          -0.4155884087085724,
          null,
          -0.19137844443321228,
          -0.3171130120754242,
          null,
          -0.39501020312309265,
          -0.18713244795799255,
          null,
          -0.4177006483078003,
          -0.3848789930343628,
          null,
          -0.2568063735961914,
          -0.18713244795799255,
          null,
          -0.3897252380847931,
          3.2170605659484863,
          null,
          -0.22985292971134186,
          -0.39724716544151306,
          null,
          -0.22985292971134186,
          -0.34325161576271057,
          null,
          -0.3455379605293274,
          -0.1693044751882553,
          null,
          -0.47152188420295715,
          -0.2894885838031769,
          null,
          -0.1305273324251175,
          -0.28489190340042114,
          null,
          -0.23898346722126007,
          -0.41115763783454895,
          null,
          -0.4606528580188751,
          -0.19078172743320465,
          null,
          -0.26513004302978516,
          -0.44848594069480896,
          null,
          -0.48571035265922546,
          0.18637502193450928,
          null,
          -0.316644549369812,
          -0.4013250470161438,
          null,
          -0.39171165227890015,
          -0.19078172743320465,
          null,
          -0.22764956951141357,
          -0.3894193470478058,
          null,
          -0.24297906458377838,
          -0.4602380394935608,
          null,
          -0.22731760144233704,
          2.5126051902770996,
          null,
          -0.19078172743320465,
          -0.44297948479652405,
          null,
          -0.2726221978664398,
          -0.39288923144340515,
          null,
          -0.3127136826515198,
          -0.3328269124031067,
          null,
          -0.39171165227890015,
          -0.3925439119338989,
          null,
          -0.4112301170825958,
          -0.19078172743320465,
          null,
          -0.4368841350078583,
          -0.336235910654068,
          null,
          -0.4112301170825958,
          -0.44594207406044006,
          null,
          -0.45638954639434814,
          -0.29411807656288147,
          null,
          -0.45638954639434814,
          -0.4013250470161438,
          null,
          -0.3763519823551178,
          -0.3900507688522339,
          null,
          -0.1563851684331894,
          -0.3900507688522339,
          null,
          -0.3920506536960602,
          -0.44848594069480896,
          null,
          -0.37798136472702026,
          1.6815776824951172,
          null
         ],
         "y": [
          0.025786764919757843,
          -0.35395893454551697,
          null,
          -0.004055174067616463,
          -0.21686099469661713,
          null,
          0.01909026689827442,
          -0.010969303548336029,
          null,
          -0.004055174067616463,
          -0.010969303548336029,
          null,
          -0.034889161586761475,
          -0.010969303548336029,
          null,
          -0.045646458864212036,
          -0.2621665894985199,
          null,
          -0.045646458864212036,
          0.020748844370245934,
          null,
          -0.045646458864212036,
          -0.05356648191809654,
          null,
          -0.286485880613327,
          0.06857658922672272,
          null,
          -0.286485880613327,
          0.28298264741897583,
          null,
          -0.006265833042562008,
          -0.0703418105840683,
          null,
          -0.006265833042562008,
          0.032695524394512177,
          null,
          -1.607568383216858,
          0.03533190116286278,
          null,
          0.008870973251760006,
          0.03533190116286278,
          null,
          -1.607568383216858,
          -0.21256551146507263,
          null,
          0.008870973251760006,
          -0.21256551146507263,
          null,
          -1.607568383216858,
          -0.2543129622936249,
          null,
          0.008870973251760006,
          -0.2543129622936249,
          null,
          -1.607568383216858,
          -0.004055174067616463,
          null,
          0.008870973251760006,
          -0.004055174067616463,
          null,
          -0.004055174067616463,
          -0.028044044971466064,
          null,
          -0.15122954547405243,
          -0.04581945762038231,
          null,
          -0.15122954547405243,
          0.041469138115644455,
          null,
          -0.15122954547405243,
          0.28298264741897583,
          null,
          -0.14388307929039001,
          -0.12376222759485245,
          null,
          0.05888929218053818,
          -0.22032634913921356,
          null,
          0.05888929218053818,
          -0.03206789866089821,
          null,
          0.05888929218053818,
          -0.05566580593585968,
          null,
          0.21943488717079163,
          0.03758803755044937,
          null,
          0.21943488717079163,
          0.041469138115644455,
          null,
          0.21943488717079163,
          0.28298264741897583,
          null,
          0.17035554349422455,
          -0.019056251272559166,
          null,
          0.17035554349422455,
          0.038328785449266434,
          null,
          0.17035554349422455,
          -0.02096337266266346,
          null,
          0.003903429489582777,
          0.06857658922672272,
          null,
          0.003903429489582777,
          0.28298264741897583,
          null,
          -0.04099371284246445,
          0.06857658922672272,
          null,
          -0.04099371284246445,
          0.28298264741897583,
          null,
          0.003903429489582777,
          -0.27481573820114136,
          null,
          -0.04099371284246445,
          -0.27481573820114136,
          null,
          0.01909026689827442,
          0.015975497663021088,
          null,
          0.01909026689827442,
          -0.21463334560394287,
          null,
          -0.004055174067616463,
          0.015975497663021088,
          null,
          -0.004055174067616463,
          -0.21463334560394287,
          null,
          -0.034889161586761475,
          0.015975497663021088,
          null,
          -0.034889161586761475,
          -0.21463334560394287,
          null,
          0.01909026689827442,
          0.041469138115644455,
          null,
          0.01909026689827442,
          0.28298264741897583,
          null,
          -0.004055174067616463,
          0.041469138115644455,
          null,
          -0.004055174067616463,
          0.28298264741897583,
          null,
          -0.034889161586761475,
          0.041469138115644455,
          null,
          -0.034889161586761475,
          0.28298264741897583,
          null,
          -0.004055174067616463,
          0.21512669324874878,
          null,
          0.01909026689827442,
          -0.04099371284246445,
          null,
          -0.004055174067616463,
          -0.04099371284246445,
          null,
          -0.034889161586761475,
          -0.04099371284246445,
          null,
          0.01909026689827442,
          -0.2691917419433594,
          null,
          -0.004055174067616463,
          -0.2691917419433594,
          null,
          -0.034889161586761475,
          -0.2691917419433594,
          null,
          0.01909026689827442,
          -0.1527850478887558,
          null,
          -0.004055174067616463,
          -0.1527850478887558,
          null,
          -0.034889161586761475,
          -0.1527850478887558,
          null,
          0.01909026689827442,
          -0.022000176832079887,
          null,
          -0.004055174067616463,
          -0.022000176832079887,
          null,
          -0.034889161586761475,
          -0.022000176832079887,
          null,
          -0.019056251272559166,
          -0.2322823703289032,
          null,
          0.038328785449266434,
          -0.2322823703289032,
          null,
          -0.02096337266266346,
          -0.2322823703289032,
          null,
          0.1596091240644455,
          -0.17403945326805115,
          null,
          0.1596091240644455,
          -0.256039023399353,
          null,
          0.17035554349422455,
          -0.31574296951293945,
          null,
          0.17035554349422455,
          0.01387202087789774,
          null,
          0.17035554349422455,
          0.047632139176130295,
          null,
          0.17035554349422455,
          -0.30297401547431946,
          null,
          0.17035554349422455,
          0.5013200044631958,
          null,
          0.05671653896570206,
          -0.23463056981563568,
          null,
          0.17035554349422455,
          0.02931520715355873,
          null,
          -0.22373005747795105,
          -0.05566580593585968,
          null,
          0.17035554349422455,
          -0.2885439097881317,
          null,
          0.17035554349422455,
          0.10364661365747452,
          null,
          0.01909026689827442,
          -0.028140997514128685,
          null,
          -0.004055174067616463,
          -0.028140997514128685,
          null,
          -0.034889161586761475,
          -0.028140997514128685,
          null,
          0.01909026689827442,
          0.12966661155223846,
          null,
          -0.004055174067616463,
          0.12966661155223846,
          null,
          -0.034889161586761475,
          0.12966661155223846,
          null,
          0.17035554349422455,
          -0.019056251272559166,
          null,
          0.17035554349422455,
          0.038328785449266434,
          null,
          0.17035554349422455,
          -0.02096337266266346,
          null,
          0.17035554349422455,
          -0.019056251272559166,
          null,
          0.17035554349422455,
          0.038328785449266434,
          null,
          0.17035554349422455,
          -0.02096337266266346,
          null,
          0.17035554349422455,
          -0.31403520703315735,
          null,
          -0.019056251272559166,
          -0.24097102880477905,
          null,
          0.038328785449266434,
          -0.24097102880477905,
          null,
          -0.02096337266266346,
          -0.24097102880477905,
          null,
          -0.019056251272559166,
          0.06594180315732956,
          null,
          0.038328785449266434,
          0.06594180315732956,
          null,
          -0.02096337266266346,
          0.06594180315732956,
          null,
          -0.019056251272559166,
          -0.04956170916557312,
          null,
          0.038328785449266434,
          -0.04956170916557312,
          null,
          -0.02096337266266346,
          -0.04956170916557312,
          null,
          -0.019056251272559166,
          -0.045646458864212036,
          null,
          0.038328785449266434,
          -0.045646458864212036,
          null,
          -0.02096337266266346,
          -0.045646458864212036,
          null,
          0.17035554349422455,
          -0.2828606963157654,
          null,
          0.17035554349422455,
          0.13866564631462097,
          null,
          0.0937369167804718,
          0.041469138115644455,
          null,
          0.0937369167804718,
          0.28298264741897583,
          null,
          -0.019056251272559166,
          0.020748844370245934,
          null,
          -0.019056251272559166,
          -0.05356648191809654,
          null,
          0.038328785449266434,
          0.020748844370245934,
          null,
          0.038328785449266434,
          -0.05356648191809654,
          null,
          -0.02096337266266346,
          0.020748844370245934,
          null,
          -0.02096337266266346,
          -0.05356648191809654,
          null,
          -0.019056251272559166,
          0.02747408114373684,
          null,
          0.038328785449266434,
          0.02747408114373684,
          null,
          -0.02096337266266346,
          0.02747408114373684,
          null,
          0.17035554349422455,
          -0.21878814697265625,
          null,
          0.17035554349422455,
          -0.21463334560394287,
          null,
          0.17035554349422455,
          0.049001339823007584,
          null,
          0.0681150034070015,
          -0.04969558119773865,
          null,
          0.0681150034070015,
          -0.019056251272559166,
          null,
          0.0681150034070015,
          0.038328785449266434,
          null,
          0.0681150034070015,
          -0.02096337266266346,
          null,
          0.17035554349422455,
          0.04510170966386795,
          null,
          0.17035554349422455,
          -0.24950258433818817,
          null,
          -0.2430470734834671,
          -0.0035903577227145433,
          null,
          -0.2430470734834671,
          -0.004055174067616463,
          null,
          -0.2430470734834671,
          0.7365708351135254,
          null,
          0.05483528599143028,
          -0.24313011765480042,
          null,
          0.05483528599143028,
          0.040483515709638596,
          null,
          -0.04600738361477852,
          -0.29279059171676636,
          null,
          -0.04600738361477852,
          0.069027841091156,
          null,
          -0.3545408248901367,
          0.03822929784655571,
          null,
          -0.3552839159965515,
          -0.2643827199935913,
          null,
          -0.0005770963034592569,
          -0.06000417843461037,
          null,
          -0.0005770963034592569,
          -0.2112647145986557,
          null,
          -0.004055174067616463,
          0.03822929784655571,
          null,
          -0.004055174067616463,
          -0.04581945762038231,
          null,
          -0.004055174067616463,
          0.041469138115644455,
          null,
          -0.004055174067616463,
          0.28298264741897583,
          null,
          0.17035554349422455,
          -0.0006804268923588097,
          null,
          0.17035554349422455,
          -1.6525819301605225,
          null,
          0.17035554349422455,
          0.004054530058056116,
          null,
          0.039834823459386826,
          0.02306346781551838,
          null,
          0.039834823459386826,
          -0.03651062771677971,
          null,
          0.041469138115644455,
          0.030737953260540962,
          null,
          0.28298264741897583,
          0.030737953260540962,
          null,
          0.041469138115644455,
          0.06857658922672272,
          null,
          0.041469138115644455,
          0.28298264741897583,
          null,
          0.28298264741897583,
          0.06857658922672272,
          null,
          0.28298264741897583,
          0.28298264741897583,
          null,
          0.11658086627721786,
          -0.04035224765539169,
          null,
          0.11658086627721786,
          -0.2561173737049103,
          null,
          0.023981276899576187,
          0.28298264741897583,
          null,
          0.023981276899576187,
          0.041469138115644455,
          null,
          -0.04600738361477852,
          -0.0054327622056007385,
          null,
          -0.045442692935466766,
          0.015124216675758362,
          null,
          -0.045442692935466766,
          0.21540409326553345,
          null,
          -0.2690351605415344,
          -0.24056832492351532,
          null,
          -0.2690351605415344,
          -0.05525379255414009,
          null,
          -0.17362235486507416,
          -0.2038835883140564,
          null,
          -0.24674858152866364,
          -0.22032634913921356,
          null,
          -0.24674858152866364,
          -0.03206789866089821,
          null,
          -0.24674858152866364,
          -0.05566580593585968,
          null,
          0.023981276899576187,
          -0.2409781813621521,
          null,
          0.023981276899576187,
          -0.08106835186481476,
          null,
          0.17035554349422455,
          -0.24840106070041656,
          null,
          0.17035554349422455,
          0.33740970492362976,
          null,
          0.17035554349422455,
          -0.004363990388810635,
          null,
          0.05671653896570206,
          0.040996260941028595,
          null,
          0.05671653896570206,
          0.03758803755044937,
          null,
          0.03713188320398331,
          -0.15776963531970978,
          null,
          0.0023724501952528954,
          -0.22032634913921356,
          null,
          0.0023724501952528954,
          -0.03206789866089821,
          null,
          0.0023724501952528954,
          -0.05566580593585968,
          null,
          0.0023724501952528954,
          0.04788525402545929,
          null,
          -0.29285821318626404,
          0.01909026689827442,
          null,
          -0.29285821318626404,
          -0.004055174067616463,
          null,
          -0.29285821318626404,
          -0.034889161586761475,
          null,
          0.05671653896570206,
          -0.15991617739200592,
          null,
          0.05671653896570206,
          -0.004055174067616463,
          null,
          -0.0183674618601799,
          -0.22032634913921356,
          null,
          -0.0183674618601799,
          -0.03206789866089821,
          null,
          -0.0183674618601799,
          -0.05566580593585968,
          null,
          -0.0183674618601799,
          -0.05525379255414009,
          null,
          0.17035554349422455,
          -0.1875329464673996,
          null,
          0.28298264741897583,
          -0.2833889126777649,
          null,
          0.041469138115644455,
          -0.2833889126777649,
          null,
          0.28298264741897583,
          0.041469138115644455,
          null,
          0.28298264741897583,
          0.28298264741897583,
          null,
          0.041469138115644455,
          0.041469138115644455,
          null,
          0.041469138115644455,
          0.28298264741897583,
          null,
          -0.18840274214744568,
          0.02507065422832966,
          null,
          -0.18840274214744568,
          -0.07698111981153488,
          null,
          -0.013211392797529697,
          -0.1476190835237503,
          null,
          -0.005234670825302601,
          0.015975497663021088,
          null,
          -0.005234670825302601,
          -0.21463334560394287,
          null,
          -0.005234670825302601,
          0.043586041778326035,
          null,
          -0.005234670825302601,
          -0.07698111981153488,
          null,
          0.17035554349422455,
          -0.19988307356834412,
          null,
          0.17035554349422455,
          -0.2531825006008148,
          null,
          0.17035554349422455,
          0.7365708351135254,
          null,
          0.17035554349422455,
          -0.0033910521306097507,
          null,
          0.17035554349422455,
          0.03125517815351486,
          null,
          -0.2963859736919403,
          0.28298264741897583,
          null,
          -0.2963859736919403,
          0.041469138115644455,
          null,
          -0.2963859736919403,
          0.01145707257091999,
          null,
          -0.10523124039173126,
          -0.015157496556639671,
          null,
          -0.10523124039173126,
          -0.08668990433216095,
          null,
          0.03713188320398331,
          0.28298264741897583,
          null,
          0.03713188320398331,
          0.041469138115644455,
          null,
          -0.26808610558509827,
          -0.22032634913921356,
          null,
          -0.26808610558509827,
          -0.03206789866089821,
          null,
          -0.26808610558509827,
          -0.05566580593585968,
          null,
          -0.26808610558509827,
          -0.03206004947423935,
          null,
          -0.26808610558509827,
          0.03305131942033768,
          null,
          0.17035554349422455,
          -0.3398614823818207,
          null,
          0.17035554349422455,
          0.01909026689827442,
          null,
          0.17035554349422455,
          -0.004055174067616463,
          null,
          0.17035554349422455,
          -0.034889161586761475,
          null,
          0.17035554349422455,
          4.491021156311035,
          null,
          0.01909026689827442,
          -0.2968100905418396,
          null,
          -0.004055174067616463,
          -0.2968100905418396,
          null,
          -0.034889161586761475,
          -0.2968100905418396,
          null,
          0.01909026689827442,
          4.477543354034424,
          null,
          -0.004055174067616463,
          4.477543354034424,
          null,
          -0.034889161586761475,
          4.477543354034424,
          null,
          0.01909026689827442,
          0.041469138115644455,
          null,
          0.01909026689827442,
          0.28298264741897583,
          null,
          -0.004055174067616463,
          0.041469138115644455,
          null,
          -0.004055174067616463,
          0.28298264741897583,
          null,
          -0.034889161586761475,
          0.041469138115644455,
          null,
          -0.034889161586761475,
          0.28298264741897583,
          null,
          0.01909026689827442,
          -0.30252885818481445,
          null,
          -0.004055174067616463,
          -0.30252885818481445,
          null,
          -0.034889161586761475,
          -0.30252885818481445,
          null,
          0.01909026689827442,
          0.041469138115644455,
          null,
          0.01909026689827442,
          0.28298264741897583,
          null,
          -0.004055174067616463,
          0.041469138115644455,
          null,
          -0.004055174067616463,
          0.28298264741897583,
          null,
          -0.034889161586761475,
          0.041469138115644455,
          null,
          -0.034889161586761475,
          0.28298264741897583,
          null,
          0.01909026689827442,
          -0.009921276941895485,
          null,
          -0.004055174067616463,
          -0.009921276941895485,
          null,
          -0.034889161586761475,
          -0.009921276941895485,
          null,
          0.01909026689827442,
          0.21943488717079163,
          null,
          -0.004055174067616463,
          0.21943488717079163,
          null,
          -0.034889161586761475,
          0.21943488717079163,
          null,
          0.01909026689827442,
          -0.045646458864212036,
          null,
          -0.004055174067616463,
          -0.045646458864212036,
          null,
          -0.034889161586761475,
          -0.045646458864212036,
          null,
          0.01909026689827442,
          5.2627997398376465,
          null,
          -0.004055174067616463,
          5.2627997398376465,
          null,
          -0.034889161586761475,
          5.2627997398376465,
          null,
          -0.004055174067616463,
          -0.009921276941895485,
          null,
          -0.004055174067616463,
          0.04298051819205284,
          null,
          0.01909026689827442,
          -0.2416340708732605,
          null,
          -0.004055174067616463,
          -0.2416340708732605,
          null,
          -0.034889161586761475,
          -0.2416340708732605,
          null,
          0.01909026689827442,
          -0.2416340708732605,
          null,
          -0.004055174067616463,
          -0.2416340708732605,
          null,
          -0.034889161586761475,
          -0.2416340708732605,
          null,
          -0.21878814697265625,
          0.022204603999853134,
          null,
          -0.21878814697265625,
          0.011530081741511822,
          null,
          -0.07482457160949707,
          0.28298264741897583,
          null,
          -0.07482457160949707,
          0.041469138115644455,
          null,
          0.17035554349422455,
          -0.246806338429451,
          null,
          0.28298264741897583,
          -0.0534442663192749,
          null,
          0.041469138115644455,
          -0.0534442663192749,
          null,
          0.28298264741897583,
          0.041469138115644455,
          null,
          0.28298264741897583,
          0.28298264741897583,
          null,
          0.041469138115644455,
          0.041469138115644455,
          null,
          0.041469138115644455,
          0.28298264741897583,
          null,
          -0.004055174067616463,
          -0.20986460149288177,
          null,
          0.01909026689827442,
          -0.09237980842590332,
          null,
          0.01909026689827442,
          -0.07867467403411865,
          null,
          -0.004055174067616463,
          -0.09237980842590332,
          null,
          -0.004055174067616463,
          -0.07867467403411865,
          null,
          -0.034889161586761475,
          -0.09237980842590332,
          null,
          -0.034889161586761475,
          -0.07867467403411865,
          null,
          0.01909026689827442,
          0.041469138115644455,
          null,
          0.01909026689827442,
          0.28298264741897583,
          null,
          -0.004055174067616463,
          0.041469138115644455,
          null,
          -0.004055174067616463,
          0.28298264741897583,
          null,
          -0.034889161586761475,
          0.041469138115644455,
          null,
          -0.034889161586761475,
          0.28298264741897583,
          null,
          0.07402859628200531,
          -2.165008306503296,
          null,
          0.07402859628200531,
          -0.2974306344985962,
          null,
          -0.31885722279548645,
          0.01909026689827442,
          null,
          -0.31885722279548645,
          -0.004055174067616463,
          null,
          -0.31885722279548645,
          -0.034889161586761475,
          null,
          0.01909026689827442,
          0.012488601729273796,
          null,
          -0.004055174067616463,
          0.012488601729273796,
          null,
          -0.034889161586761475,
          0.012488601729273796,
          null,
          -0.09237980842590332,
          -0.18840274214744568,
          null,
          -0.07867467403411865,
          -0.18840274214744568,
          null,
          0.10430304706096649,
          -0.008512781001627445,
          null,
          0.10430304706096649,
          0.069027841091156,
          null,
          0.011530081741511822,
          0.041469138115644455,
          null,
          0.011530081741511822,
          0.28298264741897583,
          null,
          0.011530081741511822,
          1.9382463693618774,
          null,
          0.011530081741511822,
          -0.3947536051273346,
          null,
          0.17035554349422455,
          -0.12215343862771988,
          null,
          0.05007840320467949,
          -0.03903908655047417,
          null,
          0.17035554349422455,
          -0.2641698718070984,
          null,
          0.17035554349422455,
          -0.05123790726065636,
          null,
          0.17035554349422455,
          0.014502695761620998,
          null,
          0.17035554349422455,
          -0.24759826064109802,
          null,
          0.17035554349422455,
          -0.12349306046962738,
          null,
          0.28298264741897583,
          -0.2604193091392517,
          null,
          0.041469138115644455,
          -0.2604193091392517,
          null,
          -0.18840274214744568,
          0.01972649060189724,
          null,
          -0.18840274214744568,
          0.041469138115644455,
          null,
          -0.18840274214744568,
          0.28298264741897583,
          null,
          0.17035554349422455,
          -0.06787369400262833,
          null,
          0.01909026689827442,
          -0.04190913587808609,
          null,
          -0.004055174067616463,
          -0.04190913587808609,
          null,
          -0.034889161586761475,
          -0.04190913587808609,
          null,
          0.01909026689827442,
          -0.2387964129447937,
          null,
          0.01909026689827442,
          0.03952103108167648,
          null,
          -0.004055174067616463,
          -0.2387964129447937,
          null,
          -0.004055174067616463,
          0.03952103108167648,
          null,
          -0.034889161586761475,
          -0.2387964129447937,
          null,
          -0.034889161586761475,
          0.03952103108167648,
          null,
          -0.26609930396080017,
          -0.21645458042621613,
          null,
          0.17035554349422455,
          -0.19988307356834412,
          null,
          0.17035554349422455,
          -0.2531825006008148,
          null,
          0.17035554349422455,
          -0.2131255865097046,
          null,
          0.17035554349422455,
          0.0822134017944336,
          null,
          0.17035554349422455,
          0.05670206621289253,
          null,
          0.17035554349422455,
          -0.18117621541023254,
          null,
          0.17035554349422455,
          0.08898111432790756,
          null,
          -0.2497459501028061,
          0.022681862115859985,
          null,
          -0.2497459501028061,
          -0.2814645767211914,
          null,
          -0.2497459501028061,
          -0.014005208387970924,
          null,
          -0.22125831246376038,
          -0.09703774750232697,
          null,
          0.17035554349422455,
          -0.2387964129447937,
          null,
          0.17035554349422455,
          0.03952103108167648,
          null,
          0.17035554349422455,
          -0.06787369400262833,
          null,
          0.03713188320398331,
          0.28298264741897583,
          null,
          0.03713188320398331,
          0.041469138115644455,
          null,
          0.04971523955464363,
          0.28298264741897583,
          null,
          0.04971523955464363,
          0.041469138115644455,
          null,
          -0.14432962238788605,
          0.28298264741897583,
          null,
          -0.14432962238788605,
          0.041469138115644455,
          null,
          0.10364661365747452,
          0.28298264741897583,
          null,
          0.10364661365747452,
          0.041469138115644455,
          null,
          -0.5322486162185669,
          -0.057742103934288025,
          null,
          0.23390766978263855,
          -0.2528893053531647,
          null,
          0.23390766978263855,
          -0.14087921380996704,
          null,
          0.17035554349422455,
          -0.2654191255569458,
          null,
          0.17035554349422455,
          0.28298264741897583,
          null,
          0.17035554349422455,
          0.041469138115644455,
          null,
          0.05671653896570206,
          0.23390766978263855,
          null,
          0.05671653896570206,
          0.04726839438080788,
          null,
          0.028587915003299713,
          0.28298264741897583,
          null,
          0.028587915003299713,
          0.041469138115644455,
          null,
          0.028587915003299713,
          -0.2804347574710846,
          null,
          0.028587915003299713,
          0.008924584835767746,
          null,
          0.17035554349422455,
          0.011699801310896873,
          null,
          0.17035554349422455,
          -0.19754347205162048,
          null,
          0.17035554349422455,
          -0.027261145412921906,
          null,
          0.05671653896570206,
          0.03229847922921181,
          null,
          0.05671653896570206,
          -0.2021324336528778,
          null,
          0.17035554349422455,
          -0.1500912308692932,
          null,
          -0.2814645767211914,
          -0.016257314011454582,
          null,
          0.03713188320398331,
          0.28298264741897583,
          null,
          0.03713188320398331,
          0.041469138115644455,
          null,
          0.28298264741897583,
          -0.3955138027667999,
          null,
          0.041469138115644455,
          -0.3955138027667999,
          null,
          -0.005234670825302601,
          -0.0534442663192749,
          null,
          -0.005234670825302601,
          0.041469138115644455,
          null,
          -0.005234670825302601,
          0.28298264741897583,
          null,
          0.01909026689827442,
          -0.07482457160949707,
          null,
          -0.004055174067616463,
          -0.07482457160949707,
          null,
          -0.034889161586761475,
          -0.07482457160949707,
          null,
          0.01909026689827442,
          -0.048347726464271545,
          null,
          -0.004055174067616463,
          -0.048347726464271545,
          null,
          -0.034889161586761475,
          -0.048347726464271545,
          null,
          0.05888929218053818,
          -0.2848208546638489,
          null,
          0.05888929218053818,
          -0.004055174067616463,
          null,
          0.17035554349422455,
          -0.006185364909470081,
          null,
          0.17035554349422455,
          -0.004067397676408291,
          null,
          0.17035554349422455,
          3.1776812076568604,
          null,
          0.17035554349422455,
          0.06610548496246338,
          null,
          0.011530081741511822,
          0.013616038486361504,
          null,
          0.011530081741511822,
          1.9617998600006104,
          null,
          0.011530081741511822,
          -0.3610604703426361,
          null,
          0.17035554349422455,
          0.04971523955464363,
          null,
          0.17035554349422455,
          -0.14432962238788605,
          null,
          0.17035554349422455,
          0.10364661365747452,
          null,
          0.17035554349422455,
          -0.044199202209711075,
          null,
          0.027567733079195023,
          1.3898658752441406,
          null,
          -0.06787369400262833,
          1.4472109079360962,
          null,
          0.17035554349422455,
          3.1140763759613037,
          null,
          0.17035554349422455,
          0.02931520715355873,
          null,
          0.01909026689827442,
          -0.0031443245243281126,
          null,
          -0.004055174067616463,
          -0.0031443245243281126,
          null,
          -0.034889161586761475,
          -0.0031443245243281126,
          null,
          -0.042118869721889496,
          -0.23031184077262878,
          null,
          0.04971523955464363,
          0.10364661365747452,
          null,
          -0.14432962238788605,
          0.10364661365747452,
          null,
          0.10364661365747452,
          0.10364661365747452,
          null,
          0.04971523955464363,
          -0.0033711667638272047,
          null,
          -0.14432962238788605,
          -0.0033711667638272047,
          null,
          0.10364661365747452,
          -0.0033711667638272047,
          null,
          0.04971523955464363,
          -0.04600738361477852,
          null,
          -0.14432962238788605,
          -0.04600738361477852,
          null,
          0.10364661365747452,
          -0.04600738361477852,
          null,
          -0.034889161586761475,
          0.049456316977739334,
          null,
          -0.034889161586761475,
          0.014532803557813168,
          null,
          0.17035554349422455,
          0.04971523955464363,
          null,
          0.17035554349422455,
          -0.14432962238788605,
          null,
          0.17035554349422455,
          0.10364661365747452,
          null,
          0.17035554349422455,
          -0.16522912681102753,
          null,
          0.17035554349422455,
          -0.06787369400262833,
          null,
          0.17035554349422455,
          -0.06686738133430481,
          null,
          0.17035554349422455,
          -0.2798210382461548,
          null,
          0.06857658922672272,
          0.013039437122642994,
          null,
          0.28298264741897583,
          0.013039437122642994,
          null,
          0.06857658922672272,
          0.011754341423511505,
          null,
          0.28298264741897583,
          0.011754341423511505,
          null,
          -0.2351812720298767,
          -0.0269568283110857,
          null,
          -0.2351812720298767,
          -0.24203740060329437,
          null,
          0.17035554349422455,
          0.028406109660863876,
          null,
          0.17035554349422455,
          0.049001339823007584,
          null,
          0.033862315118312836,
          3.239205837249756,
          null,
          0.033862315118312836,
          -0.1661044806241989,
          null,
          0.17035554349422455,
          -0.0234950240701437,
          null,
          0.17035554349422455,
          0.07952199131250381,
          null,
          0.17035554349422455,
          -0.30947017669677734,
          null,
          0.17035554349422455,
          0.1432594209909439,
          null,
          0.17035554349422455,
          0.0686955526471138,
          null,
          0.17035554349422455,
          -0.2933816909790039,
          null,
          0.17035554349422455,
          0.12208043038845062,
          null,
          1.9013365507125854,
          -0.08221989870071411,
          null,
          0.17035554349422455,
          -0.14758135378360748,
          null,
          1.8398070335388184,
          -0.12924958765506744,
          null,
          0.17035554349422455,
          0.004747449886053801,
          null,
          1.9561556577682495,
          -0.14881646633148193,
          null,
          1.9561556577682495,
          0.33275356888771057,
          null,
          0.17035554349422455,
          -0.025700297206640244,
          null,
          0.17035554349422455,
          0.08305206149816513,
          null,
          0.17035554349422455,
          0.12208043038845062,
          null,
          1.8797640800476074,
          0.1047898679971695,
          null,
          1.8797640800476074,
          1.9444395303726196,
          null,
          0.17035554349422455,
          -0.04367811605334282,
          null,
          0.17035554349422455,
          0.10157789289951324,
          null,
          1.9606003761291504,
          -0.15062597393989563,
          null,
          1.9606003761291504,
          -0.258666068315506,
          null,
          0.17035554349422455,
          0.4292198121547699,
          null,
          0.17035554349422455,
          0.45033717155456543,
          null,
          0.17035554349422455,
          3.0927071571350098,
          null,
          0.17035554349422455,
          0.0080086849629879,
          null,
          0.17035554349422455,
          0.23835787177085876,
          null,
          0.12264680117368698,
          -1.288218379020691,
          null,
          0.12264680117368698,
          -1.3730676174163818,
          null,
          0.17035554349422455,
          -0.045702021569013596,
          null,
          0.17035554349422455,
          0.01909026689827442,
          null,
          0.17035554349422455,
          -0.004055174067616463,
          null,
          0.17035554349422455,
          -0.034889161586761475,
          null,
          0.17035554349422455,
          0.7365708351135254,
          null,
          0.17035554349422455,
          -0.019056251272559166,
          null,
          0.17035554349422455,
          0.038328785449266434,
          null,
          0.17035554349422455,
          -0.02096337266266346,
          null,
          0.17035554349422455,
          -0.044361662119627,
          null,
          -0.014639594592154026,
          0.15597546100616455,
          null,
          -0.014639594592154026,
          -0.2975233495235443,
          null,
          0.17035554349422455,
          -0.0031443245243281126,
          null,
          0.07402859628200531,
          -0.0024906357284635305,
          null,
          -0.004055174067616463,
          -0.35395893454551697,
          null,
          0.17035554349422455,
          -0.22730228304862976,
          null,
          0.17035554349422455,
          0.05483528599143028,
          null,
          -0.07600093632936478,
          -0.0703418105840683,
          null,
          -0.07600093632936478,
          0.032695524394512177,
          null,
          1.9085794687271118,
          0.28298264741897583,
          null,
          1.9085794687271118,
          0.041469138115644455,
          null,
          1.9046075344085693,
          -0.1952982097864151,
          null,
          1.9046075344085693,
          0.07402859628200531,
          null,
          1.9830225706100464,
          0.28298264741897583,
          null,
          1.9830225706100464,
          0.041469138115644455,
          null,
          1.9830225706100464,
          -0.17362235486507416,
          null,
          0.07402859628200531,
          0.014647383242845535,
          null,
          0.07402859628200531,
          0.04971523955464363,
          null,
          0.07402859628200531,
          -0.14432962238788605,
          null,
          0.07402859628200531,
          0.10364661365747452,
          null,
          2.0147244930267334,
          -0.25231531262397766,
          null,
          0.17035554349422455,
          -1.9157803058624268,
          null,
          0.17035554349422455,
          -0.05331221595406532,
          null,
          0.17035554349422455,
          -2.138094663619995,
          null,
          0.17035554349422455,
          -0.03258592635393143,
          null,
          0.17035554349422455,
          -2.121323585510254,
          null,
          0.17035554349422455,
          -1.5552146434783936,
          null,
          0.17035554349422455,
          0.9579699039459229,
          null,
          0.17035554349422455,
          -0.06787369400262833,
          null,
          0.17035554349422455,
          0.022681862115859985,
          null,
          0.17035554349422455,
          -0.2814645767211914,
          null,
          0.17035554349422455,
          -0.09642279148101807,
          null,
          0.07402859628200531,
          -0.3556097149848938,
          null,
          0.07402859628200531,
          -0.2814645767211914,
          null,
          0.17035554349422455,
          -0.20225423574447632,
          null,
          0.17035554349422455,
          0.038328785449266434,
          null,
          0.17035554349422455,
          -0.2937432825565338,
          null,
          0.17035554349422455,
          -0.2310790717601776,
          null,
          0.17035554349422455,
          -0.2157248556613922,
          null,
          0.17035554349422455,
          -0.03661765903234482,
          null,
          0.17035554349422455,
          0.5013200044631958,
          null,
          0.17035554349422455,
          -0.33742865920066833,
          null,
          0.17035554349422455,
          -0.08461065590381622,
          null,
          0.17035554349422455,
          0.07402859628200531,
          null,
          0.17035554349422455,
          0.0075859869830310345,
          null,
          0.17035554349422455,
          -0.019056251272559166,
          null,
          0.17035554349422455,
          0.038328785449266434,
          null,
          0.17035554349422455,
          -0.02096337266266346,
          null,
          0.17035554349422455,
          0.03713188320398331,
          null,
          0.17035554349422455,
          -0.2351812720298767,
          null,
          -0.019151408225297928,
          0.041469138115644455,
          null,
          -0.019151408225297928,
          0.28298264741897583,
          null,
          -0.013211392797529697,
          -0.20225423574447632,
          null,
          -0.013211392797529697,
          0.038328785449266434,
          null,
          -0.013211392797529697,
          -0.06012189760804176,
          null,
          -0.014639594592154026,
          -0.2567429542541504,
          null,
          -0.014639594592154026,
          0.05014977231621742,
          null,
          -0.014639594592154026,
          -0.019056251272559166,
          null,
          -0.019056251272559166,
          -0.006094717420637608,
          null,
          0.038328785449266434,
          -0.006094717420637608,
          null,
          -0.02096337266266346,
          -0.006094717420637608,
          null,
          -0.019056251272559166,
          -2.8520684242248535,
          null,
          -0.019056251272559166,
          -2.726172685623169,
          null,
          0.038328785449266434,
          -2.8520684242248535,
          null,
          0.038328785449266434,
          -2.726172685623169,
          null,
          -0.02096337266266346,
          -2.8520684242248535,
          null,
          -0.02096337266266346,
          -2.726172685623169,
          null,
          0.013616038486361504,
          -0.09251774847507477,
          null,
          0.013616038486361504,
          0.04971523955464363,
          null,
          0.013616038486361504,
          -0.14432962238788605,
          null,
          0.013616038486361504,
          0.10364661365747452,
          null,
          -0.019056251272559166,
          -0.07621651887893677,
          null,
          -0.019056251272559166,
          -0.02096337266266346,
          null,
          0.038328785449266434,
          -0.07621651887893677,
          null,
          0.038328785449266434,
          -0.02096337266266346,
          null,
          -0.02096337266266346,
          -0.07621651887893677,
          null,
          -0.02096337266266346,
          -0.02096337266266346,
          null,
          -0.019056251272559166,
          0.4605061113834381,
          null,
          0.038328785449266434,
          0.4605061113834381,
          null,
          -0.02096337266266346,
          0.4605061113834381,
          null,
          0.0023724501952528954,
          -0.2707498073577881,
          null,
          0.0023724501952528954,
          -0.019056251272559166,
          null,
          0.0023724501952528954,
          0.038328785449266434,
          null,
          0.0023724501952528954,
          -0.02096337266266346,
          null,
          -0.013211392797529697,
          -0.019056251272559166,
          null,
          -0.013211392797529697,
          0.038328785449266434,
          null,
          -0.013211392797529697,
          -0.02096337266266346,
          null,
          -0.00950117688626051,
          -0.019056251272559166,
          null,
          -0.00950117688626051,
          0.038328785449266434,
          null,
          -0.00950117688626051,
          -0.02096337266266346,
          null,
          -0.019056251272559166,
          -0.26187974214553833,
          null,
          0.038328785449266434,
          -0.26187974214553833,
          null,
          -0.02096337266266346,
          -0.26187974214553833,
          null,
          -0.019056251272559166,
          -0.03292518109083176,
          null,
          0.038328785449266434,
          -0.03292518109083176,
          null,
          -0.02096337266266346,
          -0.03292518109083176,
          null,
          -0.019056251272559166,
          -0.06851561367511749,
          null,
          -0.019056251272559166,
          0.03532656282186508,
          null,
          0.038328785449266434,
          -0.06851561367511749,
          null,
          0.038328785449266434,
          0.03532656282186508,
          null,
          -0.02096337266266346,
          -0.06851561367511749,
          null,
          -0.02096337266266346,
          0.03532656282186508,
          null,
          -0.019056251272559166,
          -0.24812652170658112,
          null,
          0.038328785449266434,
          -0.24812652170658112,
          null,
          -0.02096337266266346,
          -0.24812652170658112,
          null,
          -0.019056251272559166,
          -0.004055174067616463,
          null,
          0.038328785449266434,
          -0.004055174067616463,
          null,
          -0.02096337266266346,
          -0.004055174067616463,
          null,
          -0.04023544490337372,
          0.041469138115644455,
          null,
          -0.04023544490337372,
          0.28298264741897583,
          null,
          0.17035554349422455,
          0.03713188320398331,
          null,
          0.17035554349422455,
          -0.19941569864749908,
          null,
          -0.013211392797529697,
          -0.28989624977111816,
          null,
          -0.019056251272559166,
          0.05014977231621742,
          null,
          -0.019056251272559166,
          -0.019056251272559166,
          null,
          0.038328785449266434,
          0.05014977231621742,
          null,
          0.038328785449266434,
          -0.019056251272559166,
          null,
          -0.02096337266266346,
          0.05014977231621742,
          null,
          -0.02096337266266346,
          -0.019056251272559166,
          null,
          0.03713188320398331,
          0.013616038486361504,
          null,
          -0.246806338429451,
          -0.0069985343143343925,
          null,
          -0.25590136647224426,
          -0.04467509686946869,
          null,
          -0.25590136647224426,
          -0.04897448420524597,
          null,
          -0.25590136647224426,
          -0.2629742920398712,
          null,
          -0.013211392797529697,
          -0.22145161032676697,
          null,
          -0.2577090263366699,
          -0.1764867752790451,
          null,
          -0.1875925213098526,
          0.004032961092889309,
          null,
          -0.1875925213098526,
          -0.004055174067616463,
          null,
          -0.013211392797529697,
          -0.06322586536407471,
          null,
          -0.019056251272559166,
          -0.24710632860660553,
          null,
          0.038328785449266434,
          -0.24710632860660553,
          null,
          -0.02096337266266346,
          -0.24710632860660553,
          null,
          -0.019056251272559166,
          -0.015178321860730648,
          null,
          -0.019056251272559166,
          0.009484868496656418,
          null,
          -0.019056251272559166,
          -0.006454857997596264,
          null,
          0.038328785449266434,
          -0.015178321860730648,
          null,
          0.038328785449266434,
          0.009484868496656418,
          null,
          0.038328785449266434,
          -0.006454857997596264,
          null,
          -0.02096337266266346,
          -0.015178321860730648,
          null,
          -0.02096337266266346,
          0.009484868496656418,
          null,
          -0.02096337266266346,
          -0.006454857997596264,
          null,
          -0.040166471153497696,
          -0.0011055943323299289,
          null,
          0.06514409929513931,
          0.002409741748124361,
          null,
          0.06514409929513931,
          -0.012490917928516865,
          null,
          -0.019056251272559166,
          -0.24591411650180817,
          null,
          0.038328785449266434,
          -0.24591411650180817,
          null,
          -0.02096337266266346,
          -0.24591411650180817,
          null,
          -0.019056251272559166,
          0.09022688865661621,
          null,
          0.038328785449266434,
          0.09022688865661621,
          null,
          -0.02096337266266346,
          0.09022688865661621,
          null,
          0.17035554349422455,
          -0.024571819230914116,
          null,
          -0.019056251272559166,
          -0.2690315842628479,
          null,
          0.038328785449266434,
          -0.2690315842628479,
          null,
          -0.02096337266266346,
          -0.2690315842628479,
          null,
          -0.019056251272559166,
          -0.15247534215450287,
          null,
          0.038328785449266434,
          -0.15247534215450287,
          null,
          -0.02096337266266346,
          -0.15247534215450287,
          null,
          0.17035554349422455,
          -0.0657239779829979,
          null,
          0.17035554349422455,
          -0.2241859883069992,
          null,
          0.17035554349422455,
          0.05014977231621742,
          null,
          0.05041157826781273,
          0.019999761134386063,
          null,
          0.05041157826781273,
          -0.3303968608379364,
          null,
          0.05041157826781273,
          -0.23039592802524567,
          null,
          -0.019056251272559166,
          -0.03622198849916458,
          null,
          0.038328785449266434,
          -0.03622198849916458,
          null,
          -0.02096337266266346,
          -0.03622198849916458,
          null,
          -0.019056251272559166,
          -2.9259932041168213,
          null,
          -0.019056251272559166,
          -2.857408285140991,
          null,
          0.038328785449266434,
          -2.9259932041168213,
          null,
          0.038328785449266434,
          -2.857408285140991,
          null,
          -0.02096337266266346,
          -2.9259932041168213,
          null,
          -0.02096337266266346,
          -2.857408285140991,
          null,
          -0.019056251272559166,
          -0.1826891452074051,
          null,
          0.038328785449266434,
          -0.1826891452074051,
          null,
          -0.02096337266266346,
          -0.1826891452074051,
          null,
          -0.019056251272559166,
          -0.2773364186286926,
          null,
          0.038328785449266434,
          -0.2773364186286926,
          null,
          -0.02096337266266346,
          -0.2773364186286926,
          null,
          -0.019056251272559166,
          -0.18843476474285126,
          null,
          0.038328785449266434,
          -0.18843476474285126,
          null,
          -0.02096337266266346,
          -0.18843476474285126,
          null,
          -0.004055174067616463,
          -0.019056251272559166,
          null,
          -0.004055174067616463,
          0.038328785449266434,
          null,
          -0.004055174067616463,
          -0.02096337266266346,
          null,
          -0.07621651887893677,
          0.05476367846131325,
          null,
          -0.07621651887893677,
          -0.2241859883069992,
          null,
          -0.02096337266266346,
          0.05476367846131325,
          null,
          -0.02096337266266346,
          -0.2241859883069992,
          null,
          0.05041157826781273,
          -0.04177001491189003,
          null,
          0.05041157826781273,
          -0.06071353703737259,
          null,
          -0.2143465131521225,
          0.23390766978263855,
          null,
          -0.2143465131521225,
          0.05607941746711731,
          null,
          -0.0029502026736736298,
          -0.03412173315882683,
          null,
          -0.05510634556412697,
          -0.03412173315882683,
          null,
          -0.019056251272559166,
          -0.27001675963401794,
          null,
          0.038328785449266434,
          -0.27001675963401794,
          null,
          -0.02096337266266346,
          -0.27001675963401794,
          null,
          0.17035554349422455,
          0.44911396503448486,
          null,
          -0.22145161032676697,
          -0.019056251272559166,
          null,
          -0.22145161032676697,
          0.038328785449266434,
          null,
          -0.22145161032676697,
          -0.02096337266266346,
          null,
          -0.22145161032676697,
          -0.030231745913624763,
          null,
          0.022681862115859985,
          -0.004055174067616463,
          null,
          -0.2814645767211914,
          -0.004055174067616463,
          null,
          -0.22145161032676697,
          -0.006454857997596264,
          null,
          0.17035554349422455,
          -0.015178321860730648,
          null,
          0.17035554349422455,
          0.009484868496656418,
          null,
          0.17035554349422455,
          -0.006454857997596264,
          null,
          -0.019056251272559166,
          -0.2310790717601776,
          null,
          0.038328785449266434,
          -0.2310790717601776,
          null,
          -0.02096337266266346,
          -0.2310790717601776,
          null,
          0.0681150034070015,
          0.0015154016437008977,
          null,
          0.0681150034070015,
          0.07595526427030563,
          null,
          0.17035554349422455,
          -1.5433865785598755,
          null,
          0.17035554349422455,
          -0.02623036690056324,
          null,
          0.17035554349422455,
          1.877993106842041,
          null,
          0.17035554349422455,
          -0.06787369400262833,
          null,
          -1.5433865785598755,
          -0.037499021738767624,
          null,
          -0.02623036690056324,
          -0.037499021738767624,
          null,
          -0.26367878913879395,
          0.022794511169195175,
          null,
          -0.26367878913879395,
          0.009484868496656418,
          null,
          -0.26367878913879395,
          -0.006454857997596264,
          null,
          -1.5433865785598755,
          -0.05899425223469734,
          null,
          -0.02623036690056324,
          -0.05899425223469734,
          null,
          0.17035554349422455,
          -0.015178321860730648,
          null,
          0.17035554349422455,
          0.009484868496656418,
          null,
          0.17035554349422455,
          -0.006454857997596264,
          null,
          0.03713188320398331,
          -0.019056251272559166,
          null,
          0.03713188320398331,
          0.038328785449266434,
          null,
          0.03713188320398331,
          -0.02096337266266346,
          null,
          0.03713188320398331,
          -0.2915736138820648,
          null,
          0.03713188320398331,
          0.05014977231621742,
          null,
          0.03713188320398331,
          -0.019056251272559166,
          null,
          0.05014977231621742,
          -0.09084514528512955,
          null,
          -0.019056251272559166,
          -0.09084514528512955,
          null,
          0.05014977231621742,
          0.01972649060189724,
          null,
          -0.019056251272559166,
          0.01972649060189724,
          null,
          -0.019056251272559166,
          0.01972649060189724,
          null,
          0.038328785449266434,
          0.01972649060189724,
          null,
          -0.02096337266266346,
          0.01972649060189724,
          null,
          -0.019056251272559166,
          0.041469138115644455,
          null,
          -0.019056251272559166,
          0.28298264741897583,
          null,
          0.038328785449266434,
          0.041469138115644455,
          null,
          0.038328785449266434,
          0.28298264741897583,
          null,
          -0.02096337266266346,
          0.041469138115644455,
          null,
          -0.02096337266266346,
          0.28298264741897583,
          null,
          0.17035554349422455,
          -0.20467206835746765,
          null,
          0.17035554349422455,
          -0.246806338429451,
          null,
          0.17035554349422455,
          -0.32484254240989685,
          null,
          -0.0381496287882328,
          -0.246806338429451,
          null,
          0.013616038486361504,
          -0.040166471153497696,
          null,
          0.013616038486361504,
          -0.000016516361938556656,
          null,
          0.041469138115644455,
          -0.246806338429451,
          null,
          0.28298264741897583,
          -0.246806338429451,
          null,
          0.17035554349422455,
          -0.22237583994865417,
          null,
          0.17035554349422455,
          -0.246806338429451,
          null,
          -0.30209875106811523,
          0.040483515709638596,
          null,
          0.17035554349422455,
          0.022681862115859985,
          null,
          0.17035554349422455,
          -0.2814645767211914,
          null,
          0.17035554349422455,
          -0.012530412524938583,
          null,
          0.17035554349422455,
          0.25829315185546875,
          null,
          0.013616038486361504,
          -0.24710632860660553,
          null,
          0.013616038486361504,
          -0.11259707808494568,
          null,
          0.022681862115859985,
          -0.0849926620721817,
          null,
          -0.2814645767211914,
          -0.0849926620721817,
          null,
          0.03713188320398331,
          -0.2351812720298767,
          null,
          0.17035554349422455,
          -0.012530412524938583,
          null,
          0.17035554349422455,
          -0.07831286638975143,
          null,
          0.17035554349422455,
          -0.05123790726065636,
          null,
          0.17035554349422455,
          0.011530081741511822,
          null,
          0.17035554349422455,
          0.06857658922672272,
          null,
          0.17035554349422455,
          0.28298264741897583,
          null,
          -0.13597504794597626,
          0.05007840320467949,
          null,
          -0.13597504794597626,
          -0.06787369400262833,
          null,
          -0.12917126715183258,
          0.05007840320467949,
          null,
          -0.12917126715183258,
          -0.06787369400262833,
          null,
          -0.12349306046962738,
          -0.06787369400262833,
          null,
          -0.07831286638975143,
          -0.06787369400262833,
          null,
          -0.05123790726065636,
          -0.06787369400262833,
          null,
          -0.09394542872905731,
          -0.22515767812728882,
          null,
          0.0032372470013797283,
          -0.24092762172222137,
          null,
          0.0032372470013797283,
          -0.013211392797529697,
          null,
          -0.09394542872905731,
          -0.15008245408535004,
          null,
          0.17035554349422455,
          -0.0065349433571100235,
          null,
          -0.013211392797529697,
          0.017566217109560966,
          null,
          -0.013211392797529697,
          -0.20225423574447632,
          null,
          -0.013211392797529697,
          0.038328785449266434,
          null,
          0.041469138115644455,
          -0.26200389862060547,
          null,
          0.28298264741897583,
          -0.26200389862060547,
          null,
          2.1907124519348145,
          -0.2631673812866211,
          null,
          -0.004055174067616463,
          -0.2631673812866211,
          null,
          2.1907124519348145,
          0.004171185661107302,
          null,
          -0.004055174067616463,
          0.004171185661107302,
          null,
          0.17035554349422455,
          -0.07314678281545639,
          null,
          0.17035554349422455,
          0.08601778000593185,
          null,
          -0.013211392797529697,
          0.061528436839580536,
          null,
          0.04971523955464363,
          -0.21256551146507263,
          null,
          -0.14432962238788605,
          -0.21256551146507263,
          null,
          0.10364661365747452,
          -0.21256551146507263,
          null,
          0.04971523955464363,
          -0.05934557318687439,
          null,
          -0.14432962238788605,
          -0.05934557318687439,
          null,
          0.10364661365747452,
          -0.05934557318687439,
          null,
          0.04971523955464363,
          -0.16874995827674866,
          null,
          -0.14432962238788605,
          -0.16874995827674866,
          null,
          0.10364661365747452,
          -0.16874995827674866,
          null,
          -0.004055174067616463,
          -0.15172116458415985,
          null,
          -0.004055174067616463,
          -0.2351812720298767,
          null,
          0.17035554349422455,
          -0.019056251272559166,
          null,
          0.17035554349422455,
          0.038328785449266434,
          null,
          0.17035554349422455,
          -0.02096337266266346,
          null,
          0.07402859628200531,
          -0.29470714926719666,
          null,
          0.07402859628200531,
          0.28298264741897583,
          null,
          0.07402859628200531,
          0.041469138115644455,
          null,
          0.17035554349422455,
          -0.07225335389375687,
          null,
          0.17035554349422455,
          0.013616038486361504,
          null,
          -0.013211392797529697,
          -0.04023544490337372,
          null,
          -0.013211392797529697,
          0.20354682207107544,
          null,
          0.05671653896570206,
          -0.23792868852615356,
          null,
          0.05671653896570206,
          0.7365708351135254,
          null,
          -0.17275039851665497,
          -0.0016250478802248836,
          null,
          0.17035554349422455,
          -0.0179132167249918,
          null,
          -0.21838897466659546,
          0.07663945853710175,
          null,
          -0.21838897466659546,
          -0.02410127781331539,
          null,
          -0.034889161586761475,
          -0.005234670825302601,
          null,
          -0.18840274214744568,
          0.015975497663021088,
          null,
          -0.18840274214744568,
          -0.21463334560394287,
          null,
          -0.18840274214744568,
          0.01972649060189724,
          null,
          -0.18840274214744568,
          -0.23281143605709076,
          null,
          0.01909026689827442,
          -1.1456881761550903,
          null,
          -0.004055174067616463,
          -1.1456881761550903,
          null,
          -0.034889161586761475,
          -1.1456881761550903,
          null,
          0.01909026689827442,
          -0.24803537130355835,
          null,
          -0.004055174067616463,
          -0.24803537130355835,
          null,
          -0.034889161586761475,
          -0.24803537130355835,
          null,
          0.0023724501952528954,
          0.014532803557813168,
          null,
          -0.07600093632936478,
          -0.0534442663192749,
          null,
          -0.07600093632936478,
          -0.019056251272559166,
          null,
          -0.07600093632936478,
          0.038328785449266434,
          null,
          -0.07600093632936478,
          -0.02096337266266346,
          null,
          0.17035554349422455,
          -0.019056251272559166,
          null,
          0.17035554349422455,
          0.038328785449266434,
          null,
          0.17035554349422455,
          -0.02096337266266346,
          null,
          0.17035554349422455,
          -0.23277607560157776,
          null,
          0.013616038486361504,
          -0.0759006142616272,
          null,
          -0.019056251272559166,
          0.05483528599143028,
          null,
          0.038328785449266434,
          0.05483528599143028,
          null,
          -0.02096337266266346,
          0.05483528599143028,
          null,
          -0.004055174067616463,
          -0.03844836726784706,
          null,
          -0.004055174067616463,
          0.01909026689827442,
          null,
          -0.004055174067616463,
          -0.004055174067616463,
          null,
          -0.004055174067616463,
          -0.034889161586761475,
          null,
          0.17035554349422455,
          -0.18152368068695068,
          null,
          0.049001339823007584,
          -0.2574446201324463,
          null,
          0.049001339823007584,
          -1.8703891038894653,
          null,
          -0.012600491754710674,
          0.0035376728046685457,
          null,
          -0.012600491754710674,
          0.0344979465007782,
          null,
          -0.0035152502823621035,
          0.049001339823007584,
          null,
          -0.0035152502823621035,
          -0.20267266035079956,
          null,
          -0.0035152502823621035,
          0.006415147799998522,
          null,
          -0.004055174067616463,
          0.32790252566337585,
          null,
          -0.004049438051879406,
          -0.26181551814079285,
          null,
          -0.004049438051879406,
          -0.004055174067616463,
          null,
          -2.0063421726226807,
          -0.23866720497608185,
          null,
          -0.03817326948046684,
          0.11367610841989517,
          null,
          -0.03817326948046684,
          -0.18415483832359314,
          null,
          -0.002399805933237076,
          -0.23735176026821136,
          null,
          0.02095196396112442,
          0.041469138115644455,
          null,
          0.02095196396112442,
          0.28298264741897583,
          null,
          -0.07600093632936478,
          0.007632523775100708,
          null,
          0.28298264741897583,
          0.044096603989601135,
          null,
          0.041469138115644455,
          0.044096603989601135,
          null,
          0.28298264741897583,
          -0.2387964129447937,
          null,
          0.28298264741897583,
          0.03952103108167648,
          null,
          0.041469138115644455,
          -0.2387964129447937,
          null,
          0.041469138115644455,
          0.03952103108167648,
          null,
          -0.01628652773797512,
          -0.03206789866089821,
          null,
          -0.3564338982105255,
          0.01643931120634079,
          null,
          -0.3564338982105255,
          2.2053072452545166,
          null,
          -0.13417577743530273,
          -0.2690351605415344,
          null,
          0.028638727962970734,
          -0.2690351605415344,
          null,
          0.028638727962970734,
          -0.2977035641670227,
          null,
          -0.0029502026736736298,
          -0.2977035641670227,
          null,
          0.17035554349422455,
          0.041469138115644455,
          null,
          0.17035554349422455,
          0.28298264741897583,
          null,
          0.17035554349422455,
          0.015975497663021088,
          null,
          0.17035554349422455,
          -0.21463334560394287,
          null,
          0.05158228054642677,
          -0.023324426263570786,
          null,
          0.05158228054642677,
          -0.004055174067616463,
          null,
          0.003903429489582777,
          0.012396183796226978,
          null,
          -0.04099371284246445,
          0.012396183796226978,
          null,
          0.003903429489582777,
          -0.07698111981153488,
          null,
          -0.04099371284246445,
          -0.07698111981153488,
          null,
          0.17035554349422455,
          -0.1875329464673996,
          null,
          0.05671653896570206,
          0.04320327565073967,
          null,
          0.05671653896570206,
          0.041469138115644455,
          null,
          0.05671653896570206,
          0.28298264741897583,
          null,
          0.17035554349422455,
          -1.1456881761550903,
          null,
          -0.019056251272559166,
          -0.31574296951293945,
          null,
          0.038328785449266434,
          -0.31574296951293945,
          null,
          -0.02096337266266346,
          -0.31574296951293945,
          null,
          -0.019056251272559166,
          0.17600998282432556,
          null,
          0.038328785449266434,
          0.17600998282432556,
          null,
          -0.02096337266266346,
          0.17600998282432556,
          null,
          0.17035554349422455,
          -0.0031443245243281126,
          null,
          0.020748844370245934,
          -0.14692190289497375,
          null,
          -0.05356648191809654,
          -0.14692190289497375,
          null,
          0.041469138115644455,
          0.011754341423511505,
          null,
          0.28298264741897583,
          0.011754341423511505,
          null,
          -0.04581945762038231,
          0.041469138115644455,
          null,
          -0.0069985343143343925,
          -0.04367811605334282,
          null,
          0.04895178601145744,
          0.02495029754936695,
          null,
          -0.013353781774640083,
          -0.004055174067616463,
          null,
          0.03758803755044937,
          0.041469138115644455,
          null,
          4.472208023071289,
          0.020748844370245934,
          null,
          0.04971523955464363,
          0.21540409326553345,
          null,
          -0.14432962238788605,
          0.21540409326553345,
          null,
          0.10364661365747452,
          0.21540409326553345,
          null,
          -0.08235474675893784,
          0.041469138115644455,
          null,
          0.013552633114159107,
          0.01909026689827442,
          null,
          0.04971523955464363,
          0.21943488717079163,
          null,
          -0.14432962238788605,
          0.21943488717079163,
          null,
          0.10364661365747452,
          0.21943488717079163,
          null,
          0.022204603999853134,
          0.10364661365747452,
          null,
          0.0803636983036995,
          -0.0033711667638272047,
          null,
          0.0803636983036995,
          0.013616038486361504,
          null,
          0.0803636983036995,
          0.10364661365747452,
          null,
          -0.032644324004650116,
          -0.1900705248117447,
          null,
          -0.2885439097881317,
          0.10364661365747452,
          null,
          -0.028140997514128685,
          0.12966661155223846,
          null,
          0.033501043915748596,
          -0.09768157452344894,
          null,
          0.06594180315732956,
          -0.11434189975261688,
          null,
          -0.11434189975261688,
          1.1993457078933716,
          null,
          -0.04956170916557312,
          -0.045646458864212036,
          null,
          -0.0031443245243281126,
          -0.17544810473918915,
          null,
          -0.019242487847805023,
          0.057320430874824524,
          null,
          -0.04969558119773865,
          -0.019056251272559166,
          null,
          -0.04969558119773865,
          0.06594180315732956,
          null,
          0.06594180315732956,
          -0.2617599070072174,
          null,
          0.04510170966386795,
          -0.24950258433818817,
          null,
          -0.0035903577227145433,
          -0.004055174067616463,
          null,
          -0.09237980842590332,
          0.041469138115644455,
          null,
          -0.07867467403411865,
          0.041469138115644455,
          null,
          -0.004055174067616463,
          -0.2712107002735138,
          null,
          -0.004055174067616463,
          2.2241146564483643,
          null,
          -0.004055174067616463,
          0.03822929784655571,
          null,
          -0.016216052696108818,
          -2.0256898403167725,
          null,
          -0.017261484637856483,
          -0.23387551307678223,
          null,
          0.020748844370245934,
          -0.1729860007762909,
          null,
          -0.05356648191809654,
          -0.1729860007762909,
          null,
          0.05483528599143028,
          -0.016452165320515633,
          null,
          0.027330830693244934,
          0.032695524394512177,
          null,
          -0.0232411976903677,
          -0.14692190289497375,
          null,
          -0.14692190289497375,
          -0.0031443245243281126,
          null,
          0.03758803755044937,
          -0.02526482380926609,
          null,
          -0.03651062771677971,
          -0.08218859136104584,
          null,
          -0.08218859136104584,
          0.01960540935397148,
          null,
          -0.04035224765539169,
          -0.004055174067616463,
          null,
          -0.2561173737049103,
          -0.004055174067616463,
          null,
          0.002610851312056184,
          -0.18644826114177704,
          null,
          0.015124216675758362,
          0.21540409326553345,
          null,
          0.03576948121190071,
          -0.18644826114177704,
          null,
          -0.01427475642412901,
          0.00814124196767807,
          null,
          -0.021641844883561134,
          -0.07698111981153488,
          null,
          -0.1286575347185135,
          -0.05525379255414009,
          null,
          0.07337527722120285,
          -0.05525379255414009,
          null,
          0.040996260941028595,
          0.03758803755044937,
          null,
          -1.6525819301605225,
          0.04971523955464363,
          null,
          0.04971523955464363,
          -0.0006804268923588097,
          null,
          -0.14432962238788605,
          -0.0006804268923588097,
          null,
          0.10364661365747452,
          -0.0006804268923588097,
          null,
          0.04971523955464363,
          -0.19988307356834412,
          null,
          -0.14432962238788605,
          -0.19988307356834412,
          null,
          0.10364661365747452,
          -0.19988307356834412,
          null,
          -0.18599438667297363,
          -3.1804416179656982,
          null,
          -0.18599438667297363,
          -3.0861263275146484,
          null,
          0.03713188320398331,
          -0.15776963531970978,
          null,
          -0.22032634913921356,
          0.04788525402545929,
          null,
          -0.03206789866089821,
          0.04788525402545929,
          null,
          -0.05566580593585968,
          0.04788525402545929,
          null,
          0.04088341444730759,
          0.041469138115644455,
          null,
          -0.22032634913921356,
          -0.05525379255414009,
          null,
          -0.03206789866089821,
          -0.05525379255414009,
          null,
          -0.05566580593585968,
          -0.05525379255414009,
          null,
          -0.009832235984504223,
          0.041469138115644455,
          null,
          -0.22194501757621765,
          0.158263698220253,
          null,
          -0.0033910521306097507,
          0.03125517815351486,
          null,
          -0.2963859736919403,
          0.28298264741897583,
          null,
          -0.024660460650920868,
          -0.2605869472026825,
          null,
          -0.2605869472026825,
          0.06857658922672272,
          null,
          -0.015157496556639671,
          -0.11595838516950607,
          null,
          -0.08668990433216095,
          -0.11595838516950607,
          null,
          -0.2639206647872925,
          0.06857658922672272,
          null,
          0.03713188320398331,
          0.28298264741897583,
          null,
          -0.004363990388810635,
          0.04971523955464363,
          null,
          0.04971523955464363,
          0.06857658922672272,
          null,
          -0.14432962238788605,
          0.06857658922672272,
          null,
          0.10364661365747452,
          0.06857658922672272,
          null,
          0.03742779791355133,
          0.01387202087789774,
          null,
          0.012813478708267212,
          -0.019056251272559166,
          null,
          0.041469138115644455,
          -0.30252885818481445,
          null,
          0.28298264741897583,
          -0.30252885818481445,
          null,
          0.022204603999853134,
          -0.22194501757621765,
          null,
          -0.3176117241382599,
          -0.05356648191809654,
          null,
          0.022204603999853134,
          -0.22760659456253052,
          null,
          -0.009921276941895485,
          0.04298051819205284,
          null,
          0.022204603999853134,
          0.06857658922672272,
          null,
          0.022204603999853134,
          0.011530081741511822,
          null,
          -0.07482457160949707,
          0.28298264741897583,
          null,
          2.0271575450897217,
          -0.04190913587808609,
          null,
          -0.0534442663192749,
          0.041469138115644455,
          null,
          -0.007205085828900337,
          0.059467244893312454,
          null,
          -0.09237980842590332,
          0.28298264741897583,
          null,
          -0.07867467403411865,
          0.28298264741897583,
          null,
          -0.09237980842590332,
          -0.18840274214744568,
          null,
          -0.07867467403411865,
          -0.18840274214744568,
          null,
          0.011530081741511822,
          0.041469138115644455,
          null,
          1.9382463693618774,
          -0.12349306046962738,
          null,
          -0.3947536051273346,
          -0.12349306046962738,
          null,
          0.1018969938158989,
          -0.09482114017009735,
          null,
          0.05007840320467949,
          -0.03903908655047417,
          null,
          -0.030932994559407234,
          0.09180006384849548,
          null,
          -0.05217559263110161,
          0.018262002617120743,
          null,
          0.08154118061065674,
          -0.02199864573776722,
          null,
          -0.014005208387970924,
          0.08470658212900162,
          null,
          -0.037355199456214905,
          -0.02207622304558754,
          null,
          -0.024239802733063698,
          -0.005234670825302601,
          null,
          -0.04963994771242142,
          -0.005234670825302601,
          null,
          0.01960540935397148,
          -0.246806338429451,
          null,
          -0.055553846061229706,
          -0.246806338429451,
          null,
          2.0271575450897217,
          0.041469138115644455,
          null,
          0.04971523955464363,
          -0.04190913587808609,
          null,
          -0.14432962238788605,
          -0.04190913587808609,
          null,
          0.10364661365747452,
          -0.04190913587808609,
          null,
          -0.037355199456214905,
          0.2212585061788559,
          null,
          -0.19988307356834412,
          -0.2131255865097046,
          null,
          -0.2531825006008148,
          -0.2131255865097046,
          null,
          0.03713188320398331,
          -3.0532078742980957,
          null,
          0.040996260941028595,
          0.01972649060189724,
          null,
          0.01972649060189724,
          0.28298264741897583,
          null,
          0.04971523955464363,
          0.041469138115644455,
          null,
          -0.14432962238788605,
          0.041469138115644455,
          null,
          0.10364661365747452,
          0.041469138115644455,
          null,
          -0.024169983342289925,
          -0.16786958277225494,
          null,
          -0.06941766291856766,
          0.28298264741897583,
          null,
          -0.18117621541023254,
          0.08898111432790756,
          null,
          0.08898111432790756,
          0.02700837329030037,
          null,
          0.022681862115859985,
          -0.014005208387970924,
          null,
          -0.2814645767211914,
          -0.014005208387970924,
          null,
          0.02931520715355873,
          -0.2387964129447937,
          null,
          0.03952103108167648,
          -0.22125831246376038,
          null,
          0.0803636983036995,
          0.01972649060189724,
          null,
          0.0803636983036995,
          0.041469138115644455,
          null,
          0.0803636983036995,
          0.28298264741897583,
          null,
          0.03576948121190071,
          0.04971523955464363,
          null,
          0.04971523955464363,
          0.28298264741897583,
          null,
          -0.14432962238788605,
          0.28298264741897583,
          null,
          0.10364661365747452,
          0.28298264741897583,
          null,
          0.06074567511677742,
          -0.2835300862789154,
          null,
          -0.2528893053531647,
          0.041469138115644455,
          null,
          -0.14087921380996704,
          0.041469138115644455,
          null,
          -0.2654191255569458,
          0.28298264741897583,
          null,
          0.028587915003299713,
          0.28298264741897583,
          null,
          -0.2804347574710846,
          0.008924584835767746,
          null,
          0.008924584835767746,
          -0.027261145412921906,
          null,
          -0.18243756890296936,
          -0.2814645767211914,
          null,
          -0.02415073849260807,
          0.04495924711227417,
          null,
          -0.006185364909470081,
          -0.004067397676408291,
          null,
          0.03976965323090553,
          -0.22332130372524261,
          null,
          2.0271575450897217,
          1.4086142778396606,
          null,
          0.020748844370245934,
          -0.04600738361477852,
          null,
          -0.05356648191809654,
          -0.04600738361477852,
          null,
          0.02890964038670063,
          3.186688184738159,
          null,
          0.02890964038670063,
          0.03305131942033768,
          null,
          0.011530081741511822,
          0.013616038486361504,
          null,
          -1.5433865785598755,
          0.158263698220253,
          null,
          -0.02623036690056324,
          0.158263698220253,
          null,
          0.02890964038670063,
          1.4086142778396606,
          null,
          0.0546756386756897,
          -0.055278632789850235,
          null,
          -0.2174501270055771,
          0.018262002617120743,
          null,
          -0.18076543509960175,
          0.018262002617120743,
          null,
          -0.18076543509960175,
          0.08470658212900162,
          null,
          -0.2174501270055771,
          -0.23496893048286438,
          null,
          -0.18076543509960175,
          -0.23496893048286438,
          null,
          -0.024239802733063698,
          -0.15904389321804047,
          null,
          -0.04963994771242142,
          -0.15904389321804047,
          null,
          0.04971523955464363,
          0.013616038486361504,
          null,
          -0.14432962238788605,
          0.013616038486361504,
          null,
          0.10364661365747452,
          0.013616038486361504,
          null,
          0.04855518415570259,
          -0.0033711667638272047,
          null,
          0.04855518415570259,
          0.10364661365747452,
          null,
          3.1140763759613037,
          0.02931520715355873,
          null,
          0.022204603999853134,
          -0.15904389321804047,
          null,
          0.04971523955464363,
          -0.16522912681102753,
          null,
          -0.14432962238788605,
          -0.16522912681102753,
          null,
          0.10364661365747452,
          -0.16522912681102753,
          null,
          0.03713188320398331,
          0.024147192016243935,
          null,
          -0.254376620054245,
          -0.036869779229164124,
          null,
          -0.042118869721889496,
          -0.23031184077262878,
          null,
          0.04971523955464363,
          0.10364661365747452,
          null,
          -0.14432962238788605,
          0.10364661365747452,
          null,
          0.10364661365747452,
          0.10364661365747452,
          null,
          0.04971523955464363,
          1.4472109079360962,
          null,
          -0.14432962238788605,
          1.4472109079360962,
          null,
          0.10364661365747452,
          1.4472109079360962,
          null,
          -0.0033711667638272047,
          -0.04600738361477852,
          null,
          -0.05934557318687439,
          -0.20698286592960358,
          null,
          -0.2410476952791214,
          0.10364661365747452,
          null,
          -0.1903046816587448,
          -0.12967589497566223,
          null,
          0.022681862115859985,
          0.06857658922672272,
          null,
          -0.2814645767211914,
          0.06857658922672272,
          null,
          0.022681862115859985,
          -0.12414689362049103,
          null,
          -0.2814645767211914,
          -0.12414689362049103,
          null,
          -0.02322792075574398,
          -0.034889161586761475,
          null,
          0.023854035884141922,
          0.04971523955464363,
          null,
          0.061509761959314346,
          -0.177397221326828,
          null,
          -0.2387964129447937,
          -0.25277236104011536,
          null,
          0.03952103108167648,
          -0.25277236104011536,
          null,
          0.040689606219530106,
          -0.012124063447117805,
          null,
          -0.18433059751987457,
          -0.0831342414021492,
          null,
          0.001505519961938262,
          0.06184535101056099,
          null,
          0.01646106131374836,
          0.028406109660863876,
          null,
          -0.43944135308265686,
          -0.31335213780403137,
          null,
          -0.010036494582891464,
          -0.01132296584546566,
          null,
          -0.23947688937187195,
          -1.8703891038894653,
          null,
          -0.08221989870071411,
          -0.29168304800987244,
          null,
          -0.14758135378360748,
          -0.10154688358306885,
          null,
          -0.364891916513443,
          0.33275356888771057,
          null,
          -0.14881646633148193,
          0.33275356888771057,
          null,
          -0.05167553573846817,
          -0.015530484728515148,
          null,
          -0.25023558735847473,
          -0.015530484728515148,
          null,
          -0.25023558735847473,
          0.03749082610011101,
          null,
          0.1047898679971695,
          1.9444395303726196,
          null,
          -0.08114045858383179,
          -0.347621887922287,
          null,
          -0.15062597393989563,
          -0.258666068315506,
          null,
          -0.011712889187037945,
          1.8371236324310303,
          null,
          -0.2984032928943634,
          0.06610548496246338,
          null,
          0.3970341980457306,
          -0.5535740852355957,
          null,
          0.056010566651821136,
          -0.06322586536407471,
          null,
          -0.3608352839946747,
          0.0080086849629879,
          null,
          0.4292198121547699,
          0.45033717155456543,
          null,
          0.8427527546882629,
          3.239205837249756,
          null,
          0.8270665407180786,
          3.239205837249756,
          null,
          -1.288218379020691,
          0.05201954022049904,
          null,
          -1.3730676174163818,
          0.05201954022049904,
          null,
          -0.20995596051216125,
          -0.04367811605334282,
          null,
          -0.02233995869755745,
          0.04575704038143158,
          null,
          0.01103968732059002,
          -0.21256551146507263,
          null,
          -0.1952982097864151,
          0.07402859628200531,
          null,
          -0.20152130722999573,
          0.09102321416139603,
          null,
          0.014647383242845535,
          0.04971523955464363,
          null,
          0.28298264741897583,
          -0.034889161586761475,
          null,
          0.041469138115644455,
          -0.034889161586761475,
          null,
          -0.05331221595406532,
          -0.034889161586761475,
          null,
          -1.5433865785598755,
          0.07402859628200531,
          null,
          -0.02623036690056324,
          0.07402859628200531,
          null,
          -0.011818972416222095,
          -0.08930189907550812,
          null,
          0.022681862115859985,
          -0.09642279148101807,
          null,
          -0.2814645767211914,
          -0.09642279148101807,
          null,
          -0.2814645767211914,
          0.08342050015926361,
          null,
          -0.05123790726065636,
          -0.15624211728572845,
          null,
          0.014502695761620998,
          -0.15624211728572845,
          null,
          0.022681862115859985,
          -0.012530412524938583,
          null,
          -0.2814645767211914,
          -0.012530412524938583,
          null,
          0.03705799952149391,
          0.041469138115644455,
          null,
          0.023520581424236298,
          0.059467244893312454,
          null,
          -0.048376407474279404,
          0.05483528599143028,
          null,
          -0.08461065590381622,
          0.07402859628200531,
          null,
          -0.23039592802524567,
          0.039947543293237686,
          null,
          0.0075859869830310345,
          -0.019056251272559166,
          null,
          0.03713188320398331,
          -0.2351812720298767,
          null,
          -0.06012189760804176,
          -0.032988838851451874,
          null,
          -0.2567429542541504,
          0.05014977231621742,
          null,
          -0.246806338429451,
          0.02069018967449665,
          null,
          -0.006094717420637608,
          -2.8520684242248535,
          null,
          0.05483528599143028,
          -0.07621651887893677,
          null,
          -0.09251774847507477,
          0.04971523955464363,
          null,
          0.04971523955464363,
          0.02069018967449665,
          null,
          -0.14432962238788605,
          0.02069018967449665,
          null,
          0.10364661365747452,
          0.02069018967449665,
          null,
          -0.2707498073577881,
          -0.019056251272559166,
          null,
          -0.20225423574447632,
          -0.019056251272559166,
          null,
          0.038328785449266434,
          -0.019056251272559166,
          null,
          0.038328785449266434,
          -0.24576324224472046,
          null,
          -0.24576324224472046,
          0.055140670388936996,
          null,
          -0.00950117688626051,
          -0.019056251272559166,
          null,
          -0.24812652170658112,
          -0.004055174067616463,
          null,
          -0.04023544490337372,
          0.041469138115644455,
          null,
          0.03713188320398331,
          -0.19941569864749908,
          null,
          0.03713188320398331,
          -0.19561323523521423,
          null,
          0.03713188320398331,
          0.013616038486361504,
          null,
          -0.0069985343143343925,
          -0.008880543522536755,
          null,
          -0.04897448420524597,
          -0.16136960685253143,
          null,
          -0.2629742920398712,
          -0.16136960685253143,
          null,
          -0.22145161032676697,
          -0.019056251272559166,
          null,
          0.038328785449266434,
          -0.24576324224472046,
          null,
          -0.1859893649816513,
          0.01909026689827442,
          null,
          0.004032961092889309,
          -0.004055174067616463,
          null,
          -0.06322586536407471,
          -0.0447269007563591,
          null,
          -0.22145161032676697,
          -0.07600093632936478,
          null,
          0.09022688865661621,
          -0.004055174067616463,
          null,
          -0.2690315842628479,
          -0.15247534215450287,
          null,
          0.01972649060189724,
          0.041469138115644455,
          null,
          -0.020076006650924683,
          0.0056843226775527,
          null,
          -0.22032634913921356,
          0.00814124196767807,
          null,
          -0.03206789866089821,
          0.00814124196767807,
          null,
          -0.05566580593585968,
          0.00814124196767807,
          null,
          -0.03206789866089821,
          0.032695524394512177,
          null,
          -0.0657239779829979,
          0.07402859628200531,
          null,
          -0.2241859883069992,
          0.07402859628200531,
          null,
          0.05014977231621742,
          0.07402859628200531,
          null,
          -0.0657239779829979,
          -0.019056251272559166,
          null,
          -0.2241859883069992,
          -0.019056251272559166,
          null,
          0.05014977231621742,
          -0.019056251272559166,
          null,
          0.05014977231621742,
          1.770751714706421,
          null,
          -0.019056251272559166,
          1.770751714706421,
          null,
          1.770751714706421,
          -0.004055174067616463,
          null,
          0.019999761134386063,
          -0.3303968608379364,
          null,
          -0.23039592802524567,
          0.07402859628200531,
          null,
          0.13661189377307892,
          -1.5433865785598755,
          null,
          -0.03622198849916458,
          -2.9259932041168213,
          null,
          -2.9259932041168213,
          -0.17407354712486267,
          null,
          -2.857408285140991,
          -0.17407354712486267,
          null,
          -2.857408285140991,
          -0.04956170916557312,
          null,
          -0.1826891452074051,
          -0.2773364186286926,
          null,
          -0.4164172112941742,
          -0.2241859883069992,
          null,
          -0.4164172112941742,
          -0.13417577743530273,
          null,
          -0.004055174067616463,
          -0.019056251272559166,
          null,
          -0.07675454765558243,
          0.06594180315732956,
          null,
          0.06594180315732956,
          -0.30287063121795654,
          null,
          -0.04177001491189003,
          -0.06071353703737259,
          null,
          -0.15959633886814117,
          -0.019056251272559166,
          null,
          0.022681862115859985,
          -0.2602705955505371,
          null,
          -0.2814645767211914,
          -0.2602705955505371,
          null,
          -0.22145161032676697,
          -0.019056251272559166,
          null,
          0.022681862115859985,
          -0.004055174067616463,
          null,
          -0.2814645767211914,
          -0.004055174067616463,
          null,
          -0.22145161032676697,
          -0.006454857997596264,
          null,
          -0.21406377851963043,
          -0.019056251272559166,
          null,
          0.0015154016437008977,
          -0.019056251272559166,
          null,
          0.07595526427030563,
          -0.019056251272559166,
          null,
          0.0015154016437008977,
          -0.22611874341964722,
          null,
          0.07595526427030563,
          -0.22611874341964722,
          null,
          0.06753848493099213,
          -1.5433865785598755,
          null,
          -1.5433865785598755,
          1.877993106842041,
          null,
          -0.02623036690056324,
          1.877993106842041,
          null,
          -1.5433865785598755,
          -0.4608602821826935,
          null,
          -0.02623036690056324,
          -0.4608602821826935,
          null,
          -0.22922025620937347,
          0.013616038486361504,
          null,
          0.022794511169195175,
          0.009484868496656418,
          null,
          0.03713188320398331,
          -0.019056251272559166,
          null,
          -0.2915736138820648,
          0.05014977231621742,
          null,
          -0.09084514528512955,
          0.01972649060189724,
          null,
          0.017566217109560966,
          -0.246806338429451,
          null,
          -0.20467206835746765,
          -0.246806338429451,
          null,
          0.04100527986884117,
          -1.3393020629882812,
          null,
          -0.0381496287882328,
          -0.246806338429451,
          null,
          -0.22237583994865417,
          -0.246806338429451,
          null,
          -0.23321902751922607,
          -0.024571819230914116,
          null,
          -0.024571819230914116,
          0.013616038486361504,
          null,
          0.022681862115859985,
          3.239205837249756,
          null,
          -0.2814645767211914,
          3.239205837249756,
          null,
          0.022681862115859985,
          -0.0849926620721817,
          null,
          -0.2814645767211914,
          -0.0849926620721817,
          null,
          -0.012530412524938583,
          -0.03206004947423935,
          null,
          -0.12349306046962738,
          -0.04190913587808609,
          null,
          -0.07831286638975143,
          -0.04190913587808609,
          null,
          -0.05123790726065636,
          -0.04190913587808609,
          null,
          0.017566217109560966,
          -0.026950418949127197,
          null,
          0.011530081741511822,
          0.06857658922672272,
          null,
          0.05007840320467949,
          -0.06787369400262833,
          null,
          0.06815880537033081,
          -0.2736371159553528,
          null,
          0.017566217109560966,
          -0.20225423574447632,
          null,
          0.04855518415570259,
          0.02069018967449665,
          null,
          0.017566217109560966,
          -0.2840852737426758,
          null,
          0.017566217109560966,
          -0.010969303548336029,
          null,
          -0.07314678281545639,
          0.08601778000593185,
          null,
          0.08601778000593185,
          -0.06532313674688339,
          null,
          0.061528436839580536,
          -0.20225423574447632,
          null,
          0.04971523955464363,
          -0.21256551146507263,
          null,
          -0.14432962238788605,
          -0.21256551146507263,
          null,
          0.10364661365747452,
          -0.21256551146507263,
          null,
          -0.05934557318687439,
          -0.16874995827674866,
          null,
          0.031634584069252014,
          0.059467244893312454,
          null,
          -0.024571819230914116,
          0.07402859628200531,
          null,
          -0.07225335389375687,
          0.013616038486361504,
          null,
          -0.04023544490337372,
          0.20354682207107544,
          null,
          0.07663945853710175,
          -0.02410127781331539,
          null,
          -0.02410127781331539,
          -0.08881308883428574,
          null,
          -0.08881308883428574,
          0.03406619653105736,
          null,
          2.3538172245025635,
          -0.02410127781331539,
          null,
          2.3538172245025635,
          -0.21838897466659546,
          null,
          2.348055362701416,
          -0.02410127781331539,
          null,
          2.348055362701416,
          -0.036869779229164124,
          null,
          0.023224705830216408,
          -0.25000229477882385,
          null,
          0.023224705830216408,
          0.020354721695184708,
          null,
          -0.18840274214744568,
          0.015975497663021088,
          null,
          0.01972649060189724,
          -0.23281143605709076,
          null,
          0.004032961092889309,
          -0.20698286592960358,
          null,
          -0.0855185016989708,
          0.031390462070703506,
          null,
          0.02840322256088257,
          -0.19791968166828156,
          null,
          -0.0534442663192749,
          -0.019056251272559166,
          null,
          -0.018026182428002357,
          4.491021156311035,
          null,
          0.009654023684561253,
          -0.019056251272559166,
          null,
          -0.2574446201324463,
          -1.8703891038894653,
          null,
          0.03524785116314888,
          0.059213098138570786,
          null,
          0.03524785116314888,
          0.046290814876556396,
          null,
          -0.0035152502823621035,
          0.049001339823007584,
          null,
          -0.20267266035079956,
          0.006415147799998522,
          null,
          -0.24907103180885315,
          0.008676419965922832,
          null,
          0.03576948121190071,
          -0.040121614933013916,
          null,
          -0.26181551814079285,
          -0.004055174067616463,
          null,
          0.023854035884141922,
          0.013616038486361504,
          null,
          -0.049045875668525696,
          0.03976965323090553,
          null,
          0.022211315110325813,
          0.041469138115644455,
          null,
          0.0021355757489800453,
          -0.004055174067616463,
          null,
          0.04855518415570259,
          4.482250213623047,
          null,
          0.03533190116286278,
          -0.21256551146507263,
          null,
          -0.06070198491215706,
          -1.607568383216858,
          null,
          -0.004055174067616463,
          -0.0907449796795845,
          null,
          0.044096603989601135,
          -0.2387964129447937,
          null,
          -0.055939845740795135,
          -0.028120743110775948,
          null,
          0.0021355757489800453,
          4.482273101806641,
          null,
          -0.023324426263570786,
          -0.004055174067616463,
          null,
          -0.1879900097846985,
          -0.034889161586761475,
          null,
          -0.023324426263570786,
          -0.26852893829345703,
          null,
          0.21943488717079163,
          0.015975497663021088,
          null,
          0.21943488717079163,
          0.041469138115644455,
          null,
          0.06857658922672272,
          -0.16495169699192047,
          null,
          0.28298264741897583,
          -0.16495169699192047,
          null,
          0.004032961092889309,
          0.013616038486361504,
          null,
          -0.2750774621963501,
          2.1872639656066895,
          null
         ],
         "z": [
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.8,
          0,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0,
          null,
          0.8,
          0,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.8,
          null,
          0.4,
          0,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0.4,
          0,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0.8,
          0,
          null,
          0.8,
          0,
          null,
          0.8,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.8,
          0,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.8,
          0,
          null,
          0.8,
          0,
          null,
          0.8,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0,
          null,
          0.8,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0.8,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0.4,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0.4,
          0,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0,
          null,
          0.4,
          0,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0.4,
          0,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0.4,
          0,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0,
          0,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0.4,
          0,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0.4,
          0,
          null,
          0.4,
          0,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.8,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0.8,
          0,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0,
          null,
          0.8,
          0.4,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0.8,
          0,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0,
          null,
          0.8,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.8,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.8,
          0,
          null,
          0.8,
          0,
          null,
          0.8,
          0,
          null,
          0.8,
          0,
          null,
          0.4,
          0,
          null,
          0.4,
          0,
          null,
          0,
          0,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0.4,
          0,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0.8,
          0.4,
          null,
          0,
          0.4,
          null,
          0.8,
          0,
          null,
          0.8,
          0,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0,
          null,
          0.4,
          0,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0,
          null,
          0.8,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0.4,
          0,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0.8,
          null,
          0,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0.4,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0.4,
          0,
          null,
          0.8,
          0,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0,
          null,
          0.4,
          0,
          null,
          0.4,
          0,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0,
          null,
          0,
          0,
          null,
          0.8,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0,
          0.4,
          null,
          0.8,
          0,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0.4,
          0.4,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.8,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0.8,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0,
          null,
          0.8,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0,
          0,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0,
          null,
          0,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0,
          null,
          0.8,
          0,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0.4,
          0,
          null,
          0,
          0,
          null,
          0.8,
          0,
          null,
          0.4,
          0,
          null,
          0.8,
          0,
          null,
          0.8,
          0,
          null,
          0.4,
          0,
          null,
          0.4,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0,
          null,
          0.8,
          0,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0.8,
          0,
          null,
          0.4,
          0.8,
          null,
          0.8,
          0,
          null,
          0.4,
          0,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0,
          null,
          0.4,
          0,
          null,
          0.8,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0,
          null,
          0.8,
          0,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.8,
          0,
          null,
          0,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0.8,
          0,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.8,
          0,
          null,
          0,
          0,
          null,
          0.4,
          0,
          null,
          0.8,
          0,
          null,
          0.8,
          0,
          null,
          0,
          0,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.4,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0,
          null,
          0,
          0,
          null,
          0.8,
          0,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0.8,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0,
          0,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0.4,
          0,
          null,
          0.8,
          0,
          null,
          0.8,
          0.8,
          null,
          0.8,
          0,
          null,
          0.8,
          0.4,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0,
          null,
          0.4,
          0.8,
          null,
          0,
          0,
          null,
          0.8,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.4,
          null,
          0.4,
          0,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0,
          null,
          0,
          0.4,
          null,
          0.8,
          0,
          null,
          0,
          0.4,
          null,
          0.8,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0,
          null,
          0,
          0.8,
          null,
          0,
          0.8,
          null,
          0,
          0,
          null,
          0,
          0.4,
          null,
          0,
          0.8,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.4,
          0,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.8,
          null,
          0.8,
          0.4,
          null,
          0.8,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.4,
          0.4,
          null,
          0.8,
          0.4,
          null
         ]
        },
        {
         "marker": {
          "color": [
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "red",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "green",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue"
          ],
          "opacity": 0.8,
          "size": 8
         },
         "mode": "markers+text",
         "name": "Nodes",
         "text": [
          "0001",
          "075",
          "[[[formula]]]",
          "accuracy",
          "aggregation",
          "all",
          "amount",
          "another",
          "architecture",
          "balance",
          "baseline",
          "bias",
          "change",
          "cifar10",
          "cinic10",
          "client",
          "clusterfl",
          "coefficient",
          "compatibility",
          "compression",
          "configuration",
          "connection",
          "consensus",
          "convergence",
          "convolution",
          "data",
          "dataset",
          "decrease",
          "deer",
          "degree",
          "digit",
          "dilation",
          "distribution",
          "downside",
          "each",
          "effect",
          "effectiveness",
          "epoch",
          "evaluation",
          "example",
          "feature",
          "fedavg",
          "fedconv",
          "fedmd",
          "fedrolex",
          "fl",
          "flower",
          "formula",
          "fusion",
          "generalizability",
          "googlenet",
          "gradient",
          "harbox",
          "head",
          "hermes",
          "heterofl",
          "image",
          "impact",
          "importance",
          "information",
          "instability",
          "integration",
          "issue",
          "iteration",
          "kd",
          "kernel",
          "kld",
          "knowledge",
          "laboratory",
          "laptop",
          "layer",
          "loss",
          "lotteryfl",
          "magnitude",
          "map",
          "method",
          "mi",
          "mlr",
          "model",
          "necessity",
          "number",
          "optimization",
          "output",
          "overhead",
          "overview",
          "padding",
          "parameter",
          "part",
          "performance",
          "personalization",
          "pfedme",
          "popularity",
          "potential",
          "practicality",
          "practice",
          "problem",
          "progress",
          "pruning",
          "pytorch",
          "ratio",
          "removal",
          "resnet18",
          "respect",
          "result",
          "robustness",
          "router",
          "s",
          "scalability",
          "scheme",
          "server",
          "serveralone",
          "set",
          "shape",
          "similarity",
          "size",
          "slope",
          "sota",
          "sr",
          "step",
          "stride",
          "subset",
          "superiority",
          "table",
          "tailorfl",
          "tc",
          "term",
          "that",
          "these",
          "this",
          "training",
          "transfer",
          "transformation",
          "tuning",
          "variation",
          "view",
          "we",
          "weight",
          "which",
          "§",
          "③",
          "05 %",
          "1 mnist",
          "1 wiar",
          "10 client",
          "100 client",
          "12 input",
          "121 user",
          "138 %",
          "16 activity",
          "16 input",
          "2 cifar10",
          "2 second",
          "20 %",
          "205 %",
          "3 cinic10",
          "3 harbox",
          "406 %",
          "5 %",
          "5 lotteryfl",
          "546 %",
          "6 hermes",
          "64000 sample",
          "7 tailorfl",
          "7336 %",
          "8404 %",
          "9 fedrolex",
          "9904 %",
          "ablation study",
          "accuracy drop",
          "affordable model",
          "aggregate vector",
          "aggregated model",
          "aggregated parameter",
          "aggregation process",
          "all baseline",
          "all channel",
          "all client",
          "all datasets",
          "all parameter",
          "android client",
          "android system",
          "appropriate sr",
          "approximately half",
          "average accuracy",
          "average consensus",
          "average improvement",
          "average saving",
          "better generalizability",
          "better performance",
          "both body",
          "case study",
          "certain threshold",
          "certain weight",
          "channel number",
          "cifar10 dataset",
          "client contribution",
          "client data",
          "client model",
          "client performance",
          "client workload",
          "cloud server",
          "cnn model",
          "communication cost",
          "communication round",
          "comparable performance",
          "compressed model",
          "compressed parameter",
          "compression layer",
          "compression method",
          "compression process",
          "computation overhead",
          "computational overhead",
          "computer font",
          "constrained resource",
          "conventional fl",
          "convolution compression",
          "convolution layer",
          "convolution parameter",
          "convolution process",
          "convolutional compression",
          "convolutional layer",
          "corresponding channel",
          "corresponding client",
          "corresponding configuration",
          "corresponding label",
          "corresponding threshold",
          "crucial information",
          "data distribution",
          "data packet",
          "data sample",
          "degraded performance",
          "detailed configuration",
          "different class",
          "different client",
          "different contribution",
          "different datasets",
          "different part",
          "different region",
          "different size",
          "different type",
          "dilated model",
          "distilled knowledge",
          "distinct part",
          "diverse resource",
          "domain gap",
          "each client",
          "each element",
          "each filter",
          "each model",
          "each part",
          "each round",
          "ensemble learning",
          "entire channel",
          "entire dataset",
          "excessive communication",
          "execution time",
          "extra burden",
          "extra content",
          "feature map",
          "federated client",
          "figure reference",
          "final aggregation",
          "first conv",
          "first layer",
          "five datasets",
          "fixed subset",
          "fl client",
          "fl server",
          "flower framework",
          "following baseline",
          "forward function",
          "four part",
          "four sr",
          "full use",
          "global model",
          "global parameter",
          "googlenet model",
          "gradient descent",
          "ground truth",
          "harbox dataset",
          "heavy overhead",
          "heterogeneous client",
          "heterogeneous data",
          "heterogeneous device",
          "heterogeneous fl",
          "heterogeneous model",
          "higher accuracy",
          "higher generalizability",
          "highest importance",
          "homogeneous data",
          "iid data",
          "imbalance issue",
          "imbalanced contribution",
          "imbalanced performance",
          "inference accuracy",
          "information loss",
          "input channel",
          "input data",
          "insufficient number",
          "iterative refining",
          "kernel size",
          "key information",
          "knowledge distillation",
          "large model",
          "larger amount",
          "larger kernel",
          "larger model",
          "larger sr",
          "larger volume",
          "last layer",
          "learnable variable",
          "learning rate",
          "less memory",
          "limited capability",
          "load_state_dict function",
          "local data",
          "local training",
          "lower accuracy",
          "lower layer",
          "maximum number",
          "memory cost",
          "memory footprint",
          "minimal modification",
          "mixed window",
          "mnist dataset",
          "mobile device",
          "model aggregation",
          "model compression",
          "model exposure",
          "model output",
          "model parameter",
          "model performance",
          "model pruning",
          "more attention",
          "more contribution",
          "more resource",
          "moreau envelope",
          "mutual information",
          "negative parameter",
          "network layer",
          "network traffic",
          "new technology",
          "one model",
          "one size",
          "other client",
          "other kind",
          "other type",
          "our knowledge",
          "our office",
          "our system",
          "output channel",
          "overall performance",
          "overlapped part",
          "parameter information",
          "parameter matrix",
          "parameter sharing",
          "performance degradation",
          "performance enhancement",
          "performance improvement",
          "performance instability",
          "personalization information",
          "personalization performance",
          "personalized fl",
          "personalized information",
          "prediction result",
          "previous solution",
          "privacy protection",
          "public data",
          "pympler library",
          "raspberry pi",
          "raw data",
          "recent advancement",
          "recent work",
          "relative importance",
          "residual connection",
          "resnet18 model",
          "resource budget",
          "resource profile",
          "resource profiling",
          "reverse operation",
          "richer information",
          "same degree",
          "same domain",
          "same set",
          "same size",
          "sample distribution",
          "sample number",
          "second conv",
          "sensing heterogeneity",
          "sensor data",
          "server side",
          "several epoch",
          "shared dataset",
          "sharing strategy",
          "shrinkage ratio",
          "significant potential",
          "significant saving",
          "sliding window",
          "small dataset",
          "small portion",
          "smaller model",
          "smaller sr",
          "smaller stride",
          "some baseline",
          "some device",
          "sota baseline",
          "standalone fedmd",
          "stride length",
          "sub model",
          "sufficient data",
          "superior performance",
          "synchronized fl",
          "system overhead",
          "tc layer",
          "tc operation",
          "tc parameter",
          "technical challenge",
          "ten class",
          "these challenge",
          "these datasets",
          "these work",
          "this paradigm",
          "this scheme",
          "three datasets",
          "total dataset",
          "total size",
          "trade off",
          "training process",
          "training task",
          "transposed convolution",
          "tuning epoch",
          "two datasets",
          "unified size",
          "uniform size",
          "upper layer",
          "upward trend",
          "useful feature",
          "valuable feature",
          "value range",
          "varying skewness",
          "weaker client",
          "weight normalization",
          "weight vector",
          "wifi signal",
          "1 iid server side global data",
          "100 communication round",
          "180000 32 formula 32 color image",
          "2 gb less memory",
          "2 iid test data",
          "20 heterogeneous mobile device",
          "20 th and 40 th epoch",
          "24 output channel",
          "3 pruning based method",
          "32 color image",
          "32 output channel",
          "480 90 formula 250 wi fi csi sample",
          "5 local training epoch",
          "5000 36 formula 36 gray scale depth image",
          "60000 32 formula",
          "60000 formula gray scale image",
          "77 different smartphones",
          "9 axis imu data",
          "900 dimensional feature",
          "actual turning point",
          "additional compute overhead",
          "aggregated global model",
          "all client model",
          "all convolution parameter",
          "all dilated model",
          "around 20 epoch",
          "around 90 minute",
          "average client model accuracy",
          "average memory usage",
          "average wall clock time",
          "better and more stable performance",
          "better global view",
          "better personalization performance",
          "both global and client model",
          "both global model",
          "both inference accuracy",
          "both server side and client side datasets",
          "channel level and filter level pruning",
          "channel level pruning",
          "channel level pruning method",
          "channel or filter level pruning",
          "channel pruned model",
          "channel state information",
          "chars74 k dataset",
          "client friendly federated learning framework",
          "client friendly fl framework",
          "client model accuracy",
          "client model performance",
          "client own personal layer",
          "client private data",
          "client s perspective",
          "client shrinkage ratio",
          "client side data",
          "client side data distribution",
          "client side non iid data",
          "client side private test datasets",
          "client side test datasets",
          "clustered multi task federated learning",
          "communication computation and energy cost",
          "comparable personalization performance",
          "comprehensive global view",
          "compressed parameter matrix",
          "compressed sub model",
          "compression dilation aggregation impact",
          "computing resource budget",
          "conventional fl scheme",
          "convolution / tc parameter",
          "convolution based compression process",
          "convolutional compression module",
          "convolutional neural network",
          "corresponding weight vector",
          "cosine annealing learning rate scheduler",
          "cosine function decay",
          "cross entropy loss",
          "default sample ratio",
          "different data heterogeneity",
          "different hardware and network condition",
          "different learnable weight vector",
          "different learned weight vector",
          "different parameter information",
          "different sensing heterogeneity",
          "different tc layer",
          "dilated large model",
          "dilated model parameter",
          "disjoint non iid client side data",
          "diverse computation and communication resource",
          "diverse personalized information",
          "diverse sub model",
          "diverse system resource",
          "dynamic rolling window",
          "e g different shape",
          "e g various writing style",
          "each client model",
          "each client s model parameter",
          "each client s process id",
          "each dilated model",
          "each tc layer",
          "each uploaded client model",
          "entire fl process",
          "estimated memory requirement",
          "even lightweight device",
          "every network layer",
          "existing fl framework",
          "existing fl system",
          "existing pruning based method",
          "extra communication or computation overhead",
          "feature extraction capability",
          "fedconv lotteryfl heterofl",
          "federated learning setup",
          "filter level pruning",
          "filter pruned model",
          "fine grained way",
          "fine tuned convolution parameter",
          "first and second part",
          "first two feature map",
          "five common gesture",
          "five daily activity",
          "flower cite framework",
          "following key contribution",
          "generated sub model",
          "global model accuracy",
          "global model parameter",
          "global model s parameter",
          "heterogeneous client model",
          "heterogeneous federated client",
          "heterogeneous formula = 005 data",
          "heterogeneous sub model",
          "high communication and computation overhead",
          "high computational complexity",
          "high end edge pc",
          "high end pc",
          "higher average accuracy",
          "higher global model accuracy",
          "highest client model accuracy",
          "i e parameter",
          "importance value based filter level pruning scheme",
          "increased data heterogeneity",
          "input channel number",
          "intrinsic clustering pattern",
          "knowledge distillation based method",
          "kullback leibler divergence",
          "large global model",
          "last two feature map",
          "learned importance value",
          "learning rate scheduler",
          "least system resource",
          "local fine tuning",
          "locally trained heterogeneous client model",
          "longer convergence time",
          "low cost embedded system",
          "lower and upper bound",
          "memory and training time",
          "memory computation and communication resource",
          "mnist cite dataset",
          "model compression dilation and aggregation process",
          "model heterogeneity aware fl system",
          "model personalized information",
          "more comprehensive global perspective",
          "more comprehensive parameter information",
          "more fine grained information",
          "more general feature",
          "more powerful client",
          "more system resource",
          "more than 35 %",
          "much constrained resource",
          "much higher accuracy",
          "much higher sensitivity",
          "much lower computation and communication overhead",
          "negative and positive value",
          "nine separate 2d convolutional layer",
          "no client side sensor data",
          "no standard model",
          "non iid data",
          "notable accuracy drop",
          "novel convolutional compression technique",
          "one data domain",
          "one fc layer",
          "only 476 %",
          "only server side global data",
          "our learned weight vector",
          "our proposed convolutional compression method",
          "output channel number",
          "parameter local data distribution",
          "parameter pruning method",
          "parameter sharing strategy",
          "popular computer vision application",
          "pre trained model",
          "pre trained resnet18 model",
          "pre training and fine tuning process",
          "previous communication round",
          "regularized loss function",
          "remaining 10 client",
          "rescaled large model",
          "resource constrained client",
          "resource constrained mobile device",
          "same heterogeneous data setting",
          "same model architecture",
          "same prediction task",
          "sample number ratio",
          "selected participating client",
          "separate tc operation",
          "server side data",
          "server side pre training process",
          "server side test dataset",
          "serveralone s global model",
          "several practical challenge",
          "shared global model",
          "significant computational and communication overhead",
          "significant performance fluctuation",
          "significant performance gain",
          "similar distribution pattern",
          "simple compression layer",
          "six public datasets",
          "small publicly available dataset",
          "smallest affordable model",
          "some input channel",
          "some input data channel",
          "some output channel",
          "sparse sub model",
          "spatial and hierarchical parameter pattern",
          "stable and robust simulated environment",
          "stride padding value",
          "sub model output",
          "sub model parameter",
          "sub optimal performance",
          "superior generalization performance",
          "tc dilation process",
          "ten handwritten digit",
          "th dilated model",
          "these dilated model",
          "these edge device",
          "these large model",
          "these two scheme",
          "this compression process",
          "this performance gain",
          "three conv layer",
          "three key technical challenge",
          "three key technical module",
          "top4 and top3 feature map",
          "transfer learning strategy",
          "transposed convolutional dilation",
          "transposed convolutional dilation method",
          "two convolutional layer",
          "two formula convolutional layer",
          "two key observation",
          "two representative fl task",
          "two representative mobile application",
          "two tc formula layer",
          "unexpected performance degradation",
          "unit parameter matrix",
          "user friendly fl framework",
          "varied parameter size",
          "various receptive field",
          "varying client number",
          "wall clock time",
          "weight vector tuning",
          "weighted average aggregation",
          "whose parameter matrix"
         ],
         "textposition": "top center",
         "type": "scatter3d",
         "x": [
          0.38434505462646484,
          0.981150209903717,
          -0.24076588451862335,
          -0.2065650075674057,
          -0.2181958705186844,
          -0.23264338076114655,
          -0.23057080805301666,
          -0.20807309448719025,
          -0.22729657590389252,
          -0.2612731158733368,
          -0.20490533113479614,
          -0.203455850481987,
          -0.21245864033699036,
          -0.14213161170482635,
          -0.22780567407608032,
          -0.19078172743320465,
          -0.19756096601486206,
          -0.13203363120555878,
          -0.22985292971134186,
          -0.20983630418777466,
          -0.2563638389110565,
          -0.24813072383403778,
          -0.24247343838214874,
          -0.23057781159877777,
          -0.14172573387622833,
          -0.22274990379810333,
          -0.17755120992660522,
          -0.19137844443321228,
          -0.04647110775113106,
          -0.13887380063533783,
          -0.11836996674537659,
          -0.13196995854377747,
          -0.23898346722126007,
          -0.30032646656036377,
          -0.18827500939369202,
          -0.2813956141471863,
          -0.23073787987232208,
          -0.03981778770685196,
          -0.2177920788526535,
          -0.20018215477466583,
          -0.26476529240608215,
          -0.10543763637542725,
          -0.18713244795799255,
          -0.19027727842330933,
          -0.20487791299819946,
          3.2170605659484863,
          -0.1693044751882553,
          -0.18511761724948883,
          -0.2040061354637146,
          -0.20057038962841034,
          -0.23231138288974762,
          -0.14034321904182434,
          -0.25219476222991943,
          -0.22054865956306458,
          0.0621141716837883,
          -0.2686671018600464,
          -0.20678871870040894,
          -0.3355262279510498,
          -0.26964008808135986,
          -0.22173690795898438,
          -0.21905949711799622,
          -0.22764956951141357,
          -0.3222001791000366,
          -0.19783899188041687,
          2.5126051902770996,
          -0.11813946068286896,
          -0.1781844049692154,
          -0.24297906458377838,
          -0.19883306324481964,
          -0.14314505457878113,
          -0.15014944970607758,
          -0.17201104760169983,
          -0.20611241459846497,
          -0.1785692721605301,
          -0.08209985494613647,
          -0.2344702035188675,
          4.052042484283447,
          0.7709515690803528,
          -0.22848264873027802,
          -0.27802595496177673,
          -0.24551264941692352,
          -0.21397796273231506,
          -0.18555043637752533,
          -0.2530515789985657,
          -0.23677243292331696,
          -0.2203851044178009,
          -0.11680853366851807,
          -0.2726221978664398,
          -0.22472740709781647,
          -0.20658208429813385,
          -0.21248289942741394,
          -0.24584197998046875,
          -0.27539458870887756,
          -0.2568063735961914,
          -0.26444950699806213,
          -0.2868480980396271,
          -0.2532028257846832,
          -0.2121078372001648,
          -0.2075643092393875,
          -0.14662082493305206,
          -0.1790398508310318,
          -0.29526907205581665,
          -0.21676914393901825,
          -0.2846773862838745,
          -0.24894845485687256,
          -0.07273076474666595,
          0.8404133915901184,
          -0.2366710752248764,
          -0.26912206411361694,
          -0.14433220028877258,
          -0.2013840526342392,
          -0.2849453091621399,
          -0.3132747411727905,
          -0.26513004302978516,
          -0.2382820099592209,
          -0.06245706230401993,
          0.3791048228740692,
          2.4730043411254883,
          -0.22675921022891998,
          -0.22491301596164703,
          -0.20838013291358948,
          -0.22429904341697693,
          -0.2259628027677536,
          -0.22581976652145386,
          2.450235605239868,
          -0.1520339548587799,
          -0.1922614723443985,
          -0.26647070050239563,
          -0.21130487322807312,
          -0.23261812329292297,
          -0.1816958487033844,
          -0.23632381856441498,
          -0.22731760144233704,
          -0.24329045414924622,
          -0.28489190340042114,
          0.77921462059021,
          -0.16772669553756714,
          -0.15461517870426178,
          3.6365485191345215,
          4.055788516998291,
          5.2661519050598145,
          2.3847849369049072,
          2.388746500015259,
          2.6596386432647705,
          0.5345849990844727,
          2.7728490829467773,
          0.8727547526359558,
          3.3319807052612305,
          2.7619822025299072,
          2.7742249965667725,
          2.445047616958618,
          2.4416439533233643,
          5.1554646492004395,
          3.2222323417663574,
          2.458759069442749,
          2.44697642326355,
          3.1300723552703857,
          5.133536338806152,
          2.626448392868042,
          3.199669122695923,
          2.73553729057312,
          0.02498847432434559,
          2.6492116451263428,
          2.6841495037078857,
          2.5981833934783936,
          2.727800130844116,
          2.732795238494873,
          -0.3551540672779083,
          -0.2813604772090912,
          -0.4509764611721039,
          -0.33939236402511597,
          -0.4215370714664459,
          -0.35303887724876404,
          -0.41495630145072937,
          -0.25057464838027954,
          -0.28719577193260193,
          -0.24309520423412323,
          -0.28206610679626465,
          -0.27001774311065674,
          -0.2894885838031769,
          -0.34325161576271057,
          0.638736367225647,
          -0.088998943567276,
          -0.24215251207351685,
          -0.28517934679985046,
          -0.28421661257743835,
          -0.25734367966651917,
          -0.38132745027542114,
          -0.40498292446136475,
          -0.2566058933734894,
          -0.44350484013557434,
          -0.32592931389808655,
          -0.27948060631752014,
          -0.3553406596183777,
          -0.29730474948883057,
          -0.38340887427330017,
          -0.41115763783454895,
          -0.44848594069480896,
          -0.38319599628448486,
          -0.3882427215576172,
          -0.3710010051727295,
          -0.024762006476521492,
          -0.3194373846054077,
          -0.36644238233566284,
          -0.39501020312309265,
          -0.4442349970340729,
          -0.3757368326187134,
          -0.37489399313926697,
          -0.3825852572917938,
          -0.4064701497554779,
          -0.3977019786834717,
          -0.36548590660095215,
          -0.3647884428501129,
          -0.4266420602798462,
          1.6463334560394287,
          -0.34479615092277527,
          -0.35558032989501953,
          -0.3492552638053894,
          -0.38715654611587524,
          -0.29411807656288147,
          -0.30490225553512573,
          -0.3754117488861084,
          -0.3313111662864685,
          -0.3944622874259949,
          -0.3551577031612396,
          -0.33716729283332825,
          -0.4155997335910797,
          -0.4082096815109253,
          -0.40659335255622864,
          -0.3632795214653015,
          -0.39728283882141113,
          -0.43539953231811523,
          -0.331317275762558,
          -0.3311408758163452,
          -0.3614845275878906,
          -0.3701118528842926,
          -0.3967806398868561,
          -0.35716545581817627,
          -0.3269636929035187,
          -0.37889471650123596,
          -0.3145896792411804,
          -0.3507192134857178,
          -0.41657862067222595,
          -0.40609073638916016,
          -0.4083673357963562,
          -0.19647401571273804,
          -0.24204786121845245,
          -0.25440406799316406,
          -0.29189473390579224,
          -0.26211366057395935,
          -0.20797963440418243,
          -0.39202407002449036,
          -0.3394008278846741,
          -0.33555471897125244,
          -0.39102399349212646,
          -0.37809693813323975,
          -0.25647208094596863,
          -0.24039003252983093,
          -0.4762248396873474,
          -0.3290537893772125,
          -0.438457727432251,
          -0.3025570213794708,
          -0.1704195737838745,
          -0.30923208594322205,
          0.03513864800333977,
          -0.3127136826515198,
          1.6815776824951172,
          1.6799345016479492,
          -0.39724716544151306,
          -0.32278284430503845,
          -0.4328012764453888,
          -0.03459852933883667,
          1.0172346830368042,
          -0.2341119349002838,
          -0.4013250470161438,
          -0.3328269124031067,
          -0.3971827030181885,
          -0.32205408811569214,
          -0.3989904820919037,
          -0.38447585701942444,
          -0.37930062413215637,
          -0.336235910654068,
          -0.3943283259868622,
          -0.37071335315704346,
          1.6513246297836304,
          -0.4316566288471222,
          -0.2961190342903137,
          -0.3214751183986664,
          -0.3286322057247162,
          -0.3979059159755707,
          0.17622002959251404,
          -0.4118274748325348,
          -0.38141024112701416,
          -0.38119739294052124,
          -0.3428748548030853,
          -0.3146917521953583,
          -0.4318200349807739,
          -0.44581183791160583,
          -0.3343993127346039,
          -0.39148107171058655,
          -0.3465925455093384,
          -0.3935699164867401,
          -0.42336010932922363,
          -0.3763519823551178,
          -0.30617713928222656,
          -0.320833295583725,
          -0.4256265163421631,
          0.6559876203536987,
          -0.33070212602615356,
          -0.20981112122535706,
          -0.33146509528160095,
          -0.24929125607013702,
          -0.2943912744522095,
          -0.3863222301006317,
          -0.3172403573989868,
          -0.3589669167995453,
          -0.35738545656204224,
          -0.3003368079662323,
          -0.3524651825428009,
          -0.2566664516925812,
          -0.33717072010040283,
          -0.40094128251075745,
          -0.39171165227890015,
          -0.37033331394195557,
          -0.34995973110198975,
          -0.29892784357070923,
          -0.38971206545829773,
          -0.37008407711982727,
          -0.36380571126937866,
          -0.3354363441467285,
          -0.37454313039779663,
          -0.37775132060050964,
          -0.41491127014160156,
          -0.34771081805229187,
          -0.3501236140727997,
          -0.3745192289352417,
          -0.2878672480583191,
          -0.4002639055252075,
          -0.36314961314201355,
          -0.38246214389801025,
          -0.37026843428611755,
          -0.3561292588710785,
          -0.2638987898826599,
          -0.16430090367794037,
          -0.32044652104377747,
          -0.40182849764823914,
          -0.36820024251937866,
          -0.20607368648052216,
          -0.22336310148239136,
          -0.23404204845428467,
          -0.3826235830783844,
          -0.3228030502796173,
          -0.4214174449443817,
          -0.3858230710029602,
          -0.37592166662216187,
          -0.38419967889785767,
          -0.35606247186660767,
          -0.3937024772167206,
          -0.36755189299583435,
          -0.3879346549510956,
          -0.3920506536960602,
          -0.3713628649711609,
          0.5669098496437073,
          -0.4009389877319336,
          -0.3914228081703186,
          -0.3527279496192932,
          -0.4177006483078003,
          -0.413530558347702,
          -0.39298760890960693,
          0.5073480606079102,
          -0.4312690496444702,
          -0.3455379605293274,
          -0.3626464307308197,
          -0.40264517068862915,
          -0.372873455286026,
          -0.4330805838108063,
          -0.4079287350177765,
          -0.42943885922431946,
          -0.4339887499809265,
          -0.3953375518321991,
          -0.42760276794433594,
          -0.256418377161026,
          -0.2924654185771942,
          -0.3983023762702942,
          -0.2741954028606415,
          -0.3526751697063446,
          -0.3162766396999359,
          -0.1404333859682083,
          -0.38663390278816223,
          -0.3543994128704071,
          -0.4155884087085724,
          -0.26713827252388,
          -0.44297948479652405,
          -0.4444885551929474,
          -0.2265467345714569,
          -0.3691391050815582,
          -0.33840781450271606,
          -0.36354753375053406,
          -0.31682345271110535,
          -0.2719423770904541,
          -0.4057043790817261,
          0.6759098172187805,
          -0.3518505394458771,
          -0.2687675356864929,
          -0.29576537013053894,
          -0.10157553106546402,
          -0.369003564119339,
          -0.3644024729728699,
          -0.1563851684331894,
          -0.38775911927223206,
          -0.4063625931739807,
          0.5607339143753052,
          -0.4112301170825958,
          1.0860406160354614,
          1.0708444118499756,
          1.0923655033111572,
          -0.44165608286857605,
          0.33335989713668823,
          -0.34613361954689026,
          -0.3149547278881073,
          -0.33044224977493286,
          -0.3397347927093506,
          -0.3570714592933655,
          -0.12149672210216522,
          -0.16589471697807312,
          -0.12146300077438354,
          -0.22445626556873322,
          -0.43135398626327515,
          -0.4665999710559845,
          -0.4023062288761139,
          -0.42359447479248047,
          0.06836844235658646,
          -0.3900507688522339,
          -0.37661755084991455,
          -0.316644549369812,
          -0.3408474922180176,
          -0.46435534954071045,
          -0.44526931643486023,
          -0.31754422187805176,
          -0.2536211311817169,
          -0.3289012610912323,
          -0.32872143387794495,
          -0.33428955078125,
          -0.29590103030204773,
          3.0325276851654053,
          0.7730562090873718,
          3.7893331050872803,
          3.7673227787017822,
          3.109830141067505,
          3.3704569339752197,
          1.2278838157653809,
          3.351423978805542,
          2.9535293579101562,
          3.719896078109741,
          3.719235897064209,
          2.9943063259124756,
          3.119036912918091,
          3.8342480659484863,
          3.8076188564300537,
          0.04129659757018089,
          3.1473608016967773,
          3.6091411113739014,
          0.5173392295837402,
          -0.40307721495628357,
          -0.35416004061698914,
          -0.39676856994628906,
          -0.24787285923957825,
          -0.2015811800956726,
          -0.20804035663604736,
          3.389488697052002,
          2.8535916805267334,
          -0.3595740795135498,
          -0.33933448791503906,
          -0.32609793543815613,
          -0.3748640716075897,
          -0.4215938150882721,
          -0.46685072779655457,
          -0.30277499556541443,
          -0.3171130120754242,
          -0.3216798007488251,
          -0.33217790722846985,
          -0.39188113808631897,
          -0.41075989603996277,
          -0.41075989603996277,
          0.05133674293756485,
          -0.4354811906814575,
          -0.4282054901123047,
          1.201676368713379,
          -0.4368841350078583,
          -0.38908207416534424,
          -0.46851131319999695,
          -0.459083616733551,
          -0.4526509642601013,
          -0.4328693747520447,
          -0.1305273324251175,
          -0.430012047290802,
          -0.47899293899536133,
          -0.47899293899536133,
          -0.42860105633735657,
          -0.45961570739746094,
          -0.4670450985431671,
          -0.48571035265922546,
          -0.3825821280479431,
          -0.46494269371032715,
          -0.41637229919433594,
          -0.41428881883621216,
          -0.4648168683052063,
          -0.40325528383255005,
          -0.4394821524620056,
          -0.3848789930343628,
          1.400133490562439,
          -0.4605691432952881,
          -0.36569589376449585,
          -0.3782137632369995,
          -0.39078325033187866,
          -0.42206594347953796,
          -0.4350427985191345,
          -0.4788881242275238,
          -0.3837820291519165,
          -0.4198969006538391,
          -0.36677849292755127,
          -0.4050523638725281,
          -0.41612109541893005,
          -0.40493643283843994,
          -0.4151816666126251,
          -0.13546526432037354,
          -0.34494277834892273,
          -0.3044790029525757,
          -0.07937533408403397,
          -0.37498152256011963,
          -0.44642961025238037,
          -0.462936133146286,
          -0.44997164607048035,
          -0.4563048481941223,
          -0.038836803287267685,
          -0.00766439363360405,
          -0.24857307970523834,
          -0.2289937138557434,
          -0.2289937138557434,
          -0.20874062180519104,
          0.05558530613780022,
          -0.21504180133342743,
          -0.31005534529685974,
          -0.3966740369796753,
          -0.4273715913295746,
          -0.2274320423603058,
          -0.3925439119338989,
          -0.3894193470478058,
          -0.4601176381111145,
          0.040011703968048096,
          -0.4934520721435547,
          -0.4035072326660156,
          -0.47152188420295715,
          -0.4032643139362335,
          -0.42798566818237305,
          -0.4221605956554413,
          -0.4795970916748047,
          -0.3809400796890259,
          0.19688217341899872,
          0.14932763576507568,
          0.157850444316864,
          -0.427303671836853,
          -0.38230210542678833,
          -0.4280901551246643,
          -0.44367122650146484,
          -0.39288923144340515,
          -0.294003963470459,
          -0.4602380394935608,
          -0.4294705390930176,
          -0.2144104391336441,
          -0.45638954639434814,
          -0.3934854567050934,
          -0.4395645260810852,
          -0.31587597727775574,
          0.040945135056972504,
          -0.3472999334335327,
          -0.4049573838710785,
          -0.39087748527526855,
          0.7856631875038147,
          -0.4933568835258484,
          -0.4415583312511444,
          -0.4448050558567047,
          -0.4606528580188751,
          -0.4869278073310852,
          -0.44035351276397705,
          -0.39528247714042664,
          0.20268774032592773,
          -0.45132964849472046,
          -0.47087204456329346,
          -0.25339505076408386,
          -0.42158243060112,
          -0.4476192593574524,
          -0.4410001039505005,
          -0.2397831231355667,
          -0.3914957046508789,
          -0.37282073497772217,
          -0.387966513633728,
          -0.4022720456123352,
          -0.4249405264854431,
          -0.5191138982772827,
          -0.4621870219707489,
          -0.4443855583667755,
          -0.4435606598854065,
          -0.40711623430252075,
          -0.4268761873245239,
          -0.4644649624824524,
          -0.3946457803249359,
          -0.11184483766555786,
          -0.47568657994270325,
          -0.3998945653438568,
          -0.38803616166114807,
          -0.37798136472702026,
          -0.3873838484287262,
          0.566757082939148,
          0.9356509447097778,
          0.9681019186973572,
          0.18637502193450928,
          -0.47925442457199097,
          -0.3837509751319885,
          -0.1386936902999878,
          0.09330374747514725,
          0.9513493180274963,
          -0.2795238494873047,
          -0.22765986621379852,
          -0.19813932478427887,
          -0.4366864860057831,
          -0.3636963665485382,
          -0.469063937664032,
          -0.4696792662143707,
          -0.4772302806377411,
          -0.38678157329559326,
          -0.4664028584957123,
          -0.39074358344078064,
          -0.3785509467124939,
          -0.46045050024986267,
          3.2727842330932617,
          -0.343284547328949,
          -0.4775387942790985,
          -0.44594207406044006,
          -0.41024792194366455,
          -0.30230751633644104,
          -0.3302881121635437,
          -0.28375157713890076,
          -0.4389159381389618,
          1.018332600593567,
          -0.4531129002571106,
          -0.11393105983734131,
          -0.40615665912628174,
          -0.08708123862743378,
          -0.4617006778717041,
          -0.4117111563682556,
          -0.3774597942829132,
          -0.4334908425807953,
          -0.440655916929245,
          -0.4717462360858917,
          -0.44961288571357727,
          0.48073095083236694,
          -0.360376238822937,
          -0.4658333957195282,
          -0.2569751739501953,
          -0.26643458008766174,
          -0.2488565891981125,
          -0.45186349749565125,
          -0.3874531388282776,
          -0.3897252380847931,
          -0.45111513137817383,
          -0.44734129309654236,
          -0.44577521085739136,
          -0.13831102848052979,
          -0.48330581188201904,
          1.0217852592468262,
          0.5529747009277344,
          1.0013710260391235,
          -0.31921032071113586,
          -0.3082584738731384,
          -0.3330538272857666,
          0.20894458889961243,
          -0.3247928321361542,
          -0.3367779850959778,
          -0.02130325697362423,
          -0.09295151382684708,
          -0.09295151382684708,
          -0.32655760645866394,
          -0.47625499963760376,
          -0.36189407110214233,
          -0.36189407110214233,
          0.233501598238945,
          0.24069277942180634,
          0.18772955238819122,
          0.5345343947410583,
          0.23794837296009064,
          0.4931749105453491,
          -0.4557967483997345,
          -0.4239879846572876,
          -0.12380795180797577,
          -0.45081573724746704,
          -0.4562217891216278,
          -0.34781262278556824,
          -0.3463955223560333,
          -0.3863079249858856,
          -0.32129302620887756,
          -0.31647583842277527
         ],
         "y": [
          0.08342050015926361,
          0.158263698220253,
          0.027567733079195023,
          0.03713188320398331,
          0.011754341423511505,
          -0.06000417843461037,
          0.040996260941028595,
          0.020354721695184708,
          0.012813478708267212,
          0.06184535101056099,
          0.05014977231621742,
          0.08898111432790756,
          0.008924584835767746,
          -0.015178321860730648,
          0.009484868496656418,
          -0.004055174067616463,
          -0.004049438051879406,
          0.001505519961938262,
          0.03524785116314888,
          0.02700837329030037,
          0.02890964038670063,
          0.07337527722120285,
          0.01103968732059002,
          0.03229847922921181,
          0.003903429489582777,
          0.01960540935397148,
          -0.04367811605334282,
          0.02840322256088257,
          -0.11595838516950607,
          0.056010566651821136,
          -0.02410127781331539,
          0.03305131942033768,
          0.03576948121190071,
          0.06514409929513931,
          0.06610548496246338,
          0.061528436839580536,
          0.023520581424236298,
          -0.012530412524938583,
          0.08305206149816513,
          0.069027841091156,
          0.043586041778326035,
          -0.07621651887893677,
          -0.019056251272559166,
          -0.07600093632936478,
          -0.05510634556412697,
          -1.8703891038894653,
          0.049001339823007584,
          -0.06787369400262833,
          -0.024660460650920868,
          0.03705799952149391,
          -0.025700297206640244,
          0.033862315118312836,
          -0.006454857997596264,
          -0.08668990433216095,
          -0.13417577743530273,
          -0.0029502026736736298,
          0.07663945853710175,
          0.017566217109560966,
          0.06815880537033081,
          0.03758803755044937,
          0.030737953260540962,
          0.04855518415570259,
          0.0344979465007782,
          0.04495924711227417,
          -1.607568383216858,
          -0.09482114017009735,
          0.061509761959314346,
          0.03533190116286278,
          0.0686955526471138,
          -0.03258592635393143,
          0.09180006384849548,
          -0.037355199456214905,
          -0.02096337266266346,
          -0.042118869721889496,
          -0.10523124039173126,
          0.05888929218053818,
          -1.6525819301605225,
          -0.5322486162185669,
          -0.0031443245243281126,
          0.04510170966386795,
          0.022681862115859985,
          0.040689606219530106,
          0.03952103108167648,
          -0.013353781774640083,
          0.019999761134386063,
          0.014502695761620998,
          0.04971523955464363,
          0.044096603989601135,
          0.028587915003299713,
          0.059467244893312454,
          -0.03817326948046684,
          0.01643931120634079,
          0.031634584069252014,
          0.009654023684561253,
          0.040483515709638596,
          0.027330830693244934,
          0.05670206621289253,
          0.04788525402545929,
          0.028406109660863876,
          -0.0381496287882328,
          0.04895178601145744,
          0.004747449886053801,
          0.08601778000593185,
          0.0681150034070015,
          0.03532656282186508,
          0.07952199131250381,
          0.10430304706096649,
          0.0015154016437008977,
          0.023981276899576187,
          0.01909026689827442,
          -0.014639594592154026,
          0.022204603999853134,
          0.05007840320467949,
          0.023854035884141922,
          -0.09237980842590332,
          0.06074567511677742,
          -0.24097102880477905,
          -1.5433865785598755,
          0.04100527986884117,
          -0.05123790726065636,
          0.014647383242845535,
          0.07595526427030563,
          0.05041157826781273,
          0.028638727962970734,
          -1.1456881761550903,
          0.06594180315732956,
          0.049456316977739334,
          -0.012600491754710674,
          0.0023724501952528954,
          0.02069018967449665,
          0.0803636983036995,
          0.023224705830216408,
          -0.06070198491215706,
          0.03406619653105736,
          0.008676419965922832,
          0.17035554349422455,
          -0.07314678281545639,
          0.05671653896570206,
          0.7365708351135254,
          5.2627997398376465,
          -1.3393020629882812,
          1.9013365507125854,
          1.8797640800476074,
          1.877993106842041,
          0.44911396503448486,
          1.9617998600006104,
          0.3970341980457306,
          -2.726172685623169,
          1.9444395303726196,
          1.9382463693618774,
          1.8398070335388184,
          1.8371236324310303,
          -1.3730676174163818,
          -2.8520684242248535,
          1.9561556577682495,
          1.9606003761291504,
          -2.9259932041168213,
          -1.288218379020691,
          1.9085794687271118,
          -2.857408285140991,
          1.9046075344085693,
          0.10157789289951324,
          1.9830225706100464,
          -3.0861263275146484,
          -3.1804416179656982,
          2.0147244930267334,
          -3.0532078742980957,
          -0.0065349433571100235,
          -0.18599438667297363,
          -0.0024906357284635305,
          -0.022000176832079887,
          0.024147192016243935,
          -0.045442692935466766,
          0.014532803557813168,
          0.038328785449266434,
          0.08154118061065674,
          0.05483528599143028,
          0.055140670388936996,
          0.04088341444730759,
          0.006415147799998522,
          0.046290814876556396,
          -2.165008306503296,
          -0.1826891452074051,
          -0.07225335389375687,
          0.007632523775100708,
          -0.006094717420637608,
          -0.03622198849916458,
          -0.06851561367511749,
          -0.040166471153497696,
          -0.015157496556639671,
          -0.0179132167249918,
          -0.037499021738767624,
          -0.1286575347185135,
          -0.09703774750232697,
          0.004054530058056116,
          -0.019242487847805023,
          -0.040121614933013916,
          0.013616038486361504,
          -0.026950418949127197,
          -0.01427475642412901,
          -0.0234950240701437,
          0.4292198121547699,
          -0.15959633886814117,
          -0.09642279148101807,
          -0.0534442663192749,
          -0.005234670825302601,
          -0.07482457160949707,
          -0.04190913587808609,
          -0.0183674618601799,
          0.01387202087789774,
          -0.04956170916557312,
          -0.012490917928516865,
          -0.08881308883428574,
          -0.02233995869755745,
          2.2241146564483643,
          -0.004067397676408291,
          -0.008512781001627445,
          -0.027261145412921906,
          0.04726839438080788,
          0.015975497663021088,
          0.011530081741511822,
          -0.021641844883561134,
          -0.048347726464271545,
          0.012488601729273796,
          -0.055553846061229706,
          -0.05899425223469734,
          -0.009832235984504223,
          -0.05356648191809654,
          -0.06071353703737259,
          -0.12414689362049103,
          -0.04897448420524597,
          -0.010036494582891464,
          -0.08930189907550812,
          -0.04600738361477852,
          -0.02322792075574398,
          -0.045702021569013596,
          0.002610851312056184,
          -0.04581945762038231,
          -0.14692190289497375,
          -0.05167553573846817,
          0.10364661365747452,
          -0.0011055943323299289,
          -0.0054327622056007385,
          -0.016452165320515633,
          -0.0855185016989708,
          0.07402859628200531,
          0.1018969938158989,
          0.09102321416139603,
          0.12966661155223846,
          0.12264680117368698,
          0.039947543293237686,
          0.008870973251760006,
          0.02495029754936695,
          -0.008880543522536755,
          0.002409741748124361,
          -0.08461065590381622,
          0.09022688865661621,
          0.05607941746711731,
          -0.08106835186481476,
          -0.045646458864212036,
          -0.013211392797529697,
          0.057320430874824524,
          -0.2497459501028061,
          0.018262002617120743,
          0.20354682207107544,
          -0.055939845740795135,
          2.1872639656066895,
          2.1907124519348145,
          0.059213098138570786,
          -0.044361662119627,
          -0.04963994771242142,
          0.23835787177085876,
          -1.9157803058624268,
          -0.017261484637856483,
          0.041469138115644455,
          -0.028120743110775948,
          0.022794511169195175,
          -0.06686738133430481,
          -0.02207622304558754,
          -0.0447269007563591,
          -0.0035903577227145433,
          -0.034889161586761475,
          -0.032988838851451874,
          -0.01132296584546566,
          2.2053072452545166,
          0.020748844370245934,
          -0.0759006142616272,
          -0.0269568283110857,
          0.03125517815351486,
          -0.03292518109083176,
          0.4605061113834381,
          -0.03206789866089821,
          -0.032644324004650116,
          -0.04035224765539169,
          -0.11434189975261688,
          -0.22032634913921356,
          -0.05217559263110161,
          -0.07698111981153488,
          -0.09251774847507477,
          0.03742779791355133,
          -0.12349306046962738,
          0.04320327565073967,
          -0.0703418105840683,
          0.06857658922672272,
          -0.09084514528512955,
          -0.09394542872905731,
          0.02306346781551838,
          -2.138094663619995,
          -0.08218859136104584,
          0.08470658212900162,
          -0.044199202209711075,
          -0.2814645767211914,
          0.05476367846131325,
          -0.024169983342289925,
          0.01646106131374836,
          -0.007205085828900337,
          0.04298051819205284,
          -0.06941766291856766,
          -0.002399805933237076,
          -0.02415073849260807,
          -0.17407354712486267,
          -0.0657239779829979,
          0.0021355757489800453,
          0.015124216675758362,
          -0.036869779229164124,
          0.025786764919757843,
          -0.010969303548336029,
          -0.03206004947423935,
          -0.03651062771677971,
          -0.0831342414021492,
          -0.05525379255414009,
          -0.02623036690056324,
          0.00814124196767807,
          0.01145707257091999,
          0.013039437122642994,
          0.03822929784655571,
          0.11367610841989517,
          -0.004363990388810635,
          -0.057742103934288025,
          -0.055278632789850235,
          -0.048376407474279404,
          0.02747408114373684,
          0.15597546100616455,
          -0.0005770963034592569,
          -0.02526482380926609,
          0.0546756386756897,
          -0.030932994559407234,
          0.13866564631462097,
          0.1432594209909439,
          0.1596091240644455,
          -0.014005208387970924,
          0.0075859869830310345,
          -0.0232411976903677,
          0.01972649060189724,
          -0.03903908655047417,
          0.032695524394512177,
          -0.05566580593585968,
          -0.00950117688626051,
          -0.04023544490337372,
          -0.020076006650924683,
          0.004032961092889309,
          -0.024571819230914116,
          -2.0063421726226807,
          -0.0033711667638272047,
          -0.024239802733063698,
          -0.006265833042562008,
          -0.018026182428002357,
          -0.028044044971466064,
          -0.03661765903234482,
          -1.5552146434783936,
          -0.02199864573776722,
          -0.0035152502823621035,
          0.02095196396112442,
          -0.028140997514128685,
          0.02931520715355873,
          -0.0006804268923588097,
          -0.07867467403411865,
          -0.05331221595406532,
          -0.03844836726784706,
          -0.006185364909470081,
          -0.000016516361938556656,
          -0.06012189760804176,
          -0.0016250478802248836,
          0.13661189377307892,
          -0.08235474675893784,
          -0.011818972416222095,
          -0.06532313674688339,
          -0.22125831246376038,
          -0.06322586536407471,
          -0.015530484728515148,
          0.031390462070703506,
          -0.009921276941895485,
          -0.0907449796795845,
          -0.01628652773797512,
          -0.22194501757621765,
          -0.03412173315882683,
          -0.07675454765558243,
          -0.011712889187037945,
          0.013552633114159107,
          -0.0069985343143343925,
          0.039834823459386826,
          -2.121323585510254,
          0.0032372470013797283,
          0.0056843226775527,
          0.04575704038143158,
          0.17600998282432556,
          -0.019151408225297928,
          -0.07831286638975143,
          0.28298264741897583,
          -0.04467509686946869,
          -0.04969558119773865,
          -2.0256898403167725,
          -0.023324426263570786,
          1.4086142778396606,
          1.4472109079360962,
          1.3898658752441406,
          0.0035376728046685457,
          0.33275356888771057,
          0.0822134017944336,
          0.0080086849629879,
          0.05158228054642677,
          0.0937369167804718,
          0.11658086627721786,
          0.12208043038845062,
          0.05201954022049904,
          -0.04177001491189003,
          0.06753848493099213,
          0.004171185661107302,
          0.047632139176130295,
          -0.04099371284246445,
          -0.0849926620721817,
          0.25829315185546875,
          -0.16495169699192047,
          -0.17544810473918915,
          0.022211315110325813,
          -0.030231745913624763,
          0.012396183796226978,
          0.02507065422832966,
          -0.14087921380996704,
          -0.05934557318687439,
          -0.016216052696108818,
          0.011699801310896873,
          -0.012124063447117805,
          0.03749082610011101,
          0.8427527546882629,
          -0.33742865920066833,
          -0.14881646633148193,
          -0.18843476474285126,
          0.8270665407180786,
          -0.43944135308265686,
          -0.11259707808494568,
          -0.3610604703426361,
          -0.3564338982105255,
          -0.364891916513443,
          -0.3947536051273346,
          0.1047898679971695,
          -0.3556097149848938,
          -0.08114045858383179,
          -0.12924958765506744,
          -0.08221989870071411,
          -0.5535740852355957,
          -0.15062597393989563,
          -0.2984032928943634,
          -0.30209875106811523,
          -0.2543129622936249,
          -0.2351812720298767,
          -0.23496893048286438,
          -0.15624211728572845,
          -0.16522912681102753,
          -0.3955138027667999,
          -0.4164172112941742,
          -0.2310790717601776,
          -0.3303968608379364,
          -0.23039592802524567,
          -0.24710632860660553,
          -0.3176117241382599,
          -0.24812652170658112,
          -0.15247534215450287,
          -0.19791968166828156,
          -0.2617599070072174,
          -0.17275039851665497,
          -0.24840106070041656,
          -0.2690351605415344,
          -0.2690351605415344,
          -0.12376222759485245,
          -0.2531825006008148,
          -0.25023558735847473,
          -0.21838897466659546,
          -0.1879900097846985,
          4.472208023071289,
          -0.22145161032676697,
          -0.21406377851963043,
          -0.29470714926719666,
          -0.21686099469661713,
          -0.24907103180885315,
          -0.20986460149288177,
          -0.20698286592960358,
          -0.20698286592960358,
          -0.16136960685253143,
          -0.2157248556613922,
          -0.19561323523521423,
          -0.049045875668525696,
          -0.2631673812866211,
          -0.24591411650180817,
          -0.2968100905418396,
          -0.12917126715183258,
          0.21512669324874878,
          -0.23321902751922607,
          -0.2974306344985962,
          4.491021156311035,
          3.239205837249756,
          -0.1476190835237503,
          -0.21878814697265625,
          -0.14758135378360748,
          -0.14432962238788605,
          -0.1500912308692932,
          -0.016257314011454582,
          -0.18433059751987457,
          -0.22237583994865417,
          -0.24576324224472046,
          -0.31335213780403137,
          -0.2885439097881317,
          -0.2691917419433594,
          -0.15172116458415985,
          -0.22332130372524261,
          3.1776812076568604,
          -0.15904389321804047,
          -0.23031184077262878,
          0.9579699039459229,
          -0.29279059171676636,
          -0.2410476952791214,
          0.21540409326553345,
          -0.2621665894985199,
          -0.25231531262397766,
          2.3538172245025635,
          2.348055362701416,
          -0.19941569864749908,
          0.5013200044631958,
          0.5013200044631958,
          -0.12967589497566223,
          3.186688184738159,
          -0.1859893649816513,
          4.477543354034424,
          -0.30252885818481445,
          -0.26367878913879395,
          -0.1903046816587448,
          4.482273101806641,
          4.482250213623047,
          -0.29285821318626404,
          -0.17403945326805115,
          -0.2639206647872925,
          -0.2143465131521225,
          -0.20267266035079956,
          -0.17362235486507416,
          -0.15776963531970978,
          -0.2021324336528778,
          -0.22760659456253052,
          -0.20995596051216125,
          -0.2963859736919403,
          -0.347621887922287,
          -0.258666068315506,
          -0.18152368068695068,
          -0.2828606963157654,
          -0.18840274214744568,
          -0.20225423574447632,
          -0.2387964129447937,
          -0.18644826114177704,
          -0.21256551146507263,
          -0.1900705248117447,
          1.770751714706421,
          0.21943488717079163,
          -0.15991617739200592,
          -0.15008245408535004,
          -0.3545408248901367,
          -0.286485880613327,
          -0.26200389862060547,
          -0.2567429542541504,
          -0.23792868852615356,
          2.0271575450897217,
          -0.2977035641670227,
          -0.26187974214553833,
          -0.2174501270055771,
          -0.26181551814079285,
          -0.2430470734834671,
          -0.2798210382461548,
          -0.23281143605709076,
          -0.2605869472026825,
          -0.20152130722999573,
          -0.19754347205162048,
          -0.2712107002735138,
          -0.23866720497608185,
          -0.24803537130355835,
          -0.2629742920398712,
          -0.3552839159965515,
          -0.18243756890296936,
          -0.2773364186286926,
          -0.30287063121795654,
          -0.2131255865097046,
          -0.2322823703289032,
          -0.24950258433818817,
          -0.23463056981563568,
          -0.24203740060329437,
          -0.22515767812728882,
          -0.24092762172222137,
          -0.23735176026821136,
          -0.23387551307678223,
          -0.27001675963401794,
          1.1993457078933716,
          -0.2643827199935913,
          -0.2915736138820648,
          -0.2804347574710846,
          -0.2750774621963501,
          -0.2835300862789154,
          -0.2641698718070984,
          -0.31885722279548645,
          -0.3608352839946747,
          0.03976965323090553,
          -0.22922025620937347,
          -0.1875329464673996,
          -0.25000229477882385,
          3.0927071571350098,
          -0.254376620054245,
          -0.2975233495235443,
          -0.2840852737426758,
          -0.26808610558509827,
          -0.18076543509960175,
          -0.16874995827674866,
          -0.14388307929039001,
          -0.15122954547405243,
          -0.23947688937187195,
          -0.19988307356834412,
          0.33740970492362976,
          0.32790252566337585,
          -0.25277236104011536,
          -0.18415483832359314,
          -0.4608602821826935,
          -0.1875925213098526,
          -0.256039023399353,
          -0.26852893829345703,
          -0.28989624977111816,
          -0.24313011765480042,
          -0.2604193091392517,
          -0.20467206835746765,
          -0.2602705955505371,
          -0.30297401547431946,
          -0.246806338429451,
          -0.2736371159553528,
          -0.2937432825565338,
          -0.25590136647224426,
          -0.26609930396080017,
          -0.35395893454551697,
          -0.2848208546638489,
          -0.2654191255569458,
          -0.2690315842628479,
          -0.2528893053531647,
          -0.16786958277225494,
          -0.31403520703315735,
          -0.3398614823818207,
          -0.22730228304862976,
          -0.24056832492351532,
          -0.2409781813621521,
          -0.2038835883140564,
          -0.1952982097864151,
          -0.2833889126777649,
          -0.2574446201324463,
          -0.24759826064109802,
          0.2212585061788559,
          0.23390766978263855,
          -0.2112647145986557,
          -0.2707498073577881,
          -0.1764867752790451,
          -0.29168304800987244,
          -0.177397221326828,
          -0.1527850478887558,
          -0.30947017669677734,
          -0.22373005747795105,
          -0.24674858152866364,
          -0.21645458042621613,
          -0.2577090263366699,
          0.45033717155456543,
          -0.31574296951293945,
          -0.31574296951293945,
          -0.0033910521306097507,
          -0.23277607560157776,
          -0.21463334560394287,
          -0.21463334560394287,
          -0.10154688358306885,
          -0.18117621541023254,
          -0.32484254240989685,
          -0.09768157452344894,
          -0.2933816909790039,
          3.1140763759613037,
          -0.2561173737049103,
          -0.12215343862771988,
          0.033501043915748596,
          -0.1729860007762909,
          -0.27481573820114136,
          -0.22611874341964722,
          -0.2241859883069992,
          -0.1661044806241989,
          -0.2416340708732605,
          -0.13597504794597626
         ],
         "z": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8
         ]
        },
        {
         "mode": "text",
         "name": "Edge Labels",
         "text": [
          "trains",
          "uses",
          "uses",
          "uses",
          "uses",
          "have",
          "demonstrate of",
          "demonstrate of",
          "support",
          "support",
          "uses",
          "uses",
          "captures",
          "captures",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "transmit",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "compress",
          "compress",
          "compress",
          "compress",
          "contain via",
          "contain via",
          "uses",
          "uses",
          "uses",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "uses",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "address",
          "uses",
          "demonstrate of",
          "applies",
          "demonstrate of",
          "inherit",
          "uses",
          "demonstrate of",
          "set",
          "demonstrate of",
          "learn",
          "learn",
          "learn",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "outperforms",
          "outperforms",
          "outperforms",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "compress",
          "compress",
          "handles",
          "handles",
          "handles",
          "handles",
          "handles",
          "handles",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "design",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "underscore",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "uses",
          "share",
          "demonstrate of",
          "have",
          "demonstrate of",
          "have",
          "have",
          "fits",
          "demonstrate of",
          "demonstrate of",
          "share",
          "demonstrate of",
          "demonstrate of",
          "trains",
          "trains",
          "demonstrate of",
          "outperforms",
          "outperform due",
          "exhibits",
          "exhibits",
          "exhibits than",
          "exhibits than",
          "exhibits than",
          "exhibits than",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "prunes",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "discard",
          "discard",
          "applies",
          "demonstrate of",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "outperform due",
          "uses",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "uses",
          "inherit",
          "inherit",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "extract",
          "demonstrate of",
          "uses",
          "extract by",
          "extract by",
          "extract",
          "demonstrate of",
          "compress",
          "compress",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "pay",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "minimize after",
          "minimize after",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "trains",
          "trains",
          "trains",
          "trains",
          "trains",
          "trains",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "applies",
          "applies",
          "applies",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "broadcasts",
          "broadcasts",
          "broadcasts",
          "broadcasts",
          "broadcasts",
          "broadcasts",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "skew in",
          "skew in",
          "have",
          "have",
          "reshape",
          "demonstrate of",
          "uses",
          "set",
          "set",
          "vary",
          "vary",
          "have",
          "have",
          "inherit",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "applies",
          "applies",
          "applies",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "emerge during",
          "uses",
          "uses",
          "demonstrate of",
          "address",
          "address",
          "uses",
          "demonstrate of",
          "uses",
          "uses",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "skew in",
          "skew in",
          "skew in",
          "skew in",
          "skew in",
          "skew in",
          "suppress",
          "exhibits",
          "exhibits",
          "learn",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "contain via",
          "demonstrate of",
          "demonstrate of",
          "exhibits",
          "demonstrate of",
          "applies",
          "applies",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "applies",
          "undergoes",
          "demonstrate of",
          "demonstrate of",
          "minimize after",
          "minimize after",
          "have",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "applies",
          "demonstrate of",
          "skew in",
          "have",
          "have",
          "set",
          "set",
          "set",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "aggregates",
          "aggregates",
          "aggregates",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "carry",
          "carry",
          "carry",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "normalize",
          "normalize",
          "normalize",
          "demonstrate of",
          "uses",
          "contain via",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "uses",
          "uses",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "uses",
          "uses",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "captures",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "divide",
          "divide into",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "trains",
          "demonstrate of",
          "uses",
          "trains",
          "trains",
          "uses",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "uses",
          "uses",
          "extract by",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "sample",
          "sample",
          "set",
          "set",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "uses",
          "uses",
          "demonstrate of",
          "report",
          "demonstrate of",
          "uses",
          "track",
          "track over",
          "uses",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "uses",
          "exhibits than",
          "exhibits than",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "have",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "outperforms",
          "outperforms",
          "outperforms",
          "outperforms",
          "outperforms",
          "outperforms",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "exhibits",
          "exhibits",
          "exhibits",
          "exhibits",
          "exhibits",
          "exhibits",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "outperforms",
          "outperforms",
          "outperforms",
          "outperforms",
          "outperforms",
          "outperforms",
          "demonstrate of",
          "occupies",
          "have",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "uses",
          "uses",
          "minimize after",
          "minimize after",
          "minimize after",
          "uses",
          "exhibits",
          "exhibits",
          "exhibits",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "needs",
          "needs",
          "needs",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "needs",
          "needs",
          "needs",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "uses",
          "lists",
          "demonstrate of",
          "transmit",
          "minimize after",
          "holds",
          "holds",
          "uses",
          "uses",
          "uses",
          "simulate",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "exhibits",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "uses",
          "uses",
          "uses",
          "uses",
          "uses",
          "set",
          "set",
          "demonstrate of",
          "vary",
          "decreases below",
          "decreases below",
          "pay",
          "demonstrate of",
          "demonstrate of",
          "decreases below",
          "decreases below",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "exhibits than",
          "exhibits than",
          "discard",
          "discard",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "vary",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "have",
          "have due",
          "demonstrate of",
          "demonstrate of",
          "set",
          "demonstrate of",
          "demonstrate of",
          "vary",
          "vary",
          "demonstrate of",
          "uses",
          "uses",
          "minimize after",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "vary",
          "vary",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "have",
          "skew in",
          "have",
          "demonstrate of",
          "needs",
          "needs",
          "needs",
          "captures",
          "captures",
          "demonstrate of",
          "uses",
          "conduct",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "exhibits",
          "exhibits",
          "exhibits",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "track",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "uses",
          "uses",
          "demonstrate of",
          "conduct",
          "uses",
          "demonstrate of",
          "tune",
          "contain via",
          "contain via",
          "uses",
          "demonstrate of",
          "applies",
          "applies",
          "applies",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "uses",
          "uses",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "demonstrate of",
          "uses",
          "uses",
          "demonstrate of",
          "support",
          "demonstrate of",
          "demonstrate of",
          "captures",
          "captures among",
          "uses",
          "uses",
          "demonstrate of",
          "captures",
          "compress",
          "compress",
          "uses",
          "share",
          "share",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "applies",
          "applies",
          "uses",
          "uses",
          "compress",
          "compress",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "demonstrate of",
          "extract",
          "extract",
          "demonstrate of",
          "demonstrate of",
          "exploit",
          "captures",
          "demonstrate of",
          "demonstrate of",
          "uses",
          "uses",
          "uses",
          "uses",
          "outperforms",
          "outperforms",
          "outperforms",
          "demonstrate of",
          "with",
          "with",
          "for",
          "for",
          "of",
          "of",
          "of",
          "of",
          "of",
          "for",
          "of",
          "of",
          "of",
          "as",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "from",
          "to",
          "of",
          "for",
          "of",
          "with",
          "of",
          "by",
          "for",
          "with",
          "for",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "with",
          "of",
          "with",
          "of",
          "of",
          "with",
          "with",
          "with",
          "of",
          "from",
          "of",
          "from",
          "to",
          "of",
          "among",
          "among",
          "of",
          "from",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "between",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "from",
          "to",
          "of",
          "due",
          "due",
          "due",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "with",
          "from",
          "of",
          "from",
          "of",
          "of",
          "of",
          "of",
          "between",
          "of",
          "of",
          "of",
          "of",
          "of",
          "with",
          "with",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "to",
          "for",
          "of",
          "of",
          "of",
          "of",
          "of",
          "with",
          "with",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "between",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "between",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "with",
          "before",
          "of",
          "of",
          "between",
          "of",
          "of",
          "from",
          "to",
          "of",
          "of",
          "of",
          "of",
          "for",
          "to",
          "to",
          "of",
          "of",
          "to",
          "of",
          "of",
          "of",
          "to",
          "with",
          "of",
          "from",
          "from",
          "of",
          "for",
          "of",
          "as",
          "as",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "from",
          "with",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "from",
          "from",
          "from",
          "from",
          "toward",
          "from",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "between",
          "for",
          "from",
          "from",
          "of",
          "for",
          "for",
          "of",
          "with",
          "of",
          "for",
          "of",
          "with",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "for",
          "with",
          "of",
          "for",
          "with",
          "for",
          "for",
          "of",
          "of",
          "of",
          "of",
          "among",
          "for",
          "of",
          "of",
          "for",
          "for",
          "of",
          "for",
          "for",
          "among",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "than",
          "for",
          "of",
          "of",
          "of",
          "for",
          "for",
          "for",
          "of",
          "of",
          "of",
          "from",
          "of",
          "of",
          "for",
          "of",
          "of",
          "with",
          "of",
          "of",
          "of",
          "of",
          "of",
          "with",
          "of",
          "from",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "with",
          "with",
          "from",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "than",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "with",
          "with",
          "between",
          "for",
          "for",
          "for",
          "for",
          "of",
          "of",
          "of",
          "than",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "of",
          "for",
          "of",
          "of",
          "of",
          "of",
          "from",
          "of",
          "of",
          "of",
          "of",
          "of",
          "for",
          "with",
          "to",
          "of",
          "from",
          "from",
          "from",
          "toward",
          "of",
          "of",
          "of",
          "of",
          "of",
          "from",
          "with",
          "of",
          "from",
          "of",
          "from",
          "from",
          "to",
          "from",
          "from",
          "of",
          "between",
          "of",
          "to",
          "of",
          "of",
          "for",
          "of",
          "with",
          "of",
          "with",
          "of",
          "of",
          "among",
          "of",
          "of",
          "of",
          "to",
          "from",
          "from",
          "of",
          "with",
          "of",
          "of",
          "to",
          "of",
          "for",
          "of",
          "with",
          "of",
          "with",
          "with",
          "of",
          "for"
         ],
         "textposition": "middle center",
         "type": "scatter3d",
         "x": [
          -0.3553194999694824,
          -0.31182554364204407,
          -0.26702213287353516,
          -0.2902469038963318,
          -0.36297398805618286,
          -0.38951271772384644,
          -0.38035520911216736,
          -0.3686317205429077,
          -0.16770341992378235,
          -0.057720016688108444,
          -0.3880440294742584,
          -0.36846381425857544,
          1.1348130702972412,
          -0.31750157475471497,
          1.0261836051940918,
          -0.42613106966018677,
          1.079222559928894,
          -0.37309205532073975,
          1.1609116792678833,
          -0.2914029061794281,
          -0.30215615034103394,
          -0.4134223461151123,
          -0.43550217151641846,
          -0.31303220987319946,
          -0.20886360108852386,
          -0.2745809853076935,
          -0.32314884662628174,
          -0.295266330242157,
          -0.33906322717666626,
          -0.42885729670524597,
          -0.30638736486434937,
          0.2960410714149475,
          0.2643199861049652,
          0.2865511178970337,
          -0.25903886556625366,
          -0.14905545115470886,
          -0.38932910561561584,
          -0.27934569120407104,
          -0.29897376894950867,
          -0.42926400899887085,
          -0.21922513842582703,
          -0.25311315059661865,
          -0.24244990944862366,
          -0.2763378918170929,
          -0.31517699360847473,
          -0.34906500577926636,
          -0.2728286385536194,
          -0.1503586769104004,
          -0.29605337977409363,
          -0.17358344793319702,
          -0.3687804937362671,
          -0.2463105320930481,
          -0.3277992904186249,
          -0.27331921458244324,
          -0.29654398560523987,
          -0.36927106976509094,
          -0.2802266478538513,
          -0.30345141887664795,
          -0.376178503036499,
          -0.23177126049995422,
          -0.25499603152275085,
          -0.32772311568260193,
          -0.24186228215694427,
          -0.2650870382785797,
          -0.3378141522407532,
          -0.30603647232055664,
          -0.33775758743286133,
          -0.31552648544311523,
          -0.09701517224311829,
          -0.3557904362678528,
          0.34313154220581055,
          0.18637223541736603,
          0.15630732476711273,
          0.8987736105918884,
          0.2751104533672333,
          -0.30840110778808594,
          0.20317058265209198,
          -0.34455814957618713,
          0.18708112835884094,
          0.23231247067451477,
          -0.27348870038986206,
          -0.2967134416103363,
          -0.36944055557250977,
          -0.2181134670972824,
          -0.24133822321891785,
          -0.3140653371810913,
          0.2960410714149475,
          0.2643199861049652,
          0.2865511178970337,
          0.2960410714149475,
          0.2643199861049652,
          0.2865511178970337,
          0.6299728155136108,
          0.09598618745803833,
          0.06426508724689484,
          0.08649620413780212,
          -0.16958320140838623,
          -0.20130430161952972,
          -0.17907318472862244,
          -0.2924172282218933,
          -0.3241383135318756,
          -0.30190718173980713,
          -0.25809311866760254,
          -0.2898142337799072,
          -0.26758310198783875,
          0.19845625758171082,
          0.2865704596042633,
          -0.3705299198627472,
          -0.24805998802185059,
          -0.3093945384025574,
          -0.2976710796356201,
          -0.34111565351486206,
          -0.3293921649456024,
          -0.3188845217227936,
          -0.30716103315353394,
          -0.2716308534145355,
          -0.3033519387245178,
          -0.28112083673477173,
          0.20675936341285706,
          0.2086602747440338,
          0.30495506525039673,
          -0.3455199897289276,
          -0.23590491712093353,
          -0.267626017332077,
          -0.24539490044116974,
          0.2505943179130554,
          0.13005036115646362,
          -0.433114230632782,
          -0.33885475993156433,
          1.5748103857040405,
          -0.27270135283470154,
          -0.2537723481655121,
          -0.3530611991882324,
          -0.2656615078449249,
          -0.3451976180076599,
          -0.3577348589897156,
          -0.19847214221954346,
          -0.15130597352981567,
          -0.2826504707336426,
          -0.27397358417510986,
          -0.29605337977409363,
          -0.17358344793319702,
          0.17306701838970184,
          2.415628433227539,
          0.2409549355506897,
          -0.4156654477119446,
          -0.38475504517555237,
          -0.3101922869682312,
          -0.1877223253250122,
          -0.388838529586792,
          -0.2788551151752472,
          -0.266368567943573,
          -0.1563851684331894,
          -0.36913442611694336,
          -0.4064341187477112,
          -0.21275362372398376,
          -0.33522355556488037,
          -0.3738597631454468,
          -0.361686110496521,
          -0.407987505197525,
          -0.33386754989624023,
          -0.3926514983177185,
          -0.3260604441165924,
          -0.052873581647872925,
          -0.10144144296646118,
          -0.07355894148349762,
          -0.26777833700180054,
          -0.3726734519004822,
          0.1936667412519455,
          0.15640588104724884,
          0.18947535753250122,
          -0.19259299337863922,
          -0.18817603588104248,
          -0.31727534532546997,
          -0.2629983127117157,
          -0.31156617403030396,
          -0.2836836576461792,
          -0.21170635521411896,
          -0.30222493410110474,
          -0.325449675321579,
          -0.39817678928375244,
          -0.2740503251552582,
          -0.17269845306873322,
          -0.34863850474357605,
          -0.3972063660621643,
          -0.36932384967803955,
          -0.37856417894363403,
          0.19773182272911072,
          -0.2719191610813141,
          -0.3943890929222107,
          -0.2788551151752472,
          -0.1563851684331894,
          -0.4013250470161438,
          -0.2788551151752472,
          -0.4366797208786011,
          -0.4369509816169739,
          -0.44951343536376953,
          -0.3691765367984772,
          -0.4030645489692688,
          -0.3545001447200775,
          -0.44502341747283936,
          0.19621652364730835,
          0.17186671495437622,
          2.207881450653076,
          0.226328507065773,
          0.2252912074327469,
          0.020248502492904663,
          -0.10222143679857254,
          -0.07541432231664658,
          -0.16935287415981293,
          -0.15132425725460052,
          -0.18147508800029755,
          -0.30394503474235535,
          -0.25641554594039917,
          -0.3049834072589874,
          -0.27710089087486267,
          -0.28411170840263367,
          -0.16505464911460876,
          0.20941919088363647,
          0.3174412250518799,
          0.29421645402908325,
          0.22148935496807098,
          0.19716781377792358,
          -0.28035223484039307,
          -0.3035770058631897,
          -0.37630409002304077,
          -0.22719377279281616,
          -0.2504185438156128,
          -0.32314562797546387,
          -0.2728286385536194,
          -0.1503586769104004,
          -0.29605337977409363,
          -0.17358344793319702,
          -0.3687804937362671,
          -0.2463105320930481,
          -0.27050310373306274,
          -0.2937278747558594,
          -0.36645495891571045,
          -0.2728286385536194,
          -0.1503586769104004,
          -0.29605337977409363,
          -0.17358344793319702,
          -0.3687804937362671,
          -0.2463105320930481,
          -0.2057352364063263,
          -0.22896000742912292,
          -0.301687091588974,
          -0.30036085844039917,
          -0.3235856294631958,
          -0.3963127136230469,
          -0.23669299483299255,
          -0.2599177658557892,
          -0.33264485001564026,
          1.9557281732559204,
          1.932503342628479,
          1.859776258468628,
          -0.22896000742912292,
          -0.27408358454704285,
          -0.23281261324882507,
          -0.2560373842716217,
          -0.3287644684314728,
          -0.23281261324882507,
          -0.2560373842716217,
          -0.3287644684314728,
          -0.32532060146331787,
          -0.3352990746498108,
          -0.266061007976532,
          -0.3885309398174286,
          0.16305086016654968,
          -0.2756976783275604,
          -0.39816761016845703,
          -0.2788551151752472,
          -0.1563851684331894,
          -0.4013250470161438,
          -0.2788551151752472,
          -0.31039687991142273,
          -0.19130709767341614,
          -0.27613046765327454,
          -0.21453186869621277,
          -0.29935523867607117,
          -0.28725895285606384,
          -0.37208232283592224,
          -0.2728286385536194,
          -0.1503586769104004,
          -0.29605337977409363,
          -0.17358344793319702,
          -0.3687804937362671,
          -0.2463105320930481,
          0.22113117575645447,
          -0.3179780840873718,
          0.3956593871116638,
          0.3724346160888672,
          0.2997075319290161,
          -0.2693972587585449,
          -0.29262199997901917,
          -0.3653491139411926,
          -0.3331860899925232,
          -0.4180094599723816,
          0.24241653084754944,
          0.3201156258583069,
          -0.35311365127563477,
          -0.23064371943473816,
          1.234661340713501,
          1.7071667909622192,
          0.17761331796646118,
          -0.3445982038974762,
          0.672985851764679,
          0.27715080976486206,
          0.2794147729873657,
          0.16404974460601807,
          0.2163110375404358,
          -0.24333664774894714,
          -0.36580657958984375,
          -0.40695661306381226,
          -0.41470760107040405,
          -0.29223766922950745,
          0.29704850912094116,
          -0.2596130967140198,
          -0.2828378677368164,
          -0.3555649518966675,
          -0.26861071586608887,
          -0.16494131088256836,
          -0.2918354868888855,
          -0.188166081905365,
          -0.3645625710487366,
          -0.26089316606521606,
          -0.39324676990509033,
          0.19621652364730835,
          0.17186671495437622,
          0.18847128748893738,
          0.21654050052165985,
          0.26300591230392456,
          0.5099536776542664,
          0.2878793776035309,
          -0.20796611905097961,
          -0.20985540747642517,
          -0.27652156352996826,
          -0.2478870153427124,
          0.1931626945734024,
          0.2968320846557617,
          0.29704850912094116,
          -0.18147508800029755,
          -0.30394503474235535,
          -0.13659685850143433,
          -0.25906679034233093,
          -0.2735842168331146,
          -0.39605414867401123,
          -0.2354874312877655,
          -0.3579573631286621,
          0.20390097796916962,
          -0.45876073837280273,
          -0.38165971636772156,
          0.17286188900470734,
          0.3114147186279297,
          0.18894478678703308,
          -0.30019518733024597,
          -0.2708858549594879,
          -0.19055628776550293,
          -0.31302621960639954,
          -0.30638179183006287,
          -0.218593031167984,
          0.2252465933561325,
          0.15417128801345825,
          0.21497967839241028,
          -0.19259649515151978,
          -0.28838789463043213,
          0.178574338555336,
          -0.3421670198440552,
          -0.18147508800029755,
          -0.30394503474235535,
          1.6165517568588257,
          1.4940818548202515,
          -0.41962260007858276,
          -0.42278003692626953,
          -0.30031007528305054,
          -0.2600345015525818,
          -0.2832592725753784,
          -0.3559863567352295,
          -0.23782168328762054,
          -0.261046439409256,
          -0.33377355337142944,
          -0.30596500635147095,
          -0.21262596547603607,
          0.19193853437900543,
          0.21720923483371735,
          0.3218746781349182,
          0.29546982049942017,
          -0.37669408321380615,
          1.2339733839035034,
          1.5232608318328857,
          0.33120304346084595,
          0.19421568512916565,
          0.23231247067451477,
          0.2238747626543045,
          0.42579981684684753,
          0.442863404750824,
          0.6361947655677795,
          0.20317058265209198,
          -0.1864074170589447,
          -0.20963218808174133,
          -0.2823592722415924,
          -0.2415241301059723,
          -0.21569910645484924,
          -0.35268646478652954,
          -0.3145896792411804,
          -0.25887376070022583,
          -0.39586111903190613,
          -0.357764333486557,
          -0.22397470474243164,
          -0.36096206307411194,
          -0.3228652775287628,
          -0.26424869894981384,
          -0.3755961060523987,
          0.33120304346084595,
          0.19421568512916565,
          0.23231247067451477,
          0.2855871319770813,
          0.29704850912094116,
          0.2285802662372589,
          0.16943055391311646,
          -0.36323779821395874,
          -0.25325438380241394,
          -0.2972739338874817,
          -0.1872905194759369,
          -0.3591218590736389,
          -0.4205770492553711,
          0.2858251631259918,
          0.30495506525039673,
          0.6298951506614685,
          -0.263325572013855,
          0.20410680770874023,
          0.3532419204711914,
          0.23547807335853577,
          0.2779257595539093,
          0.29019078612327576,
          0.5085815191268921,
          0.3288589417934418,
          1.2130407094955444,
          0.20050042867660522,
          3.126333236694336,
          0.24197277426719666,
          3.1240460872650146,
          1.396059513092041,
          0.27345162630081177,
          0.28071126341819763,
          0.3288589417934418,
          2.691526412963867,
          2.575364351272583,
          0.30083170533180237,
          0.4021015465259552,
          3.0280587673187256,
          1.3024134635925293,
          0.3772262930870056,
          0.3789556920528412,
          0.4362591803073883,
          0.23212994635105133,
          0.37230804562568665,
          2.43571138381958,
          2.4466755390167236,
          0.20455138385295868,
          0.3174412250518799,
          0.29421645402908325,
          0.22148935496807098,
          2.207881450653076,
          0.2960410714149475,
          0.2643199861049652,
          0.2865511178970337,
          0.22821588814258575,
          -0.23264142870903015,
          -0.24045395851135254,
          0.2753659784793854,
          -0.32372522354125977,
          -0.30124643445014954,
          0.15669061243534088,
          0.26805970072746277,
          -0.3068186938762665,
          -0.2872384786605835,
          1.2350316047668457,
          1.1125617027282715,
          1.1418368816375732,
          1.2695316076278687,
          1.246413230895996,
          1.1239433288574219,
          1.1229736804962158,
          -0.20242707431316376,
          -0.15664127469062805,
          -0.29362863302230835,
          -0.25553184747695923,
          1.1357476711273193,
          0.8982246518135071,
          0.17488788068294525,
          0.7176011204719543,
          0.3180347681045532,
          0.7275621891021729,
          0.6432813405990601,
          0.3499196469783783,
          0.29704850912094116,
          0.2668509781360626,
          0.26496168971061707,
          0.20638611912727356,
          1.461281418800354,
          -0.22288262844085693,
          0.16777169704437256,
          0.2643199861049652,
          0.1865289807319641,
          0.20982027053833008,
          0.1597994565963745,
          0.1931135058403015,
          0.2751104533672333,
          0.7761354446411133,
          0.2005588412284851,
          0.29137030243873596,
          0.22820578515529633,
          0.2960410714149475,
          0.2643199861049652,
          0.2865511178970337,
          0.28632479906082153,
          0.19122302532196045,
          -0.3851643204689026,
          -0.2626943588256836,
          -0.4410644769668579,
          -0.34451618790626526,
          -0.3474380373954773,
          -0.30317071080207825,
          -0.20314469933509827,
          -0.19425824284553528,
          -0.23567453026771545,
          -0.26739561557769775,
          -0.24516451358795166,
          1.517549991607666,
          1.5724241733551025,
          1.4858288764953613,
          1.5407030582427979,
          1.5080599784851074,
          1.562934160232544,
          -0.3914426267147064,
          -0.2826472520828247,
          -0.4196345806121826,
          -0.3815377950668335,
          -0.1462850421667099,
          -0.19662243127822876,
          -0.1780061423778534,
          -0.22834353148937225,
          -0.1557750254869461,
          -0.20611241459846497,
          -0.005456209182739258,
          -0.03717730939388275,
          -0.014946192502975464,
          -0.3473053574562073,
          -0.19921866059303284,
          -0.23093976080417633,
          -0.20870864391326904,
          -0.31279510259628296,
          -0.34451618790626526,
          -0.3222850561141968,
          -0.29041746258735657,
          -0.32213854789733887,
          -0.2999074459075928,
          -0.3143453896045685,
          -0.3460664749145508,
          -0.3238353729248047,
          -0.2925191819667816,
          -0.3242402672767639,
          -0.3020091652870178,
          -0.28422993421554565,
          -0.21804045140743256,
          -0.31595104932785034,
          -0.24976155161857605,
          -0.29371994733810425,
          -0.22753043472766876,
          -0.32699158787727356,
          -0.35871267318725586,
          -0.33648157119750977,
          -0.1889570951461792,
          -0.2206781804561615,
          -0.1984470784664154,
          -0.3844384551048279,
          -0.2619685232639313,
          0.28632479906082153,
          0.2653207778930664,
          -0.42435282468795776,
          -0.19601888954639435,
          -0.18713244795799255,
          -0.22773998975753784,
          -0.21885354816913605,
          -0.20550887286663055,
          -0.19662243127822876,
          -0.32752546668052673,
          -0.36252763867378235,
          -0.23742017149925232,
          -0.24218204617500305,
          -0.26404067873954773,
          -0.45348453521728516,
          0.3425036370754242,
          -0.36766761541366577,
          -0.2670331299304962,
          -0.4125458002090454,
          -0.28099825978279114,
          -0.31271934509277344,
          -0.29048824310302734,
          -0.16463202238082886,
          -0.20746906101703644,
          -0.219663605093956,
          -0.19635313749313354,
          -0.23919016122817993,
          -0.2513847053050995,
          -0.17412200570106506,
          -0.21695904433727264,
          -0.2291535884141922,
          -0.37785106897354126,
          -0.3456752300262451,
          -0.33290618658065796,
          -0.32603758573532104,
          -0.35775867104530334,
          -0.33552753925323486,
          -0.2218022644519806,
          -0.2535233497619629,
          -0.2312922477722168,
          0.20392587780952454,
          -0.3138941824436188,
          -0.3456152677536011,
          -0.323384165763855,
          -0.2449537217617035,
          -0.2766748070716858,
          -0.2544437050819397,
          0.18913666903972626,
          0.21640954911708832,
          0.2871546447277069,
          -0.23136761784553528,
          -0.28264865279197693,
          -0.27603036165237427,
          -0.22223806381225586,
          -0.25395917892456055,
          -0.23172804713249207,
          1.4714699983596802,
          1.5062683820724487,
          1.4397488832473755,
          1.474547266960144,
          1.4619799852371216,
          1.4967783689498901,
          -0.13806569576263428,
          -0.16978679597377777,
          -0.14755567908287048,
          -0.27997660636901855,
          -0.31169769167900085,
          -0.2894665598869324,
          1.7900952100753784,
          1.7583740949630737,
          1.7806051969528198,
          -0.1889570951461792,
          -0.2206781804561615,
          -0.1984470784664154,
          -0.19991445541381836,
          -0.22591657936573029,
          -0.250251829624176,
          -0.27625396847724915,
          -0.17371290922164917,
          -0.3162780702114105,
          -0.4246412217617035,
          -0.3219486474990845,
          -0.3189030885696411,
          -0.28700852394104004,
          -0.29088911414146423,
          -0.32261019945144653,
          -0.30037909746170044,
          0.6568998098373413,
          -0.32782188057899475,
          -0.35954296588897705,
          -0.33731186389923096,
          -0.40467941761016846,
          -0.2181471884250641,
          -0.22003649175167084,
          -0.3603530526161194,
          0.3185414969921112,
          0.2757044732570648,
          0.26350992918014526,
          -0.2733532786369324,
          -0.3050743639469147,
          -0.2828432321548462,
          -0.26067423820495605,
          -0.2544882297515869,
          1.6261094808578491,
          0.20073164999485016,
          1.7194266319274902,
          0.29704850912094116,
          1.0735374689102173,
          -0.3518403172492981,
          -0.4122771620750427,
          -0.32758861780166626,
          -0.3397831916809082,
          1.0679185390472412,
          -0.35745930671691895,
          0.3185414969921112,
          0.2757044732570648,
          0.26350992918014526,
          -0.19684872031211853,
          -0.22856983542442322,
          -0.20633870363235474,
          -0.30322977900505066,
          -0.20573517680168152,
          -0.19684872031211853,
          -0.25554123520851135,
          -0.24665479362010956,
          -0.2953642010688782,
          -0.2864777445793152,
          -0.2864777445793152,
          -0.3181988596916199,
          -0.2959677577018738,
          -0.294228732585907,
          -0.17175880074501038,
          -0.32594984769821167,
          -0.20347991585731506,
          -0.3037187457084656,
          -0.18124878406524658,
          0.2477315217256546,
          0.16305086016654968,
          0.48347207903862,
          -0.29986685514450073,
          -0.42673444747924805,
          -0.43804436922073364,
          -0.4272189736366272,
          -0.3047490417957306,
          0.19771629571914673,
          0.16305086016654968,
          -0.33376336097717285,
          0.2668509781360626,
          0.26496168971061707,
          0.3696984052658081,
          0.4237915277481079,
          -0.41167500615119934,
          0.38969892263412476,
          -0.3345535695552826,
          -0.33644285798072815,
          -0.301666796207428,
          0.3696984052658081,
          0.20740607380867004,
          0.27715080976486206,
          0.23715618252754211,
          0.20143131911754608,
          0.3114147186279297,
          -0.3148753046989441,
          -0.25079673528671265,
          -0.36378178000450134,
          -0.2997032105922699,
          -0.265855073928833,
          -0.27476003766059875,
          -0.20501531660556793,
          -0.38219696283340454,
          -0.3794834017753601,
          -0.39515411853790283,
          -0.3801988959312439,
          0.21203027665615082,
          -0.3869919776916504,
          -0.4410644769668579,
          -0.34451618790626526,
          -0.37431249022483826,
          -0.25184255838394165,
          0.6486761569976807,
          -0.2866819202899933,
          0.6242902278900146,
          -0.3110678493976593,
          0.3057439625263214,
          0.28122273087501526,
          -0.35992667078971863,
          -0.28852328658103943,
          -0.4255106449127197,
          -0.3874138593673706,
          -0.1852148324251175,
          -0.322202205657959,
          -0.28410542011260986,
          -0.24025245010852814,
          -0.37723982334136963,
          -0.3391430377960205,
          -0.2978590726852417,
          -0.29377514123916626,
          0.2960410714149475,
          0.2643199861049652,
          0.2865511178970337,
          -0.3245624899864197,
          -0.1764295995235443,
          -0.2988995313644409,
          0.26853105425834656,
          0.1653643399477005,
          -0.40300482511520386,
          -0.20165954530239105,
          -0.27274632453918457,
          1.7409666776657104,
          -0.31232166290283203,
          0.1678548902273178,
          0.497443825006485,
          0.5416532158851624,
          -0.39023545384407043,
          -0.3611041307449341,
          -0.3949921131134033,
          -0.40695661306381226,
          -0.4116863012313843,
          1.152951717376709,
          1.1297268867492676,
          1.0569998025894165,
          -0.2959757447242737,
          -0.3192004859447479,
          -0.3919275999069214,
          -0.31313058733940125,
          -0.2926437258720398,
          -0.18870486319065094,
          -0.22042596340179443,
          -0.19819484651088715,
          0.2960410714149475,
          0.2643199861049652,
          0.2865511178970337,
          0.1514798104763031,
          -0.37230247259140015,
          -0.2151138186454773,
          -0.24683493375778198,
          -0.2246038019657135,
          -0.312385231256485,
          -0.1675569713115692,
          -0.19078172743320465,
          -0.2635088264942169,
          0.17595547437667847,
          -0.2795148491859436,
          1.5238780975341797,
          -0.35406339168548584,
          -0.29433542490005493,
          -0.25742122530937195,
          -0.40852993726730347,
          -0.31751328706741333,
          -0.29076266288757324,
          -0.3291069269180298,
          -0.19417133927345276,
          0.07266370952129364,
          -0.2501750588417053,
          -0.3364666998386383,
          -0.3896706700325012,
          -0.38198572397232056,
          -0.25951579213142395,
          -0.2377283126115799,
          -0.214503675699234,
          -0.3369736075401306,
          -0.2746371924877167,
          -0.17096780240535736,
          -0.3971071243286133,
          -0.29343774914741516,
          -0.4281580150127411,
          1.3538436889648438,
          2.302427053451538,
          -0.17432285845279694,
          -0.3182898163795471,
          -0.3595883250236511,
          -0.3810119926929474,
          0.18894478678703308,
          0.3114147186279297,
          0.24254827201366425,
          0.2086602747440338,
          -0.37083619832992554,
          -0.26061198115348816,
          -0.3030405342578888,
          -0.433330774307251,
          -0.2937687933444977,
          -0.42405903339385986,
          0.19773182272911072,
          -0.27409255504608154,
          -0.2779701054096222,
          -0.15550017356872559,
          1.614725112915039,
          -0.14004197716712952,
          -0.171763077378273,
          -0.14953196048736572,
          -0.144353985786438,
          -0.17607508599758148,
          -0.1538439691066742,
          0.2753659784793854,
          -0.37931016087532043,
          -0.3675866723060608,
          -0.3097604513168335,
          -0.1872905194759369,
          -0.37924525141716003,
          -0.22474679350852966,
          -0.25922033190727234,
          -0.22191664576530457,
          -0.3115309774875641,
          -0.410369336605072,
          -0.28987234830856323,
          -0.42685967683792114,
          -0.388762891292572,
          -0.33776021003723145,
          -0.23057782649993896,
          -0.2865990400314331,
          -0.4235863983631134,
          -0.3854896128177643,
          -0.29976749420166016,
          -0.2913174033164978,
          -0.3150908946990967,
          -0.2481427639722824,
          -0.40544039011001587,
          -0.35982102155685425,
          -0.3472699522972107,
          0.2053632140159607,
          -0.24745440483093262,
          -0.2273598462343216,
          -0.3633778691291809,
          -0.3025501072406769,
          -0.3429829478263855,
          -0.29674750566482544,
          -0.2791982889175415,
          -0.2368568778038025,
          -0.3985699415206909,
          -0.2850411832332611,
          -0.31980353593826294,
          -0.40462690591812134,
          -0.22208839654922485,
          0.7277758717536926,
          -0.2826504707336426,
          0.11591632664203644,
          -0.3492884635925293,
          -0.4412361979484558,
          -0.42951270937919617,
          -0.3245929777622223,
          -0.33552390336990356,
          -0.3741905689239502,
          -0.27772316336631775,
          -0.2710916996002197,
          -0.3472539186477661,
          -0.27672600746154785,
          -0.28598955273628235,
          -0.32328924536705017,
          -0.34539228677749634,
          -0.416634738445282,
          -0.26649370789527893,
          -0.4015769958496094,
          -0.4106118083000183,
          -0.3270118832588196,
          -0.3113369345664978,
          -0.22615385055541992,
          1.9676170349121094,
          -0.274944543838501,
          -0.41193193197250366,
          -0.37383514642715454,
          -0.25179505348205566,
          -0.38878241181373596,
          -0.35068562626838684,
          1.1584115028381348,
          1.2013945579528809,
          -0.31727534532546997,
          -0.26339977979660034,
          -0.311967670917511,
          -0.28408515453338623,
          -0.33567139506340027,
          -0.34461742639541626,
          -0.3931853175163269,
          -0.36530280113220215,
          -0.40846240520477295,
          0.37730175256729126,
          -0.32759490609169006,
          0.020248502492904663,
          -0.0006591975688934326,
          -0.08683212101459503,
          -0.15153850615024567,
          -0.13350988924503326,
          -0.43490201234817505,
          -0.18147508800029755,
          -0.2585362195968628,
          -0.24658025801181793,
          -0.3835676312446594,
          -0.3454708456993103,
          -0.3989756107330322,
          -0.20721450448036194,
          -0.39899954199790955,
          -0.27652961015701294,
          -0.2557460069656372,
          -0.4149017333984375,
          -0.3822712004184723,
          -0.3122618794441223,
          -0.33064866065979004,
          -0.2949237823486328,
          -0.266061007976532,
          0.20538459718227386,
          -0.39816761016845703,
          -0.28277450799942017,
          -0.19733358919620514,
          -0.28215694427490234,
          -0.3331860899925232,
          -0.4180094599723816,
          -0.35311365127563477,
          1.2138161659240723,
          1.68632173538208,
          -0.1800936609506607,
          -0.3445982038974762,
          -0.2591748535633087,
          -0.3705260753631592,
          -0.35923242568969727,
          -0.2962173521518707,
          -0.28550076484680176,
          -0.41782891750335693,
          -0.43851813673973083,
          -0.33793139457702637,
          -0.4041352868080139,
          0.19216907024383545,
          -0.24585126340389252,
          -0.3828386068344116,
          -0.3447418212890625,
          -0.3096761703491211,
          -0.39452680945396423,
          -0.41887661814689636,
          1.2631151676177979,
          -0.30819693207740784,
          -0.2711041271686554,
          -0.25906679034233093,
          -0.39605414867401123,
          -0.3579573631286621,
          -0.4179675579071045,
          -0.22836098074913025,
          0.018618464469909668,
          -0.20664608478546143,
          -0.31406810879707336,
          -0.3159574270248413,
          -0.3828813433647156,
          -0.16299191117286682,
          -0.2837594747543335,
          -0.2915104627609253,
          -0.1690405011177063,
          -0.17789599299430847,
          -0.13659685850143433,
          -0.2735842168331146,
          -0.2354874312877655,
          -0.22492045164108276,
          -0.43653565645217896,
          -0.3594346344470978,
          -0.29493799805641174,
          -0.19055628776550293,
          -0.3002474009990692,
          -0.2808569669723511,
          -0.32039347290992737,
          -0.22725272178649902,
          -0.3700668513774872,
          -0.11440332233905792,
          0.9358519315719604,
          -0.3813987374305725,
          -0.36967527866363525,
          -0.100389264523983,
          -0.194166898727417,
          -0.37669408321380615,
          1.7270772457122803,
          0.3016994595527649,
          0.41483837366104126,
          -0.3921453356742859,
          -0.3770185708999634,
          -0.37295928597450256,
          -0.32324880361557007,
          -0.3463389575481415,
          -0.34227967262268066,
          -0.3681827783584595,
          -0.38887202739715576,
          -0.2826472520828247,
          -0.4196345806121826,
          -0.3815377950668335,
          -0.3142942786216736,
          -0.271119624376297,
          0.06015072762966156,
          -0.3149440288543701,
          -0.16242444515228271,
          -0.299411803483963,
          -0.2613150179386139,
          -0.3140510320663452,
          0.3006947934627533,
          -0.2415241301059723,
          -0.21569910645484924,
          -0.35268646478652954,
          -0.3145896792411804,
          0.47701793909072876,
          0.34003058075904846,
          0.3781273663043976,
          -0.3660399317741394,
          -0.36630702018737793,
          -0.3805096447467804,
          -0.2180863320827484,
          -0.31093230843544006,
          -0.312821626663208,
          -0.3043960928916931,
          -0.30628538131713867,
          -0.3488602042198181,
          -0.1909692883491516,
          0.41159331798553467,
          -0.38572007417678833,
          -0.2820506989955902,
          -0.27413374185562134,
          -0.40716224908828735,
          -0.1966533660888672,
          -0.26240232586860657,
          1.5018391609191895,
          -0.40305644273757935,
          1.3699151277542114,
          0.2971356511116028,
          -0.07235608249902725,
          2.026628017425537,
          2.0613465309143066,
          -0.36664706468582153,
          -0.3913024663925171,
          -0.3620532751083374,
          2.8781442642211914,
          1.9917879104614258,
          1.883495807647705,
          1.039048194885254,
          0.1645321100950241,
          2.0100576877593994,
          -0.26275384426116943,
          0.32657361030578613,
          -0.02303263172507286,
          2.2163305282592773,
          2.254981756210327,
          2.483820915222168,
          2.4947850704193115,
          -0.27924564480781555,
          -0.36120373010635376,
          -0.35135573148727417,
          -0.32416874170303345,
          -0.35286685824394226,
          -0.16259433329105377,
          -0.2463105320930481,
          -0.3687804937362671,
          -0.3828373849391937,
          1.1382651329040527,
          -0.28711265325546265,
          -0.3419962227344513,
          -0.3059775233268738,
          -0.30786681175231934,
          0.06752689927816391,
          -0.21324709057807922,
          -0.21098314225673676,
          -0.14266522228717804,
          -0.1445545256137848,
          -0.30094772577285767,
          -0.21865998208522797,
          -0.3066818118095398,
          -0.2872854769229889,
          -0.2670387923717499,
          -0.25496774911880493,
          -0.301666796207428,
          -0.3253733515739441,
          -0.3049313426017761,
          -0.342865526676178,
          1.4690078496932983,
          -0.17426642775535583,
          -0.22560392320156097,
          -0.17471332848072052,
          -0.311700701713562,
          -0.2736039161682129,
          -0.335219144821167,
          -0.3154018521308899,
          -0.21885354816913605,
          -0.3352357745170593,
          -0.3509815037250519,
          -0.29041746258735657,
          -0.3288162350654602,
          -0.3844384551048279,
          -0.22756904363632202,
          -0.3368050456047058,
          -0.32752546668052673,
          -0.30374854803085327,
          -0.41294193267822266,
          -0.43480056524276733,
          -0.32782188057899475,
          -0.3352357745170593,
          -0.1796869933605194,
          -0.291416198015213,
          -0.38555487990379333,
          -0.32939428091049194,
          -0.22362691164016724,
          -0.3717154562473297,
          -0.393574059009552,
          -0.32835108041763306,
          -0.3648015260696411,
          -0.413369357585907,
          -0.3854868710041046,
          -0.3980135917663574,
          -0.29870766401290894,
          -0.2714347839355469,
          -0.2006896734237671,
          -0.294036865234375,
          -0.26676398515701294,
          -0.19601888954639435,
          -0.20965787768363953,
          -0.20077145099639893,
          -0.20259608328342438,
          -0.2880534529685974,
          -0.2612859606742859,
          1.0373510122299194,
          1.4363642930984497,
          1.3964507579803467,
          1.4312491416931152,
          1.4009835720062256,
          -0.23090983927249908,
          1.2535980939865112,
          1.4578529596328735,
          -0.1889570951461792,
          -0.24522088468074799,
          -0.2700002193450928,
          -0.2640281915664673,
          -0.25328493118286133,
          -0.34221428632736206,
          -0.34410360455513,
          -0.32782188057899475,
          -0.2181471884250641,
          -0.22003649175167084,
          -0.3603530526161194,
          -0.3231080174446106,
          -0.21190175414085388,
          -0.20571574568748474,
          -0.2922418415546417,
          -0.2860558331012726,
          1.1242740154266357,
          2.56632137298584,
          1.1409436464309692,
          2.872894287109375,
          1.4475164413452148,
          -0.46387016773223877,
          -0.3124941885471344,
          -0.19684872031211853,
          -0.3023999333381653,
          -0.3460001051425934,
          -0.3943195641040802,
          -0.3684322237968445,
          2.5196962356567383,
          -0.29986685514450073,
          -0.41844746470451355,
          -0.38730907440185547,
          -0.40992438793182373,
          0.5773104429244995,
          0.5754210948944092,
          -0.3345535695552826,
          -0.33644285798072815,
          -0.20495092868804932,
          -0.36074328422546387,
          -0.3696482181549072,
          -0.2999035120010376,
          -0.35936111211776733,
          -0.34062713384628296,
          -0.24919617176055908,
          -0.19178557395935059,
          -0.3895987272262573,
          -0.23013384640216827,
          -0.28159305453300476,
          -0.36261916160583496,
          -0.1922479271888733,
          -0.2665228843688965,
          -0.36253342032432556,
          -0.28852328658103943,
          -0.4255106449127197,
          -0.3874138593673706,
          -0.30865874886512756,
          -0.2409883439540863,
          -0.28391844034194946,
          -0.3453192114830017,
          -0.16620662808418274,
          -0.16257934272289276,
          -0.24157920479774475,
          -0.30403944849967957,
          -0.07860338687896729,
          0.5814197659492493,
          -0.06301718205213547,
          -0.17881205677986145,
          -0.18750876188278198,
          -0.2221984565258026,
          -0.3611041307449341,
          -0.3905527591705322,
          -0.43552178144454956,
          -0.4119778871536255,
          -0.25424572825431824,
          -0.2910713255405426,
          -0.40128982067108154,
          -0.22196941077709198,
          1.4136676788330078,
          -0.31355005502700806,
          -0.2865522801876068,
          -0.25742122530937195,
          -0.380505234003067,
          -0.20770961046218872,
          -0.3250705599784851,
          -0.3257173001766205,
          -0.35680800676345825,
          -0.1496676653623581,
          -0.3589847981929779,
          -0.2912466824054718,
          -0.3085344433784485,
          -0.351608544588089,
          1.1426438093185425,
          -0.31688061356544495,
          -0.3327557146549225,
          -0.32277029752731323,
          -0.39212778210639954,
          -0.30100592970848083,
          -0.38656002283096313,
          -0.42858609557151794,
          -0.3752537965774536,
          -0.42885729670524597,
          -0.38320136070251465,
          -0.27321797609329224,
          -0.42026829719543457,
          0.6517981290817261
         ],
         "y": [
          -0.16408608853816986,
          -0.11045808345079422,
          0.004060481674969196,
          -0.007512238807976246,
          -0.022929232567548752,
          -0.15390652418136597,
          -0.012448807246983051,
          -0.04960647225379944,
          -0.10895464569330215,
          -0.0017516165971755981,
          -0.03830382227897644,
          0.013214845210313797,
          -0.7861182689666748,
          0.02210143767297268,
          -0.9100669622421265,
          -0.10184726864099503,
          -0.9309406876564026,
          -0.12272099405527115,
          -0.8058117628097534,
          0.0024078995920717716,
          -0.01604960858821869,
          -0.09852450340986252,
          -0.05488020181655884,
          0.0658765509724617,
          -0.13382264971733093,
          -0.08071853220462799,
          0.013410696759819984,
          0.0016117431223392487,
          0.1285114586353302,
          0.1304520070552826,
          0.2512087821960449,
          0.07564964890480042,
          0.10434216260910034,
          0.07469608634710312,
          0.03624000772833824,
          0.1434430330991745,
          0.013791438192129135,
          0.1209944635629654,
          -0.1354561597108841,
          -0.1579047292470932,
          0.01753288134932518,
          -0.0977715402841568,
          0.0059601617977023125,
          -0.10934425890445709,
          -0.009456831961870193,
          -0.12476125359535217,
          0.030279703438282013,
          0.15103645622730255,
          0.01870698109269142,
          0.13946373760700226,
          0.00328998826444149,
          0.12404674291610718,
          0.10553576052188873,
          -0.010951722972095013,
          -0.02252444252371788,
          -0.03794143721461296,
          -0.12505073845386505,
          -0.13662345707416534,
          -0.15204045176506042,
          -0.06684739142656326,
          -0.07842011004686356,
          -0.09383710473775864,
          -0.0014549549669027328,
          -0.013027675449848175,
          -0.028444670140743256,
          -0.12566931545734406,
          -0.09697679430246353,
          -0.12662287056446075,
          -0.007215164601802826,
          -0.048214949667453766,
          -0.07269371300935745,
          0.09211378544569016,
          0.10899384319782257,
          -0.06630923599004745,
          0.33583778142929077,
          -0.08895701169967651,
          0.09983537346124649,
          -0.13969793915748596,
          -0.05909418314695358,
          0.13700108230113983,
          -0.004525365307927132,
          -0.016098085790872574,
          -0.031515080481767654,
          0.07437843829393387,
          0.06280571967363358,
          0.047388724982738495,
          0.07564964890480042,
          0.10434216260910034,
          0.07469608634710312,
          0.07564964890480042,
          0.10434216260910034,
          0.07469608634710312,
          -0.0718398317694664,
          -0.13001364469528198,
          -0.10132112354040146,
          -0.13096719980239868,
          0.023442775011062622,
          0.052135296165943146,
          0.022489216178655624,
          -0.03430898115038872,
          -0.005616461858153343,
          -0.035262539982795715,
          -0.032351355999708176,
          -0.003658836707472801,
          -0.03330491483211517,
          -0.056252576410770416,
          0.15451058745384216,
          0.06760302931070328,
          0.18835978209972382,
          0.0008462965488433838,
          -0.03631136566400528,
          0.02953881397843361,
          -0.007618848234415054,
          -0.00010726414620876312,
          -0.037264928221702576,
          0.004208914935588837,
          0.03290143236517906,
          0.0032553542405366898,
          -0.02421630173921585,
          -0.02213890105485916,
          0.10967843979597092,
          0.009209711104631424,
          0.02452937513589859,
          0.053221896290779114,
          0.023575816303491592,
          0.10772863030433655,
          -0.03957352042198181,
          -0.12331871688365936,
          -0.12355112284421921,
          0.24676188826560974,
          -0.09414741396903992,
          0.04765940085053444,
          -0.16939899325370789,
          0.011510228738188744,
          -0.15815576910972595,
          -0.3098333179950714,
          -0.030290637165308,
          -0.10592090338468552,
          0.01708706095814705,
          -0.02493731677532196,
          0.01870698109269142,
          0.13946373760700226,
          0.08483755588531494,
          -0.7411131858825684,
          0.08720503747463226,
          0.03144914656877518,
          0.0016620978713035583,
          0.03610354661941528,
          0.15686030685901642,
          0.055022865533828735,
          0.1622258871793747,
          0.17577961087226868,
          0.28298264741897583,
          0.038114309310913086,
          -0.06976824998855591,
          0.15348196029663086,
          0.03272520750761032,
          -0.02572007291018963,
          -0.015159238129854202,
          0.08498069643974304,
          -0.25480175018310547,
          -0.1621444821357727,
          -0.18875297904014587,
          -0.2335374653339386,
          -0.13940824568271637,
          -0.15120719373226166,
          -0.1084984540939331,
          -0.028543537482619286,
          -0.03902275860309601,
          0.25388261675834656,
          0.08299577981233597,
          0.048856399953365326,
          0.047152288258075714,
          -0.060318876057863235,
          -0.10897695273160934,
          -0.01484772376716137,
          -0.026646677404642105,
          0.02512885257601738,
          -0.13688397407531738,
          -0.14845669269561768,
          -0.16387368738651276,
          -0.05159981921315193,
          0.02633068338036537,
          -0.11934690177440643,
          -0.025217680260539055,
          -0.03701663389801979,
          -0.036810629069805145,
          -0.008588701486587524,
          -0.00020313262939453125,
          -0.12095988541841507,
          0.1622258871793747,
          0.28298264741897583,
          0.041469138115644455,
          0.1622258871793747,
          -0.08166604489088058,
          -0.13269193470478058,
          -0.08041524142026901,
          0.005370413418859243,
          -0.1099340096116066,
          0.019175685942173004,
          -0.0411078967154026,
          -0.014763765037059784,
          -0.041413478553295135,
          0.45346319675445557,
          0.08348224312067032,
          0.1008053570985794,
          -0.006701663136482239,
          -0.12745842337608337,
          -0.14246444404125214,
          -0.06019436940550804,
          -0.0959605723619461,
          0.16005726158618927,
          0.03930050879716873,
          -0.24420621991157532,
          -0.1500770002603531,
          -0.16187596321105957,
          -0.1500730812549591,
          -0.1175173968076706,
          -0.08475296944379807,
          0.09472290426492691,
          0.08315018564462662,
          0.06773319095373154,
          2.330688238143921,
          -0.13885991275310516,
          -0.15043263137340546,
          -0.16584962606430054,
          2.248316764831543,
          2.2367441654205322,
          2.221327066421509,
          0.030279703438282013,
          0.15103645622730255,
          0.01870698109269142,
          0.13946373760700226,
          0.00328998826444149,
          0.12404674291610718,
          -0.1417192965745926,
          -0.15329201519489288,
          -0.16870900988578796,
          0.030279703438282013,
          0.15103645622730255,
          0.01870698109269142,
          0.13946373760700226,
          0.00328998826444149,
          0.12404674291610718,
          0.004584494978189468,
          -0.006988225504755974,
          -0.022405218333005905,
          0.11926257610321045,
          0.10768985748291016,
          0.09227286279201508,
          -0.013278095982968807,
          -0.024850815534591675,
          -0.040267810225486755,
          2.6409449577331543,
          2.6293723583221436,
          2.61395525932312,
          -0.006988225504755974,
          0.019462671130895615,
          -0.11127190291881561,
          -0.1228446215391159,
          -0.138261616230011,
          -0.11127190291881561,
          -0.1228446215391159,
          -0.138261616230011,
          -0.09829176962375641,
          -0.10362903028726578,
          0.10407903790473938,
          -0.016677716746926308,
          -0.03822539746761322,
          0.11476919054985046,
          -0.005987564101815224,
          0.1622258871793747,
          0.28298264741897583,
          0.041469138115644455,
          0.1622258871793747,
          -0.10695988684892654,
          -0.036644771695137024,
          -0.02979220449924469,
          -0.04821749031543732,
          -0.04136492311954498,
          -0.0636344850063324,
          -0.056781917810440063,
          0.030279703438282013,
          0.15103645622730255,
          0.01870698109269142,
          0.13946373760700226,
          0.00328998826444149,
          0.12404674291610718,
          -1.0454899072647095,
          -0.11170101910829544,
          -0.1498834788799286,
          -0.16145619750022888,
          -0.17687319219112396,
          0.01578943431377411,
          0.004216713830828667,
          -0.01120027992874384,
          -0.1403912752866745,
          -0.13353870809078217,
          0.04789513349533081,
          0.08666544407606125,
          0.026499610394239426,
          0.14725635945796967,
          0.9748882055282593,
          -0.19161176681518555,
          0.024101052433252335,
          0.005519658327102661,
          -0.04690716415643692,
          0.05955881625413895,
          0.09242911636829376,
          -0.03862135857343674,
          0.023431241512298584,
          0.01128166913986206,
          -0.10947508364915848,
          -0.08433812856674194,
          -0.07346680015325546,
          0.047289952635765076,
          0.05124092474579811,
          -0.011409434489905834,
          -0.022982154041528702,
          -0.03839914873242378,
          -0.10985307395458221,
          0.029305648058652878,
          -0.12142579257488251,
          0.017732929438352585,
          -0.1368427872657776,
          0.0023159347474575043,
          -0.24127694964408875,
          -0.014763765037059784,
          -0.041413478553295135,
          -0.02138502150774002,
          0.12628448009490967,
          0.11352880299091339,
          -0.005410335958003998,
          0.12966832518577576,
          -0.11353204399347305,
          -0.26560527086257935,
          -0.13187557458877563,
          -0.15914803743362427,
          -0.034220434725284576,
          0.10493828356266022,
          0.05124092474579811,
          0.16005726158618927,
          0.03930050879716873,
          0.16634894907474518,
          0.04559218883514404,
          0.06932651251554489,
          -0.05143024027347565,
          0.19331462681293488,
          0.07255787402391434,
          -0.29499536752700806,
          -0.009490817785263062,
          0.046514227986335754,
          -0.047531791031360626,
          0.2266691029071808,
          0.10591234266757965,
          0.14531210064888,
          0.051992468535900116,
          0.15578527748584747,
          0.035028524696826935,
          -0.12592342495918274,
          0.01875624991953373,
          0.09102766960859299,
          -0.013593964278697968,
          0.07154719531536102,
          0.04450751096010208,
          -0.07270795106887817,
          0.010132156312465668,
          -0.14886094629764557,
          0.16005726158618927,
          0.03930050879716873,
          -0.05626557767391205,
          -0.17702233791351318,
          -0.029339468106627464,
          0.018117234110832214,
          0.13887399435043335,
          -0.0278671532869339,
          -0.03943987190723419,
          -0.05485686659812927,
          -0.014628729782998562,
          -0.02620144933462143,
          -0.04161844402551651,
          -0.11296577751636505,
          0.027417059987783432,
          0.08208508789539337,
          0.08314407616853714,
          1.674018383026123,
          0.11823051422834396,
          0.012573059648275375,
          0.9866649508476257,
          -0.1747651994228363,
          0.11003538966178894,
          0.01301296055316925,
          0.13700108230113983,
          0.06307817250490189,
          0.7087168097496033,
          0.689668595790863,
          1.6422159671783447,
          0.09983537346124649,
          0.00797297153621912,
          -0.0035997494123876095,
          -0.019016742706298828,
          -0.13621535897254944,
          0.07668092846870422,
          -0.020341504365205765,
          0.10364661365747452,
          0.023172035813331604,
          -0.07385039329528809,
          0.0501377247273922,
          0.0018539279699325562,
          -0.09516850113868713,
          0.028819615021348,
          0.00728357769548893,
          -0.010178178548812866,
          0.11003538966178894,
          0.01301296055316925,
          0.13700108230113983,
          0.0025632083415985107,
          0.05124092474579811,
          0.05174408107995987,
          -0.05473274737596512,
          0.04080801457166672,
          0.14801104366779327,
          0.04016546532511711,
          0.14736849069595337,
          -0.13106904923915863,
          -0.23860934376716614,
          0.09938082844018936,
          0.10967843979597092,
          1.6365340948104858,
          -0.06612108647823334,
          0.07343026250600815,
          0.12493877112865448,
          -0.0695573166012764,
          0.15680748224258423,
          0.11952555179595947,
          -0.06151307374238968,
          0.14621798694133759,
          0.9095582962036133,
          0.011387094855308533,
          0.855278730392456,
          0.08755149692296982,
          0.9036695957183838,
          1.1444545984268188,
          0.072327621281147,
          0.12670379877090454,
          0.14621798694133759,
          0.9922769665718079,
          1.9121017456054688,
          0.06333871185779572,
          0.1359667181968689,
          0.9049872159957886,
          0.8509671688079834,
          0.2997876703739166,
          0.3103463649749756,
          1.6315313577651978,
          0.08918211609125137,
          0.20435670018196106,
          -0.5827857851982117,
          -0.6252104043960571,
          0.06232675909996033,
          0.09472290426492691,
          0.08315018564462662,
          0.06773319095373154,
          0.45346319675445557,
          0.07564964890480042,
          0.10434216260910034,
          0.07469608634710312,
          0.06299693882465363,
          0.07066792994737625,
          -0.15608146786689758,
          0.08360560983419418,
          0.03576898202300072,
          -0.17900705337524414,
          -0.028473369777202606,
          0.11259541660547256,
          -0.07317137718200684,
          -0.0216527059674263,
          1.0957810878753662,
          0.9750242829322815,
          0.8546546697616577,
          0.9893180727958679,
          1.1330026388168335,
          1.0122458934783936,
          0.9047001004219055,
          0.04433798789978027,
          0.06187191605567932,
          -0.03515051305294037,
          0.08883760869503021,
          0.8812046051025391,
          -0.8727123737335205,
          0.05852166563272476,
          -0.9838695526123047,
          0.06888480484485626,
          -0.9754840135574341,
          -0.6924295425415039,
          0.5641627311706543,
          0.05124092474579811,
          0.09651870280504227,
          -0.05555451661348343,
          0.03696637600660324,
          -0.14079055190086365,
          -0.10371799021959305,
          -0.015949346125125885,
          0.10434216260910034,
          -0.06169386953115463,
          -0.030361764132976532,
          -0.022684656083583832,
          0.06686894595623016,
          0.33583778142929077,
          -0.0835365578532219,
          0.04287244379520416,
          0.12219206988811493,
          0.08897076547145844,
          0.07564964890480042,
          0.10434216260910034,
          0.07469608634710312,
          0.10374371707439423,
          -0.03241286426782608,
          0.011158864945173264,
          0.1319156140089035,
          -0.10773281753063202,
          0.012558696791529655,
          -0.03666664659976959,
          -0.13569127023220062,
          0.017755089327692986,
          -0.016847923398017883,
          -0.012575484812259674,
          0.0161170344799757,
          -0.013529045507311821,
          -1.4355623722076416,
          -1.3726145029067993,
          -1.4068697690963745,
          -1.3439218997955322,
          -1.4365159273147583,
          -1.373568058013916,
          -0.03945085406303406,
          0.03166563808917999,
          -0.0653567910194397,
          0.058631327003240585,
          -0.04763638600707054,
          -0.020009811967611313,
          -0.018943866714835167,
          0.008682706393301487,
          -0.04858994483947754,
          -0.02096337266266346,
          0.2207249253988266,
          0.24941745400428772,
          0.2197713702917099,
          -0.1341886818408966,
          -0.008341901004314423,
          0.020350618287920952,
          -0.00929546169936657,
          -0.01613382250070572,
          0.012558696791529655,
          -0.017087383195757866,
          -0.01427871361374855,
          0.014413803815841675,
          -0.015232274308800697,
          -0.14046800136566162,
          -0.1117754802107811,
          -0.14142155647277832,
          -0.025990717113018036,
          0.0027018021792173386,
          -0.026944275945425034,
          -0.043785933405160904,
          0.008135155774652958,
          -0.01509341411292553,
          0.03682767599821091,
          -0.0447394922375679,
          0.007181595079600811,
          -0.13359138369560242,
          -0.10489886999130249,
          -0.1345449537038803,
          -0.011555712670087814,
          0.01713680475950241,
          -0.012509273365139961,
          0.0006168466061353683,
          0.12137360125780106,
          0.10374371707439423,
          -0.014530077576637268,
          -0.15155382454395294,
          0.015546760521829128,
          -0.019056251272559166,
          0.04423927888274193,
          0.009636267088353634,
          0.014593199826776981,
          -0.020009811967611313,
          0.02537396177649498,
          -0.12690243124961853,
          -0.15028822422027588,
          -0.15243792533874512,
          -0.25943782925605774,
          -0.11733150482177734,
          -0.2170979082584381,
          -0.09177978336811066,
          -0.09582384675741196,
          -0.038218628615140915,
          -0.13308128714561462,
          -0.1043887734413147,
          -0.13403485715389252,
          -0.01711728610098362,
          -0.004785691387951374,
          -0.012755554169416428,
          0.011575231328606606,
          0.023906826972961426,
          0.015936963260173798,
          -0.018070846796035767,
          -0.005739252083003521,
          -0.013709114864468575,
          -0.02063603326678276,
          0.03377692028880119,
          0.02632659114897251,
          -0.13248518109321594,
          -0.10379266738891602,
          -0.13343875110149384,
          0.03558531776070595,
          0.06427783519029617,
          0.03463175892829895,
          0.07289186120033264,
          -0.1440439224243164,
          -0.11535140126943588,
          -0.1449974775314331,
          -0.0857657939195633,
          -0.05707328021526337,
          -0.08671935647726059,
          0.05231578275561333,
          -0.02691522240638733,
          0.11025265604257584,
          0.035205669701099396,
          -0.1399926394224167,
          -0.08999217301607132,
          -0.027639120817184448,
          0.0010533984750509262,
          -0.028592679649591446,
          -1.4725247621536255,
          -1.4382323026657104,
          -1.4438321590423584,
          -1.4095396995544434,
          -1.4734783172607422,
          -1.4391858577728271,
          -0.1008726954460144,
          -0.07218018174171448,
          -0.1018262580037117,
          -0.14819633960723877,
          -0.11950381845235825,
          -0.14914989471435547,
          -0.10374550521373749,
          -0.07505299150943756,
          -0.10469906777143478,
          -0.011555712670087814,
          0.01713680475950241,
          -0.012509273365139961,
          -0.01072642020881176,
          -0.15020126104354858,
          0.01690015196800232,
          -0.12257467955350876,
          0.0043207816779613495,
          -0.00515097938477993,
          0.009780578315258026,
          -0.0791335478425026,
          -0.01853596791625023,
          -0.0446140393614769,
          -0.14453651010990143,
          -0.1158439889550209,
          -0.14549006521701813,
          0.3097347617149353,
          -0.12025392800569534,
          -0.09156141430139542,
          -0.12120749056339264,
          -0.1258416771888733,
          0.009313344024121761,
          -0.14275987446308136,
          -0.11395323276519775,
          0.07758861035108566,
          0.08992020785808563,
          0.081950344145298,
          -0.12506766617298126,
          -0.09637514501810074,
          -0.12602122128009796,
          0.03481520339846611,
          0.07203513383865356,
          -0.6865155100822449,
          0.07206258922815323,
          1.0241743326187134,
          0.05124092474579811,
          -0.7904428243637085,
          -0.03186469525098801,
          -0.12044213712215424,
          -0.1270969659090042,
          -0.13506682217121124,
          -0.8011904358863831,
          -0.042612310498952866,
          0.07758861035108566,
          0.08992020785808563,
          0.081950344145298,
          0.00903781596571207,
          0.03773033618927002,
          0.008084255270659924,
          -0.12722086906433105,
          0.043640829622745514,
          0.00903781596571207,
          -0.020347686484456062,
          -0.05495069921016693,
          0.034938130527734756,
          0.00033511966466903687,
          0.00033511966466903687,
          0.029027637094259262,
          -0.00061844103038311,
          0.011206443421542645,
          0.13196319341659546,
          0.039898961782455444,
          0.16065572202205658,
          0.010252882726490498,
          0.13100963830947876,
          -0.01715826243162155,
          -0.03822539746761322,
          -0.07724349945783615,
          -0.14247798919677734,
          -0.013275216333568096,
          0.006799761205911636,
          -0.10266859829425812,
          0.01808815449476242,
          -0.026010148227214813,
          -0.03822539746761322,
          -0.13080762326717377,
          0.09651870280504227,
          -0.05555451661348343,
          0.07891256362199783,
          0.21432435512542725,
          -0.11674514412879944,
          -0.04949051886796951,
          -0.031155399978160858,
          -0.18322861194610596,
          -0.099024698138237,
          0.07891256362199783,
          0.04602133855223656,
          0.05955881625413895,
          0.09094281494617462,
          0.11946606636047363,
          0.2266691029071808,
          -0.042948320508003235,
          -0.10192437469959259,
          -0.039546430110931396,
          -0.09852248430252075,
          -0.09568338096141815,
          -0.07309328019618988,
          -0.05955579876899719,
          -0.15955156087875366,
          -0.11884518712759018,
          -0.004987073130905628,
          -0.12201394140720367,
          0.08191029727458954,
          0.0021774121560156345,
          -0.10773281753063202,
          0.012558696791529655,
          -0.11026737838983536,
          0.01048937439918518,
          0.9637725353240967,
          -0.1336112767457962,
          1.0974417924880981,
          0.0000580057967454195,
          0.04860438033938408,
          0.1281866580247879,
          0.024158522486686707,
          -0.08142513781785965,
          -0.17844757437705994,
          -0.05445944890379906,
          -0.004815166816115379,
          -0.10183759778738022,
          0.022150520235300064,
          -0.05951736122369766,
          -0.15653979778289795,
          -0.03255167230963707,
          -0.07788816839456558,
          -0.11961822211742401,
          0.07564964890480042,
          0.10434216260910034,
          0.07469608634710312,
          -0.11033927649259567,
          0.17850562930107117,
          0.05774886906147003,
          0.04905109480023384,
          0.0919857919216156,
          -0.02672341838479042,
          0.09516771137714386,
          -0.09060607850551605,
          0.3966436982154846,
          -0.08718772232532501,
          0.07622116059064865,
          -0.07087475806474686,
          -0.1212451234459877,
          -0.02006191574037075,
          -0.086213618516922,
          -0.20151804387569427,
          -0.08433812856674194,
          -0.21060708165168762,
          -0.5632989406585693,
          -0.5748716592788696,
          -0.5902886390686035,
          -0.11447255313396454,
          -0.12604527175426483,
          -0.1414622664451599,
          0.008452626876533031,
          -0.06472259759902954,
          -0.047528594732284546,
          -0.01883607544004917,
          -0.048482153564691544,
          0.07564964890480042,
          0.10434216260910034,
          0.07469608634710312,
          -0.031210266053676605,
          -0.031142286956310272,
          0.017889518290758133,
          0.04658203572034836,
          0.016935955733060837,
          -0.021251771599054337,
          0.0075175464153289795,
          -0.004055174067616463,
          -0.019472166895866394,
          -0.005584068596363068,
          -0.1042216420173645,
          -0.910693883895874,
          -0.004531409591436386,
          0.010948726907372475,
          0.022743044421076775,
          -0.1030939519405365,
          0.0014499487588182092,
          0.16192367672920227,
          -0.13293248414993286,
          -0.004052306059747934,
          -1.122504711151123,
          0.037751421332359314,
          -0.11116405576467514,
          -0.11987578123807907,
          0.031210551038384438,
          0.15196730196475983,
          -0.034184206277132034,
          0.16353961825370789,
          0.042782872915267944,
          0.022093117237091064,
          0.16125184297561646,
          -0.09866363555192947,
          0.04049508273601532,
          -0.02417721226811409,
          -0.16999728977680206,
          0.9244366884231567,
          -0.20160546898841858,
          -0.12019822001457214,
          -0.13453242182731628,
          -0.15032687783241272,
          0.10591234266757965,
          0.2266691029071808,
          0.09316551685333252,
          -0.02213890105485916,
          0.014128927141427994,
          0.02376355230808258,
          0.008149806410074234,
          -0.014298764988780022,
          -0.03653884679079056,
          -0.058987416326999664,
          -0.008588701486587524,
          0.049959905445575714,
          0.04909283667802811,
          0.16984958946704865,
          -0.4876663088798523,
          -0.16739961504936218,
          -0.13870708644390106,
          -0.16835317015647888,
          0.07847686856985092,
          0.10716938227415085,
          0.07752330601215363,
          0.08360560983419418,
          -0.06308653205633163,
          -0.1002441942691803,
          0.02661173976957798,
          0.14736849069595337,
          -0.002175159752368927,
          -0.025338325649499893,
          0.03695104271173477,
          -0.008704477921128273,
          0.039528585970401764,
          2.246478319168091,
          0.132559671998024,
          0.0355372354388237,
          0.15952534973621368,
          -0.02044280432164669,
          0.016321450471878052,
          0.13457506895065308,
          0.03755263239145279,
          0.16154074668884277,
          0.06292560696601868,
          0.038496267050504684,
          0.04698986932635307,
          0.092005155980587,
          -0.1113574206829071,
          -0.0924486517906189,
          0.050762806087732315,
          -0.032090265303850174,
          -0.02420004829764366,
          0.5425019264221191,
          -0.04760408401489258,
          -0.08929621428251266,
          0.01903897151350975,
          -0.03437591716647148,
          0.008123110979795456,
          -0.09790904819965363,
          -0.10220043361186981,
          -0.003822765778750181,
          -0.025455335155129433,
          -0.0186027679592371,
          -0.13763293623924255,
          1.110029697418213,
          0.01708706095814705,
          -1.0209529399871826,
          -0.12556849420070648,
          -0.0761185809969902,
          -0.11327624320983887,
          0.01919155940413475,
          0.030013177543878555,
          -0.085081547498703,
          -0.07503311336040497,
          0.0061616068705916405,
          -0.05934961140155792,
          -0.03129158914089203,
          -0.022203709930181503,
          -0.1300862729549408,
          -0.0919187068939209,
          0.1152641549706459,
          -0.07533939182758331,
          -0.0030667572282254696,
          -0.04931148141622543,
          -0.09195566177368164,
          0.00906074233353138,
          0.03929214924573898,
          -0.8014333248138428,
          0.024517405778169632,
          -0.07250502705574036,
          0.051483094692230225,
          -0.07508391886949539,
          -0.17210635542869568,
          -0.0481182299554348,
          -1.683218002319336,
          -1.636060357093811,
          -0.060318876057863235,
          -0.08622054755687714,
          0.00790867768228054,
          -0.0038902759552001953,
          0.04117627441883087,
          -0.13779006898403168,
          -0.04366084560751915,
          -0.055459797382354736,
          0.01581845059990883,
          -0.03184065967798233,
          0.0139320632442832,
          -0.006701663136482239,
          -0.14262370765209198,
          -0.09600517898797989,
          -0.06555794179439545,
          -0.10132414102554321,
          -0.09767203778028488,
          0.16005726158618927,
          0.02267562411725521,
          0.059145912528038025,
          -0.037876516580581665,
          0.08611160516738892,
          0.025649908930063248,
          -0.003121386282145977,
          -0.13052986562252045,
          -0.009773105382919312,
          -0.09987020492553711,
          -0.18558910489082336,
          -0.10270099341869354,
          0.016529619693756104,
          0.045390598475933075,
          0.016867343336343765,
          0.10407903790473938,
          0.9926242232322693,
          -0.005987564101815224,
          0.026131078600883484,
          0.09530141949653625,
          0.10215398669242859,
          -0.1403912752866745,
          -0.13353870809078217,
          0.026499610394239426,
          0.9073766469955444,
          -0.2591233253479004,
          0.003537926822900772,
          0.005519658327102661,
          0.0304335355758667,
          -0.016956795006990433,
          0.029771268367767334,
          0.03535068780183792,
          -0.029715711250901222,
          -0.014737237244844437,
          -0.027437308803200722,
          -0.1136004626750946,
          -0.15118008852005005,
          1.0343133211135864,
          0.0039030518382787704,
          -0.09311938285827637,
          0.030868738889694214,
          0.0919516533613205,
          -0.20650433003902435,
          -0.2331540435552597,
          -1.50803804397583,
          0.030361376702785492,
          0.1513545662164688,
          0.04559218883514404,
          -0.05143024027347565,
          0.07255787402391434,
          -0.09601978212594986,
          0.10678249597549438,
          -0.04609755054116249,
          0.057994745671749115,
          0.0043383268639445305,
          -0.1477348953485489,
          -0.10474060475826263,
          -0.09086863696575165,
          0.05004509538412094,
          0.060916416347026825,
          0.18167316913604736,
          0.04274236038327217,
          0.16634894907474518,
          0.06932651251554489,
          0.19331462681293488,
          -0.11139220744371414,
          -0.10571008175611496,
          -0.049705035984516144,
          0.008781760931015015,
          0.15578527748584747,
          -0.13575509190559387,
          -0.00916828028857708,
          -0.23195107281208038,
          0.01040425430983305,
          -0.005126381292939186,
          -0.09177582710981369,
          1.717885971069336,
          -0.012629269622266293,
          -0.04978693276643753,
          1.6077989339828491,
          0.03098047897219658,
          0.012573059648275375,
          -0.6925614476203918,
          0.06601666659116745,
          0.7187619805335999,
          -0.00030149705708026886,
          -0.09959406405687332,
          -0.08125171810388565,
          -0.048029426485300064,
          -0.22620952129364014,
          -0.20786717534065247,
          -0.0916418507695198,
          -0.10434192419052124,
          0.03166563808917999,
          -0.0653567910194397,
          0.058631327003240585,
          0.022592008113861084,
          0.0761009007692337,
          1.5716958045959473,
          -0.06841964274644852,
          -0.0577569454908371,
          -0.1547793745994568,
          -0.030791256576776505,
          0.030639536678791046,
          -0.14562320709228516,
          -0.13621535897254944,
          0.07668092846870422,
          -0.020341504365205765,
          0.10364661365747452,
          0.7484630942344666,
          0.6514406204223633,
          0.7754287719726562,
          -0.02468927577137947,
          -0.13316422700881958,
          -0.06870053708553314,
          -0.15999028086662292,
          0.04562922567129135,
          -0.10644399374723434,
          -0.05073251575231552,
          -0.20280572772026062,
          -0.029058542102575302,
          0.036784637719392776,
          -0.05794373154640198,
          -0.24578438699245453,
          -0.10662566125392914,
          0.01428277138620615,
          -0.13373242318630219,
          0.03167543560266495,
          0.022433586418628693,
          -0.3763967454433441,
          -0.010679730214178562,
          -1.054932951927185,
          -0.18695147335529327,
          -0.12456411868333817,
          -0.01606917381286621,
          0.09196855127811432,
          -0.0336030088365078,
          -0.13288304209709167,
          -0.10637237876653671,
          1.024614691734314,
          -0.2143811732530594,
          -0.2046460211277008,
          0.9127053618431091,
          -0.11614890396595001,
          -0.07826994359493256,
          -0.0036076493561267853,
          -0.17641329765319824,
          0.43977850675582886,
          2.0409793853759766,
          2.0331361293792725,
          -0.6180993914604187,
          -0.6605240106582642,
          -0.1268170326948166,
          0.011708540841937065,
          -0.10076291114091873,
          -0.060634806752204895,
          -0.05524904653429985,
          0.03218131139874458,
          0.12404674291610718,
          0.00328998826444149,
          -0.04410068690776825,
          -0.7346789836883545,
          0.02389911562204361,
          -0.05056043714284897,
          -0.03687046468257904,
          -0.18894368410110474,
          -0.0990220382809639,
          -0.10374001413583755,
          -0.07086971402168274,
          0.005075724795460701,
          -0.14699749648571014,
          0.03926356881856918,
          0.041493915021419525,
          0.0032294392585754395,
          -0.0052910298109054565,
          -0.09522419422864914,
          -0.005735131911933422,
          -0.099024698138237,
          -0.04655537009239197,
          -0.10329659283161163,
          -0.11305807530879974,
          -1.4290815591812134,
          -0.010690616443753242,
          -0.02140125446021557,
          0.035202715545892715,
          -0.06181971728801727,
          0.06216840073466301,
          -0.1449030339717865,
          -0.11065524071455002,
          0.009636267088353634,
          -0.10371723026037216,
          -0.09531128406524658,
          -0.01427871361374855,
          -0.1260908544063568,
          0.0006168466061353683,
          -0.08114190399646759,
          -0.07924067974090576,
          0.02537396177649498,
          -0.007939538918435574,
          -0.1051720455288887,
          -0.21217194199562073,
          -0.12025392800569534,
          -0.10371723026037216,
          -0.08344954997301102,
          -0.000011106487363576889,
          -0.053976383060216904,
          -0.14872626960277557,
          0.04308585822582245,
          -0.21075347065925598,
          0.030597813427448273,
          -0.007195841986685991,
          -0.10609255731105804,
          -0.01196332834661007,
          -0.023762281984090805,
          0.00031381286680698395,
          0.004152309149503708,
          -0.07507869601249695,
          0.06208918243646622,
          -0.042390115559101105,
          -0.12162111699581146,
          0.015546760521829128,
          0.9104507565498352,
          0.8758477568626404,
          0.883348286151886,
          -0.15519854426383972,
          -0.07818366587162018,
          -0.7033873200416565,
          -1.4811075925827026,
          -1.5500333309173584,
          -1.5157408714294434,
          -1.4534850120544434,
          -0.23001277446746826,
          -0.3203015923500061,
          -0.27529650926589966,
          -0.011555712670087814,
          -0.005406372249126434,
          -0.1184644103050232,
          -0.05124177783727646,
          -0.08932629227638245,
          -0.11879436671733856,
          -0.27086758613586426,
          -0.12025392800569534,
          0.009313344024121761,
          -0.14275987446308136,
          -0.11395323276519775,
          -0.11656001210212708,
          -0.008770424872636795,
          0.02844950556755066,
          -0.11230167001485825,
          -0.0750817358493805,
          -0.7379240393638611,
          0.16730326414108276,
          0.9258813858032227,
          -1.002123475074768,
          -0.2435453236103058,
          -0.10780210793018341,
          0.016139689832925797,
          0.00903781596571207,
          -0.12071192264556885,
          -0.03555932641029358,
          -0.11462005972862244,
          -0.22573921084403992,
          -0.6491484045982361,
          -0.14247798919677734,
          -0.23459109663963318,
          -0.12889541685581207,
          -0.005477890372276306,
          1.6309438943862915,
          1.4788706302642822,
          -0.031155399978160858,
          -0.18322861194610596,
          -0.022295230999588966,
          -0.08270110189914703,
          -0.06011100113391876,
          -0.046573519706726074,
          -0.004692100919783115,
          0.04005333408713341,
          -0.008897645398974419,
          -0.10273915529251099,
          -0.0923440083861351,
          0.034622687846422195,
          -0.13325953483581543,
          0.0032984567806124687,
          0.006435498595237732,
          0.010347321629524231,
          -0.07036289572715759,
          -0.08142513781785965,
          -0.17844757437705994,
          -0.05445944890379906,
          -0.11404776573181152,
          0.045550912618637085,
          0.024728387594223022,
          -0.029318656772375107,
          0.08165568858385086,
          0.026269089430570602,
          -0.05645718425512314,
          -0.02737344615161419,
          1.1648579835891724,
          1.0677140951156616,
          1.1619770526885986,
          1.1555927991867065,
          -0.113388791680336,
          0.021789714694023132,
          -0.086213618516922,
          -0.10654247552156448,
          -0.10147495567798615,
          -0.027064019814133644,
          -0.0847582295536995,
          -0.03625025972723961,
          2.236497402191162,
          -0.004701113793998957,
          -1.0639169216156006,
          0.04723047465085983,
          0.04076933115720749,
          0.022743044421076775,
          -0.09812875837087631,
          -0.12019730359315872,
          -0.0021760668605566025,
          -0.13293534517288208,
          0.018735036253929138,
          -0.0046381112188100815,
          0.03184022754430771,
          -0.0009597991593182087,
          2.2654027938842773,
          -0.08861680328845978,
          -0.8341351747512817,
          -0.04740007594227791,
          -0.09734990447759628,
          -0.04203029349446297,
          2.242204427719116,
          -0.013689800165593624,
          -0.11143958568572998,
          -0.14592668414115906,
          0.11770519614219666,
          0.1304520070552826,
          -0.04818755388259888,
          0.05901547521352768,
          0.008824499323964119,
          0.9560932517051697
         ],
         "z": [
          0.6000000000000001,
          0.4,
          0.2,
          0.2,
          0.4,
          0.6000000000000001,
          0.4,
          0.4,
          0.6000000000000001,
          0.6000000000000001,
          0.4,
          0.4,
          0,
          0.2,
          0.4,
          0.6000000000000001,
          0.4,
          0.6000000000000001,
          0,
          0.2,
          0.2,
          0.6000000000000001,
          0.6000000000000001,
          0.6000000000000001,
          0.8,
          0.2,
          0.2,
          0.2,
          0.4,
          0.6000000000000001,
          0.6000000000000001,
          0,
          0.2,
          0,
          0.2,
          0.2,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.4,
          0.2,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.2,
          0.2,
          0.2,
          0.4,
          0.4,
          0.4,
          0.2,
          0.2,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.2,
          0.4,
          0.4,
          0.6000000000000001,
          0.4,
          0.6000000000000001,
          0.6000000000000001,
          0.4,
          0.2,
          0.2,
          0.4,
          0.4,
          0.4,
          0.2,
          0.6000000000000001,
          0.4,
          0.2,
          0.2,
          0.2,
          0.4,
          0.2,
          0.2,
          0.4,
          0,
          0.2,
          0,
          0,
          0.2,
          0,
          0.4,
          0,
          0.2,
          0,
          0,
          0.2,
          0,
          0.2,
          0.4,
          0.2,
          0.2,
          0.4,
          0.2,
          0.4,
          0.2,
          0.4,
          0.4,
          0.2,
          0.2,
          0.4,
          0.4,
          0.2,
          0.2,
          0.2,
          0.4,
          0.2,
          0.4,
          0.4,
          0,
          0.2,
          0,
          0.2,
          0,
          0,
          0.4,
          0.6000000000000001,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.6000000000000001,
          0.2,
          0.6000000000000001,
          0.8,
          0.2,
          0.6000000000000001,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0,
          0.2,
          0.4,
          0.4,
          0.2,
          0.2,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.2,
          0.4,
          0.4,
          0.6000000000000001,
          0.8,
          0.6000000000000001,
          0.8,
          0.6000000000000001,
          0.6000000000000001,
          0.6000000000000001,
          0.4,
          0.2,
          0.4,
          0.4,
          0.2,
          0,
          0,
          0.4,
          0.2,
          0.2,
          0.2,
          0,
          0.4,
          0.4,
          0.6000000000000001,
          0.4,
          0,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.6000000000000001,
          0.4,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.6000000000000001,
          0.6000000000000001,
          0.4,
          0.6000000000000001,
          0.2,
          0.4,
          0.4,
          0.4,
          0,
          0.4,
          0.2,
          0.6000000000000001,
          0.6000000000000001,
          0.6000000000000001,
          0.2,
          0,
          0.2,
          0.2,
          0.6000000000000001,
          0.6000000000000001,
          0.6000000000000001,
          0.6000000000000001,
          0.4,
          0.4,
          0,
          0,
          0.2,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.2,
          0.2,
          0.2,
          0.4,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.2,
          0.2,
          0.2,
          0.4,
          0.4,
          0.2,
          0.2,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.2,
          0.4,
          0,
          0,
          0.2,
          0.2,
          0.2,
          0.4,
          0.4,
          0.6000000000000001,
          0.4,
          0.4,
          0.6000000000000001,
          0.4,
          0.6000000000000001,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0,
          0.2,
          0,
          0.2,
          0.2,
          0.4,
          0.2,
          0.2,
          0.2,
          0.2,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.2,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.4,
          0.2,
          0.4,
          0,
          0,
          0.4,
          0.2,
          0.6000000000000001,
          0.6000000000000001,
          0.6000000000000001,
          0.6000000000000001,
          0.6000000000000001,
          0,
          0.2,
          0.2,
          0.4,
          0.4,
          0,
          0.4,
          0,
          0.6000000000000001,
          0.2,
          0.8,
          0.4,
          0.4,
          0.4,
          0.2,
          0,
          0.4,
          0,
          0.2,
          0.4,
          0.4,
          0.4,
          0.4,
          0,
          0,
          0.2,
          0.2,
          0.2,
          0.2,
          0.6000000000000001,
          0.6000000000000001,
          0.4,
          0.4,
          0.2,
          0.8,
          0.6000000000000001,
          0.4,
          0.2,
          0.2,
          0.4,
          0.2,
          0.2,
          0.2,
          0.4,
          0,
          0.2,
          0.4,
          0.2,
          0,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.2,
          0.6000000000000001,
          0.6000000000000001,
          0.4,
          0.4,
          0.4,
          0.2,
          0.2,
          0.4,
          0.2,
          0.2,
          0.4,
          0.4,
          0,
          0.2,
          0.2,
          0.4,
          0,
          0.4,
          0.4,
          0.6000000000000001,
          0,
          0.4,
          0.2,
          0.2,
          0.2,
          0.2,
          0.4,
          0.2,
          0,
          0,
          0.2,
          0.4,
          0.2,
          0.6000000000000001,
          0.4,
          0.2,
          0.6000000000000001,
          0.4,
          0.2,
          0.6000000000000001,
          0.4,
          0.2,
          0.4,
          0,
          0.4,
          0.2,
          0.4,
          0,
          0.2,
          0.4,
          0.4,
          0.4,
          0.2,
          0.2,
          0.6000000000000001,
          0.8,
          0,
          0,
          0.4,
          0.4,
          0.2,
          0,
          0.4,
          0.2,
          0,
          0.4,
          0.2,
          0.6000000000000001,
          0.4,
          0.6000000000000001,
          0,
          0.6000000000000001,
          0.4,
          0,
          0,
          0.2,
          0.6000000000000001,
          0.4,
          0,
          0.2,
          0.6000000000000001,
          0.6000000000000001,
          0.2,
          0.4,
          0.4,
          0.2,
          0.2,
          0.4,
          0.4,
          0.2,
          0,
          0,
          0.2,
          0,
          0,
          0.2,
          0,
          0.2,
          0.2,
          0.4,
          0,
          0.4,
          0.4,
          0.4,
          0.2,
          0.2,
          0.2,
          0.4,
          0.4,
          0.6000000000000001,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.2,
          0.6000000000000001,
          0.4,
          0.6000000000000001,
          0.2,
          0.2,
          0.2,
          0,
          0.2,
          0.2,
          0.4,
          0,
          0,
          0.2,
          0.2,
          0.6000000000000001,
          0.4,
          0.4,
          0.2,
          0.4,
          0.4,
          0.4,
          0.2,
          0.4,
          0.4,
          0.2,
          0.2,
          0.2,
          0,
          0.2,
          0,
          0,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.4,
          0.4,
          0.4,
          0,
          0,
          0.2,
          0.4,
          0.2,
          0.2,
          0.2,
          0.4,
          0.4,
          0.2,
          0.2,
          0.4,
          0.2,
          0.6000000000000001,
          0.4,
          0,
          0,
          0.2,
          0.2,
          0,
          0,
          0.2,
          0.4,
          0.2,
          0.4,
          0,
          0.2,
          0,
          0.2,
          0.4,
          0.2,
          0.2,
          0.4,
          0.2,
          0.4,
          0.6000000000000001,
          0.4,
          0.2,
          0.4,
          0.2,
          0.2,
          0,
          0.4,
          0.2,
          0.2,
          0,
          0.4,
          0.6000000000000001,
          0.4,
          0,
          0.2,
          0,
          0.4,
          0.4,
          0,
          0.4,
          0.6000000000000001,
          0,
          0,
          0.2,
          0.2,
          0,
          0,
          0.2,
          0.6000000000000001,
          0.6000000000000001,
          0.6000000000000001,
          0.8,
          0.6000000000000001,
          0.8,
          0.6000000000000001,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.4,
          0,
          0,
          0,
          0.2,
          0.2,
          0.2,
          0,
          0,
          0,
          0.4,
          0.2,
          0.2,
          0.4,
          0.6000000000000001,
          0.4,
          0.2,
          0.4,
          0.2,
          0.2,
          0.4,
          0.6000000000000001,
          0.4,
          0.4,
          0.6000000000000001,
          0.4,
          0.2,
          0.4,
          0,
          0,
          0.4,
          0.4,
          0.2,
          0.4,
          0.2,
          0.2,
          0.2,
          0.4,
          0.4,
          0.2,
          0.2,
          0.2,
          0.4,
          0.2,
          0.4,
          0.6000000000000001,
          0.4,
          0.4,
          0.6000000000000001,
          0.4,
          0,
          0.2,
          0,
          0.2,
          0.4,
          0.2,
          0.4,
          0.2,
          0.2,
          0.8,
          0.6000000000000001,
          0.2,
          0.2,
          0.4,
          0.6000000000000001,
          0.4,
          0.2,
          0.4,
          0.6000000000000001,
          0.4,
          0.6000000000000001,
          0,
          0.2,
          0.4,
          0,
          0,
          0,
          0.4,
          0.6000000000000001,
          0.4,
          0,
          0,
          0,
          0.2,
          0.2,
          0,
          0.2,
          0.4,
          0.6000000000000001,
          0.4,
          0.4,
          0.2,
          0.4,
          0,
          0,
          0,
          0,
          0.2,
          0,
          0.4,
          0,
          0,
          0.2,
          0.2,
          0.2,
          0.2,
          0.2,
          0.4,
          0.2,
          0.2,
          0.2,
          0.4,
          0.4,
          0.2,
          0.2,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.6000000000000001,
          0.4,
          0.4,
          0.4,
          0,
          0.2,
          0,
          0.2,
          0.6000000000000001,
          0.6000000000000001,
          0.2,
          0.4,
          0.4,
          0,
          0.2,
          0,
          0.2,
          0.2,
          0.2,
          0.4,
          0.4,
          0.4,
          0.4,
          0.2,
          0.2,
          0,
          0.6000000000000001,
          0.6000000000000001,
          0.4,
          0.6000000000000001,
          0.2,
          0.2,
          0.6000000000000001,
          0.4,
          0.6000000000000001,
          0.6000000000000001,
          0.6000000000000001,
          0.4,
          0.4,
          0.2,
          0,
          0,
          0.2,
          0.4,
          0.8,
          0.6000000000000001,
          0.2,
          0.6000000000000001,
          0.4,
          0.4,
          0.8,
          0.6000000000000001,
          0.4,
          0.4,
          0,
          0.2,
          0,
          0.6000000000000001,
          0.4,
          0.4,
          0.2,
          0.2,
          0.4,
          0.4,
          0.4,
          0,
          0.6000000000000001,
          0.2,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.8,
          0.6000000000000001,
          0.8,
          0,
          0,
          0.2,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.2,
          0,
          0.2,
          0,
          0,
          0.2,
          0,
          0.4,
          0.4,
          0.2,
          0.4,
          0.2,
          0.2,
          0,
          0,
          0.2,
          0.4,
          0.4,
          0,
          0.2,
          0,
          0.2,
          0.6000000000000001,
          0.4,
          0.4,
          0.4,
          0,
          0.6000000000000001,
          0.2,
          0.4,
          0.6000000000000001,
          0.4,
          0.4,
          0.2,
          0.2,
          0.2,
          0.6000000000000001,
          0.2,
          0.6000000000000001,
          0.2,
          0.4,
          0.4,
          0.6000000000000001,
          0.4,
          0.4,
          0.4,
          0.4,
          0.2,
          0.2,
          0.2,
          0.4,
          0.4,
          0.2,
          0.2,
          0.4,
          0.2,
          0.4,
          0.4,
          0.2,
          0.2,
          0.2,
          0,
          0.4,
          0.6000000000000001,
          0.4,
          0.2,
          0.4,
          0.2,
          0,
          0.4,
          0.4,
          0.2,
          0.2,
          0.4,
          0.2,
          0.2,
          0,
          0.2,
          0.6000000000000001,
          0.4,
          0.8,
          0.6000000000000001,
          0.4,
          0.2,
          0.4,
          0.8,
          0.6000000000000001,
          0.2,
          0.2,
          0.2,
          0.2,
          0.6000000000000001,
          0.6000000000000001,
          0.4,
          0.8,
          0.2,
          0.6000000000000001,
          0.4,
          0.2,
          0.4,
          0.2,
          0.2,
          0.4,
          0.4,
          0.2,
          0.2,
          0.4,
          0.4,
          0.2,
          0.2,
          0.4,
          0.6000000000000001,
          0.6000000000000001,
          0.6000000000000001,
          0.4,
          0.2,
          0.4,
          0.2,
          0.2,
          0.4,
          0.2,
          0.2,
          0.4,
          0.6000000000000001,
          0.6000000000000001,
          0.4,
          0.4,
          0.4,
          0.4,
          0.2,
          0,
          0,
          0.2,
          0.6000000000000001,
          0.4,
          0.4,
          0.8,
          0.6000000000000001,
          0.4,
          0.4,
          0.4,
          0.2,
          0.2,
          0.2,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.2,
          0.6000000000000001,
          0.6000000000000001,
          0.4,
          0.6000000000000001,
          0.2,
          0,
          0.6000000000000001,
          0.2,
          0.2,
          0.2,
          0.6000000000000001,
          0.4,
          0.4,
          0,
          0.6000000000000001,
          0.6000000000000001,
          0.2,
          0.6000000000000001,
          0.4,
          0.4,
          0.2,
          0.2,
          0.4,
          0.6000000000000001,
          0.4,
          0.2,
          0.2,
          0.4,
          0.4,
          0.6000000000000001,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.2,
          0.2,
          0.4,
          0.4,
          0.4,
          0.2,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.6000000000000001,
          0.2,
          0.6000000000000001,
          0.4,
          0.4,
          0.8,
          0.8,
          0.2,
          0.2,
          0.4,
          0.2,
          0.6000000000000001,
          0.4,
          0.6000000000000001,
          0.4,
          0.4,
          0,
          0.2,
          0.4,
          0.6000000000000001,
          0.2,
          0.2,
          0.2,
          0.2,
          0,
          0.2,
          0.6000000000000001,
          0.4,
          0.4,
          0.6000000000000001,
          0.4,
          0.6000000000000001,
          0.2,
          0.4,
          0.2,
          0.6000000000000001,
          0.2,
          0.4,
          0.8,
          0.6000000000000001,
          0.4,
          0.4,
          0.4,
          0,
          0.4,
          0,
          0.2,
          0.2,
          0.4,
          0.6000000000000001,
          0.6000000000000001,
          0.6000000000000001,
          0.8,
          0.8,
          0.6000000000000001,
          0.6000000000000001,
          0.2,
          0.6000000000000001,
          0.4,
          0.2,
          0.2,
          0.6000000000000001,
          0.4,
          0.4,
          0.8,
          0.6000000000000001,
          0.2,
          0.6000000000000001,
          0.4,
          0.2,
          0.6000000000000001,
          0.4,
          0.2,
          0.6000000000000001,
          0.4,
          0.4,
          0.6000000000000001,
          0.6000000000000001,
          0.8,
          0.2,
          0.4,
          0.2,
          0.4,
          0.4,
          0,
          0.4,
          0.8,
          0.4,
          0.2,
          0.6000000000000001,
          0,
          0.2,
          0.8,
          0.4,
          0.4,
          0.8,
          0.8,
          0.6000000000000001,
          0.6000000000000001,
          0.4,
          0.6000000000000001,
          0.6000000000000001,
          0.6000000000000001,
          0.8,
          0.8,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.6000000000000001,
          0.6000000000000001,
          0.8,
          0.8,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.6000000000000001,
          0,
          0.4,
          0.4,
          0.4,
          0.2,
          0.4,
          0.4,
          0.2,
          0.4,
          0.2,
          0.4,
          0.4,
          0,
          0.2,
          0.2,
          0,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.2,
          0.2,
          0,
          0.4,
          0.2,
          0.4,
          0.4,
          0.2,
          0.6000000000000001,
          0.6000000000000001,
          0.2,
          0.4,
          0.4,
          0.4,
          0.4,
          0.2,
          0.4,
          0.6000000000000001,
          0.8,
          0.4,
          0.6000000000000001,
          0.4,
          0.2,
          0.4,
          0.4,
          0.2,
          0.8,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.2,
          0.4,
          0,
          0.4,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.4,
          0.4,
          0.4,
          0.4,
          0.6000000000000001,
          0.8,
          0.4,
          0,
          0.2,
          0.4,
          0.4,
          0.2,
          0.4,
          0.6000000000000001,
          0.4,
          0,
          0.2,
          0.4,
          0.4,
          0,
          0,
          0.4,
          0.4,
          0.2,
          0.2,
          0.4,
          0.4,
          0.6000000000000001,
          0.6000000000000001,
          0.2,
          0,
          0.4,
          0.4,
          0.4,
          0.8,
          0.2,
          0.4,
          0.8,
          0.6000000000000001,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.4,
          0.2,
          0.4,
          0.4,
          0.2,
          0.2,
          0.4,
          0,
          0.4,
          0.4,
          0,
          0.4,
          0.2,
          0,
          0.2,
          0.4,
          0.4,
          0.8,
          0.6000000000000001,
          0.6000000000000001,
          0,
          0.4,
          0.4,
          0.4,
          0,
          0.2,
          0.2,
          0.4,
          0.8,
          0.4,
          0.6000000000000001,
          0.4,
          0,
          0.6000000000000001,
          0.6000000000000001,
          0.6000000000000001,
          0.4,
          0.4,
          0.2,
          0.6000000000000001,
          0,
          0.4,
          0.2,
          0.2,
          0.2,
          0.6000000000000001,
          0.4,
          0.2,
          0.4,
          0.2,
          0.8,
          0.4,
          0.2,
          0.4,
          0.4,
          0,
          0.2,
          0.4,
          0.4,
          0.6000000000000001,
          0.2,
          0.6000000000000001,
          0.6000000000000001,
          0.6000000000000001,
          0.6000000000000001,
          0.4,
          0.4,
          0.4,
          0.6000000000000001
         ]
        }
       ],
       "layout": {
        "height": 1000,
        "scene": {
         "xaxis": {
          "title": {
           "text": "PCA Component 1"
          }
         },
         "yaxis": {
          "title": {
           "text": "PCA Component 2"
          }
         },
         "zaxis": {
          "title": {
           "text": "Z Axis"
          }
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "3D Graph Visualization"
        },
        "width": 1000
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from directed_graph.visualize_graph import visualize_graph_ngrams, visualize_graph_ngrams_with_pca\n",
    "# visualize_graph_ngrams(clustered_graph)\n",
    "visualize_graph_ngrams_with_pca(clustered_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "edge_cluster_to_word_map = defaultdict(list)\n",
    "for key, value in edge_map.items():\n",
    "    edge_cluster_to_word_map[value].append(key)\n",
    "edge_cluster_to_word_map = dict(edge_cluster_to_word_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"address\": [\n",
      "        \"address\"\n",
      "    ],\n",
      "    \"aggregates\": [\n",
      "        \"aggregates\"\n",
      "    ],\n",
      "    \"among\": [\n",
      "        \"among\"\n",
      "    ],\n",
      "    \"applies\": [\n",
      "        \"apply\",\n",
      "        \"applies\"\n",
      "    ],\n",
      "    \"as\": [\n",
      "        \"as\"\n",
      "    ],\n",
      "    \"between\": [\n",
      "        \"between\"\n",
      "    ],\n",
      "    \"broadcasts\": [\n",
      "        \"broadcasts\"\n",
      "    ],\n",
      "    \"captures\": [\n",
      "        \"distills\",\n",
      "        \"captures\",\n",
      "        \"capture\"\n",
      "    ],\n",
      "    \"carry\": [\n",
      "        \"carry\"\n",
      "    ],\n",
      "    \"compress\": [\n",
      "        \"compress\"\n",
      "    ],\n",
      "    \"conduct\": [\n",
      "        \"conduct\"\n",
      "    ],\n",
      "    \"contain via\": [\n",
      "        \"compress via\",\n",
      "        \"generate via\",\n",
      "        \"optimize via\",\n",
      "        \"contain via\"\n",
      "    ],\n",
      "    \"decreases below\": [\n",
      "        \"decreases below\",\n",
      "        \"remains above\"\n",
      "    ],\n",
      "    \"demonstrate of\": [\n",
      "        \"have for\",\n",
      "        \"distills from\",\n",
      "        \"imposes on\",\n",
      "        \"train on\",\n",
      "        \"distribute of\",\n",
      "        \"suffer from\",\n",
      "        \"retain of\",\n",
      "        \"performs on\",\n",
      "        \"assigns to\",\n",
      "        \"incur for\",\n",
      "        \"formulate as\",\n",
      "        \"apply on\",\n",
      "        \"lead to\",\n",
      "        \"set for\",\n",
      "        \"learn of\",\n",
      "        \"evaluate on\",\n",
      "        \"outperforms in\",\n",
      "        \"reduces for\",\n",
      "        \"make To\",\n",
      "        \"handles with\",\n",
      "        \"demonstrate of\",\n",
      "        \"underscore of\",\n",
      "        \"incur on\",\n",
      "        \"share In\",\n",
      "        \"have For\",\n",
      "        \"fits to\",\n",
      "        \"suffer with\",\n",
      "        \"share of\",\n",
      "        \"comprise from\",\n",
      "        \"removes from\",\n",
      "        \"apply to\",\n",
      "        \"quantifies of\",\n",
      "        \"drops of\",\n",
      "        \"incurs for\",\n",
      "        \"minimize of\",\n",
      "        \"inherit from\",\n",
      "        \"extract from\",\n",
      "        \"compress in\",\n",
      "        \"select with\",\n",
      "        \"pay from\",\n",
      "        \"focuses on\",\n",
      "        \"decreases of\",\n",
      "        \"maintain on\",\n",
      "        \"note as\",\n",
      "        \"gain of\",\n",
      "        \"initializes with\",\n",
      "        \"trains for\",\n",
      "        \"sends to\",\n",
      "        \"perform of\",\n",
      "        \"leverages of\",\n",
      "        \"become of\",\n",
      "        \"achieve to\",\n",
      "        \"broadcasts of\",\n",
      "        \"needs to\",\n",
      "        \"match of\",\n",
      "        \"take as\",\n",
      "        \"becomes of\",\n",
      "        \"applies on\",\n",
      "        \"use on\",\n",
      "        \"add with\",\n",
      "        \"increases of\",\n",
      "        \"add between\",\n",
      "        \"observe of\",\n",
      "        \"exhibits of\",\n",
      "        \"exhibits to\",\n",
      "        \"stabilizes in\",\n",
      "        \"improves of\",\n",
      "        \"have to\",\n",
      "        \"impose on\",\n",
      "        \"use to\",\n",
      "        \"set as\",\n",
      "        \"varies of\",\n",
      "        \"carry of\",\n",
      "        \"carry from\",\n",
      "        \"make in\",\n",
      "        \"normalize of\",\n",
      "        \"make to\",\n",
      "        \"implement with\",\n",
      "        \"propagate to\",\n",
      "        \"evaluate with\",\n",
      "        \"deploy in\",\n",
      "        \"consists of\",\n",
      "        \"contains in\",\n",
      "        \"use for\",\n",
      "        \"contains of\",\n",
      "        \"augment to\",\n",
      "        \"captures of\",\n",
      "        \"use with\",\n",
      "        \"counts for\",\n",
      "        \"employ on\",\n",
      "        \"compare with\",\n",
      "        \"trains with\",\n",
      "        \"assign to\",\n",
      "        \"finds for\",\n",
      "        \"select of\",\n",
      "        \"consider to\",\n",
      "        \"assign for\",\n",
      "        \"set of\",\n",
      "        \"performs with\",\n",
      "        \"measure with\",\n",
      "        \"report with\",\n",
      "        \"measure of\",\n",
      "        \"evaluate of\",\n",
      "        \"shows under\",\n",
      "        \"achieves of\",\n",
      "        \"have of\",\n",
      "        \"outperform with\",\n",
      "        \"shows of\",\n",
      "        \"cope with\",\n",
      "        \"provides for\",\n",
      "        \"stem of\",\n",
      "        \"shows with\",\n",
      "        \"seen to\",\n",
      "        \"stems from\",\n",
      "        \"preserve from\",\n",
      "        \"achieves on\",\n",
      "        \"exhibits in\",\n",
      "        \"provides of\",\n",
      "        \"needs of\",\n",
      "        \"need in\",\n",
      "        \"lists of\",\n",
      "        \"increases on\",\n",
      "        \"afford on\",\n",
      "        \"discard of\",\n",
      "        \"preserve of\",\n",
      "        \"vary of\",\n",
      "        \"tends to\",\n",
      "        \"differ in\",\n",
      "        \"exceeds of\",\n",
      "        \"select from\",\n",
      "        \"capture in\",\n",
      "        \"shows on\",\n",
      "        \"save in\",\n",
      "        \"assign with\",\n",
      "        \"exhibit from\",\n",
      "        \"exhibit toward\",\n",
      "        \"contribute to\",\n",
      "        \"appends to\",\n",
      "        \"record of\",\n",
      "        \"originate from\",\n",
      "        \"contain from\",\n",
      "        \"applies to\",\n",
      "        \"achieves to\",\n",
      "        \"enhance with\",\n",
      "        \"perform to\",\n",
      "        \"offers for\",\n",
      "        \"support in\",\n",
      "        \"support with\",\n",
      "        \"uses as\",\n",
      "        \"suffers from\",\n",
      "        \"gained in\",\n",
      "        \"compress with\",\n",
      "        \"reduce of\",\n",
      "        \"believe on\"\n",
      "    ],\n",
      "    \"discard\": [\n",
      "        \"discard\"\n",
      "    ],\n",
      "    \"due\": [\n",
      "        \"due\"\n",
      "    ],\n",
      "    \"exhibits\": [\n",
      "        \"exhibits\",\n",
      "        \"exhibit\"\n",
      "    ],\n",
      "    \"exhibits than\": [\n",
      "        \"exhibits than\",\n",
      "        \"achieves than\",\n",
      "        \"retain than\"\n",
      "    ],\n",
      "    \"extract\": [\n",
      "        \"extract\"\n",
      "    ],\n",
      "    \"extract by\": [\n",
      "        \"extract by\",\n",
      "        \"produces by\"\n",
      "    ],\n",
      "    \"for\": [\n",
      "        \"for\"\n",
      "    ],\n",
      "    \"from\": [\n",
      "        \"from\",\n",
      "        \"across\",\n",
      "        \"into\",\n",
      "        \"through\",\n",
      "        \"via\"\n",
      "    ],\n",
      "    \"handles\": [\n",
      "        \"handles\"\n",
      "    ],\n",
      "    \"have\": [\n",
      "        \"have\",\n",
      "        \"has\",\n",
      "        \"seen\"\n",
      "    ],\n",
      "    \"holds\": [\n",
      "        \"holds\"\n",
      "    ],\n",
      "    \"inherit\": [\n",
      "        \"inherit\"\n",
      "    ],\n",
      "    \"learn\": [\n",
      "        \"learn\",\n",
      "        \"observe\"\n",
      "    ],\n",
      "    \"minimize after\": [\n",
      "        \"minimize after\",\n",
      "        \"converges after\",\n",
      "        \"achieve without\",\n",
      "        \"transmit without\",\n",
      "        \"achieve After\"\n",
      "    ],\n",
      "    \"needs\": [\n",
      "        \"needs\",\n",
      "        \"satisfy\"\n",
      "    ],\n",
      "    \"normalize\": [\n",
      "        \"normalize\"\n",
      "    ],\n",
      "    \"of\": [\n",
      "        \"of\",\n",
      "        \"on\",\n",
      "        \"in\"\n",
      "    ],\n",
      "    \"outperform due\": [\n",
      "        \"outperform due\",\n",
      "        \"indicates due\"\n",
      "    ],\n",
      "    \"outperforms\": [\n",
      "        \"outperforms\",\n",
      "        \"outperform\"\n",
      "    ],\n",
      "    \"pay\": [\n",
      "        \"pay\",\n",
      "        \"afford\"\n",
      "    ],\n",
      "    \"sample\": [\n",
      "        \"sample\"\n",
      "    ],\n",
      "    \"set\": [\n",
      "        \"set\"\n",
      "    ],\n",
      "    \"share\": [\n",
      "        \"share\"\n",
      "    ],\n",
      "    \"skew in\": [\n",
      "        \"has in\",\n",
      "        \"skew in\",\n",
      "        \"has of\"\n",
      "    ],\n",
      "    \"support\": [\n",
      "        \"support\"\n",
      "    ],\n",
      "    \"than\": [\n",
      "        \"than\"\n",
      "    ],\n",
      "    \"to\": [\n",
      "        \"to\"\n",
      "    ],\n",
      "    \"toward\": [\n",
      "        \"toward\"\n",
      "    ],\n",
      "    \"track\": [\n",
      "        \"track\",\n",
      "        \"record\"\n",
      "    ],\n",
      "    \"trains\": [\n",
      "        \"train\",\n",
      "        \"trains\"\n",
      "    ],\n",
      "    \"transmit\": [\n",
      "        \"distribute\",\n",
      "        \"transmit\"\n",
      "    ],\n",
      "    \"uses\": [\n",
      "        \"keep\",\n",
      "        \"orchestrates\",\n",
      "        \"include\",\n",
      "        \"imposes\",\n",
      "        \"utilize\",\n",
      "        \"retain\",\n",
      "        \"propose\",\n",
      "        \"performs\",\n",
      "        \"uses\",\n",
      "        \"assigns\",\n",
      "        \"optimizes\",\n",
      "        \"incur\",\n",
      "        \"formulate\",\n",
      "        \"add\",\n",
      "        \"implement\",\n",
      "        \"evaluate\",\n",
      "        \"reduces\",\n",
      "        \"make\",\n",
      "        \"demonstrate\",\n",
      "        \"enables\",\n",
      "        \"contribute\",\n",
      "        \"comprise\",\n",
      "        \"removes\",\n",
      "        \"measure\",\n",
      "        \"quantifies\",\n",
      "        \"indicates\",\n",
      "        \"require\",\n",
      "        \"incurs\",\n",
      "        \"minimize\",\n",
      "        \"shows\",\n",
      "        \"select\",\n",
      "        \"maintain\",\n",
      "        \"gain\",\n",
      "        \"initializes\",\n",
      "        \"sends\",\n",
      "        \"perform\",\n",
      "        \"leverages\",\n",
      "        \"use\",\n",
      "        \"achieve\",\n",
      "        \"specify\",\n",
      "        \"determine\",\n",
      "        \"determines\",\n",
      "        \"take\",\n",
      "        \"increases\",\n",
      "        \"decreases\",\n",
      "        \"generate\",\n",
      "        \"stabilizes\",\n",
      "        \"impose\",\n",
      "        \"denotes\",\n",
      "        \"represents\",\n",
      "        \"optimize\",\n",
      "        \"attain\",\n",
      "        \"deploy\",\n",
      "        \"choose\",\n",
      "        \"contains\",\n",
      "        \"augment\",\n",
      "        \"employ\",\n",
      "        \"compare\",\n",
      "        \"assign\",\n",
      "        \"utilizes\",\n",
      "        \"generates\",\n",
      "        \"finds\",\n",
      "        \"produces\",\n",
      "        \"adopts\",\n",
      "        \"consider\",\n",
      "        \"create\",\n",
      "        \"achieves\",\n",
      "        \"provides\",\n",
      "        \"preserve\",\n",
      "        \"improve\",\n",
      "        \"consumes\",\n",
      "        \"saves\",\n",
      "        \"attains\",\n",
      "        \"obtain\",\n",
      "        \"save\",\n",
      "        \"extend\",\n",
      "        \"appends\",\n",
      "        \"contain\",\n",
      "        \"facilitates\",\n",
      "        \"enhance\",\n",
      "        \"requires\",\n",
      "        \"offers\",\n",
      "        \"computes\",\n",
      "        \"gained\",\n",
      "        \"proposes\",\n",
      "        \"reduce\",\n",
      "        \"leverage\",\n",
      "        \"contributes\"\n",
      "    ],\n",
      "    \"vary\": [\n",
      "        \"vary\"\n",
      "    ],\n",
      "    \"with\": [\n",
      "        \"with\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def print_beautiful_dict(d):\n",
    "    \"\"\"Prints a dictionary with pretty formatting.\"\"\"\n",
    "    print(json.dumps(d, indent=4, sort_keys=True))\n",
    "\n",
    "print_beautiful_dict(edge_cluster_to_word_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edge_cluster_to_word_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edge_cluster_to_word_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from directed_graph.graph import save_graph\n",
    "\n",
    "save_graph(clustered_graph, \"clustered_graph.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_02_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
