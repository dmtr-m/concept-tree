{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DgXxLjUbklGg"
      },
      "outputs": [],
      "source": [
        "import feedparser\n",
        "\n",
        "def get_recent_arxiv_ids(category=\"cs.LG\", max_results=100):\n",
        "    base_url = f\"https://export.arxiv.org/api/query?search_query=cat:{category}&sortBy=submittedDate&sortOrder=descending&max_results={max_results}\"\n",
        "    feed = feedparser.parse(base_url)\n",
        "    ids = []\n",
        "\n",
        "    for entry in feed.entries:\n",
        "        arxiv_id = entry.id.split('/abs/')[-1]\n",
        "        ids.append(arxiv_id)\n",
        "\n",
        "    return ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "o0wdl9HciOXl"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "from time import sleep\n",
        "\n",
        "def download_arxiv_html(paper_id, output_dir=\"arxiv_html\"):\n",
        "    url = f\"https://arxiv.org/html/{paper_id}\"\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        filepath = os.path.join(output_dir, f\"{paper_id}.html\")\n",
        "        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(response.text)\n",
        "        print(f\"✅ Downloaded {paper_id}\")\n",
        "    else:\n",
        "        print(f\"❌ Failed to download {paper_id}: HTTP {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSJxJejCqWZV",
        "outputId": "4b464139-3daf-45d8-940b-b77af2f6f66f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Downloaded 2503.16421v1\n",
            "✅ Downloaded 2503.16416v1\n",
            "✅ Downloaded 2503.16412v1\n",
            "❌ Failed to download 2503.16408v1: HTTP 404\n",
            "✅ Downloaded 2503.16402v1\n",
            "✅ Downloaded 2503.16399v1\n",
            "✅ Downloaded 2503.16394v1\n",
            "✅ Downloaded 2503.16392v1\n",
            "✅ Downloaded 2503.16389v1\n",
            "✅ Downloaded 2503.16385v1\n",
            "✅ Downloaded 2503.16371v1\n",
            "✅ Downloaded 2503.16365v1\n",
            "❌ Failed to download 2503.16364v1: HTTP 404\n",
            "✅ Downloaded 2503.16356v1\n",
            "✅ Downloaded 2503.16348v1\n",
            "✅ Downloaded 2503.16342v1\n",
            "❌ Failed to download 2503.16335v1: HTTP 404\n",
            "✅ Downloaded 2503.16328v1\n",
            "✅ Downloaded 2503.16326v1\n",
            "✅ Downloaded 2503.16311v1\n",
            "❌ Failed to download 2503.16307v1: HTTP 404\n",
            "✅ Downloaded 2503.16304v1\n",
            "✅ Downloaded 2503.16302v1\n",
            "✅ Downloaded 2503.16290v1\n",
            "✅ Downloaded 2503.16248v1\n",
            "✅ Downloaded 2503.16227v1\n",
            "✅ Downloaded 2503.16212v1\n",
            "✅ Downloaded 2503.16203v1\n",
            "❌ Failed to download 2503.16191v1: HTTP 404\n",
            "✅ Downloaded 2503.16184v1\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "paper_ids = get_recent_arxiv_ids(\"cs.AI\", 30)\n",
        "\n",
        "for pid in paper_ids:\n",
        "    download_arxiv_html(pid, \"arXiv/\")\n",
        "    sleep(1)  # Be polite to the server"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
