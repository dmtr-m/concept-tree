{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy --q\n",
        "!python -m spacy download ru_core_news_lg --q\n",
        "!pip install pymorphy3 --q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP5j0yWoz9oB",
        "outputId": "38ad1e62-55bb-470b-ec77-09d9316eb2ff",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.8.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m513.4/513.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BAM2FR6dzvv0"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.tokens import Span\n",
        "from spacy import displacy\n",
        "\n",
        "from pymorphy3 import MorphAnalyzer\n",
        "\n",
        "import types\n",
        "from types import NoneType"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''Мама мыла оконную раму. Из неё выпало стекло. Оно разбилось о пол.\n",
        "На полу спал наш пёс шарик. Он услышал звук бьющегося стекла. Шарик залаял на маму.\n",
        "Мама включила телевизор. На Первом Канале выступал Григорий Лепс. Недавно Правительство РФ присвоило ему звание Народного Артиста РФ.'''"
      ],
      "metadata": {
        "id": "6HdtRNkW0TTr"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"ru_core_news_lg\")\n",
        "doc = nlp(text)\n",
        "\n",
        "morph = MorphAnalyzer()"
      ],
      "metadata": {
        "id": "AJQeTF8K5b19"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def head_in_named_entity(doc, span): # на вход подаются документ и именованная сущность, которая в нём содержится\n",
        "    span_parts = span.text.split(' ')\n",
        "    head = None\n",
        "    heads = [[], []] # [[token], [head]]\n",
        "    for span_part in span_parts:\n",
        "        for token in doc: # перебираем токены, потому что именно они, в отличие от строк, содержат всю информацию\n",
        "            if span_part == token.text:\n",
        "                heads[0].append(token)\n",
        "                heads[1].append(token.head)\n",
        "    for i in range(len(span_parts)):\n",
        "        if heads[1][i] not in heads[0]: # вершиной является то, что не зависит от других слов, входящих в именованную сущность\n",
        "            head = heads[0][i]\n",
        "    return head, [_.split('=')[1] for _ in str(head.morph).split('|')], head.head, head.dep_, heads"
      ],
      "metadata": {
        "id": "vQLSZI925ZMN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_noun_phrase(doc, np): # на вход подаётся документ и именная группа\n",
        "    head, morphology, parent, dep, np_parts = head_in_named_entity(doc, np)\n",
        "    ana = morph.parse(head.text)[0]\n",
        "    res = ''\n",
        "    for i, np_part in enumerate(np_parts[0]):\n",
        "        np_part_head = np_parts[1][i]\n",
        "        if np_part == head:\n",
        "            np_part = ana.normal_form\n",
        "        else:\n",
        "            np_part = morph.parse(np_part.text)[0]\n",
        "            pos = str(np_part.tag).split(',')[0].split(' ')[0]\n",
        "            if pos == 'ADJF' and np_part_head == head:\n",
        "                gender, number = str(ana.normalized.tag).split(',')[2].split()\n",
        "                np_part = np_part.inflect({gender, 'nomn'})[0]\n",
        "            else:\n",
        "                np_part = np_part.word\n",
        "        res += np_part + ' '\n",
        "    return res.strip()"
      ],
      "metadata": {
        "id": "CzuXR6dT-phW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_syntactic_relations(doc):\n",
        "    chunks = [] # [((индекс первого символа, индекс последнего символа), чанк в тексте, нормализованный чанк, морфологические признаки чанка, родитель чанка, тип зависимости}\n",
        "    res = [] # [(Концепция1, глагол, Концепция2)]\n",
        "    subs_and_preds = {} # {сказуемое: подлежащее}\n",
        "    for ent in doc.ents: # добавляем именованные сущности\n",
        "        chars = (ent.start_char, ent.end_char)\n",
        "        chunks.append((chars, ent, normalize_noun_phrase(doc, ent)) + head_in_named_entity(doc, ent)[1:-1])\n",
        "    for token in doc: # добавляем существительные\n",
        "        if token.pos_ == 'NOUN':\n",
        "            morph = [_.split('=')[1] for _ in str(token.morph).split('|')]\n",
        "            chars = (token.idx, token.idx + len(token.text))\n",
        "            chunks.append((chars, token, token.lemma_, morph, token.head, token.dep_))\n",
        "    chunks.sort(key=lambda x: x[0])\n",
        "    for token in doc: # решаем анафору\n",
        "        if token.pos_ == 'PRON':\n",
        "            morph = [_.split('=')[1] for _ in str(token.morph).split('|')]\n",
        "            for chunk in chunks:\n",
        "                if chunk[0][0] < token.idx and chunk[3][2:4] == morph[1:3]:\n",
        "                    chars = (token.idx, token.idx + len(token.text))\n",
        "                    pron_chunk = (chars, token, normalize_noun_phrase(doc, chunk[1]), morph, token.head, token.dep_)\n",
        "            chunks.append(pron_chunk)\n",
        "    for chunk in chunks:\n",
        "        if chunk[5] == 'nsubj':\n",
        "            subs_and_preds[chunk[4]] = chunk[2]\n",
        "    for chunk in chunks:\n",
        "        if (type(chunk[1]) == Span or chunk[1].pos_ == 'NOUN' or chunk[1].pos_ == 'PRON') and chunk[4].pos_ == 'VERB' and chunk[5] != 'nsubj':\n",
        "            res.append((subs_and_preds[chunk[4]], chunk[4].text, chunk[2], chunk[5]))\n",
        "    return res"
      ],
      "metadata": {
        "id": "Tbuo4mN2CXkc"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_syntactic_relations(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWW_EJU5Emz7",
        "outputId": "a79ce128-c83b-4f7a-a88d-375dc8291ac2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[((0, 4), Мама, 'мама', ['Anim', 'Nom', 'Fem', 'Sing'], мыла, 'nsubj'), ((18, 22), раму, 'рама', ['Inan', 'Acc', 'Fem', 'Sing'], мыла, 'obj'), ((38, 44), стекло, 'стекло', ['Inan', 'Nom', 'Neut', 'Sing'], выпало, 'nsubj'), ((62, 65), пол, 'пол', ['Inan', 'Acc', 'Masc', 'Sing'], разбилось, 'obl'), ((70, 74), полу, 'пол', ['Inan', 'Loc', 'Masc', 'Sing'], спал, 'obl'), ((88, 93), шарик, 'шарик', ['Inan', 'Nom', 'Masc', 'Sing'], спал, 'nsubj'), ((106, 110), звук, 'звук', ['Inan', 'Acc', 'Masc', 'Sing'], услышал, 'obj'), ((121, 127), стекла, 'стекло', ['Inan', 'Gen', 'Neut', 'Sing'], звук, 'nmod'), ((129, 134), Шарик, 'шарик', ['Anim', 'Nom', 'Masc', 'Sing'], залаял, 'nsubj'), ((145, 149), маму, 'мама', ['Anim', 'Acc', 'Fem', 'Sing'], залаял, 'obl'), ((151, 155), Мама, 'мама', ['Anim', 'Nom', 'Fem', 'Sing'], включила, 'nsubj'), ((165, 174), телевизор, 'телевизор', ['Inan', 'Acc', 'Masc', 'Sing'], включила, 'obj'), ((179, 192), Первом Канале, 'первый канал', ['Inan', 'Loc', 'Masc', 'Sing'], выступал, 'obl'), ((202, 215), Григорий Лепс, 'григорий лепс', ['Anim', 'Nom', 'Masc', 'Sing'], выступал, 'nsubj'), ((225, 238), Правительство, 'правительство', ['Inan', 'Nom', 'Neut', 'Sing'], присвоило, 'nsubj'), ((239, 241), РФ, 'рф рф', ['Inan', 'Gen', 'Fem', 'Sing'], Правительство, 'nmod'), ((256, 262), звание, 'звание', ['Inan', 'Acc', 'Neut', 'Sing'], присвоило, 'obj'), ((281, 283), РФ, 'рф рф', ['Inan', 'Gen', 'Fem', 'Sing'], Правительство, 'nmod'), ((27, 30), неё, 'рама', ['Gen', 'Fem', 'Sing', 'Third'], выпало, 'obl'), ((46, 49), Оно, 'стекло', ['Nom', 'Neut', 'Sing', 'Third'], разбилось, 'nsubj'), ((95, 97), Он, 'шарик', ['Nom', 'Masc', 'Sing', 'Third'], услышал, 'nsubj'), ((252, 255), ему, 'григорий лепс', ['Dat', 'Masc', 'Sing', 'Third'], присвоило, 'iobj')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('мама', 'мыла', 'рама', 'obj'),\n",
              " ('стекло', 'разбилось', 'пол', 'obl'),\n",
              " ('шарик', 'спал', 'пол', 'obl'),\n",
              " ('шарик', 'услышал', 'звук', 'obj'),\n",
              " ('шарик', 'залаял', 'мама', 'obl'),\n",
              " ('мама', 'включила', 'телевизор', 'obj'),\n",
              " ('григорий лепс', 'выступал', 'первый канал', 'obl'),\n",
              " ('правительство', 'присвоило', 'звание', 'obj'),\n",
              " ('стекло', 'выпало', 'рама', 'obl'),\n",
              " ('правительство', 'присвоило', 'григорий лепс', 'iobj')]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}